50000
train_size:  40000 val_size:  10000
Training started
Epoch 1/10000; Iter 1/80; Loss: 109.0264
Epoch 1/10000; Iter 51/80; Loss: 80.3307
Epoch 1/10000; Iter 80/80; Training Loss: 84.2360, Test Loss: 26.343
Model saved
Epoch 2/10000; Iter 1/80; Loss: 25.2183
Epoch 2/10000; Iter 51/80; Loss: 9.2176
Epoch 2/10000; Iter 80/80; Training Loss: 10.6970, Test Loss: 4.854
Epoch 3/10000; Iter 1/80; Loss: 8.8333
Epoch 3/10000; Iter 51/80; Loss: 8.1101
Epoch 3/10000; Iter 80/80; Training Loss: 8.0580, Test Loss: 3.804
Epoch 4/10000; Iter 1/80; Loss: 7.7747
Epoch 4/10000; Iter 51/80; Loss: 7.5910
Epoch 4/10000; Iter 80/80; Training Loss: 7.1860, Test Loss: 3.249
Epoch 5/10000; Iter 1/80; Loss: 6.9157
Epoch 5/10000; Iter 51/80; Loss: 5.6966
Epoch 5/10000; Iter 80/80; Training Loss: 6.4810, Test Loss: 2.982
Epoch 6/10000; Iter 1/80; Loss: 6.7099
Epoch 6/10000; Iter 51/80; Loss: 5.7085
Epoch 6/10000; Iter 80/80; Training Loss: 6.1030, Test Loss: 2.646
Epoch 7/10000; Iter 1/80; Loss: 5.9799
Epoch 7/10000; Iter 51/80; Loss: 5.6618
Epoch 7/10000; Iter 80/80; Training Loss: 5.7420, Test Loss: 2.472
Epoch 8/10000; Iter 1/80; Loss: 5.5679
Epoch 8/10000; Iter 51/80; Loss: 5.2869
Epoch 8/10000; Iter 80/80; Training Loss: 5.4550, Test Loss: 2.561
Epoch 9/10000; Iter 1/80; Loss: 5.5284
Epoch 9/10000; Iter 51/80; Loss: 5.0423
Epoch 9/10000; Iter 80/80; Training Loss: 5.2350, Test Loss: 2.354
Epoch 10/10000; Iter 1/80; Loss: 5.1153
Epoch 10/10000; Iter 51/80; Loss: 4.9610
Epoch 10/10000; Iter 80/80; Training Loss: 5.0470, Test Loss: 2.293
Epoch 11/10000; Iter 1/80; Loss: 5.0591
Epoch 11/10000; Iter 51/80; Loss: 5.5132
Epoch 11/10000; Iter 80/80; Training Loss: 4.9300, Test Loss: 2.054
Epoch 12/10000; Iter 1/80; Loss: 4.8146
Epoch 12/10000; Iter 51/80; Loss: 4.7321
Epoch 12/10000; Iter 80/80; Training Loss: 4.7730, Test Loss: 2.134
Epoch 13/10000; Iter 1/80; Loss: 5.1535
Epoch 13/10000; Iter 51/80; Loss: 4.4130
Epoch 13/10000; Iter 80/80; Training Loss: 4.6710, Test Loss: 2.139
Epoch 14/10000; Iter 1/80; Loss: 4.4544
Epoch 14/10000; Iter 51/80; Loss: 4.8593
Epoch 14/10000; Iter 80/80; Training Loss: 4.6280, Test Loss: 2.119
Epoch 15/10000; Iter 1/80; Loss: 4.3721
Epoch 15/10000; Iter 51/80; Loss: 4.5980
Epoch 15/10000; Iter 80/80; Training Loss: 4.4720, Test Loss: 2.013
Epoch 16/10000; Iter 1/80; Loss: 4.3038
Epoch 16/10000; Iter 51/80; Loss: 4.5204
Epoch 16/10000; Iter 80/80; Training Loss: 4.4030, Test Loss: 2.19
Epoch 17/10000; Iter 1/80; Loss: 4.1870
Epoch 17/10000; Iter 51/80; Loss: 4.1452
Epoch 17/10000; Iter 80/80; Training Loss: 4.2710, Test Loss: 1.965
Epoch 18/10000; Iter 1/80; Loss: 4.5751
Epoch 18/10000; Iter 51/80; Loss: 4.6611
Epoch 18/10000; Iter 80/80; Training Loss: 4.2270, Test Loss: 2.068
Epoch 19/10000; Iter 1/80; Loss: 4.7509
Epoch 19/10000; Iter 51/80; Loss: 4.5958
Epoch 19/10000; Iter 80/80; Training Loss: 4.1590, Test Loss: 2.012
Epoch 20/10000; Iter 1/80; Loss: 4.4087
Epoch 20/10000; Iter 51/80; Loss: 3.7599
Epoch 20/10000; Iter 80/80; Training Loss: 4.0670, Test Loss: 1.855
Epoch 21/10000; Iter 1/80; Loss: 3.9207
Epoch 21/10000; Iter 51/80; Loss: 3.9002
Epoch 21/10000; Iter 80/80; Training Loss: 4.0420, Test Loss: 1.942
Epoch 22/10000; Iter 1/80; Loss: 4.2615
Epoch 22/10000; Iter 51/80; Loss: 4.2671
Epoch 22/10000; Iter 80/80; Training Loss: 4.0330, Test Loss: 1.893
Epoch 23/10000; Iter 1/80; Loss: 3.5147
Epoch 23/10000; Iter 51/80; Loss: 3.8314
Epoch 23/10000; Iter 80/80; Training Loss: 3.8830, Test Loss: 1.777
Epoch 24/10000; Iter 1/80; Loss: 3.6899
Epoch 24/10000; Iter 51/80; Loss: 3.8419
Epoch 24/10000; Iter 80/80; Training Loss: 3.8910, Test Loss: 1.735
Epoch 25/10000; Iter 1/80; Loss: 4.1252
Epoch 25/10000; Iter 51/80; Loss: 3.4774
Epoch 25/10000; Iter 80/80; Training Loss: 3.8180, Test Loss: 1.933
Epoch 26/10000; Iter 1/80; Loss: 3.6171
Epoch 26/10000; Iter 51/80; Loss: 3.3554
Epoch 26/10000; Iter 80/80; Training Loss: 3.7740, Test Loss: 1.907
Epoch 27/10000; Iter 1/80; Loss: 4.0941
Epoch 27/10000; Iter 51/80; Loss: 3.7735
Epoch 27/10000; Iter 80/80; Training Loss: 3.7780, Test Loss: 1.746
Epoch 28/10000; Iter 1/80; Loss: 3.6515
Epoch 28/10000; Iter 51/80; Loss: 3.8081
Epoch 28/10000; Iter 80/80; Training Loss: 3.7170, Test Loss: 1.849
Epoch 29/10000; Iter 1/80; Loss: 3.5649
Epoch 29/10000; Iter 51/80; Loss: 3.9496
Epoch 29/10000; Iter 80/80; Training Loss: 3.6410, Test Loss: 1.625
Epoch 30/10000; Iter 1/80; Loss: 3.4348
Epoch 30/10000; Iter 51/80; Loss: 3.3255
Epoch 30/10000; Iter 80/80; Training Loss: 3.6290, Test Loss: 1.711
Epoch 31/10000; Iter 1/80; Loss: 3.9589
Epoch 31/10000; Iter 51/80; Loss: 3.4832
Epoch 31/10000; Iter 80/80; Training Loss: 3.5750, Test Loss: 1.672
Epoch 32/10000; Iter 1/80; Loss: 3.4791
Epoch 32/10000; Iter 51/80; Loss: 3.2965
Epoch 32/10000; Iter 80/80; Training Loss: 3.5120, Test Loss: 1.77
Epoch 33/10000; Iter 1/80; Loss: 3.5094
Epoch 33/10000; Iter 51/80; Loss: 3.4758
Epoch 33/10000; Iter 80/80; Training Loss: 3.4810, Test Loss: 1.674
Epoch 34/10000; Iter 1/80; Loss: 3.6997
Epoch 34/10000; Iter 51/80; Loss: 3.2740
Epoch 34/10000; Iter 80/80; Training Loss: 3.4730, Test Loss: 1.573
Epoch 35/10000; Iter 1/80; Loss: 3.4722
Epoch 35/10000; Iter 51/80; Loss: 3.5967
Epoch 35/10000; Iter 80/80; Training Loss: 3.4210, Test Loss: 1.78
Epoch 36/10000; Iter 1/80; Loss: 2.9835
Epoch 36/10000; Iter 51/80; Loss: 3.2594
Epoch 36/10000; Iter 80/80; Training Loss: 3.3850, Test Loss: 1.672
Epoch 37/10000; Iter 1/80; Loss: 2.9501
Epoch 37/10000; Iter 51/80; Loss: 3.2166
Epoch 37/10000; Iter 80/80; Training Loss: 3.3030, Test Loss: 1.659
Epoch 38/10000; Iter 1/80; Loss: 3.6390
Epoch 38/10000; Iter 51/80; Loss: 3.3643
Epoch 38/10000; Iter 80/80; Training Loss: 3.2930, Test Loss: 1.656
Epoch 39/10000; Iter 1/80; Loss: 3.0445
Epoch 39/10000; Iter 51/80; Loss: 3.3246
Epoch 39/10000; Iter 80/80; Training Loss: 3.2450, Test Loss: 1.636
Epoch 40/10000; Iter 1/80; Loss: 3.3589
Epoch 40/10000; Iter 51/80; Loss: 3.3114
Epoch 40/10000; Iter 80/80; Training Loss: 3.2120, Test Loss: 1.533
Epoch 41/10000; Iter 1/80; Loss: 3.4582
Epoch 41/10000; Iter 51/80; Loss: 2.9689
Epoch 41/10000; Iter 80/80; Training Loss: 3.1830, Test Loss: 1.704
Epoch 42/10000; Iter 1/80; Loss: 2.9734
Epoch 42/10000; Iter 51/80; Loss: 3.1288
Epoch 42/10000; Iter 80/80; Training Loss: 3.1840, Test Loss: 1.74
Epoch 43/10000; Iter 1/80; Loss: 3.3785
Epoch 43/10000; Iter 51/80; Loss: 3.2524
Epoch 43/10000; Iter 80/80; Training Loss: 3.1330, Test Loss: 1.52
Epoch 44/10000; Iter 1/80; Loss: 3.2923
Epoch 44/10000; Iter 51/80; Loss: 3.0327
Epoch 44/10000; Iter 80/80; Training Loss: 3.0870, Test Loss: 1.566
Epoch 45/10000; Iter 1/80; Loss: 2.9911
Epoch 45/10000; Iter 51/80; Loss: 3.1516
Epoch 45/10000; Iter 80/80; Training Loss: 3.0570, Test Loss: 1.405
Epoch 46/10000; Iter 1/80; Loss: 3.2452
Epoch 46/10000; Iter 51/80; Loss: 2.9901
Epoch 46/10000; Iter 80/80; Training Loss: 3.0270, Test Loss: 1.362
Epoch 47/10000; Iter 1/80; Loss: 2.8365
Epoch 47/10000; Iter 51/80; Loss: 2.9152
Epoch 47/10000; Iter 80/80; Training Loss: 2.9800, Test Loss: 1.498
Epoch 48/10000; Iter 1/80; Loss: 3.0612
Epoch 48/10000; Iter 51/80; Loss: 3.0185
Epoch 48/10000; Iter 80/80; Training Loss: 2.9790, Test Loss: 1.324
Epoch 49/10000; Iter 1/80; Loss: 3.1026
Epoch 49/10000; Iter 51/80; Loss: 2.9230
Epoch 49/10000; Iter 80/80; Training Loss: 2.9390, Test Loss: 1.284
Epoch 50/10000; Iter 1/80; Loss: 2.9338
Epoch 50/10000; Iter 51/80; Loss: 3.1832
Epoch 50/10000; Iter 80/80; Training Loss: 2.9070, Test Loss: 1.406
Epoch 51/10000; Iter 1/80; Loss: 2.8001
Epoch 51/10000; Iter 51/80; Loss: 2.9735
Epoch 51/10000; Iter 80/80; Training Loss: 2.9000, Test Loss: 1.381
Epoch 52/10000; Iter 1/80; Loss: 2.7161
Epoch 52/10000; Iter 51/80; Loss: 2.7817
Epoch 52/10000; Iter 80/80; Training Loss: 2.8710, Test Loss: 1.441
Epoch 53/10000; Iter 1/80; Loss: 3.3058
Epoch 53/10000; Iter 51/80; Loss: 2.7580
Epoch 53/10000; Iter 80/80; Training Loss: 2.8130, Test Loss: 1.328
Epoch 54/10000; Iter 1/80; Loss: 2.7886
Epoch 54/10000; Iter 51/80; Loss: 3.0174
Epoch 54/10000; Iter 80/80; Training Loss: 2.8020, Test Loss: 1.369
Epoch 55/10000; Iter 1/80; Loss: 2.4029
Epoch 55/10000; Iter 51/80; Loss: 2.4656
Epoch 55/10000; Iter 80/80; Training Loss: 2.7540, Test Loss: 1.339
Epoch 56/10000; Iter 1/80; Loss: 2.7401
Epoch 56/10000; Iter 51/80; Loss: 2.7503
Epoch 56/10000; Iter 80/80; Training Loss: 2.7150, Test Loss: 1.19
Epoch 57/10000; Iter 1/80; Loss: 2.7156
Epoch 57/10000; Iter 51/80; Loss: 2.5896
Epoch 57/10000; Iter 80/80; Training Loss: 2.6880, Test Loss: 1.36
Epoch 58/10000; Iter 1/80; Loss: 2.4919
Epoch 58/10000; Iter 51/80; Loss: 2.7021
Epoch 58/10000; Iter 80/80; Training Loss: 2.6760, Test Loss: 1.3
Epoch 59/10000; Iter 1/80; Loss: 2.7586
Epoch 59/10000; Iter 51/80; Loss: 2.7251
Epoch 59/10000; Iter 80/80; Training Loss: 2.6460, Test Loss: 1.328
Epoch 60/10000; Iter 1/80; Loss: 2.6283
Epoch 60/10000; Iter 51/80; Loss: 2.4226
Epoch 60/10000; Iter 80/80; Training Loss: 2.6230, Test Loss: 1.217
Epoch 61/10000; Iter 1/80; Loss: 2.6006
Epoch 61/10000; Iter 51/80; Loss: 2.7177
Epoch 61/10000; Iter 80/80; Training Loss: 2.5960, Test Loss: 1.096
Epoch 62/10000; Iter 1/80; Loss: 2.4486
Epoch 62/10000; Iter 51/80; Loss: 2.7171
Epoch 62/10000; Iter 80/80; Training Loss: 2.5610, Test Loss: 1.116
Epoch 63/10000; Iter 1/80; Loss: 2.4811
Epoch 63/10000; Iter 51/80; Loss: 2.7054
Epoch 63/10000; Iter 80/80; Training Loss: 2.5170, Test Loss: 0.968
Epoch 64/10000; Iter 1/80; Loss: 2.4713
Epoch 64/10000; Iter 51/80; Loss: 2.1022
Epoch 64/10000; Iter 80/80; Training Loss: 2.4800, Test Loss: 1.089
Epoch 65/10000; Iter 1/80; Loss: 2.6001
Epoch 65/10000; Iter 51/80; Loss: 2.8930
Epoch 65/10000; Iter 80/80; Training Loss: 2.4660, Test Loss: 1.037
Epoch 66/10000; Iter 1/80; Loss: 2.6935
Epoch 66/10000; Iter 51/80; Loss: 2.5517
Epoch 66/10000; Iter 80/80; Training Loss: 2.4560, Test Loss: 1.089
Epoch 67/10000; Iter 1/80; Loss: 2.6037
Epoch 67/10000; Iter 51/80; Loss: 2.6171
Epoch 67/10000; Iter 80/80; Training Loss: 2.4600, Test Loss: 1.013
Epoch 68/10000; Iter 1/80; Loss: 2.4416
Epoch 68/10000; Iter 51/80; Loss: 2.4763
Epoch 68/10000; Iter 80/80; Training Loss: 2.4010, Test Loss: 1.037
Epoch 69/10000; Iter 1/80; Loss: 2.2755
Epoch 69/10000; Iter 51/80; Loss: 2.2414
Epoch 69/10000; Iter 80/80; Training Loss: 2.3720, Test Loss: 0.943
Epoch 70/10000; Iter 1/80; Loss: 2.5521
Epoch 70/10000; Iter 51/80; Loss: 2.2803
Epoch 70/10000; Iter 80/80; Training Loss: 2.3290, Test Loss: 0.99
Epoch 71/10000; Iter 1/80; Loss: 2.4228
Epoch 71/10000; Iter 51/80; Loss: 2.3713
Epoch 71/10000; Iter 80/80; Training Loss: 2.3200, Test Loss: 0.918
Epoch 72/10000; Iter 1/80; Loss: 2.4289
Epoch 72/10000; Iter 51/80; Loss: 2.1224
Epoch 72/10000; Iter 80/80; Training Loss: 2.2910, Test Loss: 0.935
Epoch 73/10000; Iter 1/80; Loss: 2.5540
Epoch 73/10000; Iter 51/80; Loss: 2.3455
Epoch 73/10000; Iter 80/80; Training Loss: 2.2760, Test Loss: 0.966
Epoch 74/10000; Iter 1/80; Loss: 2.0733
Epoch 74/10000; Iter 51/80; Loss: 1.9305
Epoch 74/10000; Iter 80/80; Training Loss: 2.2580, Test Loss: 0.899
Epoch 75/10000; Iter 1/80; Loss: 2.3856
Epoch 75/10000; Iter 51/80; Loss: 2.4162
Epoch 75/10000; Iter 80/80; Training Loss: 2.2390, Test Loss: 0.816
Epoch 76/10000; Iter 1/80; Loss: 2.1682
Epoch 76/10000; Iter 51/80; Loss: 2.3354
Epoch 76/10000; Iter 80/80; Training Loss: 2.2420, Test Loss: 0.835
Epoch 77/10000; Iter 1/80; Loss: 2.1419
Epoch 77/10000; Iter 51/80; Loss: 1.9154
Epoch 77/10000; Iter 80/80; Training Loss: 2.2080, Test Loss: 0.885
Epoch 78/10000; Iter 1/80; Loss: 2.1975
Epoch 78/10000; Iter 51/80; Loss: 2.2968
Epoch 78/10000; Iter 80/80; Training Loss: 2.2030, Test Loss: 0.781
Epoch 79/10000; Iter 1/80; Loss: 2.2909
Epoch 79/10000; Iter 51/80; Loss: 1.9106
Epoch 79/10000; Iter 80/80; Training Loss: 2.1610, Test Loss: 0.772
Epoch 80/10000; Iter 1/80; Loss: 2.2501
Epoch 80/10000; Iter 51/80; Loss: 2.1702
Epoch 80/10000; Iter 80/80; Training Loss: 2.1370, Test Loss: 0.866
Epoch 81/10000; Iter 1/80; Loss: 2.1052
Epoch 81/10000; Iter 51/80; Loss: 1.7708
Epoch 81/10000; Iter 80/80; Training Loss: 2.1160, Test Loss: 0.864
Epoch 82/10000; Iter 1/80; Loss: 2.0448
Epoch 82/10000; Iter 51/80; Loss: 2.0283
Epoch 82/10000; Iter 80/80; Training Loss: 2.1320, Test Loss: 0.817
Epoch 83/10000; Iter 1/80; Loss: 2.2903
Epoch 83/10000; Iter 51/80; Loss: 2.1152
Epoch 83/10000; Iter 80/80; Training Loss: 2.1030, Test Loss: 0.832
Epoch 84/10000; Iter 1/80; Loss: 1.9302
Epoch 84/10000; Iter 51/80; Loss: 2.0382
Epoch 84/10000; Iter 80/80; Training Loss: 2.0820, Test Loss: 0.786
Epoch 85/10000; Iter 1/80; Loss: 2.0399
Epoch 85/10000; Iter 51/80; Loss: 1.7695
Epoch 85/10000; Iter 80/80; Training Loss: 2.0570, Test Loss: 0.798
Epoch 86/10000; Iter 1/80; Loss: 1.8776
Epoch 86/10000; Iter 51/80; Loss: 1.6720
Epoch 86/10000; Iter 80/80; Training Loss: 2.0770, Test Loss: 0.8
Epoch 87/10000; Iter 1/80; Loss: 2.0293
Epoch 87/10000; Iter 51/80; Loss: 1.8903
Epoch 87/10000; Iter 80/80; Training Loss: 2.0380, Test Loss: 0.858
Epoch 88/10000; Iter 1/80; Loss: 1.9556
Epoch 88/10000; Iter 51/80; Loss: 1.9351
Epoch 88/10000; Iter 80/80; Training Loss: 2.0560, Test Loss: 0.846
Epoch 89/10000; Iter 1/80; Loss: 1.8830
Epoch 89/10000; Iter 51/80; Loss: 1.9774
Epoch 89/10000; Iter 80/80; Training Loss: 2.0050, Test Loss: 0.708
Epoch 90/10000; Iter 1/80; Loss: 2.2428
Epoch 90/10000; Iter 51/80; Loss: 1.6829
Epoch 90/10000; Iter 80/80; Training Loss: 2.0010, Test Loss: 0.63
Epoch 91/10000; Iter 1/80; Loss: 2.0810
Epoch 91/10000; Iter 51/80; Loss: 1.7486
Epoch 91/10000; Iter 80/80; Training Loss: 2.0050, Test Loss: 0.755
Epoch 92/10000; Iter 1/80; Loss: 1.8210
Epoch 92/10000; Iter 51/80; Loss: 1.8431
Epoch 92/10000; Iter 80/80; Training Loss: 1.9540, Test Loss: 0.618
Epoch 93/10000; Iter 1/80; Loss: 2.2400
Epoch 93/10000; Iter 51/80; Loss: 1.9897
Epoch 93/10000; Iter 80/80; Training Loss: 1.9710, Test Loss: 0.741
Epoch 94/10000; Iter 1/80; Loss: 1.7054
Epoch 94/10000; Iter 51/80; Loss: 1.9586
Epoch 94/10000; Iter 80/80; Training Loss: 1.9240, Test Loss: 0.726
Epoch 95/10000; Iter 1/80; Loss: 2.1949
Epoch 95/10000; Iter 51/80; Loss: 1.8648
Epoch 95/10000; Iter 80/80; Training Loss: 1.9260, Test Loss: 0.661
Epoch 96/10000; Iter 1/80; Loss: 2.2274
Epoch 96/10000; Iter 51/80; Loss: 2.0492
Epoch 96/10000; Iter 80/80; Training Loss: 1.9190, Test Loss: 0.612
Epoch 97/10000; Iter 1/80; Loss: 1.9025
Epoch 97/10000; Iter 51/80; Loss: 2.0037
Epoch 97/10000; Iter 80/80; Training Loss: 1.8970, Test Loss: 0.612
Epoch 98/10000; Iter 1/80; Loss: 1.9555
Epoch 98/10000; Iter 51/80; Loss: 1.9024
Epoch 98/10000; Iter 80/80; Training Loss: 1.9090, Test Loss: 0.688
Epoch 99/10000; Iter 1/80; Loss: 2.1096
Epoch 99/10000; Iter 51/80; Loss: 1.8174
Epoch 99/10000; Iter 80/80; Training Loss: 1.9110, Test Loss: 0.608
Epoch 100/10000; Iter 1/80; Loss: 1.9589
Epoch 100/10000; Iter 51/80; Loss: 1.8456
Epoch 100/10000; Iter 80/80; Training Loss: 1.8510, Test Loss: 0.526
Epoch 101/10000; Iter 1/80; Loss: 1.9632
Epoch 101/10000; Iter 51/80; Loss: 1.9654
Epoch 101/10000; Iter 80/80; Training Loss: 1.8550, Test Loss: 0.633
Model saved
Epoch 102/10000; Iter 1/80; Loss: 1.9094
Epoch 102/10000; Iter 51/80; Loss: 1.8030
Epoch 102/10000; Iter 80/80; Training Loss: 1.8650, Test Loss: 0.683
Epoch 103/10000; Iter 1/80; Loss: 1.7410
Epoch 103/10000; Iter 51/80; Loss: 2.0259
Epoch 103/10000; Iter 80/80; Training Loss: 1.8400, Test Loss: 0.619
Epoch 104/10000; Iter 1/80; Loss: 1.8393
Epoch 104/10000; Iter 51/80; Loss: 1.8232
Epoch 104/10000; Iter 80/80; Training Loss: 1.8520, Test Loss: 0.56
Epoch 105/10000; Iter 1/80; Loss: 1.6779
Epoch 105/10000; Iter 51/80; Loss: 1.8604
Epoch 105/10000; Iter 80/80; Training Loss: 1.8240, Test Loss: 0.601
Epoch 106/10000; Iter 1/80; Loss: 1.9625
Epoch 106/10000; Iter 51/80; Loss: 1.6665
Epoch 106/10000; Iter 80/80; Training Loss: 1.8080, Test Loss: 0.559
Epoch 107/10000; Iter 1/80; Loss: 1.7198
Epoch 107/10000; Iter 51/80; Loss: 1.8852
Epoch 107/10000; Iter 80/80; Training Loss: 1.8070, Test Loss: 0.503
Epoch 108/10000; Iter 1/80; Loss: 1.5004
Epoch 108/10000; Iter 51/80; Loss: 2.0186
Epoch 108/10000; Iter 80/80; Training Loss: 1.8220, Test Loss: 0.612
Epoch 109/10000; Iter 1/80; Loss: 1.5905
Epoch 109/10000; Iter 51/80; Loss: 1.8146
Epoch 109/10000; Iter 80/80; Training Loss: 1.8040, Test Loss: 0.6
Epoch 110/10000; Iter 1/80; Loss: 1.9182
Epoch 110/10000; Iter 51/80; Loss: 1.7057
Epoch 110/10000; Iter 80/80; Training Loss: 1.7910, Test Loss: 0.617
Epoch 111/10000; Iter 1/80; Loss: 1.6516
Epoch 111/10000; Iter 51/80; Loss: 1.7932
Epoch 111/10000; Iter 80/80; Training Loss: 1.7900, Test Loss: 0.542
Epoch 112/10000; Iter 1/80; Loss: 1.7877
Epoch 112/10000; Iter 51/80; Loss: 2.0743
Epoch 112/10000; Iter 80/80; Training Loss: 1.7790, Test Loss: 0.534
Epoch 113/10000; Iter 1/80; Loss: 1.8070
Epoch 113/10000; Iter 51/80; Loss: 1.8483
Epoch 113/10000; Iter 80/80; Training Loss: 1.7700, Test Loss: 0.554
Epoch 114/10000; Iter 1/80; Loss: 1.6578
Epoch 114/10000; Iter 51/80; Loss: 1.8418
Epoch 114/10000; Iter 80/80; Training Loss: 1.7710, Test Loss: 0.52
Epoch 115/10000; Iter 1/80; Loss: 1.7869
Epoch 115/10000; Iter 51/80; Loss: 1.5903
Epoch 115/10000; Iter 80/80; Training Loss: 1.7820, Test Loss: 0.546
Epoch 116/10000; Iter 1/80; Loss: 1.6326
Epoch 116/10000; Iter 51/80; Loss: 1.6595
Epoch 116/10000; Iter 80/80; Training Loss: 1.7460, Test Loss: 0.595
Epoch 117/10000; Iter 1/80; Loss: 1.5964
Epoch 117/10000; Iter 51/80; Loss: 1.7418
Epoch 117/10000; Iter 80/80; Training Loss: 1.7520, Test Loss: 0.463
Epoch 118/10000; Iter 1/80; Loss: 1.6373
Epoch 118/10000; Iter 51/80; Loss: 1.8883
Epoch 118/10000; Iter 80/80; Training Loss: 1.7560, Test Loss: 0.536
Epoch 119/10000; Iter 1/80; Loss: 1.8519
Epoch 119/10000; Iter 51/80; Loss: 1.6562
Epoch 119/10000; Iter 80/80; Training Loss: 1.6980, Test Loss: 0.493
Epoch 120/10000; Iter 1/80; Loss: 1.6415
Epoch 120/10000; Iter 51/80; Loss: 1.5882
Epoch 120/10000; Iter 80/80; Training Loss: 1.7330, Test Loss: 0.463
Epoch 121/10000; Iter 1/80; Loss: 1.7580
Epoch 121/10000; Iter 51/80; Loss: 1.6433
Epoch 121/10000; Iter 80/80; Training Loss: 1.7050, Test Loss: 0.459
Epoch 122/10000; Iter 1/80; Loss: 1.8091
Epoch 122/10000; Iter 51/80; Loss: 1.9216
Epoch 122/10000; Iter 80/80; Training Loss: 1.6880, Test Loss: 0.499
Epoch 123/10000; Iter 1/80; Loss: 1.7264
Epoch 123/10000; Iter 51/80; Loss: 1.6194
Epoch 123/10000; Iter 80/80; Training Loss: 1.7000, Test Loss: 0.463
Epoch 124/10000; Iter 1/80; Loss: 1.7613
Epoch 124/10000; Iter 51/80; Loss: 1.6309
Epoch 124/10000; Iter 80/80; Training Loss: 1.6610, Test Loss: 0.506
Epoch 125/10000; Iter 1/80; Loss: 1.8097
Epoch 125/10000; Iter 51/80; Loss: 1.7366
Epoch 125/10000; Iter 80/80; Training Loss: 1.6760, Test Loss: 0.426
Epoch 126/10000; Iter 1/80; Loss: 1.9626
Epoch 126/10000; Iter 51/80; Loss: 1.6068
Epoch 126/10000; Iter 80/80; Training Loss: 1.6590, Test Loss: 0.453
Epoch 127/10000; Iter 1/80; Loss: 1.5405
Epoch 127/10000; Iter 51/80; Loss: 1.5814
Epoch 127/10000; Iter 80/80; Training Loss: 1.6750, Test Loss: 0.427
Epoch 128/10000; Iter 1/80; Loss: 1.6764
Epoch 128/10000; Iter 51/80; Loss: 1.5691
Epoch 128/10000; Iter 80/80; Training Loss: 1.6870, Test Loss: 0.532
Epoch 129/10000; Iter 1/80; Loss: 1.6603
Epoch 129/10000; Iter 51/80; Loss: 1.7449
Epoch 129/10000; Iter 80/80; Training Loss: 1.6480, Test Loss: 0.469
Epoch 130/10000; Iter 1/80; Loss: 1.7196
Epoch 130/10000; Iter 51/80; Loss: 1.4256
Epoch 130/10000; Iter 80/80; Training Loss: 1.6330, Test Loss: 0.49
Epoch 131/10000; Iter 1/80; Loss: 1.6545
Epoch 131/10000; Iter 51/80; Loss: 1.6114
Epoch 131/10000; Iter 80/80; Training Loss: 1.6300, Test Loss: 0.48
Epoch 132/10000; Iter 1/80; Loss: 1.9202
Epoch 132/10000; Iter 51/80; Loss: 1.6181
Epoch 132/10000; Iter 80/80; Training Loss: 1.6210, Test Loss: 0.432
Epoch 133/10000; Iter 1/80; Loss: 1.6389
Epoch 133/10000; Iter 51/80; Loss: 1.6365
Epoch 133/10000; Iter 80/80; Training Loss: 1.6310, Test Loss: 0.461
Epoch 134/10000; Iter 1/80; Loss: 1.4688
Epoch 134/10000; Iter 51/80; Loss: 1.5751
Epoch 134/10000; Iter 80/80; Training Loss: 1.6290, Test Loss: 0.447
Epoch 135/10000; Iter 1/80; Loss: 1.5801
Epoch 135/10000; Iter 51/80; Loss: 1.6044
Epoch 135/10000; Iter 80/80; Training Loss: 1.6200, Test Loss: 0.427
Epoch 136/10000; Iter 1/80; Loss: 1.6105
Epoch 136/10000; Iter 51/80; Loss: 1.6077
Epoch 136/10000; Iter 80/80; Training Loss: 1.6070, Test Loss: 0.428
Epoch 137/10000; Iter 1/80; Loss: 1.8878
Epoch 137/10000; Iter 51/80; Loss: 1.5962
Epoch 137/10000; Iter 80/80; Training Loss: 1.6030, Test Loss: 0.43
Epoch 138/10000; Iter 1/80; Loss: 1.7152
Epoch 138/10000; Iter 51/80; Loss: 1.3904
Epoch 138/10000; Iter 80/80; Training Loss: 1.5840, Test Loss: 0.418
Epoch 139/10000; Iter 1/80; Loss: 1.7730
Epoch 139/10000; Iter 51/80; Loss: 1.5362
Epoch 139/10000; Iter 80/80; Training Loss: 1.5990, Test Loss: 0.453
Epoch 140/10000; Iter 1/80; Loss: 1.5428
Epoch 140/10000; Iter 51/80; Loss: 1.6496
Epoch 140/10000; Iter 80/80; Training Loss: 1.5830, Test Loss: 0.447
Epoch 141/10000; Iter 1/80; Loss: 1.4158
Epoch 141/10000; Iter 51/80; Loss: 1.5338
Epoch 141/10000; Iter 80/80; Training Loss: 1.5800, Test Loss: 0.426
Epoch 142/10000; Iter 1/80; Loss: 1.5634
Epoch 142/10000; Iter 51/80; Loss: 1.5630
Epoch 142/10000; Iter 80/80; Training Loss: 1.5930, Test Loss: 0.409
Epoch 143/10000; Iter 1/80; Loss: 1.5694
Epoch 143/10000; Iter 51/80; Loss: 1.5127
Epoch 143/10000; Iter 80/80; Training Loss: 1.5750, Test Loss: 0.413
Epoch 144/10000; Iter 1/80; Loss: 1.5154
Epoch 144/10000; Iter 51/80; Loss: 1.8035
Epoch 144/10000; Iter 80/80; Training Loss: 1.5650, Test Loss: 0.371
Epoch 145/10000; Iter 1/80; Loss: 1.7322
Epoch 145/10000; Iter 51/80; Loss: 1.9938
Epoch 145/10000; Iter 80/80; Training Loss: 1.5740, Test Loss: 0.393
Epoch 146/10000; Iter 1/80; Loss: 1.6055
Epoch 146/10000; Iter 51/80; Loss: 1.5071
Epoch 146/10000; Iter 80/80; Training Loss: 1.5660, Test Loss: 0.454
Epoch 147/10000; Iter 1/80; Loss: 1.5390
Epoch 147/10000; Iter 51/80; Loss: 1.7548
Epoch 147/10000; Iter 80/80; Training Loss: 1.5560, Test Loss: 0.444
Epoch 148/10000; Iter 1/80; Loss: 1.8719
Epoch 148/10000; Iter 51/80; Loss: 1.4802
Epoch 148/10000; Iter 80/80; Training Loss: 1.5590, Test Loss: 0.387
Epoch 149/10000; Iter 1/80; Loss: 1.6496
Epoch 149/10000; Iter 51/80; Loss: 1.4653
Epoch 149/10000; Iter 80/80; Training Loss: 1.5450, Test Loss: 0.395
Epoch 150/10000; Iter 1/80; Loss: 1.4908
Epoch 150/10000; Iter 51/80; Loss: 1.6556
Epoch 150/10000; Iter 80/80; Training Loss: 1.5510, Test Loss: 0.4
Epoch 151/10000; Iter 1/80; Loss: 1.5658
Epoch 151/10000; Iter 51/80; Loss: 1.3774
Epoch 151/10000; Iter 80/80; Training Loss: 1.5270, Test Loss: 0.371
Epoch 152/10000; Iter 1/80; Loss: 1.5488
Epoch 152/10000; Iter 51/80; Loss: 1.6397
Epoch 152/10000; Iter 80/80; Training Loss: 1.5340, Test Loss: 0.401
Epoch 153/10000; Iter 1/80; Loss: 1.3876
Epoch 153/10000; Iter 51/80; Loss: 1.6404
Epoch 153/10000; Iter 80/80; Training Loss: 1.5270, Test Loss: 0.358
Epoch 154/10000; Iter 1/80; Loss: 1.5914
Epoch 154/10000; Iter 51/80; Loss: 1.7542
Epoch 154/10000; Iter 80/80; Training Loss: 1.5290, Test Loss: 0.413
Epoch 155/10000; Iter 1/80; Loss: 1.5191
Epoch 155/10000; Iter 51/80; Loss: 1.5785
Epoch 155/10000; Iter 80/80; Training Loss: 1.5320, Test Loss: 0.373
Epoch 156/10000; Iter 1/80; Loss: 1.6084
Epoch 156/10000; Iter 51/80; Loss: 1.5868
Epoch 156/10000; Iter 80/80; Training Loss: 1.5280, Test Loss: 0.413
Epoch 157/10000; Iter 1/80; Loss: 1.4613
Epoch 157/10000; Iter 51/80; Loss: 1.4457
Epoch 157/10000; Iter 80/80; Training Loss: 1.5170, Test Loss: 0.36
Epoch 158/10000; Iter 1/80; Loss: 1.4572
Epoch 158/10000; Iter 51/80; Loss: 1.4797
Epoch 158/10000; Iter 80/80; Training Loss: 1.5100, Test Loss: 0.351
Epoch 159/10000; Iter 1/80; Loss: 1.4186
Epoch 159/10000; Iter 51/80; Loss: 1.4062
Epoch 159/10000; Iter 80/80; Training Loss: 1.5040, Test Loss: 0.398
Epoch 160/10000; Iter 1/80; Loss: 1.4248
Epoch 160/10000; Iter 51/80; Loss: 1.4660
Epoch 160/10000; Iter 80/80; Training Loss: 1.5070, Test Loss: 0.367
Epoch 161/10000; Iter 1/80; Loss: 1.3930
Epoch 161/10000; Iter 51/80; Loss: 1.5912
Epoch 161/10000; Iter 80/80; Training Loss: 1.4720, Test Loss: 0.383
Epoch 162/10000; Iter 1/80; Loss: 1.4798
Epoch 162/10000; Iter 51/80; Loss: 1.5453
Epoch 162/10000; Iter 80/80; Training Loss: 1.5070, Test Loss: 0.362
Epoch 163/10000; Iter 1/80; Loss: 1.5902
Epoch 163/10000; Iter 51/80; Loss: 1.4767
Epoch 163/10000; Iter 80/80; Training Loss: 1.4850, Test Loss: 0.363
Epoch 164/10000; Iter 1/80; Loss: 1.4273
Epoch 164/10000; Iter 51/80; Loss: 1.4535
Epoch 164/10000; Iter 80/80; Training Loss: 1.4770, Test Loss: 0.415
Epoch 165/10000; Iter 1/80; Loss: 1.4374
Epoch 165/10000; Iter 51/80; Loss: 1.4970
Epoch 165/10000; Iter 80/80; Training Loss: 1.4720, Test Loss: 0.391
Epoch 166/10000; Iter 1/80; Loss: 1.5469
Epoch 166/10000; Iter 51/80; Loss: 1.3317
Epoch 166/10000; Iter 80/80; Training Loss: 1.5100, Test Loss: 0.359
Epoch 167/10000; Iter 1/80; Loss: 1.4577
Epoch 167/10000; Iter 51/80; Loss: 1.6855
Epoch 167/10000; Iter 80/80; Training Loss: 1.4680, Test Loss: 0.311
Epoch 168/10000; Iter 1/80; Loss: 1.3288
Epoch 168/10000; Iter 51/80; Loss: 1.5005
Epoch 168/10000; Iter 80/80; Training Loss: 1.4830, Test Loss: 0.3
Epoch 169/10000; Iter 1/80; Loss: 1.5068
Epoch 169/10000; Iter 51/80; Loss: 1.6392
Epoch 169/10000; Iter 80/80; Training Loss: 1.4610, Test Loss: 0.347
Epoch 170/10000; Iter 1/80; Loss: 1.4187
Epoch 170/10000; Iter 51/80; Loss: 1.3979
Epoch 170/10000; Iter 80/80; Training Loss: 1.4620, Test Loss: 0.341
Epoch 171/10000; Iter 1/80; Loss: 1.3666
Epoch 171/10000; Iter 51/80; Loss: 1.4204
Epoch 171/10000; Iter 80/80; Training Loss: 1.4500, Test Loss: 0.34
Epoch 172/10000; Iter 1/80; Loss: 1.3489
Epoch 172/10000; Iter 51/80; Loss: 1.3797
Epoch 172/10000; Iter 80/80; Training Loss: 1.4660, Test Loss: 0.353
Epoch 173/10000; Iter 1/80; Loss: 1.3748
Epoch 173/10000; Iter 51/80; Loss: 1.5335
Epoch 173/10000; Iter 80/80; Training Loss: 1.4680, Test Loss: 0.392
Epoch 174/10000; Iter 1/80; Loss: 1.4577
Epoch 174/10000; Iter 51/80; Loss: 1.6295
Epoch 174/10000; Iter 80/80; Training Loss: 1.4480, Test Loss: 0.391
Epoch 175/10000; Iter 1/80; Loss: 1.4861
Epoch 175/10000; Iter 51/80; Loss: 1.6347
Epoch 175/10000; Iter 80/80; Training Loss: 1.4510, Test Loss: 0.324
Epoch 176/10000; Iter 1/80; Loss: 1.4001
Epoch 176/10000; Iter 51/80; Loss: 1.5002
Epoch 176/10000; Iter 80/80; Training Loss: 1.4400, Test Loss: 0.388
Epoch 177/10000; Iter 1/80; Loss: 1.4282
Epoch 177/10000; Iter 51/80; Loss: 1.4109
Epoch 177/10000; Iter 80/80; Training Loss: 1.4290, Test Loss: 0.406
Epoch 178/10000; Iter 1/80; Loss: 1.3482
Epoch 178/10000; Iter 51/80; Loss: 1.4732
Epoch 178/10000; Iter 80/80; Training Loss: 1.4410, Test Loss: 0.309
Epoch 179/10000; Iter 1/80; Loss: 1.3916
Epoch 179/10000; Iter 51/80; Loss: 1.4538
Epoch 179/10000; Iter 80/80; Training Loss: 1.4100, Test Loss: 0.332
Epoch 180/10000; Iter 1/80; Loss: 1.4955
Epoch 180/10000; Iter 51/80; Loss: 1.4437
Epoch 180/10000; Iter 80/80; Training Loss: 1.4270, Test Loss: 0.359
Epoch 181/10000; Iter 1/80; Loss: 1.3046
Epoch 181/10000; Iter 51/80; Loss: 1.5060
Epoch 181/10000; Iter 80/80; Training Loss: 1.4330, Test Loss: 0.327
Epoch 182/10000; Iter 1/80; Loss: 1.3338
Epoch 182/10000; Iter 51/80; Loss: 1.3884
Epoch 182/10000; Iter 80/80; Training Loss: 1.4400, Test Loss: 0.31
Epoch 183/10000; Iter 1/80; Loss: 1.5491
Epoch 183/10000; Iter 51/80; Loss: 1.2874
Epoch 183/10000; Iter 80/80; Training Loss: 1.4310, Test Loss: 0.334
Epoch 184/10000; Iter 1/80; Loss: 1.5302
Epoch 184/10000; Iter 51/80; Loss: 1.2446
Epoch 184/10000; Iter 80/80; Training Loss: 1.4110, Test Loss: 0.316
Epoch 185/10000; Iter 1/80; Loss: 1.2758
Epoch 185/10000; Iter 51/80; Loss: 1.2760
Epoch 185/10000; Iter 80/80; Training Loss: 1.3940, Test Loss: 0.35
Epoch 186/10000; Iter 1/80; Loss: 1.4857
Epoch 186/10000; Iter 51/80; Loss: 1.2979
Epoch 186/10000; Iter 80/80; Training Loss: 1.3950, Test Loss: 0.352
Epoch 187/10000; Iter 1/80; Loss: 1.4036
Epoch 187/10000; Iter 51/80; Loss: 1.2551
Epoch 187/10000; Iter 80/80; Training Loss: 1.4080, Test Loss: 0.33
Epoch 188/10000; Iter 1/80; Loss: 1.3048
Epoch 188/10000; Iter 51/80; Loss: 1.3261
Epoch 188/10000; Iter 80/80; Training Loss: 1.3990, Test Loss: 0.389
Epoch 189/10000; Iter 1/80; Loss: 1.4177
Epoch 189/10000; Iter 51/80; Loss: 1.3791
Epoch 189/10000; Iter 80/80; Training Loss: 1.4110, Test Loss: 0.333
Epoch 190/10000; Iter 1/80; Loss: 1.5370
Epoch 190/10000; Iter 51/80; Loss: 1.4313
Epoch 190/10000; Iter 80/80; Training Loss: 1.3970, Test Loss: 0.346
Epoch 191/10000; Iter 1/80; Loss: 1.4594
Epoch 191/10000; Iter 51/80; Loss: 1.2476
Epoch 191/10000; Iter 80/80; Training Loss: 1.4120, Test Loss: 0.341
Epoch 192/10000; Iter 1/80; Loss: 1.3330
Epoch 192/10000; Iter 51/80; Loss: 1.4245
Epoch 192/10000; Iter 80/80; Training Loss: 1.4090, Test Loss: 0.372
Epoch 193/10000; Iter 1/80; Loss: 1.3044
Epoch 193/10000; Iter 51/80; Loss: 1.3923
Epoch 193/10000; Iter 80/80; Training Loss: 1.3890, Test Loss: 0.374
Epoch 194/10000; Iter 1/80; Loss: 1.2311
Epoch 194/10000; Iter 51/80; Loss: 1.2467
Epoch 194/10000; Iter 80/80; Training Loss: 1.4100, Test Loss: 0.373
Epoch 195/10000; Iter 1/80; Loss: 1.3985
Epoch 195/10000; Iter 51/80; Loss: 1.5701
Epoch 195/10000; Iter 80/80; Training Loss: 1.4050, Test Loss: 0.323
Epoch 196/10000; Iter 1/80; Loss: 1.4060
Epoch 196/10000; Iter 51/80; Loss: 1.2635
Epoch 196/10000; Iter 80/80; Training Loss: 1.3800, Test Loss: 0.325
Epoch 197/10000; Iter 1/80; Loss: 1.2779
Epoch 197/10000; Iter 51/80; Loss: 1.2995
Epoch 197/10000; Iter 80/80; Training Loss: 1.3970, Test Loss: 0.296
Epoch 198/10000; Iter 1/80; Loss: 1.3710
Epoch 198/10000; Iter 51/80; Loss: 1.5312
Epoch 198/10000; Iter 80/80; Training Loss: 1.3860, Test Loss: 0.281
Epoch 199/10000; Iter 1/80; Loss: 1.5509
Epoch 199/10000; Iter 51/80; Loss: 1.4972
Epoch 199/10000; Iter 80/80; Training Loss: 1.3760, Test Loss: 0.309
Epoch 200/10000; Iter 1/80; Loss: 1.4154
Epoch 200/10000; Iter 51/80; Loss: 1.2972
Epoch 200/10000; Iter 80/80; Training Loss: 1.3680, Test Loss: 0.353
Epoch 201/10000; Iter 1/80; Loss: 1.3425
Epoch 201/10000; Iter 51/80; Loss: 1.3857
Epoch 201/10000; Iter 80/80; Training Loss: 1.3750, Test Loss: 0.331
Model saved
Epoch 202/10000; Iter 1/80; Loss: 1.2720
Epoch 202/10000; Iter 51/80; Loss: 1.3425
Epoch 202/10000; Iter 80/80; Training Loss: 1.3730, Test Loss: 0.361
Epoch 203/10000; Iter 1/80; Loss: 1.3234
Epoch 203/10000; Iter 51/80; Loss: 1.5198
Epoch 203/10000; Iter 80/80; Training Loss: 1.3630, Test Loss: 0.324
Epoch 204/10000; Iter 1/80; Loss: 1.4758
Epoch 204/10000; Iter 51/80; Loss: 1.2847
Epoch 204/10000; Iter 80/80; Training Loss: 1.3780, Test Loss: 0.294
Epoch 205/10000; Iter 1/80; Loss: 1.4107
Epoch 205/10000; Iter 51/80; Loss: 1.4155
Epoch 205/10000; Iter 80/80; Training Loss: 1.3580, Test Loss: 0.303
Epoch 206/10000; Iter 1/80; Loss: 1.3768
Epoch 206/10000; Iter 51/80; Loss: 1.2991
Epoch 206/10000; Iter 80/80; Training Loss: 1.3640, Test Loss: 0.371
Epoch 207/10000; Iter 1/80; Loss: 1.6059
Epoch 207/10000; Iter 51/80; Loss: 1.3352
Epoch 207/10000; Iter 80/80; Training Loss: 1.3680, Test Loss: 0.343
Epoch 208/10000; Iter 1/80; Loss: 1.2838
Epoch 208/10000; Iter 51/80; Loss: 1.2863
Epoch 208/10000; Iter 80/80; Training Loss: 1.3280, Test Loss: 0.37
Epoch 209/10000; Iter 1/80; Loss: 1.4268
Epoch 209/10000; Iter 51/80; Loss: 1.3655
Epoch 209/10000; Iter 80/80; Training Loss: 1.3590, Test Loss: 0.291
Epoch 210/10000; Iter 1/80; Loss: 1.4645
Epoch 210/10000; Iter 51/80; Loss: 1.1957
Epoch 210/10000; Iter 80/80; Training Loss: 1.3350, Test Loss: 0.317
Epoch 211/10000; Iter 1/80; Loss: 1.5121
Epoch 211/10000; Iter 51/80; Loss: 1.3887
Epoch 211/10000; Iter 80/80; Training Loss: 1.3550, Test Loss: 0.328
Epoch 212/10000; Iter 1/80; Loss: 1.3512
Epoch 212/10000; Iter 51/80; Loss: 1.3658
Epoch 212/10000; Iter 80/80; Training Loss: 1.3450, Test Loss: 0.342
Epoch 213/10000; Iter 1/80; Loss: 1.3340
Epoch 213/10000; Iter 51/80; Loss: 1.4238
Epoch 213/10000; Iter 80/80; Training Loss: 1.3560, Test Loss: 0.339
Epoch 214/10000; Iter 1/80; Loss: 1.2860
Epoch 214/10000; Iter 51/80; Loss: 1.4038
Epoch 214/10000; Iter 80/80; Training Loss: 1.3490, Test Loss: 0.299
Epoch 215/10000; Iter 1/80; Loss: 1.2802
Epoch 215/10000; Iter 51/80; Loss: 1.2792
Epoch 215/10000; Iter 80/80; Training Loss: 1.3440, Test Loss: 0.275
Epoch 216/10000; Iter 1/80; Loss: 1.1941
Epoch 216/10000; Iter 51/80; Loss: 1.1609
Epoch 216/10000; Iter 80/80; Training Loss: 1.3290, Test Loss: 0.292
Epoch 217/10000; Iter 1/80; Loss: 1.4082
Epoch 217/10000; Iter 51/80; Loss: 1.4418
Epoch 217/10000; Iter 80/80; Training Loss: 1.3390, Test Loss: 0.312
Epoch 218/10000; Iter 1/80; Loss: 1.3121
Epoch 218/10000; Iter 51/80; Loss: 1.3268
Epoch 218/10000; Iter 80/80; Training Loss: 1.3460, Test Loss: 0.323
Epoch 219/10000; Iter 1/80; Loss: 1.2027
Epoch 219/10000; Iter 51/80; Loss: 1.6246
Epoch 219/10000; Iter 80/80; Training Loss: 1.3250, Test Loss: 0.303
Epoch 220/10000; Iter 1/80; Loss: 1.2357
Epoch 220/10000; Iter 51/80; Loss: 1.2037
Epoch 220/10000; Iter 80/80; Training Loss: 1.3310, Test Loss: 0.308
Epoch 221/10000; Iter 1/80; Loss: 1.1193
Epoch 221/10000; Iter 51/80; Loss: 1.2688
Epoch 221/10000; Iter 80/80; Training Loss: 1.3270, Test Loss: 0.277
Epoch 222/10000; Iter 1/80; Loss: 1.4280
Epoch 222/10000; Iter 51/80; Loss: 1.1821
Epoch 222/10000; Iter 80/80; Training Loss: 1.3250, Test Loss: 0.306
Epoch 223/10000; Iter 1/80; Loss: 1.2881
Epoch 223/10000; Iter 51/80; Loss: 1.5414
Epoch 223/10000; Iter 80/80; Training Loss: 1.3190, Test Loss: 0.272
Epoch 224/10000; Iter 1/80; Loss: 1.2845
Epoch 224/10000; Iter 51/80; Loss: 1.3959
Epoch 224/10000; Iter 80/80; Training Loss: 1.3040, Test Loss: 0.329
Epoch 225/10000; Iter 1/80; Loss: 1.2804
Epoch 225/10000; Iter 51/80; Loss: 1.3310
Epoch 225/10000; Iter 80/80; Training Loss: 1.3150, Test Loss: 0.287
Epoch 226/10000; Iter 1/80; Loss: 1.3524
Epoch 226/10000; Iter 51/80; Loss: 1.3371
Epoch 226/10000; Iter 80/80; Training Loss: 1.3190, Test Loss: 0.327
Epoch 227/10000; Iter 1/80; Loss: 1.4299
Epoch 227/10000; Iter 51/80; Loss: 1.3382
Epoch 227/10000; Iter 80/80; Training Loss: 1.3140, Test Loss: 0.28
Epoch 228/10000; Iter 1/80; Loss: 1.3757
Epoch 228/10000; Iter 51/80; Loss: 1.3254
Epoch 228/10000; Iter 80/80; Training Loss: 1.3090, Test Loss: 0.331
Epoch 229/10000; Iter 1/80; Loss: 1.2265
Epoch 229/10000; Iter 51/80; Loss: 1.3115
Epoch 229/10000; Iter 80/80; Training Loss: 1.3310, Test Loss: 0.307
Epoch 230/10000; Iter 1/80; Loss: 1.4683
Epoch 230/10000; Iter 51/80; Loss: 1.4560
Epoch 230/10000; Iter 80/80; Training Loss: 1.3210, Test Loss: 0.304
Epoch 231/10000; Iter 1/80; Loss: 1.2240
Epoch 231/10000; Iter 51/80; Loss: 1.2695
Epoch 231/10000; Iter 80/80; Training Loss: 1.3160, Test Loss: 0.281
Epoch 232/10000; Iter 1/80; Loss: 1.3758
Epoch 232/10000; Iter 51/80; Loss: 1.3436
Epoch 232/10000; Iter 80/80; Training Loss: 1.3060, Test Loss: 0.286
Epoch 233/10000; Iter 1/80; Loss: 1.2505
Epoch 233/10000; Iter 51/80; Loss: 1.1916
Epoch 233/10000; Iter 80/80; Training Loss: 1.3040, Test Loss: 0.288
Epoch 234/10000; Iter 1/80; Loss: 1.2375
Epoch 234/10000; Iter 51/80; Loss: 1.2668
Epoch 234/10000; Iter 80/80; Training Loss: 1.3100, Test Loss: 0.295
Epoch 235/10000; Iter 1/80; Loss: 1.4015
Epoch 235/10000; Iter 51/80; Loss: 1.3970
Epoch 235/10000; Iter 80/80; Training Loss: 1.2950, Test Loss: 0.298
Epoch 236/10000; Iter 1/80; Loss: 1.3056
Epoch 236/10000; Iter 51/80; Loss: 1.1121
Epoch 236/10000; Iter 80/80; Training Loss: 1.2850, Test Loss: 0.289
Epoch 237/10000; Iter 1/80; Loss: 1.2413
Epoch 237/10000; Iter 51/80; Loss: 1.2947
Epoch 237/10000; Iter 80/80; Training Loss: 1.2990, Test Loss: 0.293
Epoch 238/10000; Iter 1/80; Loss: 1.1200
Epoch 238/10000; Iter 51/80; Loss: 1.1534
Epoch 238/10000; Iter 80/80; Training Loss: 1.2930, Test Loss: 0.307
Epoch 239/10000; Iter 1/80; Loss: 1.2068
Epoch 239/10000; Iter 51/80; Loss: 1.3047
Epoch 239/10000; Iter 80/80; Training Loss: 1.2930, Test Loss: 0.309
Epoch 240/10000; Iter 1/80; Loss: 1.3786
Epoch 240/10000; Iter 51/80; Loss: 1.0891
Epoch 240/10000; Iter 80/80; Training Loss: 1.2960, Test Loss: 0.306
Epoch 241/10000; Iter 1/80; Loss: 1.4485
Epoch 241/10000; Iter 51/80; Loss: 1.5716
Epoch 241/10000; Iter 80/80; Training Loss: 1.2990, Test Loss: 0.306
Epoch 242/10000; Iter 1/80; Loss: 1.1537
Epoch 242/10000; Iter 51/80; Loss: 1.2229
Epoch 242/10000; Iter 80/80; Training Loss: 1.2790, Test Loss: 0.268
Epoch 243/10000; Iter 1/80; Loss: 1.2092
Epoch 243/10000; Iter 51/80; Loss: 1.6098
Epoch 243/10000; Iter 80/80; Training Loss: 1.2740, Test Loss: 0.28
Epoch 244/10000; Iter 1/80; Loss: 1.2394
Epoch 244/10000; Iter 51/80; Loss: 1.4538
Epoch 244/10000; Iter 80/80; Training Loss: 1.3010, Test Loss: 0.324
Epoch 245/10000; Iter 1/80; Loss: 1.2294
Epoch 245/10000; Iter 51/80; Loss: 1.3027
Epoch 245/10000; Iter 80/80; Training Loss: 1.2610, Test Loss: 0.274
Epoch 246/10000; Iter 1/80; Loss: 1.2786
Epoch 246/10000; Iter 51/80; Loss: 1.2510
Epoch 246/10000; Iter 80/80; Training Loss: 1.2820, Test Loss: 0.3
Epoch 247/10000; Iter 1/80; Loss: 1.3531
Epoch 247/10000; Iter 51/80; Loss: 1.1635
Epoch 247/10000; Iter 80/80; Training Loss: 1.2850, Test Loss: 0.303
Epoch 248/10000; Iter 1/80; Loss: 1.3470
Epoch 248/10000; Iter 51/80; Loss: 1.1811
Epoch 248/10000; Iter 80/80; Training Loss: 1.2690, Test Loss: 0.271
Epoch 249/10000; Iter 1/80; Loss: 1.2736
Epoch 249/10000; Iter 51/80; Loss: 1.3040
Epoch 249/10000; Iter 80/80; Training Loss: 1.2840, Test Loss: 0.319
Epoch 250/10000; Iter 1/80; Loss: 1.1894
Epoch 250/10000; Iter 51/80; Loss: 1.3784
Epoch 250/10000; Iter 80/80; Training Loss: 1.2630, Test Loss: 0.272
Epoch 251/10000; Iter 1/80; Loss: 1.3516
Epoch 251/10000; Iter 51/80; Loss: 1.2076
Epoch 251/10000; Iter 80/80; Training Loss: 1.2790, Test Loss: 0.307
Epoch 252/10000; Iter 1/80; Loss: 1.2841
Epoch 252/10000; Iter 51/80; Loss: 1.4050
Epoch 252/10000; Iter 80/80; Training Loss: 1.2740, Test Loss: 0.306
Epoch 253/10000; Iter 1/80; Loss: 1.1840
Epoch 253/10000; Iter 51/80; Loss: 1.3306
Epoch 253/10000; Iter 80/80; Training Loss: 1.2680, Test Loss: 0.307
Epoch 254/10000; Iter 1/80; Loss: 1.3148
Epoch 254/10000; Iter 51/80; Loss: 1.2526
Epoch 254/10000; Iter 80/80; Training Loss: 1.2550, Test Loss: 0.271
Epoch 255/10000; Iter 1/80; Loss: 1.3181
Epoch 255/10000; Iter 51/80; Loss: 1.1864
Epoch 255/10000; Iter 80/80; Training Loss: 1.2500, Test Loss: 0.305
Epoch 256/10000; Iter 1/80; Loss: 1.3058
Epoch 256/10000; Iter 51/80; Loss: 1.1530
Epoch 256/10000; Iter 80/80; Training Loss: 1.2680, Test Loss: 0.242
Epoch 257/10000; Iter 1/80; Loss: 1.2762
Epoch 257/10000; Iter 51/80; Loss: 1.4397
Epoch 257/10000; Iter 80/80; Training Loss: 1.2470, Test Loss: 0.284
Epoch 258/10000; Iter 1/80; Loss: 1.0812
Epoch 258/10000; Iter 51/80; Loss: 1.1874
Epoch 258/10000; Iter 80/80; Training Loss: 1.2570, Test Loss: 0.267
Epoch 259/10000; Iter 1/80; Loss: 1.2499
Epoch 259/10000; Iter 51/80; Loss: 1.0204
Epoch 259/10000; Iter 80/80; Training Loss: 1.2590, Test Loss: 0.287
Epoch 260/10000; Iter 1/80; Loss: 1.2474
Epoch 260/10000; Iter 51/80; Loss: 1.3409
Epoch 260/10000; Iter 80/80; Training Loss: 1.2710, Test Loss: 0.272
Epoch 261/10000; Iter 1/80; Loss: 1.2230
Epoch 261/10000; Iter 51/80; Loss: 1.3384
Epoch 261/10000; Iter 80/80; Training Loss: 1.2610, Test Loss: 0.273
Epoch 262/10000; Iter 1/80; Loss: 1.3863
Epoch 262/10000; Iter 51/80; Loss: 1.3095
Epoch 262/10000; Iter 80/80; Training Loss: 1.2470, Test Loss: 0.289
Epoch 263/10000; Iter 1/80; Loss: 1.1525
Epoch 263/10000; Iter 51/80; Loss: 1.1581
Epoch 263/10000; Iter 80/80; Training Loss: 1.2450, Test Loss: 0.288
Epoch 264/10000; Iter 1/80; Loss: 1.2105
Epoch 264/10000; Iter 51/80; Loss: 1.2654
Epoch 264/10000; Iter 80/80; Training Loss: 1.2490, Test Loss: 0.294
Epoch 265/10000; Iter 1/80; Loss: 1.1841
Epoch 265/10000; Iter 51/80; Loss: 1.1474
Epoch 265/10000; Iter 80/80; Training Loss: 1.2330, Test Loss: 0.271
Epoch 266/10000; Iter 1/80; Loss: 1.2317
Epoch 266/10000; Iter 51/80; Loss: 1.2681
Epoch 266/10000; Iter 80/80; Training Loss: 1.2310, Test Loss: 0.288
Epoch 267/10000; Iter 1/80; Loss: 1.1718
Epoch 267/10000; Iter 51/80; Loss: 1.4086
Epoch 267/10000; Iter 80/80; Training Loss: 1.2430, Test Loss: 0.291
Epoch 268/10000; Iter 1/80; Loss: 1.1657
Epoch 268/10000; Iter 51/80; Loss: 1.1337
Epoch 268/10000; Iter 80/80; Training Loss: 1.2440, Test Loss: 0.286
Epoch 269/10000; Iter 1/80; Loss: 1.3800
Epoch 269/10000; Iter 51/80; Loss: 1.2222
Epoch 269/10000; Iter 80/80; Training Loss: 1.2310, Test Loss: 0.305
Epoch 270/10000; Iter 1/80; Loss: 1.1873
Epoch 270/10000; Iter 51/80; Loss: 1.1227
Epoch 270/10000; Iter 80/80; Training Loss: 1.2420, Test Loss: 0.248
Epoch 271/10000; Iter 1/80; Loss: 1.3081
Epoch 271/10000; Iter 51/80; Loss: 1.1050
Epoch 271/10000; Iter 80/80; Training Loss: 1.2330, Test Loss: 0.277
Epoch 272/10000; Iter 1/80; Loss: 1.3185
Epoch 272/10000; Iter 51/80; Loss: 1.2560
Epoch 272/10000; Iter 80/80; Training Loss: 1.2270, Test Loss: 0.314
Epoch 273/10000; Iter 1/80; Loss: 1.1637
Epoch 273/10000; Iter 51/80; Loss: 1.3022
Epoch 273/10000; Iter 80/80; Training Loss: 1.2340, Test Loss: 0.262
Epoch 274/10000; Iter 1/80; Loss: 1.3347
Epoch 274/10000; Iter 51/80; Loss: 1.2195
Epoch 274/10000; Iter 80/80; Training Loss: 1.2140, Test Loss: 0.276
Epoch 275/10000; Iter 1/80; Loss: 1.2964
Epoch 275/10000; Iter 51/80; Loss: 1.2139
Epoch 275/10000; Iter 80/80; Training Loss: 1.2250, Test Loss: 0.293
Epoch 276/10000; Iter 1/80; Loss: 1.0717
Epoch 276/10000; Iter 51/80; Loss: 1.1808
Epoch 276/10000; Iter 80/80; Training Loss: 1.2250, Test Loss: 0.255
Epoch 277/10000; Iter 1/80; Loss: 1.3399
Epoch 277/10000; Iter 51/80; Loss: 1.4650
Epoch 277/10000; Iter 80/80; Training Loss: 1.2340, Test Loss: 0.298
Epoch 278/10000; Iter 1/80; Loss: 1.4129
Epoch 278/10000; Iter 51/80; Loss: 1.1283
Epoch 278/10000; Iter 80/80; Training Loss: 1.2190, Test Loss: 0.248
Epoch 279/10000; Iter 1/80; Loss: 1.2133
Epoch 279/10000; Iter 51/80; Loss: 1.2785
Epoch 279/10000; Iter 80/80; Training Loss: 1.2210, Test Loss: 0.282
Epoch 280/10000; Iter 1/80; Loss: 1.0787
Epoch 280/10000; Iter 51/80; Loss: 1.3773
Epoch 280/10000; Iter 80/80; Training Loss: 1.2190, Test Loss: 0.266
Epoch 281/10000; Iter 1/80; Loss: 1.1318
Epoch 281/10000; Iter 51/80; Loss: 1.3161
Epoch 281/10000; Iter 80/80; Training Loss: 1.2240, Test Loss: 0.281
Epoch 282/10000; Iter 1/80; Loss: 1.0426
Epoch 282/10000; Iter 51/80; Loss: 1.1996
Epoch 282/10000; Iter 80/80; Training Loss: 1.2020, Test Loss: 0.286
Epoch 283/10000; Iter 1/80; Loss: 1.3235
Epoch 283/10000; Iter 51/80; Loss: 1.1512
Epoch 283/10000; Iter 80/80; Training Loss: 1.2090, Test Loss: 0.269
Epoch 284/10000; Iter 1/80; Loss: 1.1694
Epoch 284/10000; Iter 51/80; Loss: 1.3300
Epoch 284/10000; Iter 80/80; Training Loss: 1.2130, Test Loss: 0.253
Epoch 285/10000; Iter 1/80; Loss: 1.3519
Epoch 285/10000; Iter 51/80; Loss: 1.2274
Epoch 285/10000; Iter 80/80; Training Loss: 1.2200, Test Loss: 0.264
Epoch 286/10000; Iter 1/80; Loss: 1.2386
Epoch 286/10000; Iter 51/80; Loss: 1.1725
Epoch 286/10000; Iter 80/80; Training Loss: 1.2070, Test Loss: 0.28
Epoch 287/10000; Iter 1/80; Loss: 1.1691
Epoch 287/10000; Iter 51/80; Loss: 1.2611
Epoch 287/10000; Iter 80/80; Training Loss: 1.2290, Test Loss: 0.297
Epoch 288/10000; Iter 1/80; Loss: 1.3710
Epoch 288/10000; Iter 51/80; Loss: 1.1780
Epoch 288/10000; Iter 80/80; Training Loss: 1.1980, Test Loss: 0.26
Epoch 289/10000; Iter 1/80; Loss: 1.2357
Epoch 289/10000; Iter 51/80; Loss: 1.2717
Epoch 289/10000; Iter 80/80; Training Loss: 1.1820, Test Loss: 0.235
Epoch 290/10000; Iter 1/80; Loss: 1.1908
Epoch 290/10000; Iter 51/80; Loss: 1.0007
Epoch 290/10000; Iter 80/80; Training Loss: 1.1980, Test Loss: 0.253
Epoch 291/10000; Iter 1/80; Loss: 1.3141
Epoch 291/10000; Iter 51/80; Loss: 1.3230
Epoch 291/10000; Iter 80/80; Training Loss: 1.1970, Test Loss: 0.254
Epoch 292/10000; Iter 1/80; Loss: 1.1755
Epoch 292/10000; Iter 51/80; Loss: 1.0979
Epoch 292/10000; Iter 80/80; Training Loss: 1.2140, Test Loss: 0.256
Epoch 293/10000; Iter 1/80; Loss: 1.0937
Epoch 293/10000; Iter 51/80; Loss: 1.2546
Epoch 293/10000; Iter 80/80; Training Loss: 1.2070, Test Loss: 0.268
Epoch 294/10000; Iter 1/80; Loss: 1.1356
Epoch 294/10000; Iter 51/80; Loss: 1.1868
Epoch 294/10000; Iter 80/80; Training Loss: 1.2180, Test Loss: 0.274
Epoch 295/10000; Iter 1/80; Loss: 1.2920
Epoch 295/10000; Iter 51/80; Loss: 1.2457
Epoch 295/10000; Iter 80/80; Training Loss: 1.2020, Test Loss: 0.265
Epoch 296/10000; Iter 1/80; Loss: 1.1330
Epoch 296/10000; Iter 51/80; Loss: 1.0891
Epoch 296/10000; Iter 80/80; Training Loss: 1.1970, Test Loss: 0.301
Epoch 297/10000; Iter 1/80; Loss: 1.1905
Epoch 297/10000; Iter 51/80; Loss: 1.1073
Epoch 297/10000; Iter 80/80; Training Loss: 1.2100, Test Loss: 0.256
Epoch 298/10000; Iter 1/80; Loss: 1.4796
Epoch 298/10000; Iter 51/80; Loss: 1.1172
Epoch 298/10000; Iter 80/80; Training Loss: 1.1960, Test Loss: 0.273
Epoch 299/10000; Iter 1/80; Loss: 1.2083
Epoch 299/10000; Iter 51/80; Loss: 1.0872
Epoch 299/10000; Iter 80/80; Training Loss: 1.1990, Test Loss: 0.277
Epoch 300/10000; Iter 1/80; Loss: 1.1150
Epoch 300/10000; Iter 51/80; Loss: 1.2862
Epoch 300/10000; Iter 80/80; Training Loss: 1.1990, Test Loss: 0.259
Epoch 301/10000; Iter 1/80; Loss: 1.2551
Epoch 301/10000; Iter 51/80; Loss: 1.1458
Epoch 301/10000; Iter 80/80; Training Loss: 1.1860, Test Loss: 0.231
Model saved
Epoch 302/10000; Iter 1/80; Loss: 1.2300
Epoch 302/10000; Iter 51/80; Loss: 1.1191
Epoch 302/10000; Iter 80/80; Training Loss: 1.1900, Test Loss: 0.297
Epoch 303/10000; Iter 1/80; Loss: 1.3201
Epoch 303/10000; Iter 51/80; Loss: 1.2700
Epoch 303/10000; Iter 80/80; Training Loss: 1.2030, Test Loss: 0.26
Epoch 304/10000; Iter 1/80; Loss: 1.2371
Epoch 304/10000; Iter 51/80; Loss: 1.2417
Epoch 304/10000; Iter 80/80; Training Loss: 1.1960, Test Loss: 0.242
Epoch 305/10000; Iter 1/80; Loss: 1.2743
Epoch 305/10000; Iter 51/80; Loss: 1.2139
Epoch 305/10000; Iter 80/80; Training Loss: 1.1870, Test Loss: 0.245
Epoch 306/10000; Iter 1/80; Loss: 1.1520
Epoch 306/10000; Iter 51/80; Loss: 1.2024
Epoch 306/10000; Iter 80/80; Training Loss: 1.1830, Test Loss: 0.254
Epoch 307/10000; Iter 1/80; Loss: 1.1353
Epoch 307/10000; Iter 51/80; Loss: 1.0643
Epoch 307/10000; Iter 80/80; Training Loss: 1.1760, Test Loss: 0.282
Epoch 308/10000; Iter 1/80; Loss: 1.1453
Epoch 308/10000; Iter 51/80; Loss: 1.1821
Epoch 308/10000; Iter 80/80; Training Loss: 1.1740, Test Loss: 0.26
Epoch 309/10000; Iter 1/80; Loss: 1.2353
Epoch 309/10000; Iter 51/80; Loss: 1.1336
Epoch 309/10000; Iter 80/80; Training Loss: 1.1830, Test Loss: 0.284
Epoch 310/10000; Iter 1/80; Loss: 1.1651
Epoch 310/10000; Iter 51/80; Loss: 1.2266
Epoch 310/10000; Iter 80/80; Training Loss: 1.1740, Test Loss: 0.25
Epoch 311/10000; Iter 1/80; Loss: 1.0882
Epoch 311/10000; Iter 51/80; Loss: 1.0493
Epoch 311/10000; Iter 80/80; Training Loss: 1.1720, Test Loss: 0.279
Epoch 312/10000; Iter 1/80; Loss: 1.2348
Epoch 312/10000; Iter 51/80; Loss: 1.1136
Epoch 312/10000; Iter 80/80; Training Loss: 1.1830, Test Loss: 0.253
Epoch 313/10000; Iter 1/80; Loss: 1.2400
Epoch 313/10000; Iter 51/80; Loss: 0.9957
Epoch 313/10000; Iter 80/80; Training Loss: 1.1780, Test Loss: 0.266
Epoch 314/10000; Iter 1/80; Loss: 1.2102
Epoch 314/10000; Iter 51/80; Loss: 1.1630
Epoch 314/10000; Iter 80/80; Training Loss: 1.1710, Test Loss: 0.258
Epoch 315/10000; Iter 1/80; Loss: 1.2189
Epoch 315/10000; Iter 51/80; Loss: 1.0846
Epoch 315/10000; Iter 80/80; Training Loss: 1.1730, Test Loss: 0.252
Epoch 316/10000; Iter 1/80; Loss: 1.0811
Epoch 316/10000; Iter 51/80; Loss: 1.2406
Epoch 316/10000; Iter 80/80; Training Loss: 1.1670, Test Loss: 0.27
Epoch 317/10000; Iter 1/80; Loss: 1.2487
Epoch 317/10000; Iter 51/80; Loss: 1.0321
Epoch 317/10000; Iter 80/80; Training Loss: 1.1760, Test Loss: 0.241
Epoch 318/10000; Iter 1/80; Loss: 1.3167
Epoch 318/10000; Iter 51/80; Loss: 1.0662
Epoch 318/10000; Iter 80/80; Training Loss: 1.1680, Test Loss: 0.268
Epoch 319/10000; Iter 1/80; Loss: 1.2350
Epoch 319/10000; Iter 51/80; Loss: 1.2048
Epoch 319/10000; Iter 80/80; Training Loss: 1.1680, Test Loss: 0.236
Epoch 320/10000; Iter 1/80; Loss: 1.2176
Epoch 320/10000; Iter 51/80; Loss: 1.3744
Epoch 320/10000; Iter 80/80; Training Loss: 1.1720, Test Loss: 0.261
Epoch 321/10000; Iter 1/80; Loss: 1.0762
Epoch 321/10000; Iter 51/80; Loss: 1.2549
Epoch 321/10000; Iter 80/80; Training Loss: 1.1740, Test Loss: 0.233
Epoch 322/10000; Iter 1/80; Loss: 1.3933
Epoch 322/10000; Iter 51/80; Loss: 1.1359
Epoch 322/10000; Iter 80/80; Training Loss: 1.1650, Test Loss: 0.228
Epoch 323/10000; Iter 1/80; Loss: 1.0101
Epoch 323/10000; Iter 51/80; Loss: 1.0905
Epoch 323/10000; Iter 80/80; Training Loss: 1.1510, Test Loss: 0.26
Epoch 324/10000; Iter 1/80; Loss: 1.0511
Epoch 324/10000; Iter 51/80; Loss: 1.2272
Epoch 324/10000; Iter 80/80; Training Loss: 1.1380, Test Loss: 0.251
Epoch 325/10000; Iter 1/80; Loss: 1.1554
Epoch 325/10000; Iter 51/80; Loss: 1.1599
Epoch 325/10000; Iter 80/80; Training Loss: 1.1440, Test Loss: 0.258
Epoch 326/10000; Iter 1/80; Loss: 1.1746
Epoch 326/10000; Iter 51/80; Loss: 1.2466
Epoch 326/10000; Iter 80/80; Training Loss: 1.1430, Test Loss: 0.248
Epoch 327/10000; Iter 1/80; Loss: 1.2417
Epoch 327/10000; Iter 51/80; Loss: 1.0149
Epoch 327/10000; Iter 80/80; Training Loss: 1.1570, Test Loss: 0.23
Epoch 328/10000; Iter 1/80; Loss: 1.1934
Epoch 328/10000; Iter 51/80; Loss: 1.0646
Epoch 328/10000; Iter 80/80; Training Loss: 1.1560, Test Loss: 0.201
Epoch 329/10000; Iter 1/80; Loss: 1.2820
Epoch 329/10000; Iter 51/80; Loss: 1.0801
Epoch 329/10000; Iter 80/80; Training Loss: 1.1610, Test Loss: 0.231
Epoch 330/10000; Iter 1/80; Loss: 1.1100
Epoch 330/10000; Iter 51/80; Loss: 1.0699
Epoch 330/10000; Iter 80/80; Training Loss: 1.1480, Test Loss: 0.254
Epoch 331/10000; Iter 1/80; Loss: 0.9611
Epoch 331/10000; Iter 51/80; Loss: 1.1614
Epoch 331/10000; Iter 80/80; Training Loss: 1.1310, Test Loss: 0.262
Epoch 332/10000; Iter 1/80; Loss: 1.3099
Epoch 332/10000; Iter 51/80; Loss: 1.1254
Epoch 332/10000; Iter 80/80; Training Loss: 1.1490, Test Loss: 0.235
Epoch 333/10000; Iter 1/80; Loss: 1.0514
Epoch 333/10000; Iter 51/80; Loss: 1.2554
Epoch 333/10000; Iter 80/80; Training Loss: 1.1460, Test Loss: 0.241
Epoch 334/10000; Iter 1/80; Loss: 1.3572
Epoch 334/10000; Iter 51/80; Loss: 1.1718
Epoch 334/10000; Iter 80/80; Training Loss: 1.1620, Test Loss: 0.267
Epoch 335/10000; Iter 1/80; Loss: 1.3342
Epoch 335/10000; Iter 51/80; Loss: 1.1265
Epoch 335/10000; Iter 80/80; Training Loss: 1.1540, Test Loss: 0.243
Epoch 336/10000; Iter 1/80; Loss: 1.0324
Epoch 336/10000; Iter 51/80; Loss: 1.1211
Epoch 336/10000; Iter 80/80; Training Loss: 1.1330, Test Loss: 0.267
Epoch 337/10000; Iter 1/80; Loss: 1.1276
Epoch 337/10000; Iter 51/80; Loss: 1.2316
Epoch 337/10000; Iter 80/80; Training Loss: 1.1370, Test Loss: 0.234
Epoch 338/10000; Iter 1/80; Loss: 1.1597
Epoch 338/10000; Iter 51/80; Loss: 1.2111
Epoch 338/10000; Iter 80/80; Training Loss: 1.1290, Test Loss: 0.241
Epoch 339/10000; Iter 1/80; Loss: 1.1168
Epoch 339/10000; Iter 51/80; Loss: 1.0332
Epoch 339/10000; Iter 80/80; Training Loss: 1.1310, Test Loss: 0.222
Epoch 340/10000; Iter 1/80; Loss: 1.1555
Epoch 340/10000; Iter 51/80; Loss: 0.9416
Epoch 340/10000; Iter 80/80; Training Loss: 1.1340, Test Loss: 0.243
Epoch 341/10000; Iter 1/80; Loss: 1.1402
Epoch 341/10000; Iter 51/80; Loss: 1.1275
Epoch 341/10000; Iter 80/80; Training Loss: 1.1320, Test Loss: 0.246
Epoch 342/10000; Iter 1/80; Loss: 1.0518
Epoch 342/10000; Iter 51/80; Loss: 1.1074
Epoch 342/10000; Iter 80/80; Training Loss: 1.1330, Test Loss: 0.252
Epoch 343/10000; Iter 1/80; Loss: 1.1848
Epoch 343/10000; Iter 51/80; Loss: 1.0766
Epoch 343/10000; Iter 80/80; Training Loss: 1.1320, Test Loss: 0.252
Epoch 344/10000; Iter 1/80; Loss: 1.0387
Epoch 344/10000; Iter 51/80; Loss: 1.1338
Epoch 344/10000; Iter 80/80; Training Loss: 1.1270, Test Loss: 0.237
Epoch 345/10000; Iter 1/80; Loss: 1.0164
Epoch 345/10000; Iter 51/80; Loss: 1.2178
Epoch 345/10000; Iter 80/80; Training Loss: 1.1460, Test Loss: 0.271
Epoch 346/10000; Iter 1/80; Loss: 0.9962
Epoch 346/10000; Iter 51/80; Loss: 1.1416
Epoch 346/10000; Iter 80/80; Training Loss: 1.1190, Test Loss: 0.23
Epoch 347/10000; Iter 1/80; Loss: 1.1056
Epoch 347/10000; Iter 51/80; Loss: 1.1997
Epoch 347/10000; Iter 80/80; Training Loss: 1.1370, Test Loss: 0.249
Epoch 348/10000; Iter 1/80; Loss: 1.0945
Epoch 348/10000; Iter 51/80; Loss: 1.1724
Epoch 348/10000; Iter 80/80; Training Loss: 1.1280, Test Loss: 0.232
Epoch 349/10000; Iter 1/80; Loss: 1.0451
Epoch 349/10000; Iter 51/80; Loss: 1.1085
Epoch 349/10000; Iter 80/80; Training Loss: 1.1290, Test Loss: 0.237
Epoch 350/10000; Iter 1/80; Loss: 1.1858
Epoch 350/10000; Iter 51/80; Loss: 1.1030
Epoch 350/10000; Iter 80/80; Training Loss: 1.1300, Test Loss: 0.227
Epoch 351/10000; Iter 1/80; Loss: 1.0399
Epoch 351/10000; Iter 51/80; Loss: 1.0815
Epoch 351/10000; Iter 80/80; Training Loss: 1.1220, Test Loss: 0.245
Epoch 352/10000; Iter 1/80; Loss: 1.1189
Epoch 352/10000; Iter 51/80; Loss: 1.1546
Epoch 352/10000; Iter 80/80; Training Loss: 1.1340, Test Loss: 0.244
Epoch 353/10000; Iter 1/80; Loss: 1.1170
Epoch 353/10000; Iter 51/80; Loss: 1.0715
Epoch 353/10000; Iter 80/80; Training Loss: 1.1220, Test Loss: 0.245
Epoch 354/10000; Iter 1/80; Loss: 1.1841
Epoch 354/10000; Iter 51/80; Loss: 1.0835
Epoch 354/10000; Iter 80/80; Training Loss: 1.1120, Test Loss: 0.235
Epoch 355/10000; Iter 1/80; Loss: 1.1868
Epoch 355/10000; Iter 51/80; Loss: 1.1881
Epoch 355/10000; Iter 80/80; Training Loss: 1.1130, Test Loss: 0.227
Epoch 356/10000; Iter 1/80; Loss: 1.1662
Epoch 356/10000; Iter 51/80; Loss: 1.0694
Epoch 356/10000; Iter 80/80; Training Loss: 1.1070, Test Loss: 0.236
Epoch 357/10000; Iter 1/80; Loss: 1.0378
Epoch 357/10000; Iter 51/80; Loss: 1.0423
Epoch 357/10000; Iter 80/80; Training Loss: 1.0910, Test Loss: 0.235
Epoch 358/10000; Iter 1/80; Loss: 1.0669
Epoch 358/10000; Iter 51/80; Loss: 1.1552
Epoch 358/10000; Iter 80/80; Training Loss: 1.1060, Test Loss: 0.211
Epoch 359/10000; Iter 1/80; Loss: 1.0205
Epoch 359/10000; Iter 51/80; Loss: 1.1848
Epoch 359/10000; Iter 80/80; Training Loss: 1.1090, Test Loss: 0.229
Epoch 360/10000; Iter 1/80; Loss: 1.1886
Epoch 360/10000; Iter 51/80; Loss: 1.1625
Epoch 360/10000; Iter 80/80; Training Loss: 1.1120, Test Loss: 0.242
Epoch 361/10000; Iter 1/80; Loss: 1.1008
Epoch 361/10000; Iter 51/80; Loss: 1.2290
Epoch 361/10000; Iter 80/80; Training Loss: 1.0910, Test Loss: 0.237
Epoch 362/10000; Iter 1/80; Loss: 1.0708
Epoch 362/10000; Iter 51/80; Loss: 1.1072
Epoch 362/10000; Iter 80/80; Training Loss: 1.1080, Test Loss: 0.253
Epoch 363/10000; Iter 1/80; Loss: 1.0588
Epoch 363/10000; Iter 51/80; Loss: 1.0521
Epoch 363/10000; Iter 80/80; Training Loss: 1.1150, Test Loss: 0.238
Epoch 364/10000; Iter 1/80; Loss: 1.0040
Epoch 364/10000; Iter 51/80; Loss: 1.1678
Epoch 364/10000; Iter 80/80; Training Loss: 1.1100, Test Loss: 0.221
Epoch 365/10000; Iter 1/80; Loss: 1.0055
Epoch 365/10000; Iter 51/80; Loss: 0.9896
Epoch 365/10000; Iter 80/80; Training Loss: 1.0930, Test Loss: 0.239
Epoch 366/10000; Iter 1/80; Loss: 1.3466
Epoch 366/10000; Iter 51/80; Loss: 0.9933
Epoch 366/10000; Iter 80/80; Training Loss: 1.1070, Test Loss: 0.235
Epoch 367/10000; Iter 1/80; Loss: 1.1344
Epoch 367/10000; Iter 51/80; Loss: 1.0975
Epoch 367/10000; Iter 80/80; Training Loss: 1.0990, Test Loss: 0.238
Epoch 368/10000; Iter 1/80; Loss: 1.0658
Epoch 368/10000; Iter 51/80; Loss: 1.0803
Epoch 368/10000; Iter 80/80; Training Loss: 1.1150, Test Loss: 0.251
Epoch 369/10000; Iter 1/80; Loss: 0.9147
Epoch 369/10000; Iter 51/80; Loss: 1.2023
Epoch 369/10000; Iter 80/80; Training Loss: 1.0780, Test Loss: 0.235
Epoch 370/10000; Iter 1/80; Loss: 1.1687
Epoch 370/10000; Iter 51/80; Loss: 1.0346
Epoch 370/10000; Iter 80/80; Training Loss: 1.0880, Test Loss: 0.273
Epoch 371/10000; Iter 1/80; Loss: 1.1350
Epoch 371/10000; Iter 51/80; Loss: 0.9373
Epoch 371/10000; Iter 80/80; Training Loss: 1.0900, Test Loss: 0.245
Epoch 372/10000; Iter 1/80; Loss: 1.1665
Epoch 372/10000; Iter 51/80; Loss: 1.2164
Epoch 372/10000; Iter 80/80; Training Loss: 1.0960, Test Loss: 0.221
Epoch 373/10000; Iter 1/80; Loss: 1.0296
Epoch 373/10000; Iter 51/80; Loss: 1.1325
Epoch 373/10000; Iter 80/80; Training Loss: 1.1110, Test Loss: 0.191
Epoch 374/10000; Iter 1/80; Loss: 0.9597
Epoch 374/10000; Iter 51/80; Loss: 1.0076
Epoch 374/10000; Iter 80/80; Training Loss: 1.1050, Test Loss: 0.228
Epoch 375/10000; Iter 1/80; Loss: 1.1551
Epoch 375/10000; Iter 51/80; Loss: 1.0744
Epoch 375/10000; Iter 80/80; Training Loss: 1.0690, Test Loss: 0.243
Epoch 376/10000; Iter 1/80; Loss: 1.0876
Epoch 376/10000; Iter 51/80; Loss: 1.0899
Epoch 376/10000; Iter 80/80; Training Loss: 1.0960, Test Loss: 0.225
Epoch 377/10000; Iter 1/80; Loss: 1.0071
Epoch 377/10000; Iter 51/80; Loss: 1.1153
Epoch 377/10000; Iter 80/80; Training Loss: 1.0820, Test Loss: 0.221
Epoch 378/10000; Iter 1/80; Loss: 0.9661
Epoch 378/10000; Iter 51/80; Loss: 1.0091
Epoch 378/10000; Iter 80/80; Training Loss: 1.0840, Test Loss: 0.229
Epoch 379/10000; Iter 1/80; Loss: 0.9792
Epoch 379/10000; Iter 51/80; Loss: 1.0927
Epoch 379/10000; Iter 80/80; Training Loss: 1.0910, Test Loss: 0.226
Epoch 380/10000; Iter 1/80; Loss: 0.9902
Epoch 380/10000; Iter 51/80; Loss: 1.2866
Epoch 380/10000; Iter 80/80; Training Loss: 1.0870, Test Loss: 0.22
Epoch 381/10000; Iter 1/80; Loss: 1.1705
Epoch 381/10000; Iter 51/80; Loss: 1.0355
Epoch 381/10000; Iter 80/80; Training Loss: 1.0920, Test Loss: 0.215
Epoch 382/10000; Iter 1/80; Loss: 1.1058
Epoch 382/10000; Iter 51/80; Loss: 1.2192
Epoch 382/10000; Iter 80/80; Training Loss: 1.0840, Test Loss: 0.216
Epoch 383/10000; Iter 1/80; Loss: 1.0673
Epoch 383/10000; Iter 51/80; Loss: 1.0913
Epoch 383/10000; Iter 80/80; Training Loss: 1.0890, Test Loss: 0.25
Epoch 384/10000; Iter 1/80; Loss: 1.1058
Epoch 384/10000; Iter 51/80; Loss: 0.9925
Epoch 384/10000; Iter 80/80; Training Loss: 1.0820, Test Loss: 0.241
Epoch 385/10000; Iter 1/80; Loss: 0.9534
Epoch 385/10000; Iter 51/80; Loss: 1.1201
Epoch 385/10000; Iter 80/80; Training Loss: 1.0830, Test Loss: 0.214
Epoch 386/10000; Iter 1/80; Loss: 1.2534
Epoch 386/10000; Iter 51/80; Loss: 1.1949
Epoch 386/10000; Iter 80/80; Training Loss: 1.0810, Test Loss: 0.222
Epoch 387/10000; Iter 1/80; Loss: 1.2316
Epoch 387/10000; Iter 51/80; Loss: 1.0685
Epoch 387/10000; Iter 80/80; Training Loss: 1.0990, Test Loss: 0.225
Epoch 388/10000; Iter 1/80; Loss: 1.1081
Epoch 388/10000; Iter 51/80; Loss: 1.0266
Epoch 388/10000; Iter 80/80; Training Loss: 1.0700, Test Loss: 0.208
Epoch 389/10000; Iter 1/80; Loss: 1.1600
Epoch 389/10000; Iter 51/80; Loss: 0.9861
Epoch 389/10000; Iter 80/80; Training Loss: 1.0730, Test Loss: 0.217
Epoch 390/10000; Iter 1/80; Loss: 1.1652
Epoch 390/10000; Iter 51/80; Loss: 1.0614
Epoch 390/10000; Iter 80/80; Training Loss: 1.0990, Test Loss: 0.255
Epoch 391/10000; Iter 1/80; Loss: 1.2441
Epoch 391/10000; Iter 51/80; Loss: 1.3219
Epoch 391/10000; Iter 80/80; Training Loss: 1.0690, Test Loss: 0.218
Epoch 392/10000; Iter 1/80; Loss: 1.1534
Epoch 392/10000; Iter 51/80; Loss: 1.0305
Epoch 392/10000; Iter 80/80; Training Loss: 1.0700, Test Loss: 0.217
Epoch 393/10000; Iter 1/80; Loss: 1.0492
Epoch 393/10000; Iter 51/80; Loss: 1.3809
Epoch 393/10000; Iter 80/80; Training Loss: 1.0710, Test Loss: 0.208
Epoch 394/10000; Iter 1/80; Loss: 1.0503
Epoch 394/10000; Iter 51/80; Loss: 1.0510
Epoch 394/10000; Iter 80/80; Training Loss: 1.0690, Test Loss: 0.22
Epoch 395/10000; Iter 1/80; Loss: 1.1657
Epoch 395/10000; Iter 51/80; Loss: 1.0161
Epoch 395/10000; Iter 80/80; Training Loss: 1.0840, Test Loss: 0.219
Epoch 396/10000; Iter 1/80; Loss: 1.1366
Epoch 396/10000; Iter 51/80; Loss: 0.9997
Epoch 396/10000; Iter 80/80; Training Loss: 1.0780, Test Loss: 0.228
Epoch 397/10000; Iter 1/80; Loss: 1.1117
Epoch 397/10000; Iter 51/80; Loss: 1.1708
Epoch 397/10000; Iter 80/80; Training Loss: 1.0710, Test Loss: 0.235
Epoch 398/10000; Iter 1/80; Loss: 1.1445
Epoch 398/10000; Iter 51/80; Loss: 1.0865
Epoch 398/10000; Iter 80/80; Training Loss: 1.0620, Test Loss: 0.219
Epoch 399/10000; Iter 1/80; Loss: 1.0470
Epoch 399/10000; Iter 51/80; Loss: 1.1366
Epoch 399/10000; Iter 80/80; Training Loss: 1.0730, Test Loss: 0.193
Epoch 400/10000; Iter 1/80; Loss: 1.0961
Epoch 400/10000; Iter 51/80; Loss: 1.0280
Epoch 400/10000; Iter 80/80; Training Loss: 1.0610, Test Loss: 0.209
Epoch 401/10000; Iter 1/80; Loss: 1.0323
Epoch 401/10000; Iter 51/80; Loss: 0.9830
Epoch 401/10000; Iter 80/80; Training Loss: 1.0470, Test Loss: 0.25
Model saved
Epoch 402/10000; Iter 1/80; Loss: 1.0143
Epoch 402/10000; Iter 51/80; Loss: 0.9425
Epoch 402/10000; Iter 80/80; Training Loss: 1.0650, Test Loss: 0.24
Epoch 403/10000; Iter 1/80; Loss: 1.1056
Epoch 403/10000; Iter 51/80; Loss: 1.0512
Epoch 403/10000; Iter 80/80; Training Loss: 1.0630, Test Loss: 0.216
Epoch 404/10000; Iter 1/80; Loss: 1.0376
Epoch 404/10000; Iter 51/80; Loss: 1.2011
Epoch 404/10000; Iter 80/80; Training Loss: 1.0680, Test Loss: 0.238
Epoch 405/10000; Iter 1/80; Loss: 1.0276
Epoch 405/10000; Iter 51/80; Loss: 1.1486
Epoch 405/10000; Iter 80/80; Training Loss: 1.0600, Test Loss: 0.221
Epoch 406/10000; Iter 1/80; Loss: 0.9945
Epoch 406/10000; Iter 51/80; Loss: 0.9593
Epoch 406/10000; Iter 80/80; Training Loss: 1.0580, Test Loss: 0.23
Epoch 407/10000; Iter 1/80; Loss: 1.0567
Epoch 407/10000; Iter 51/80; Loss: 1.1015
Epoch 407/10000; Iter 80/80; Training Loss: 1.0540, Test Loss: 0.216
Epoch 408/10000; Iter 1/80; Loss: 1.1158
Epoch 408/10000; Iter 51/80; Loss: 0.9746
Epoch 408/10000; Iter 80/80; Training Loss: 1.0540, Test Loss: 0.216
Epoch 409/10000; Iter 1/80; Loss: 0.9710
Epoch 409/10000; Iter 51/80; Loss: 1.0785
Epoch 409/10000; Iter 80/80; Training Loss: 1.0620, Test Loss: 0.222
Epoch 410/10000; Iter 1/80; Loss: 1.0881
Epoch 410/10000; Iter 51/80; Loss: 1.0806
Epoch 410/10000; Iter 80/80; Training Loss: 1.0530, Test Loss: 0.215
Epoch 411/10000; Iter 1/80; Loss: 1.0224
Epoch 411/10000; Iter 51/80; Loss: 0.9457
Epoch 411/10000; Iter 80/80; Training Loss: 1.0450, Test Loss: 0.238
Epoch 412/10000; Iter 1/80; Loss: 1.0529
Epoch 412/10000; Iter 51/80; Loss: 1.1270
Epoch 412/10000; Iter 80/80; Training Loss: 1.0470, Test Loss: 0.207
Epoch 413/10000; Iter 1/80; Loss: 0.9135
Epoch 413/10000; Iter 51/80; Loss: 1.2375
Epoch 413/10000; Iter 80/80; Training Loss: 1.0610, Test Loss: 0.225
Epoch 414/10000; Iter 1/80; Loss: 1.0194
Epoch 414/10000; Iter 51/80; Loss: 0.9751
Epoch 414/10000; Iter 80/80; Training Loss: 1.0340, Test Loss: 0.227
Epoch 415/10000; Iter 1/80; Loss: 1.2406
Epoch 415/10000; Iter 51/80; Loss: 1.0153
Epoch 415/10000; Iter 80/80; Training Loss: 1.0710, Test Loss: 0.227
Epoch 416/10000; Iter 1/80; Loss: 1.0852
Epoch 416/10000; Iter 51/80; Loss: 1.0752
Epoch 416/10000; Iter 80/80; Training Loss: 1.0470, Test Loss: 0.197
Epoch 417/10000; Iter 1/80; Loss: 1.1905
Epoch 417/10000; Iter 51/80; Loss: 1.0872
Epoch 417/10000; Iter 80/80; Training Loss: 1.0510, Test Loss: 0.229
Epoch 418/10000; Iter 1/80; Loss: 0.9423
Epoch 418/10000; Iter 51/80; Loss: 1.1803
Epoch 418/10000; Iter 80/80; Training Loss: 1.0470, Test Loss: 0.197
Epoch 419/10000; Iter 1/80; Loss: 1.0450
Epoch 419/10000; Iter 51/80; Loss: 1.0191
Epoch 419/10000; Iter 80/80; Training Loss: 1.0420, Test Loss: 0.19
Epoch 420/10000; Iter 1/80; Loss: 1.0331
Epoch 420/10000; Iter 51/80; Loss: 1.0184
Epoch 420/10000; Iter 80/80; Training Loss: 1.0400, Test Loss: 0.199
Epoch 421/10000; Iter 1/80; Loss: 0.9461
Epoch 421/10000; Iter 51/80; Loss: 1.0056
Epoch 421/10000; Iter 80/80; Training Loss: 1.0380, Test Loss: 0.203
Epoch 422/10000; Iter 1/80; Loss: 0.9462
Epoch 422/10000; Iter 51/80; Loss: 1.0010
Epoch 422/10000; Iter 80/80; Training Loss: 1.0270, Test Loss: 0.198
Epoch 423/10000; Iter 1/80; Loss: 1.0288
Epoch 423/10000; Iter 51/80; Loss: 1.0058
Epoch 423/10000; Iter 80/80; Training Loss: 1.0330, Test Loss: 0.204
Epoch 424/10000; Iter 1/80; Loss: 0.9435
Epoch 424/10000; Iter 51/80; Loss: 1.1442
Epoch 424/10000; Iter 80/80; Training Loss: 1.0280, Test Loss: 0.224
Epoch 425/10000; Iter 1/80; Loss: 0.9149
Epoch 425/10000; Iter 51/80; Loss: 1.0881
Epoch 425/10000; Iter 80/80; Training Loss: 1.0290, Test Loss: 0.211
Epoch 426/10000; Iter 1/80; Loss: 0.9987
Epoch 426/10000; Iter 51/80; Loss: 1.0679
Epoch 426/10000; Iter 80/80; Training Loss: 1.0300, Test Loss: 0.229
Epoch 427/10000; Iter 1/80; Loss: 1.0040
Epoch 427/10000; Iter 51/80; Loss: 1.1144
Epoch 427/10000; Iter 80/80; Training Loss: 1.0400, Test Loss: 0.223
Epoch 428/10000; Iter 1/80; Loss: 0.9181
Epoch 428/10000; Iter 51/80; Loss: 1.0381
Epoch 428/10000; Iter 80/80; Training Loss: 1.0320, Test Loss: 0.2
Epoch 429/10000; Iter 1/80; Loss: 0.9154
Epoch 429/10000; Iter 51/80; Loss: 0.9785
Epoch 429/10000; Iter 80/80; Training Loss: 1.0430, Test Loss: 0.211
Epoch 430/10000; Iter 1/80; Loss: 0.9966
Epoch 430/10000; Iter 51/80; Loss: 0.9366
Epoch 430/10000; Iter 80/80; Training Loss: 1.0240, Test Loss: 0.213
Epoch 431/10000; Iter 1/80; Loss: 0.9256
Epoch 431/10000; Iter 51/80; Loss: 1.0228
Epoch 431/10000; Iter 80/80; Training Loss: 1.0200, Test Loss: 0.193
Epoch 432/10000; Iter 1/80; Loss: 0.9692
Epoch 432/10000; Iter 51/80; Loss: 0.9979
Epoch 432/10000; Iter 80/80; Training Loss: 1.0190, Test Loss: 0.212
Epoch 433/10000; Iter 1/80; Loss: 0.9402
Epoch 433/10000; Iter 51/80; Loss: 1.0554
Epoch 433/10000; Iter 80/80; Training Loss: 1.0300, Test Loss: 0.224
Epoch 434/10000; Iter 1/80; Loss: 1.0589
Epoch 434/10000; Iter 51/80; Loss: 1.0902
Epoch 434/10000; Iter 80/80; Training Loss: 1.0200, Test Loss: 0.204
Epoch 435/10000; Iter 1/80; Loss: 0.9940
Epoch 435/10000; Iter 51/80; Loss: 1.0294
Epoch 435/10000; Iter 80/80; Training Loss: 1.0250, Test Loss: 0.202
Epoch 436/10000; Iter 1/80; Loss: 1.0605
Epoch 436/10000; Iter 51/80; Loss: 1.0316
Epoch 436/10000; Iter 80/80; Training Loss: 1.0150, Test Loss: 0.216
Epoch 437/10000; Iter 1/80; Loss: 1.0776
Epoch 437/10000; Iter 51/80; Loss: 1.0185
Epoch 437/10000; Iter 80/80; Training Loss: 1.0270, Test Loss: 0.187
Epoch 438/10000; Iter 1/80; Loss: 1.0892
Epoch 438/10000; Iter 51/80; Loss: 1.0519
Epoch 438/10000; Iter 80/80; Training Loss: 1.0290, Test Loss: 0.217
Epoch 439/10000; Iter 1/80; Loss: 1.0462
Epoch 439/10000; Iter 51/80; Loss: 0.9286
Epoch 439/10000; Iter 80/80; Training Loss: 1.0120, Test Loss: 0.198
Epoch 440/10000; Iter 1/80; Loss: 0.9387
Epoch 440/10000; Iter 51/80; Loss: 0.9856
Epoch 440/10000; Iter 80/80; Training Loss: 1.0190, Test Loss: 0.233
Epoch 441/10000; Iter 1/80; Loss: 1.0884
Epoch 441/10000; Iter 51/80; Loss: 1.0865
Epoch 441/10000; Iter 80/80; Training Loss: 1.0210, Test Loss: 0.203
Epoch 442/10000; Iter 1/80; Loss: 1.0268
Epoch 442/10000; Iter 51/80; Loss: 0.9616
Epoch 442/10000; Iter 80/80; Training Loss: 1.0090, Test Loss: 0.217
Epoch 443/10000; Iter 1/80; Loss: 0.9262
Epoch 443/10000; Iter 51/80; Loss: 1.0367
Epoch 443/10000; Iter 80/80; Training Loss: 1.0190, Test Loss: 0.195
Epoch 444/10000; Iter 1/80; Loss: 0.9276
Epoch 444/10000; Iter 51/80; Loss: 1.0499
Epoch 444/10000; Iter 80/80; Training Loss: 1.0070, Test Loss: 0.184
Epoch 445/10000; Iter 1/80; Loss: 1.0724
Epoch 445/10000; Iter 51/80; Loss: 1.1087
Epoch 445/10000; Iter 80/80; Training Loss: 1.0270, Test Loss: 0.215
Epoch 446/10000; Iter 1/80; Loss: 0.9826
Epoch 446/10000; Iter 51/80; Loss: 1.0829
Epoch 446/10000; Iter 80/80; Training Loss: 1.0180, Test Loss: 0.186
Epoch 447/10000; Iter 1/80; Loss: 0.8975
Epoch 447/10000; Iter 51/80; Loss: 1.0094
Epoch 447/10000; Iter 80/80; Training Loss: 1.0010, Test Loss: 0.182
Epoch 448/10000; Iter 1/80; Loss: 0.9285
Epoch 448/10000; Iter 51/80; Loss: 0.9534
Epoch 448/10000; Iter 80/80; Training Loss: 1.0050, Test Loss: 0.22
Epoch 449/10000; Iter 1/80; Loss: 1.0968
Epoch 449/10000; Iter 51/80; Loss: 1.2465
Epoch 449/10000; Iter 80/80; Training Loss: 1.0260, Test Loss: 0.187
Epoch 450/10000; Iter 1/80; Loss: 0.9838
Epoch 450/10000; Iter 51/80; Loss: 1.0557
Epoch 450/10000; Iter 80/80; Training Loss: 1.0080, Test Loss: 0.198
Epoch 451/10000; Iter 1/80; Loss: 0.9990
Epoch 451/10000; Iter 51/80; Loss: 1.1218
Epoch 451/10000; Iter 80/80; Training Loss: 1.0020, Test Loss: 0.199
Epoch 452/10000; Iter 1/80; Loss: 0.7889
Epoch 452/10000; Iter 51/80; Loss: 0.9974
Epoch 452/10000; Iter 80/80; Training Loss: 1.0080, Test Loss: 0.187
Epoch 453/10000; Iter 1/80; Loss: 0.9549
Epoch 453/10000; Iter 51/80; Loss: 0.9055
Epoch 453/10000; Iter 80/80; Training Loss: 0.9930, Test Loss: 0.214
Epoch 454/10000; Iter 1/80; Loss: 1.0477
Epoch 454/10000; Iter 51/80; Loss: 0.9500
Epoch 454/10000; Iter 80/80; Training Loss: 0.9990, Test Loss: 0.185
Epoch 455/10000; Iter 1/80; Loss: 1.0353
Epoch 455/10000; Iter 51/80; Loss: 0.9778
Epoch 455/10000; Iter 80/80; Training Loss: 0.9940, Test Loss: 0.18
Epoch 456/10000; Iter 1/80; Loss: 0.9095
Epoch 456/10000; Iter 51/80; Loss: 1.1418
Epoch 456/10000; Iter 80/80; Training Loss: 0.9910, Test Loss: 0.214
Epoch 457/10000; Iter 1/80; Loss: 1.0583
Epoch 457/10000; Iter 51/80; Loss: 1.0908
Epoch 457/10000; Iter 80/80; Training Loss: 1.0140, Test Loss: 0.205
Epoch 458/10000; Iter 1/80; Loss: 1.0682
Epoch 458/10000; Iter 51/80; Loss: 1.1065
Epoch 458/10000; Iter 80/80; Training Loss: 1.0020, Test Loss: 0.193
Epoch 459/10000; Iter 1/80; Loss: 0.9631
Epoch 459/10000; Iter 51/80; Loss: 1.0842
Epoch 459/10000; Iter 80/80; Training Loss: 1.0020, Test Loss: 0.196
Epoch 460/10000; Iter 1/80; Loss: 1.0567
Epoch 460/10000; Iter 51/80; Loss: 0.9936
Epoch 460/10000; Iter 80/80; Training Loss: 1.0060, Test Loss: 0.21
Epoch 461/10000; Iter 1/80; Loss: 0.9577
Epoch 461/10000; Iter 51/80; Loss: 0.9710
Epoch 461/10000; Iter 80/80; Training Loss: 0.9960, Test Loss: 0.177
Epoch 462/10000; Iter 1/80; Loss: 0.9872
Epoch 462/10000; Iter 51/80; Loss: 0.9619
Epoch 462/10000; Iter 80/80; Training Loss: 0.9970, Test Loss: 0.186
Epoch 463/10000; Iter 1/80; Loss: 1.1876
Epoch 463/10000; Iter 51/80; Loss: 0.9856
Epoch 463/10000; Iter 80/80; Training Loss: 0.9970, Test Loss: 0.181
Epoch 464/10000; Iter 1/80; Loss: 0.9585
Epoch 464/10000; Iter 51/80; Loss: 0.8852
Epoch 464/10000; Iter 80/80; Training Loss: 1.0010, Test Loss: 0.187
Epoch 465/10000; Iter 1/80; Loss: 1.1028
Epoch 465/10000; Iter 51/80; Loss: 0.9033
Epoch 465/10000; Iter 80/80; Training Loss: 0.9820, Test Loss: 0.19
Epoch 466/10000; Iter 1/80; Loss: 0.9964
Epoch 466/10000; Iter 51/80; Loss: 0.9819
Epoch 466/10000; Iter 80/80; Training Loss: 0.9800, Test Loss: 0.171
Epoch 467/10000; Iter 1/80; Loss: 0.9248
Epoch 467/10000; Iter 51/80; Loss: 1.0518
Epoch 467/10000; Iter 80/80; Training Loss: 0.9880, Test Loss: 0.18
Epoch 468/10000; Iter 1/80; Loss: 0.9643
Epoch 468/10000; Iter 51/80; Loss: 0.9691
Epoch 468/10000; Iter 80/80; Training Loss: 0.9810, Test Loss: 0.172
Epoch 469/10000; Iter 1/80; Loss: 0.8496
Epoch 469/10000; Iter 51/80; Loss: 0.9890
Epoch 469/10000; Iter 80/80; Training Loss: 0.9870, Test Loss: 0.169
Epoch 470/10000; Iter 1/80; Loss: 1.3234
Epoch 470/10000; Iter 51/80; Loss: 0.9447
Epoch 470/10000; Iter 80/80; Training Loss: 0.9870, Test Loss: 0.197
Epoch 471/10000; Iter 1/80; Loss: 1.0783
Epoch 471/10000; Iter 51/80; Loss: 0.9672
Epoch 471/10000; Iter 80/80; Training Loss: 1.0060, Test Loss: 0.192
Epoch 472/10000; Iter 1/80; Loss: 0.9438
Epoch 472/10000; Iter 51/80; Loss: 0.9913
Epoch 472/10000; Iter 80/80; Training Loss: 0.9760, Test Loss: 0.169
Epoch 473/10000; Iter 1/80; Loss: 0.8808
Epoch 473/10000; Iter 51/80; Loss: 1.1405
Epoch 473/10000; Iter 80/80; Training Loss: 0.9940, Test Loss: 0.188
Epoch 474/10000; Iter 1/80; Loss: 1.0296
Epoch 474/10000; Iter 51/80; Loss: 1.0241
Epoch 474/10000; Iter 80/80; Training Loss: 0.9750, Test Loss: 0.177
Epoch 475/10000; Iter 1/80; Loss: 1.0206
Epoch 475/10000; Iter 51/80; Loss: 1.0497
Epoch 475/10000; Iter 80/80; Training Loss: 0.9890, Test Loss: 0.181
Epoch 476/10000; Iter 1/80; Loss: 1.1131
Epoch 476/10000; Iter 51/80; Loss: 0.9709
Epoch 476/10000; Iter 80/80; Training Loss: 0.9850, Test Loss: 0.189
Epoch 477/10000; Iter 1/80; Loss: 0.9553
Epoch 477/10000; Iter 51/80; Loss: 0.9514
Epoch 477/10000; Iter 80/80; Training Loss: 0.9810, Test Loss: 0.181
Epoch 478/10000; Iter 1/80; Loss: 0.8412
Epoch 478/10000; Iter 51/80; Loss: 1.0451
Epoch 478/10000; Iter 80/80; Training Loss: 0.9770, Test Loss: 0.186
Epoch 479/10000; Iter 1/80; Loss: 0.9777
Epoch 479/10000; Iter 51/80; Loss: 0.9464
Epoch 479/10000; Iter 80/80; Training Loss: 0.9720, Test Loss: 0.196
Epoch 480/10000; Iter 1/80; Loss: 1.0046
Epoch 480/10000; Iter 51/80; Loss: 0.9501
Epoch 480/10000; Iter 80/80; Training Loss: 0.9700, Test Loss: 0.195
Epoch 481/10000; Iter 1/80; Loss: 1.0357
Epoch 481/10000; Iter 51/80; Loss: 0.9607
Epoch 481/10000; Iter 80/80; Training Loss: 0.9700, Test Loss: 0.175
Epoch 482/10000; Iter 1/80; Loss: 0.9748
Epoch 482/10000; Iter 51/80; Loss: 0.8643
Epoch 482/10000; Iter 80/80; Training Loss: 0.9640, Test Loss: 0.183
Epoch 483/10000; Iter 1/80; Loss: 0.9701
Epoch 483/10000; Iter 51/80; Loss: 1.0232
Epoch 483/10000; Iter 80/80; Training Loss: 0.9800, Test Loss: 0.183
Epoch 484/10000; Iter 1/80; Loss: 0.9226
Epoch 484/10000; Iter 51/80; Loss: 1.0162
Epoch 484/10000; Iter 80/80; Training Loss: 0.9690, Test Loss: 0.158
Epoch 485/10000; Iter 1/80; Loss: 1.0242
Epoch 485/10000; Iter 51/80; Loss: 0.9009
Epoch 485/10000; Iter 80/80; Training Loss: 0.9730, Test Loss: 0.171
Epoch 486/10000; Iter 1/80; Loss: 0.9347
Epoch 486/10000; Iter 51/80; Loss: 0.9318
Epoch 486/10000; Iter 80/80; Training Loss: 0.9630, Test Loss: 0.176
Epoch 487/10000; Iter 1/80; Loss: 1.1114
Epoch 487/10000; Iter 51/80; Loss: 0.9389
Epoch 487/10000; Iter 80/80; Training Loss: 0.9720, Test Loss: 0.186
Epoch 488/10000; Iter 1/80; Loss: 0.9167
Epoch 488/10000; Iter 51/80; Loss: 1.0070
Epoch 488/10000; Iter 80/80; Training Loss: 0.9680, Test Loss: 0.173
Epoch 489/10000; Iter 1/80; Loss: 1.1116
Epoch 489/10000; Iter 51/80; Loss: 0.9429
Epoch 489/10000; Iter 80/80; Training Loss: 0.9680, Test Loss: 0.159
Epoch 490/10000; Iter 1/80; Loss: 1.0135
Epoch 490/10000; Iter 51/80; Loss: 1.0044
Epoch 490/10000; Iter 80/80; Training Loss: 0.9730, Test Loss: 0.16
Epoch 491/10000; Iter 1/80; Loss: 0.9241
Epoch 491/10000; Iter 51/80; Loss: 0.9275
Epoch 491/10000; Iter 80/80; Training Loss: 0.9620, Test Loss: 0.156
Epoch 492/10000; Iter 1/80; Loss: 0.9466
Epoch 492/10000; Iter 51/80; Loss: 0.9155
Epoch 492/10000; Iter 80/80; Training Loss: 0.9630, Test Loss: 0.187
Epoch 493/10000; Iter 1/80; Loss: 0.8684
Epoch 493/10000; Iter 51/80; Loss: 0.8914
Epoch 493/10000; Iter 80/80; Training Loss: 0.9630, Test Loss: 0.193
Epoch 494/10000; Iter 1/80; Loss: 1.0006
Epoch 494/10000; Iter 51/80; Loss: 1.2880
Epoch 494/10000; Iter 80/80; Training Loss: 0.9730, Test Loss: 0.184
Epoch 495/10000; Iter 1/80; Loss: 0.9344
Epoch 495/10000; Iter 51/80; Loss: 0.9884
Epoch 495/10000; Iter 80/80; Training Loss: 0.9720, Test Loss: 0.177
Epoch 496/10000; Iter 1/80; Loss: 1.0644
Epoch 496/10000; Iter 51/80; Loss: 0.8838
Epoch 496/10000; Iter 80/80; Training Loss: 0.9540, Test Loss: 0.176
Epoch 497/10000; Iter 1/80; Loss: 0.9435
Epoch 497/10000; Iter 51/80; Loss: 0.8671
Epoch 497/10000; Iter 80/80; Training Loss: 0.9600, Test Loss: 0.175
Epoch 498/10000; Iter 1/80; Loss: 0.8921
Epoch 498/10000; Iter 51/80; Loss: 0.9948
Epoch 498/10000; Iter 80/80; Training Loss: 0.9520, Test Loss: 0.176
Epoch 499/10000; Iter 1/80; Loss: 1.0316
Epoch 499/10000; Iter 51/80; Loss: 1.0143
Epoch 499/10000; Iter 80/80; Training Loss: 0.9570, Test Loss: 0.172
Epoch 500/10000; Iter 1/80; Loss: 0.9814
Epoch 500/10000; Iter 51/80; Loss: 0.8518
Epoch 500/10000; Iter 80/80; Training Loss: 0.9540, Test Loss: 0.186
Epoch 501/10000; Iter 1/80; Loss: 1.0333
Epoch 501/10000; Iter 51/80; Loss: 0.9025
Epoch 501/10000; Iter 80/80; Training Loss: 0.9540, Test Loss: 0.192
Model saved
Epoch 502/10000; Iter 1/80; Loss: 0.9219
Epoch 502/10000; Iter 51/80; Loss: 0.9929
Epoch 502/10000; Iter 80/80; Training Loss: 0.9550, Test Loss: 0.16
Epoch 503/10000; Iter 1/80; Loss: 0.9177
Epoch 503/10000; Iter 51/80; Loss: 0.9747
Epoch 503/10000; Iter 80/80; Training Loss: 0.9430, Test Loss: 0.163
Epoch 504/10000; Iter 1/80; Loss: 0.8822
Epoch 504/10000; Iter 51/80; Loss: 1.1017
Epoch 504/10000; Iter 80/80; Training Loss: 0.9570, Test Loss: 0.167
Epoch 505/10000; Iter 1/80; Loss: 0.9957
Epoch 505/10000; Iter 51/80; Loss: 1.0370
Epoch 505/10000; Iter 80/80; Training Loss: 0.9550, Test Loss: 0.156
Epoch 506/10000; Iter 1/80; Loss: 0.9648
Epoch 506/10000; Iter 51/80; Loss: 0.8499
Epoch 506/10000; Iter 80/80; Training Loss: 0.9460, Test Loss: 0.169
Epoch 507/10000; Iter 1/80; Loss: 0.8271
Epoch 507/10000; Iter 51/80; Loss: 0.9249
Epoch 507/10000; Iter 80/80; Training Loss: 0.9540, Test Loss: 0.158
Epoch 508/10000; Iter 1/80; Loss: 0.9983
Epoch 508/10000; Iter 51/80; Loss: 0.9502
Epoch 508/10000; Iter 80/80; Training Loss: 0.9550, Test Loss: 0.171
Epoch 509/10000; Iter 1/80; Loss: 0.9355
Epoch 509/10000; Iter 51/80; Loss: 0.9687
Epoch 509/10000; Iter 80/80; Training Loss: 0.9420, Test Loss: 0.169
Epoch 510/10000; Iter 1/80; Loss: 0.9416
Epoch 510/10000; Iter 51/80; Loss: 0.9470
Epoch 510/10000; Iter 80/80; Training Loss: 0.9380, Test Loss: 0.189
Epoch 511/10000; Iter 1/80; Loss: 0.9864
Epoch 511/10000; Iter 51/80; Loss: 0.9025
Epoch 511/10000; Iter 80/80; Training Loss: 0.9540, Test Loss: 0.167
Epoch 512/10000; Iter 1/80; Loss: 0.9067
Epoch 512/10000; Iter 51/80; Loss: 0.8798
Epoch 512/10000; Iter 80/80; Training Loss: 0.9470, Test Loss: 0.175
Epoch 513/10000; Iter 1/80; Loss: 0.9562
Epoch 513/10000; Iter 51/80; Loss: 0.9402
Epoch 513/10000; Iter 80/80; Training Loss: 0.9390, Test Loss: 0.169
Epoch 514/10000; Iter 1/80; Loss: 0.9586
Epoch 514/10000; Iter 51/80; Loss: 0.9503
Epoch 514/10000; Iter 80/80; Training Loss: 0.9450, Test Loss: 0.154
Epoch 515/10000; Iter 1/80; Loss: 1.0581
Epoch 515/10000; Iter 51/80; Loss: 0.8405
Epoch 515/10000; Iter 80/80; Training Loss: 0.9450, Test Loss: 0.156
Epoch 516/10000; Iter 1/80; Loss: 0.9184
Epoch 516/10000; Iter 51/80; Loss: 0.8455
Epoch 516/10000; Iter 80/80; Training Loss: 0.9510, Test Loss: 0.17
Epoch 517/10000; Iter 1/80; Loss: 0.9144
Epoch 517/10000; Iter 51/80; Loss: 0.9216
Epoch 517/10000; Iter 80/80; Training Loss: 0.9420, Test Loss: 0.162
Epoch 518/10000; Iter 1/80; Loss: 0.9217
Epoch 518/10000; Iter 51/80; Loss: 0.8472
Epoch 518/10000; Iter 80/80; Training Loss: 0.9490, Test Loss: 0.14
Epoch 519/10000; Iter 1/80; Loss: 0.8417
Epoch 519/10000; Iter 51/80; Loss: 0.9572
Epoch 519/10000; Iter 80/80; Training Loss: 0.9400, Test Loss: 0.179
Epoch 520/10000; Iter 1/80; Loss: 0.9823
Epoch 520/10000; Iter 51/80; Loss: 0.9279
Epoch 520/10000; Iter 80/80; Training Loss: 0.9350, Test Loss: 0.173
Epoch 521/10000; Iter 1/80; Loss: 0.9331
Epoch 521/10000; Iter 51/80; Loss: 0.8507
Epoch 521/10000; Iter 80/80; Training Loss: 0.9300, Test Loss: 0.154
Epoch 522/10000; Iter 1/80; Loss: 0.8349
Epoch 522/10000; Iter 51/80; Loss: 0.9703
Epoch 522/10000; Iter 80/80; Training Loss: 0.9400, Test Loss: 0.156
Epoch 523/10000; Iter 1/80; Loss: 0.9172
Epoch 523/10000; Iter 51/80; Loss: 0.9969
Epoch 523/10000; Iter 80/80; Training Loss: 0.9370, Test Loss: 0.173
Epoch 524/10000; Iter 1/80; Loss: 0.9652
Epoch 524/10000; Iter 51/80; Loss: 0.9225
Epoch 524/10000; Iter 80/80; Training Loss: 0.9240, Test Loss: 0.165
Epoch 525/10000; Iter 1/80; Loss: 0.9132
Epoch 525/10000; Iter 51/80; Loss: 0.9990
Epoch 525/10000; Iter 80/80; Training Loss: 0.9300, Test Loss: 0.171
Epoch 526/10000; Iter 1/80; Loss: 0.9798
Epoch 526/10000; Iter 51/80; Loss: 1.0160
Epoch 526/10000; Iter 80/80; Training Loss: 0.9270, Test Loss: 0.151
Epoch 527/10000; Iter 1/80; Loss: 0.9717
Epoch 527/10000; Iter 51/80; Loss: 0.9355
Epoch 527/10000; Iter 80/80; Training Loss: 0.9280, Test Loss: 0.139
Epoch 528/10000; Iter 1/80; Loss: 0.9224
Epoch 528/10000; Iter 51/80; Loss: 0.8159
Epoch 528/10000; Iter 80/80; Training Loss: 0.9340, Test Loss: 0.162
Epoch 529/10000; Iter 1/80; Loss: 0.9427
Epoch 529/10000; Iter 51/80; Loss: 1.0328
Epoch 529/10000; Iter 80/80; Training Loss: 0.9450, Test Loss: 0.164
Epoch 530/10000; Iter 1/80; Loss: 0.9531
Epoch 530/10000; Iter 51/80; Loss: 0.8772
Epoch 530/10000; Iter 80/80; Training Loss: 0.9400, Test Loss: 0.146
Epoch 531/10000; Iter 1/80; Loss: 1.0069
Epoch 531/10000; Iter 51/80; Loss: 0.9164
Epoch 531/10000; Iter 80/80; Training Loss: 0.9370, Test Loss: 0.162
Epoch 532/10000; Iter 1/80; Loss: 0.9328
Epoch 532/10000; Iter 51/80; Loss: 0.9140
Epoch 532/10000; Iter 80/80; Training Loss: 0.9240, Test Loss: 0.171
Epoch 533/10000; Iter 1/80; Loss: 0.9183
Epoch 533/10000; Iter 51/80; Loss: 0.9668
Epoch 533/10000; Iter 80/80; Training Loss: 0.9360, Test Loss: 0.157
Epoch 534/10000; Iter 1/80; Loss: 0.9722
Epoch 534/10000; Iter 51/80; Loss: 0.8376
Epoch 534/10000; Iter 80/80; Training Loss: 0.9260, Test Loss: 0.154
Epoch 535/10000; Iter 1/80; Loss: 0.9331
Epoch 535/10000; Iter 51/80; Loss: 0.8863
Epoch 535/10000; Iter 80/80; Training Loss: 0.9150, Test Loss: 0.158
Epoch 536/10000; Iter 1/80; Loss: 1.0129
Epoch 536/10000; Iter 51/80; Loss: 0.8360
Epoch 536/10000; Iter 80/80; Training Loss: 0.9220, Test Loss: 0.128
Epoch 537/10000; Iter 1/80; Loss: 0.9042
Epoch 537/10000; Iter 51/80; Loss: 0.9691
Epoch 537/10000; Iter 80/80; Training Loss: 0.9210, Test Loss: 0.154
Epoch 538/10000; Iter 1/80; Loss: 0.9170
Epoch 538/10000; Iter 51/80; Loss: 0.9694
Epoch 538/10000; Iter 80/80; Training Loss: 0.9360, Test Loss: 0.176
Epoch 539/10000; Iter 1/80; Loss: 0.8893
Epoch 539/10000; Iter 51/80; Loss: 0.9342
Epoch 539/10000; Iter 80/80; Training Loss: 0.9260, Test Loss: 0.166
Epoch 540/10000; Iter 1/80; Loss: 0.9489
Epoch 540/10000; Iter 51/80; Loss: 0.9781
Epoch 540/10000; Iter 80/80; Training Loss: 0.9100, Test Loss: 0.154
Epoch 541/10000; Iter 1/80; Loss: 0.9093
Epoch 541/10000; Iter 51/80; Loss: 0.8533
Epoch 541/10000; Iter 80/80; Training Loss: 0.9110, Test Loss: 0.142
Epoch 542/10000; Iter 1/80; Loss: 0.9802
Epoch 542/10000; Iter 51/80; Loss: 0.9218
Epoch 542/10000; Iter 80/80; Training Loss: 0.9190, Test Loss: 0.159
Epoch 543/10000; Iter 1/80; Loss: 1.0155
Epoch 543/10000; Iter 51/80; Loss: 0.9624
Epoch 543/10000; Iter 80/80; Training Loss: 0.9280, Test Loss: 0.158
Epoch 544/10000; Iter 1/80; Loss: 0.9931
Epoch 544/10000; Iter 51/80; Loss: 0.8104
Epoch 544/10000; Iter 80/80; Training Loss: 0.9040, Test Loss: 0.169
Epoch 545/10000; Iter 1/80; Loss: 0.8300
Epoch 545/10000; Iter 51/80; Loss: 0.9031
Epoch 545/10000; Iter 80/80; Training Loss: 0.9200, Test Loss: 0.156
Epoch 546/10000; Iter 1/80; Loss: 0.9027
Epoch 546/10000; Iter 51/80; Loss: 0.8675
Epoch 546/10000; Iter 80/80; Training Loss: 0.9150, Test Loss: 0.163
Epoch 547/10000; Iter 1/80; Loss: 0.8978
Epoch 547/10000; Iter 51/80; Loss: 0.9363
Epoch 547/10000; Iter 80/80; Training Loss: 0.9210, Test Loss: 0.156
Epoch 548/10000; Iter 1/80; Loss: 0.8989
Epoch 548/10000; Iter 51/80; Loss: 0.8809
Epoch 548/10000; Iter 80/80; Training Loss: 0.9250, Test Loss: 0.152
Epoch 549/10000; Iter 1/80; Loss: 0.8447
Epoch 549/10000; Iter 51/80; Loss: 0.8918
Epoch 549/10000; Iter 80/80; Training Loss: 0.9200, Test Loss: 0.146
Epoch 550/10000; Iter 1/80; Loss: 0.8539
Epoch 550/10000; Iter 51/80; Loss: 0.7709
Epoch 550/10000; Iter 80/80; Training Loss: 0.9060, Test Loss: 0.143
Epoch 551/10000; Iter 1/80; Loss: 0.9461
Epoch 551/10000; Iter 51/80; Loss: 1.0259
Epoch 551/10000; Iter 80/80; Training Loss: 0.9210, Test Loss: 0.145
Epoch 552/10000; Iter 1/80; Loss: 0.8948
Epoch 552/10000; Iter 51/80; Loss: 0.9499
Epoch 552/10000; Iter 80/80; Training Loss: 0.8920, Test Loss: 0.148
Epoch 553/10000; Iter 1/80; Loss: 0.8779
Epoch 553/10000; Iter 51/80; Loss: 0.9735
Epoch 553/10000; Iter 80/80; Training Loss: 0.9080, Test Loss: 0.152
Epoch 554/10000; Iter 1/80; Loss: 0.8019
Epoch 554/10000; Iter 51/80; Loss: 0.8731
Epoch 554/10000; Iter 80/80; Training Loss: 0.9020, Test Loss: 0.135
Epoch 555/10000; Iter 1/80; Loss: 0.8136
Epoch 555/10000; Iter 51/80; Loss: 0.8461
Epoch 555/10000; Iter 80/80; Training Loss: 0.9050, Test Loss: 0.154
Epoch 556/10000; Iter 1/80; Loss: 0.9946
Epoch 556/10000; Iter 51/80; Loss: 0.9910
Epoch 556/10000; Iter 80/80; Training Loss: 0.9100, Test Loss: 0.161
Epoch 557/10000; Iter 1/80; Loss: 0.8072
Epoch 557/10000; Iter 51/80; Loss: 0.9383
Epoch 557/10000; Iter 80/80; Training Loss: 0.8960, Test Loss: 0.144
Epoch 558/10000; Iter 1/80; Loss: 0.9986
Epoch 558/10000; Iter 51/80; Loss: 1.0272
Epoch 558/10000; Iter 80/80; Training Loss: 0.9090, Test Loss: 0.158
Epoch 559/10000; Iter 1/80; Loss: 0.9371
Epoch 559/10000; Iter 51/80; Loss: 0.8564
Epoch 559/10000; Iter 80/80; Training Loss: 0.9090, Test Loss: 0.146
Epoch 560/10000; Iter 1/80; Loss: 0.8070
Epoch 560/10000; Iter 51/80; Loss: 0.8518
Epoch 560/10000; Iter 80/80; Training Loss: 0.9100, Test Loss: 0.165
Epoch 561/10000; Iter 1/80; Loss: 0.8884
Epoch 561/10000; Iter 51/80; Loss: 0.8364
Epoch 561/10000; Iter 80/80; Training Loss: 0.9010, Test Loss: 0.148
Epoch 562/10000; Iter 1/80; Loss: 1.0473
Epoch 562/10000; Iter 51/80; Loss: 0.9895
Epoch 562/10000; Iter 80/80; Training Loss: 0.9060, Test Loss: 0.141
Epoch 563/10000; Iter 1/80; Loss: 0.8612
Epoch 563/10000; Iter 51/80; Loss: 0.8609
Epoch 563/10000; Iter 80/80; Training Loss: 0.9040, Test Loss: 0.157
Epoch 564/10000; Iter 1/80; Loss: 0.9863
Epoch 564/10000; Iter 51/80; Loss: 0.8155
Epoch 564/10000; Iter 80/80; Training Loss: 0.9140, Test Loss: 0.159
Epoch 565/10000; Iter 1/80; Loss: 0.7690
Epoch 565/10000; Iter 51/80; Loss: 1.1106
Epoch 565/10000; Iter 80/80; Training Loss: 0.9010, Test Loss: 0.149
Epoch 566/10000; Iter 1/80; Loss: 0.9747
Epoch 566/10000; Iter 51/80; Loss: 0.8301
Epoch 566/10000; Iter 80/80; Training Loss: 0.8970, Test Loss: 0.161
Epoch 567/10000; Iter 1/80; Loss: 1.1390
Epoch 567/10000; Iter 51/80; Loss: 0.9077
Epoch 567/10000; Iter 80/80; Training Loss: 0.9010, Test Loss: 0.151
Epoch 568/10000; Iter 1/80; Loss: 0.8301
Epoch 568/10000; Iter 51/80; Loss: 0.8373
Epoch 568/10000; Iter 80/80; Training Loss: 0.8970, Test Loss: 0.164
Epoch 569/10000; Iter 1/80; Loss: 0.7955
Epoch 569/10000; Iter 51/80; Loss: 0.9916
Epoch 569/10000; Iter 80/80; Training Loss: 0.9060, Test Loss: 0.139
Epoch 570/10000; Iter 1/80; Loss: 0.9208
Epoch 570/10000; Iter 51/80; Loss: 0.8992
Epoch 570/10000; Iter 80/80; Training Loss: 0.9010, Test Loss: 0.146
Epoch 571/10000; Iter 1/80; Loss: 0.8025
Epoch 571/10000; Iter 51/80; Loss: 0.9321
Epoch 571/10000; Iter 80/80; Training Loss: 0.9000, Test Loss: 0.151
Epoch 572/10000; Iter 1/80; Loss: 0.9553
Epoch 572/10000; Iter 51/80; Loss: 0.9823
Epoch 572/10000; Iter 80/80; Training Loss: 0.8850, Test Loss: 0.156
Epoch 573/10000; Iter 1/80; Loss: 0.7849
Epoch 573/10000; Iter 51/80; Loss: 0.8921
Epoch 573/10000; Iter 80/80; Training Loss: 0.8880, Test Loss: 0.128
Epoch 574/10000; Iter 1/80; Loss: 0.8738
Epoch 574/10000; Iter 51/80; Loss: 0.9264
Epoch 574/10000; Iter 80/80; Training Loss: 0.8940, Test Loss: 0.162
Epoch 575/10000; Iter 1/80; Loss: 1.0080
Epoch 575/10000; Iter 51/80; Loss: 0.8134
Epoch 575/10000; Iter 80/80; Training Loss: 0.8910, Test Loss: 0.135
Epoch 576/10000; Iter 1/80; Loss: 0.8885
Epoch 576/10000; Iter 51/80; Loss: 0.8985
Epoch 576/10000; Iter 80/80; Training Loss: 0.8860, Test Loss: 0.151
Epoch 577/10000; Iter 1/80; Loss: 0.9379
Epoch 577/10000; Iter 51/80; Loss: 0.9090
Epoch 577/10000; Iter 80/80; Training Loss: 0.9080, Test Loss: 0.144
Epoch 578/10000; Iter 1/80; Loss: 0.8774
Epoch 578/10000; Iter 51/80; Loss: 0.8165
Epoch 578/10000; Iter 80/80; Training Loss: 0.8930, Test Loss: 0.136
Epoch 579/10000; Iter 1/80; Loss: 0.8071
Epoch 579/10000; Iter 51/80; Loss: 0.8734
Epoch 579/10000; Iter 80/80; Training Loss: 0.8930, Test Loss: 0.15
Epoch 580/10000; Iter 1/80; Loss: 0.8593
Epoch 580/10000; Iter 51/80; Loss: 0.9118
Epoch 580/10000; Iter 80/80; Training Loss: 0.8850, Test Loss: 0.156
Epoch 581/10000; Iter 1/80; Loss: 0.9222
Epoch 581/10000; Iter 51/80; Loss: 0.8016
Epoch 581/10000; Iter 80/80; Training Loss: 0.8930, Test Loss: 0.138
Epoch 582/10000; Iter 1/80; Loss: 0.8961
Epoch 582/10000; Iter 51/80; Loss: 0.9885
Epoch 582/10000; Iter 80/80; Training Loss: 0.8840, Test Loss: 0.144
Epoch 583/10000; Iter 1/80; Loss: 0.8488
Epoch 583/10000; Iter 51/80; Loss: 0.9069
Epoch 583/10000; Iter 80/80; Training Loss: 0.8830, Test Loss: 0.151
Epoch 584/10000; Iter 1/80; Loss: 0.9224
Epoch 584/10000; Iter 51/80; Loss: 0.8592
Epoch 584/10000; Iter 80/80; Training Loss: 0.9060, Test Loss: 0.147
Epoch 585/10000; Iter 1/80; Loss: 0.8066
Epoch 585/10000; Iter 51/80; Loss: 0.9129
Epoch 585/10000; Iter 80/80; Training Loss: 0.8850, Test Loss: 0.141
Epoch 586/10000; Iter 1/80; Loss: 0.9212
Epoch 586/10000; Iter 51/80; Loss: 0.9523
Epoch 586/10000; Iter 80/80; Training Loss: 0.8870, Test Loss: 0.133
Epoch 587/10000; Iter 1/80; Loss: 0.8157
Epoch 587/10000; Iter 51/80; Loss: 0.9737
Epoch 587/10000; Iter 80/80; Training Loss: 0.8820, Test Loss: 0.151
Epoch 588/10000; Iter 1/80; Loss: 1.0255
Epoch 588/10000; Iter 51/80; Loss: 1.0179
Epoch 588/10000; Iter 80/80; Training Loss: 0.8970, Test Loss: 0.147
Epoch 589/10000; Iter 1/80; Loss: 0.8778
Epoch 589/10000; Iter 51/80; Loss: 0.9486
Epoch 589/10000; Iter 80/80; Training Loss: 0.8910, Test Loss: 0.146
Epoch 590/10000; Iter 1/80; Loss: 0.8296
Epoch 590/10000; Iter 51/80; Loss: 0.8484
Epoch 590/10000; Iter 80/80; Training Loss: 0.8780, Test Loss: 0.128
Epoch 591/10000; Iter 1/80; Loss: 0.8959
Epoch 591/10000; Iter 51/80; Loss: 0.8886
Epoch 591/10000; Iter 80/80; Training Loss: 0.8780, Test Loss: 0.162
Epoch 592/10000; Iter 1/80; Loss: 0.8570
Epoch 592/10000; Iter 51/80; Loss: 0.8328
Epoch 592/10000; Iter 80/80; Training Loss: 0.8860, Test Loss: 0.146
Epoch 593/10000; Iter 1/80; Loss: 0.7867
Epoch 593/10000; Iter 51/80; Loss: 0.9541
Epoch 593/10000; Iter 80/80; Training Loss: 0.8850, Test Loss: 0.147
Epoch 594/10000; Iter 1/80; Loss: 0.9706
Epoch 594/10000; Iter 51/80; Loss: 0.7796
Epoch 594/10000; Iter 80/80; Training Loss: 0.8740, Test Loss: 0.136
Epoch 595/10000; Iter 1/80; Loss: 0.8125
Epoch 595/10000; Iter 51/80; Loss: 1.0256
Epoch 595/10000; Iter 80/80; Training Loss: 0.8830, Test Loss: 0.133
Epoch 596/10000; Iter 1/80; Loss: 0.9116
Epoch 596/10000; Iter 51/80; Loss: 0.9828
Epoch 596/10000; Iter 80/80; Training Loss: 0.8900, Test Loss: 0.165
Epoch 597/10000; Iter 1/80; Loss: 0.8026
Epoch 597/10000; Iter 51/80; Loss: 0.8462
Epoch 597/10000; Iter 80/80; Training Loss: 0.8780, Test Loss: 0.175
Epoch 598/10000; Iter 1/80; Loss: 0.9011
Epoch 598/10000; Iter 51/80; Loss: 0.8483
Epoch 598/10000; Iter 80/80; Training Loss: 0.8840, Test Loss: 0.139
Epoch 599/10000; Iter 1/80; Loss: 0.8485
Epoch 599/10000; Iter 51/80; Loss: 0.8397
Epoch 599/10000; Iter 80/80; Training Loss: 0.8870, Test Loss: 0.138
Epoch 600/10000; Iter 1/80; Loss: 0.8979
Epoch 600/10000; Iter 51/80; Loss: 0.8449
Epoch 600/10000; Iter 80/80; Training Loss: 0.8680, Test Loss: 0.15
Epoch 601/10000; Iter 1/80; Loss: 0.8653
Epoch 601/10000; Iter 51/80; Loss: 0.9044
Epoch 601/10000; Iter 80/80; Training Loss: 0.8740, Test Loss: 0.151
Model saved
Epoch 602/10000; Iter 1/80; Loss: 0.9891
Epoch 602/10000; Iter 51/80; Loss: 0.9042
Epoch 602/10000; Iter 80/80; Training Loss: 0.8790, Test Loss: 0.137
Epoch 603/10000; Iter 1/80; Loss: 0.8702
Epoch 603/10000; Iter 51/80; Loss: 0.9878
Epoch 603/10000; Iter 80/80; Training Loss: 0.8770, Test Loss: 0.148
Epoch 604/10000; Iter 1/80; Loss: 0.9231
Epoch 604/10000; Iter 51/80; Loss: 1.0016
Epoch 604/10000; Iter 80/80; Training Loss: 0.8710, Test Loss: 0.128
Epoch 605/10000; Iter 1/80; Loss: 0.8936
Epoch 605/10000; Iter 51/80; Loss: 0.8364
Epoch 605/10000; Iter 80/80; Training Loss: 0.8720, Test Loss: 0.141
Epoch 606/10000; Iter 1/80; Loss: 0.8477
Epoch 606/10000; Iter 51/80; Loss: 0.8507
Epoch 606/10000; Iter 80/80; Training Loss: 0.8740, Test Loss: 0.145
Epoch 607/10000; Iter 1/80; Loss: 0.9089
Epoch 607/10000; Iter 51/80; Loss: 0.9485
Epoch 607/10000; Iter 80/80; Training Loss: 0.8650, Test Loss: 0.14
Epoch 608/10000; Iter 1/80; Loss: 0.8553
Epoch 608/10000; Iter 51/80; Loss: 0.9680
Epoch 608/10000; Iter 80/80; Training Loss: 0.8760, Test Loss: 0.134
Epoch 609/10000; Iter 1/80; Loss: 0.9214
Epoch 609/10000; Iter 51/80; Loss: 0.8011
Epoch 609/10000; Iter 80/80; Training Loss: 0.8760, Test Loss: 0.143
Epoch 610/10000; Iter 1/80; Loss: 0.7536
Epoch 610/10000; Iter 51/80; Loss: 0.9967
Epoch 610/10000; Iter 80/80; Training Loss: 0.8750, Test Loss: 0.144
Epoch 611/10000; Iter 1/80; Loss: 1.0026
Epoch 611/10000; Iter 51/80; Loss: 1.0111
Epoch 611/10000; Iter 80/80; Training Loss: 0.8680, Test Loss: 0.139
Epoch 612/10000; Iter 1/80; Loss: 0.8706
Epoch 612/10000; Iter 51/80; Loss: 0.7762
Epoch 612/10000; Iter 80/80; Training Loss: 0.8710, Test Loss: 0.131
Epoch 613/10000; Iter 1/80; Loss: 0.7429
Epoch 613/10000; Iter 51/80; Loss: 0.8389
Epoch 613/10000; Iter 80/80; Training Loss: 0.8610, Test Loss: 0.155
Epoch 614/10000; Iter 1/80; Loss: 0.9724
Epoch 614/10000; Iter 51/80; Loss: 0.8813
Epoch 614/10000; Iter 80/80; Training Loss: 0.8720, Test Loss: 0.16
Epoch 615/10000; Iter 1/80; Loss: 0.9168
Epoch 615/10000; Iter 51/80; Loss: 0.9987
Epoch 615/10000; Iter 80/80; Training Loss: 0.8700, Test Loss: 0.142
Epoch 616/10000; Iter 1/80; Loss: 0.8905
Epoch 616/10000; Iter 51/80; Loss: 0.8550
Epoch 616/10000; Iter 80/80; Training Loss: 0.8630, Test Loss: 0.124
Epoch 617/10000; Iter 1/80; Loss: 0.9243
Epoch 617/10000; Iter 51/80; Loss: 0.9068
Epoch 617/10000; Iter 80/80; Training Loss: 0.8770, Test Loss: 0.15
Epoch 618/10000; Iter 1/80; Loss: 0.8589
Epoch 618/10000; Iter 51/80; Loss: 0.8519
Epoch 618/10000; Iter 80/80; Training Loss: 0.8590, Test Loss: 0.144
Epoch 619/10000; Iter 1/80; Loss: 0.9466
Epoch 619/10000; Iter 51/80; Loss: 0.9068
Epoch 619/10000; Iter 80/80; Training Loss: 0.8620, Test Loss: 0.146
Epoch 620/10000; Iter 1/80; Loss: 0.7857
Epoch 620/10000; Iter 51/80; Loss: 0.8664
Epoch 620/10000; Iter 80/80; Training Loss: 0.8610, Test Loss: 0.15
Epoch 621/10000; Iter 1/80; Loss: 0.8530
Epoch 621/10000; Iter 51/80; Loss: 0.7539
Epoch 621/10000; Iter 80/80; Training Loss: 0.8700, Test Loss: 0.129
Epoch 622/10000; Iter 1/80; Loss: 0.8836
Epoch 622/10000; Iter 51/80; Loss: 0.8229
Epoch 622/10000; Iter 80/80; Training Loss: 0.8570, Test Loss: 0.113
Epoch 623/10000; Iter 1/80; Loss: 0.7906
Epoch 623/10000; Iter 51/80; Loss: 0.8119
Epoch 623/10000; Iter 80/80; Training Loss: 0.8670, Test Loss: 0.134
Epoch 624/10000; Iter 1/80; Loss: 0.8986
Epoch 624/10000; Iter 51/80; Loss: 0.8535
Epoch 624/10000; Iter 80/80; Training Loss: 0.8610, Test Loss: 0.155
Epoch 625/10000; Iter 1/80; Loss: 0.8950
Epoch 625/10000; Iter 51/80; Loss: 0.8560
Epoch 625/10000; Iter 80/80; Training Loss: 0.8810, Test Loss: 0.119
Epoch 626/10000; Iter 1/80; Loss: 0.8084
Epoch 626/10000; Iter 51/80; Loss: 0.8188
Epoch 626/10000; Iter 80/80; Training Loss: 0.8470, Test Loss: 0.144
Epoch 627/10000; Iter 1/80; Loss: 0.9151
Epoch 627/10000; Iter 51/80; Loss: 0.7692
Epoch 627/10000; Iter 80/80; Training Loss: 0.8720, Test Loss: 0.151
Epoch 628/10000; Iter 1/80; Loss: 0.9038
Epoch 628/10000; Iter 51/80; Loss: 0.8297
Epoch 628/10000; Iter 80/80; Training Loss: 0.8560, Test Loss: 0.142
Epoch 629/10000; Iter 1/80; Loss: 0.7775
Epoch 629/10000; Iter 51/80; Loss: 0.9310
Epoch 629/10000; Iter 80/80; Training Loss: 0.8520, Test Loss: 0.139
Epoch 630/10000; Iter 1/80; Loss: 0.8580
Epoch 630/10000; Iter 51/80; Loss: 0.8656
Epoch 630/10000; Iter 80/80; Training Loss: 0.8540, Test Loss: 0.122
Epoch 631/10000; Iter 1/80; Loss: 0.9232
Epoch 631/10000; Iter 51/80; Loss: 0.7980
Epoch 631/10000; Iter 80/80; Training Loss: 0.8570, Test Loss: 0.135
Epoch 632/10000; Iter 1/80; Loss: 0.8383
Epoch 632/10000; Iter 51/80; Loss: 0.9184
Epoch 632/10000; Iter 80/80; Training Loss: 0.8610, Test Loss: 0.143
Epoch 633/10000; Iter 1/80; Loss: 0.7346
Epoch 633/10000; Iter 51/80; Loss: 0.8297
Epoch 633/10000; Iter 80/80; Training Loss: 0.8580, Test Loss: 0.134
Epoch 634/10000; Iter 1/80; Loss: 0.9055
Epoch 634/10000; Iter 51/80; Loss: 0.8538
Epoch 634/10000; Iter 80/80; Training Loss: 0.8530, Test Loss: 0.137
Epoch 635/10000; Iter 1/80; Loss: 0.8701
Epoch 635/10000; Iter 51/80; Loss: 0.7293
Epoch 635/10000; Iter 80/80; Training Loss: 0.8490, Test Loss: 0.157
Epoch 636/10000; Iter 1/80; Loss: 0.8891
Epoch 636/10000; Iter 51/80; Loss: 0.8934
Epoch 636/10000; Iter 80/80; Training Loss: 0.8610, Test Loss: 0.141
Epoch 637/10000; Iter 1/80; Loss: 0.9697
Epoch 637/10000; Iter 51/80; Loss: 0.8674
Epoch 637/10000; Iter 80/80; Training Loss: 0.8490, Test Loss: 0.141
Epoch 638/10000; Iter 1/80; Loss: 0.8282
Epoch 638/10000; Iter 51/80; Loss: 0.7491
Epoch 638/10000; Iter 80/80; Training Loss: 0.8670, Test Loss: 0.154
Epoch 639/10000; Iter 1/80; Loss: 0.8835
Epoch 639/10000; Iter 51/80; Loss: 0.8325
Epoch 639/10000; Iter 80/80; Training Loss: 0.8590, Test Loss: 0.132
Epoch 640/10000; Iter 1/80; Loss: 0.8846
Epoch 640/10000; Iter 51/80; Loss: 0.9667
Epoch 640/10000; Iter 80/80; Training Loss: 0.8510, Test Loss: 0.158
Epoch 641/10000; Iter 1/80; Loss: 0.9382
Epoch 641/10000; Iter 51/80; Loss: 0.7760
Epoch 641/10000; Iter 80/80; Training Loss: 0.8510, Test Loss: 0.123
Epoch 642/10000; Iter 1/80; Loss: 0.8617
Epoch 642/10000; Iter 51/80; Loss: 0.7974
Epoch 642/10000; Iter 80/80; Training Loss: 0.8550, Test Loss: 0.131
Epoch 643/10000; Iter 1/80; Loss: 0.8810
Epoch 643/10000; Iter 51/80; Loss: 0.8057
Epoch 643/10000; Iter 80/80; Training Loss: 0.8550, Test Loss: 0.137
Epoch 644/10000; Iter 1/80; Loss: 0.8835
Epoch 644/10000; Iter 51/80; Loss: 0.7290
Epoch 644/10000; Iter 80/80; Training Loss: 0.8440, Test Loss: 0.126
Epoch 645/10000; Iter 1/80; Loss: 0.8306
Epoch 645/10000; Iter 51/80; Loss: 0.8367
Epoch 645/10000; Iter 80/80; Training Loss: 0.8460, Test Loss: 0.131
Epoch 646/10000; Iter 1/80; Loss: 0.7538
Epoch 646/10000; Iter 51/80; Loss: 0.9402
Epoch 646/10000; Iter 80/80; Training Loss: 0.8500, Test Loss: 0.132
Epoch 647/10000; Iter 1/80; Loss: 0.7268
Epoch 647/10000; Iter 51/80; Loss: 0.8280
Epoch 647/10000; Iter 80/80; Training Loss: 0.8470, Test Loss: 0.137
Epoch 648/10000; Iter 1/80; Loss: 0.7753
Epoch 648/10000; Iter 51/80; Loss: 0.7987
Epoch 648/10000; Iter 80/80; Training Loss: 0.8530, Test Loss: 0.132
Epoch 649/10000; Iter 1/80; Loss: 0.7790
Epoch 649/10000; Iter 51/80; Loss: 0.7793
Epoch 649/10000; Iter 80/80; Training Loss: 0.8550, Test Loss: 0.13
Epoch 650/10000; Iter 1/80; Loss: 0.7376
Epoch 650/10000; Iter 51/80; Loss: 1.0082
Epoch 650/10000; Iter 80/80; Training Loss: 0.8540, Test Loss: 0.14
Epoch 651/10000; Iter 1/80; Loss: 0.9213
Epoch 651/10000; Iter 51/80; Loss: 0.8678
Epoch 651/10000; Iter 80/80; Training Loss: 0.8490, Test Loss: 0.14
Epoch 652/10000; Iter 1/80; Loss: 0.7986
Epoch 652/10000; Iter 51/80; Loss: 0.8155
Epoch 652/10000; Iter 80/80; Training Loss: 0.8490, Test Loss: 0.12
Epoch 653/10000; Iter 1/80; Loss: 0.8852
Epoch 653/10000; Iter 51/80; Loss: 0.9697
Epoch 653/10000; Iter 80/80; Training Loss: 0.8610, Test Loss: 0.13
Epoch 654/10000; Iter 1/80; Loss: 0.8932
Epoch 654/10000; Iter 51/80; Loss: 0.7841
Epoch 654/10000; Iter 80/80; Training Loss: 0.8650, Test Loss: 0.142
Epoch 655/10000; Iter 1/80; Loss: 0.8841
Epoch 655/10000; Iter 51/80; Loss: 0.8694
Epoch 655/10000; Iter 80/80; Training Loss: 0.8420, Test Loss: 0.135
Epoch 656/10000; Iter 1/80; Loss: 0.8164
Epoch 656/10000; Iter 51/80; Loss: 0.8875
Epoch 656/10000; Iter 80/80; Training Loss: 0.8440, Test Loss: 0.141
Epoch 657/10000; Iter 1/80; Loss: 0.8147
Epoch 657/10000; Iter 51/80; Loss: 0.8128
Epoch 657/10000; Iter 80/80; Training Loss: 0.8410, Test Loss: 0.125
Epoch 658/10000; Iter 1/80; Loss: 0.8249
Epoch 658/10000; Iter 51/80; Loss: 0.8085
Epoch 658/10000; Iter 80/80; Training Loss: 0.8460, Test Loss: 0.132
Epoch 659/10000; Iter 1/80; Loss: 0.8058
Epoch 659/10000; Iter 51/80; Loss: 0.8812
Epoch 659/10000; Iter 80/80; Training Loss: 0.8470, Test Loss: 0.132
Epoch 660/10000; Iter 1/80; Loss: 0.8242
Epoch 660/10000; Iter 51/80; Loss: 0.8389
Epoch 660/10000; Iter 80/80; Training Loss: 0.8420, Test Loss: 0.134
Epoch 661/10000; Iter 1/80; Loss: 0.8868
Epoch 661/10000; Iter 51/80; Loss: 0.8146
Epoch 661/10000; Iter 80/80; Training Loss: 0.8380, Test Loss: 0.136
Epoch 662/10000; Iter 1/80; Loss: 0.7739
Epoch 662/10000; Iter 51/80; Loss: 0.8461
Epoch 662/10000; Iter 80/80; Training Loss: 0.8480, Test Loss: 0.111
Epoch 663/10000; Iter 1/80; Loss: 0.7857
Epoch 663/10000; Iter 51/80; Loss: 0.8310
Epoch 663/10000; Iter 80/80; Training Loss: 0.8500, Test Loss: 0.127
Epoch 664/10000; Iter 1/80; Loss: 0.7715
Epoch 664/10000; Iter 51/80; Loss: 0.7884
Epoch 664/10000; Iter 80/80; Training Loss: 0.8340, Test Loss: 0.138
Epoch 665/10000; Iter 1/80; Loss: 0.8083
Epoch 665/10000; Iter 51/80; Loss: 0.8371
Epoch 665/10000; Iter 80/80; Training Loss: 0.8310, Test Loss: 0.135
Epoch 666/10000; Iter 1/80; Loss: 0.8287
Epoch 666/10000; Iter 51/80; Loss: 0.7896
Epoch 666/10000; Iter 80/80; Training Loss: 0.8340, Test Loss: 0.116
Epoch 667/10000; Iter 1/80; Loss: 0.9176
Epoch 667/10000; Iter 51/80; Loss: 0.8278
Epoch 667/10000; Iter 80/80; Training Loss: 0.8490, Test Loss: 0.135
Epoch 668/10000; Iter 1/80; Loss: 0.9072
Epoch 668/10000; Iter 51/80; Loss: 0.8399
Epoch 668/10000; Iter 80/80; Training Loss: 0.8340, Test Loss: 0.136
Epoch 669/10000; Iter 1/80; Loss: 0.7448
Epoch 669/10000; Iter 51/80; Loss: 0.7558
Epoch 669/10000; Iter 80/80; Training Loss: 0.8390, Test Loss: 0.135
Epoch 670/10000; Iter 1/80; Loss: 0.8088
Epoch 670/10000; Iter 51/80; Loss: 0.8329
Epoch 670/10000; Iter 80/80; Training Loss: 0.8300, Test Loss: 0.116
Epoch 671/10000; Iter 1/80; Loss: 0.8171
Epoch 671/10000; Iter 51/80; Loss: 0.8299
Epoch 671/10000; Iter 80/80; Training Loss: 0.8300, Test Loss: 0.112
Epoch 672/10000; Iter 1/80; Loss: 0.8715
Epoch 672/10000; Iter 51/80; Loss: 0.8010
Epoch 672/10000; Iter 80/80; Training Loss: 0.8340, Test Loss: 0.133
Epoch 673/10000; Iter 1/80; Loss: 0.7809
Epoch 673/10000; Iter 51/80; Loss: 0.7975
Epoch 673/10000; Iter 80/80; Training Loss: 0.8340, Test Loss: 0.125
Epoch 674/10000; Iter 1/80; Loss: 0.8026
Epoch 674/10000; Iter 51/80; Loss: 0.7464
Epoch 674/10000; Iter 80/80; Training Loss: 0.8370, Test Loss: 0.131
Epoch 675/10000; Iter 1/80; Loss: 0.7908
Epoch 675/10000; Iter 51/80; Loss: 0.9067
Epoch 675/10000; Iter 80/80; Training Loss: 0.8460, Test Loss: 0.126
Epoch 676/10000; Iter 1/80; Loss: 0.8423
Epoch 676/10000; Iter 51/80; Loss: 0.7497
Epoch 676/10000; Iter 80/80; Training Loss: 0.8300, Test Loss: 0.134
Epoch 677/10000; Iter 1/80; Loss: 0.8411
Epoch 677/10000; Iter 51/80; Loss: 1.1280
Epoch 677/10000; Iter 80/80; Training Loss: 0.8440, Test Loss: 0.129
Epoch 678/10000; Iter 1/80; Loss: 0.9144
Epoch 678/10000; Iter 51/80; Loss: 0.8759
Epoch 678/10000; Iter 80/80; Training Loss: 0.8340, Test Loss: 0.136
Epoch 679/10000; Iter 1/80; Loss: 0.7840
Epoch 679/10000; Iter 51/80; Loss: 0.7987
Epoch 679/10000; Iter 80/80; Training Loss: 0.8250, Test Loss: 0.134
Epoch 680/10000; Iter 1/80; Loss: 0.7671
Epoch 680/10000; Iter 51/80; Loss: 0.8110
Epoch 680/10000; Iter 80/80; Training Loss: 0.8330, Test Loss: 0.118
Epoch 681/10000; Iter 1/80; Loss: 0.8752
Epoch 681/10000; Iter 51/80; Loss: 0.8307
Epoch 681/10000; Iter 80/80; Training Loss: 0.8440, Test Loss: 0.138
Epoch 682/10000; Iter 1/80; Loss: 0.8528
Epoch 682/10000; Iter 51/80; Loss: 0.8601
Epoch 682/10000; Iter 80/80; Training Loss: 0.8240, Test Loss: 0.123
Epoch 683/10000; Iter 1/80; Loss: 0.7448
Epoch 683/10000; Iter 51/80; Loss: 0.8756
Epoch 683/10000; Iter 80/80; Training Loss: 0.8280, Test Loss: 0.128
Epoch 684/10000; Iter 1/80; Loss: 0.8584
Epoch 684/10000; Iter 51/80; Loss: 0.8541
Epoch 684/10000; Iter 80/80; Training Loss: 0.8160, Test Loss: 0.118
Epoch 685/10000; Iter 1/80; Loss: 0.8622
Epoch 685/10000; Iter 51/80; Loss: 0.8271
Epoch 685/10000; Iter 80/80; Training Loss: 0.8210, Test Loss: 0.115
Epoch 686/10000; Iter 1/80; Loss: 0.8749
Epoch 686/10000; Iter 51/80; Loss: 0.7188
Epoch 686/10000; Iter 80/80; Training Loss: 0.8380, Test Loss: 0.126
Epoch 687/10000; Iter 1/80; Loss: 0.9608
Epoch 687/10000; Iter 51/80; Loss: 0.7462
Epoch 687/10000; Iter 80/80; Training Loss: 0.8320, Test Loss: 0.139
Epoch 688/10000; Iter 1/80; Loss: 0.7725
Epoch 688/10000; Iter 51/80; Loss: 0.8679
Epoch 688/10000; Iter 80/80; Training Loss: 0.8200, Test Loss: 0.138
Epoch 689/10000; Iter 1/80; Loss: 0.8254
Epoch 689/10000; Iter 51/80; Loss: 0.8248
Epoch 689/10000; Iter 80/80; Training Loss: 0.8140, Test Loss: 0.126
Epoch 690/10000; Iter 1/80; Loss: 0.9116
Epoch 690/10000; Iter 51/80; Loss: 0.8064
Epoch 690/10000; Iter 80/80; Training Loss: 0.8260, Test Loss: 0.117
Epoch 691/10000; Iter 1/80; Loss: 0.9676
Epoch 691/10000; Iter 51/80; Loss: 0.7905
Epoch 691/10000; Iter 80/80; Training Loss: 0.8280, Test Loss: 0.129
Epoch 692/10000; Iter 1/80; Loss: 0.7782
Epoch 692/10000; Iter 51/80; Loss: 0.8490
Epoch 692/10000; Iter 80/80; Training Loss: 0.8260, Test Loss: 0.127
Epoch 693/10000; Iter 1/80; Loss: 0.8557
Epoch 693/10000; Iter 51/80; Loss: 0.8157
Epoch 693/10000; Iter 80/80; Training Loss: 0.8270, Test Loss: 0.141
Epoch 694/10000; Iter 1/80; Loss: 0.8683
Epoch 694/10000; Iter 51/80; Loss: 0.8086
Epoch 694/10000; Iter 80/80; Training Loss: 0.8210, Test Loss: 0.118
Epoch 695/10000; Iter 1/80; Loss: 0.8152
Epoch 695/10000; Iter 51/80; Loss: 0.7460
Epoch 695/10000; Iter 80/80; Training Loss: 0.8250, Test Loss: 0.119
Epoch 696/10000; Iter 1/80; Loss: 0.8181
Epoch 696/10000; Iter 51/80; Loss: 0.7593
Epoch 696/10000; Iter 80/80; Training Loss: 0.8270, Test Loss: 0.125
Epoch 697/10000; Iter 1/80; Loss: 0.8155
Epoch 697/10000; Iter 51/80; Loss: 0.7867
Epoch 697/10000; Iter 80/80; Training Loss: 0.8180, Test Loss: 0.125
Epoch 698/10000; Iter 1/80; Loss: 0.8190
Epoch 698/10000; Iter 51/80; Loss: 0.8186
Epoch 698/10000; Iter 80/80; Training Loss: 0.8280, Test Loss: 0.103
Epoch 699/10000; Iter 1/80; Loss: 0.9056
Epoch 699/10000; Iter 51/80; Loss: 0.7482
Epoch 699/10000; Iter 80/80; Training Loss: 0.8230, Test Loss: 0.131
Epoch 700/10000; Iter 1/80; Loss: 0.7338
Epoch 700/10000; Iter 51/80; Loss: 0.7875
Epoch 700/10000; Iter 80/80; Training Loss: 0.8200, Test Loss: 0.127
Epoch 701/10000; Iter 1/80; Loss: 0.8090
Epoch 701/10000; Iter 51/80; Loss: 0.7120
Epoch 701/10000; Iter 80/80; Training Loss: 0.8210, Test Loss: 0.123
Model saved
Epoch 702/10000; Iter 1/80; Loss: 0.7696
Epoch 702/10000; Iter 51/80; Loss: 0.9113
Epoch 702/10000; Iter 80/80; Training Loss: 0.8140, Test Loss: 0.149
Epoch 703/10000; Iter 1/80; Loss: 0.9381
Epoch 703/10000; Iter 51/80; Loss: 0.8579
Epoch 703/10000; Iter 80/80; Training Loss: 0.8220, Test Loss: 0.128
Epoch 704/10000; Iter 1/80; Loss: 0.9630
Epoch 704/10000; Iter 51/80; Loss: 0.8185
Epoch 704/10000; Iter 80/80; Training Loss: 0.8120, Test Loss: 0.12
Epoch 705/10000; Iter 1/80; Loss: 0.8468
Epoch 705/10000; Iter 51/80; Loss: 0.8302
Epoch 705/10000; Iter 80/80; Training Loss: 0.8080, Test Loss: 0.125
Epoch 706/10000; Iter 1/80; Loss: 0.7543
Epoch 706/10000; Iter 51/80; Loss: 0.8095
Epoch 706/10000; Iter 80/80; Training Loss: 0.8180, Test Loss: 0.123
Epoch 707/10000; Iter 1/80; Loss: 0.8541
Epoch 707/10000; Iter 51/80; Loss: 0.7404
Epoch 707/10000; Iter 80/80; Training Loss: 0.8160, Test Loss: 0.132
Epoch 708/10000; Iter 1/80; Loss: 0.7863
Epoch 708/10000; Iter 51/80; Loss: 0.7820
Epoch 708/10000; Iter 80/80; Training Loss: 0.8170, Test Loss: 0.13
Epoch 709/10000; Iter 1/80; Loss: 0.9111
Epoch 709/10000; Iter 51/80; Loss: 0.8678
Epoch 709/10000; Iter 80/80; Training Loss: 0.8170, Test Loss: 0.128
Epoch 710/10000; Iter 1/80; Loss: 0.8196
Epoch 710/10000; Iter 51/80; Loss: 0.7412
Epoch 710/10000; Iter 80/80; Training Loss: 0.8180, Test Loss: 0.149
Epoch 711/10000; Iter 1/80; Loss: 0.8548
Epoch 711/10000; Iter 51/80; Loss: 0.7816
Epoch 711/10000; Iter 80/80; Training Loss: 0.8070, Test Loss: 0.12
Epoch 712/10000; Iter 1/80; Loss: 0.7261
Epoch 712/10000; Iter 51/80; Loss: 0.7916
Epoch 712/10000; Iter 80/80; Training Loss: 0.8200, Test Loss: 0.121
Epoch 713/10000; Iter 1/80; Loss: 0.7449
Epoch 713/10000; Iter 51/80; Loss: 0.7149
Epoch 713/10000; Iter 80/80; Training Loss: 0.8080, Test Loss: 0.135
Epoch 714/10000; Iter 1/80; Loss: 0.8255
Epoch 714/10000; Iter 51/80; Loss: 0.8629
Epoch 714/10000; Iter 80/80; Training Loss: 0.8170, Test Loss: 0.124
Epoch 715/10000; Iter 1/80; Loss: 0.8392
Epoch 715/10000; Iter 51/80; Loss: 0.7851
Epoch 715/10000; Iter 80/80; Training Loss: 0.8220, Test Loss: 0.143
Epoch 716/10000; Iter 1/80; Loss: 0.7245
Epoch 716/10000; Iter 51/80; Loss: 0.7826
Epoch 716/10000; Iter 80/80; Training Loss: 0.8150, Test Loss: 0.129
Epoch 717/10000; Iter 1/80; Loss: 0.8162
Epoch 717/10000; Iter 51/80; Loss: 0.9399
Epoch 717/10000; Iter 80/80; Training Loss: 0.8100, Test Loss: 0.125
Epoch 718/10000; Iter 1/80; Loss: 0.8376
Epoch 718/10000; Iter 51/80; Loss: 0.8137
Epoch 718/10000; Iter 80/80; Training Loss: 0.8190, Test Loss: 0.121
Epoch 719/10000; Iter 1/80; Loss: 0.7832
Epoch 719/10000; Iter 51/80; Loss: 0.8860
Epoch 719/10000; Iter 80/80; Training Loss: 0.8130, Test Loss: 0.129
Epoch 720/10000; Iter 1/80; Loss: 0.7450
Epoch 720/10000; Iter 51/80; Loss: 0.8455
Epoch 720/10000; Iter 80/80; Training Loss: 0.8070, Test Loss: 0.128
Epoch 721/10000; Iter 1/80; Loss: 0.7295
Epoch 721/10000; Iter 51/80; Loss: 0.7318
Epoch 721/10000; Iter 80/80; Training Loss: 0.8070, Test Loss: 0.135
Epoch 722/10000; Iter 1/80; Loss: 0.9027
Epoch 722/10000; Iter 51/80; Loss: 0.8364
Epoch 722/10000; Iter 80/80; Training Loss: 0.8120, Test Loss: 0.128
Epoch 723/10000; Iter 1/80; Loss: 0.7311
Epoch 723/10000; Iter 51/80; Loss: 0.7677
Epoch 723/10000; Iter 80/80; Training Loss: 0.8010, Test Loss: 0.135
Epoch 724/10000; Iter 1/80; Loss: 0.7789
Epoch 724/10000; Iter 51/80; Loss: 0.7164
Epoch 724/10000; Iter 80/80; Training Loss: 0.7980, Test Loss: 0.124
Epoch 725/10000; Iter 1/80; Loss: 0.7487
Epoch 725/10000; Iter 51/80; Loss: 0.7933
Epoch 725/10000; Iter 80/80; Training Loss: 0.8060, Test Loss: 0.132
Epoch 726/10000; Iter 1/80; Loss: 0.8635
Epoch 726/10000; Iter 51/80; Loss: 0.8627
Epoch 726/10000; Iter 80/80; Training Loss: 0.8040, Test Loss: 0.125
Epoch 727/10000; Iter 1/80; Loss: 0.7338
Epoch 727/10000; Iter 51/80; Loss: 0.9378
Epoch 727/10000; Iter 80/80; Training Loss: 0.8120, Test Loss: 0.121
Epoch 728/10000; Iter 1/80; Loss: 0.7729
Epoch 728/10000; Iter 51/80; Loss: 0.7692
Epoch 728/10000; Iter 80/80; Training Loss: 0.7990, Test Loss: 0.112
Epoch 729/10000; Iter 1/80; Loss: 0.8361
Epoch 729/10000; Iter 51/80; Loss: 0.7783
Epoch 729/10000; Iter 80/80; Training Loss: 0.8060, Test Loss: 0.119
Epoch 730/10000; Iter 1/80; Loss: 0.7867
Epoch 730/10000; Iter 51/80; Loss: 0.8641
Epoch 730/10000; Iter 80/80; Training Loss: 0.8080, Test Loss: 0.146
Epoch 731/10000; Iter 1/80; Loss: 0.8168
Epoch 731/10000; Iter 51/80; Loss: 0.6902
Epoch 731/10000; Iter 80/80; Training Loss: 0.8050, Test Loss: 0.127
Epoch 732/10000; Iter 1/80; Loss: 0.7704
Epoch 732/10000; Iter 51/80; Loss: 0.7548
Epoch 732/10000; Iter 80/80; Training Loss: 0.8070, Test Loss: 0.13
Epoch 733/10000; Iter 1/80; Loss: 0.8293
Epoch 733/10000; Iter 51/80; Loss: 0.8086
Epoch 733/10000; Iter 80/80; Training Loss: 0.8030, Test Loss: 0.124
Epoch 734/10000; Iter 1/80; Loss: 0.8546
Epoch 734/10000; Iter 51/80; Loss: 0.7648
Epoch 734/10000; Iter 80/80; Training Loss: 0.8020, Test Loss: 0.128
Epoch 735/10000; Iter 1/80; Loss: 0.7300
Epoch 735/10000; Iter 51/80; Loss: 0.7959
Epoch 735/10000; Iter 80/80; Training Loss: 0.7990, Test Loss: 0.131
Epoch 736/10000; Iter 1/80; Loss: 0.9449
Epoch 736/10000; Iter 51/80; Loss: 0.8288
Epoch 736/10000; Iter 80/80; Training Loss: 0.8030, Test Loss: 0.105
Epoch 737/10000; Iter 1/80; Loss: 0.7013
Epoch 737/10000; Iter 51/80; Loss: 0.9868
Epoch 737/10000; Iter 80/80; Training Loss: 0.8110, Test Loss: 0.12
Epoch 738/10000; Iter 1/80; Loss: 0.8069
Epoch 738/10000; Iter 51/80; Loss: 0.7804
Epoch 738/10000; Iter 80/80; Training Loss: 0.8000, Test Loss: 0.103
Epoch 739/10000; Iter 1/80; Loss: 0.8269
Epoch 739/10000; Iter 51/80; Loss: 0.9702
Epoch 739/10000; Iter 80/80; Training Loss: 0.8170, Test Loss: 0.138
Epoch 740/10000; Iter 1/80; Loss: 0.8091
Epoch 740/10000; Iter 51/80; Loss: 0.9288
Epoch 740/10000; Iter 80/80; Training Loss: 0.8010, Test Loss: 0.115
Epoch 741/10000; Iter 1/80; Loss: 0.8132
Epoch 741/10000; Iter 51/80; Loss: 0.8076
Epoch 741/10000; Iter 80/80; Training Loss: 0.8130, Test Loss: 0.122
Epoch 742/10000; Iter 1/80; Loss: 0.8411
Epoch 742/10000; Iter 51/80; Loss: 0.7843
Epoch 742/10000; Iter 80/80; Training Loss: 0.7940, Test Loss: 0.115
Epoch 743/10000; Iter 1/80; Loss: 0.8133
Epoch 743/10000; Iter 51/80; Loss: 0.8202
Epoch 743/10000; Iter 80/80; Training Loss: 0.7870, Test Loss: 0.118
Epoch 744/10000; Iter 1/80; Loss: 0.7822
Epoch 744/10000; Iter 51/80; Loss: 0.8362
Epoch 744/10000; Iter 80/80; Training Loss: 0.7980, Test Loss: 0.119
Epoch 745/10000; Iter 1/80; Loss: 0.7841
Epoch 745/10000; Iter 51/80; Loss: 0.7118
Epoch 745/10000; Iter 80/80; Training Loss: 0.7970, Test Loss: 0.126
Epoch 746/10000; Iter 1/80; Loss: 0.8338
Epoch 746/10000; Iter 51/80; Loss: 0.7935
Epoch 746/10000; Iter 80/80; Training Loss: 0.8110, Test Loss: 0.119
Epoch 747/10000; Iter 1/80; Loss: 0.7324
Epoch 747/10000; Iter 51/80; Loss: 0.7472
Epoch 747/10000; Iter 80/80; Training Loss: 0.7930, Test Loss: 0.134
Epoch 748/10000; Iter 1/80; Loss: 0.8077
Epoch 748/10000; Iter 51/80; Loss: 0.8047
Epoch 748/10000; Iter 80/80; Training Loss: 0.8000, Test Loss: 0.111
Epoch 749/10000; Iter 1/80; Loss: 0.7280
Epoch 749/10000; Iter 51/80; Loss: 0.8187
Epoch 749/10000; Iter 80/80; Training Loss: 0.8060, Test Loss: 0.124
Epoch 750/10000; Iter 1/80; Loss: 0.8028
Epoch 750/10000; Iter 51/80; Loss: 0.7746
Epoch 750/10000; Iter 80/80; Training Loss: 0.7950, Test Loss: 0.12
Epoch 751/10000; Iter 1/80; Loss: 0.8725
Epoch 751/10000; Iter 51/80; Loss: 0.8120
Epoch 751/10000; Iter 80/80; Training Loss: 0.7890, Test Loss: 0.135
Epoch 752/10000; Iter 1/80; Loss: 0.7936
Epoch 752/10000; Iter 51/80; Loss: 0.7259
Epoch 752/10000; Iter 80/80; Training Loss: 0.7920, Test Loss: 0.115
Epoch 753/10000; Iter 1/80; Loss: 0.8337
Epoch 753/10000; Iter 51/80; Loss: 0.9672
Epoch 753/10000; Iter 80/80; Training Loss: 0.8080, Test Loss: 0.126
Epoch 754/10000; Iter 1/80; Loss: 0.8400
Epoch 754/10000; Iter 51/80; Loss: 0.7320
Epoch 754/10000; Iter 80/80; Training Loss: 0.7970, Test Loss: 0.119
Epoch 755/10000; Iter 1/80; Loss: 0.8460
Epoch 755/10000; Iter 51/80; Loss: 0.8639
Epoch 755/10000; Iter 80/80; Training Loss: 0.8020, Test Loss: 0.11
Epoch 756/10000; Iter 1/80; Loss: 0.9038
Epoch 756/10000; Iter 51/80; Loss: 0.7298
Epoch 756/10000; Iter 80/80; Training Loss: 0.7920, Test Loss: 0.102
Epoch 757/10000; Iter 1/80; Loss: 0.8481
Epoch 757/10000; Iter 51/80; Loss: 0.7938
Epoch 757/10000; Iter 80/80; Training Loss: 0.7990, Test Loss: 0.145
Epoch 758/10000; Iter 1/80; Loss: 0.8620
Epoch 758/10000; Iter 51/80; Loss: 0.6653
Epoch 758/10000; Iter 80/80; Training Loss: 0.7930, Test Loss: 0.123
Epoch 759/10000; Iter 1/80; Loss: 0.7799
Epoch 759/10000; Iter 51/80; Loss: 0.7199
Epoch 759/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.119
Epoch 760/10000; Iter 1/80; Loss: 0.7936
Epoch 760/10000; Iter 51/80; Loss: 0.8524
Epoch 760/10000; Iter 80/80; Training Loss: 0.7910, Test Loss: 0.121
Epoch 761/10000; Iter 1/80; Loss: 0.7388
Epoch 761/10000; Iter 51/80; Loss: 0.8653
Epoch 761/10000; Iter 80/80; Training Loss: 0.7880, Test Loss: 0.114
Epoch 762/10000; Iter 1/80; Loss: 0.7999
Epoch 762/10000; Iter 51/80; Loss: 0.7641
Epoch 762/10000; Iter 80/80; Training Loss: 0.7890, Test Loss: 0.12
Epoch 763/10000; Iter 1/80; Loss: 0.7085
Epoch 763/10000; Iter 51/80; Loss: 0.7420
Epoch 763/10000; Iter 80/80; Training Loss: 0.7980, Test Loss: 0.122
Epoch 764/10000; Iter 1/80; Loss: 0.9433
Epoch 764/10000; Iter 51/80; Loss: 0.7946
Epoch 764/10000; Iter 80/80; Training Loss: 0.7900, Test Loss: 0.124
Epoch 765/10000; Iter 1/80; Loss: 0.8733
Epoch 765/10000; Iter 51/80; Loss: 0.7993
Epoch 765/10000; Iter 80/80; Training Loss: 0.7930, Test Loss: 0.121
Epoch 766/10000; Iter 1/80; Loss: 0.7659
Epoch 766/10000; Iter 51/80; Loss: 0.8434
Epoch 766/10000; Iter 80/80; Training Loss: 0.8050, Test Loss: 0.127
Epoch 767/10000; Iter 1/80; Loss: 0.7940
Epoch 767/10000; Iter 51/80; Loss: 0.7334
Epoch 767/10000; Iter 80/80; Training Loss: 0.7830, Test Loss: 0.112
Epoch 768/10000; Iter 1/80; Loss: 0.7370
Epoch 768/10000; Iter 51/80; Loss: 0.8498
Epoch 768/10000; Iter 80/80; Training Loss: 0.7950, Test Loss: 0.12
Epoch 769/10000; Iter 1/80; Loss: 0.8322
Epoch 769/10000; Iter 51/80; Loss: 0.7941
Epoch 769/10000; Iter 80/80; Training Loss: 0.7890, Test Loss: 0.119
Epoch 770/10000; Iter 1/80; Loss: 0.7961
Epoch 770/10000; Iter 51/80; Loss: 0.6596
Epoch 770/10000; Iter 80/80; Training Loss: 0.7940, Test Loss: 0.126
Epoch 771/10000; Iter 1/80; Loss: 0.8372
Epoch 771/10000; Iter 51/80; Loss: 0.9083
Epoch 771/10000; Iter 80/80; Training Loss: 0.7830, Test Loss: 0.125
Epoch 772/10000; Iter 1/80; Loss: 0.6634
Epoch 772/10000; Iter 51/80; Loss: 0.7783
Epoch 772/10000; Iter 80/80; Training Loss: 0.7870, Test Loss: 0.112
Epoch 773/10000; Iter 1/80; Loss: 0.7917
Epoch 773/10000; Iter 51/80; Loss: 0.7201
Epoch 773/10000; Iter 80/80; Training Loss: 0.7900, Test Loss: 0.117
Epoch 774/10000; Iter 1/80; Loss: 0.7666
Epoch 774/10000; Iter 51/80; Loss: 0.7072
Epoch 774/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.121
Epoch 775/10000; Iter 1/80; Loss: 0.7809
Epoch 775/10000; Iter 51/80; Loss: 0.8395
Epoch 775/10000; Iter 80/80; Training Loss: 0.7730, Test Loss: 0.116
Epoch 776/10000; Iter 1/80; Loss: 0.7948
Epoch 776/10000; Iter 51/80; Loss: 0.7232
Epoch 776/10000; Iter 80/80; Training Loss: 0.7890, Test Loss: 0.136
Epoch 777/10000; Iter 1/80; Loss: 0.7590
Epoch 777/10000; Iter 51/80; Loss: 0.8958
Epoch 777/10000; Iter 80/80; Training Loss: 0.7930, Test Loss: 0.112
Epoch 778/10000; Iter 1/80; Loss: 0.8450
Epoch 778/10000; Iter 51/80; Loss: 0.7477
Epoch 778/10000; Iter 80/80; Training Loss: 0.7760, Test Loss: 0.105
Epoch 779/10000; Iter 1/80; Loss: 0.9215
Epoch 779/10000; Iter 51/80; Loss: 0.8166
Epoch 779/10000; Iter 80/80; Training Loss: 0.7900, Test Loss: 0.145
Epoch 780/10000; Iter 1/80; Loss: 0.7885
Epoch 780/10000; Iter 51/80; Loss: 0.8007
Epoch 780/10000; Iter 80/80; Training Loss: 0.7870, Test Loss: 0.122
Epoch 781/10000; Iter 1/80; Loss: 0.8465
Epoch 781/10000; Iter 51/80; Loss: 0.8544
Epoch 781/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.111
Epoch 782/10000; Iter 1/80; Loss: 0.8057
Epoch 782/10000; Iter 51/80; Loss: 0.7759
Epoch 782/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.112
Epoch 783/10000; Iter 1/80; Loss: 0.7093
Epoch 783/10000; Iter 51/80; Loss: 0.8929
Epoch 783/10000; Iter 80/80; Training Loss: 0.7870, Test Loss: 0.117
Epoch 784/10000; Iter 1/80; Loss: 0.7352
Epoch 784/10000; Iter 51/80; Loss: 0.8591
Epoch 784/10000; Iter 80/80; Training Loss: 0.7740, Test Loss: 0.114
Epoch 785/10000; Iter 1/80; Loss: 0.7918
Epoch 785/10000; Iter 51/80; Loss: 0.7744
Epoch 785/10000; Iter 80/80; Training Loss: 0.7930, Test Loss: 0.112
Epoch 786/10000; Iter 1/80; Loss: 0.7370
Epoch 786/10000; Iter 51/80; Loss: 0.7308
Epoch 786/10000; Iter 80/80; Training Loss: 0.7760, Test Loss: 0.118
Epoch 787/10000; Iter 1/80; Loss: 0.8124
Epoch 787/10000; Iter 51/80; Loss: 0.8336
Epoch 787/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.111
Epoch 788/10000; Iter 1/80; Loss: 0.9158
Epoch 788/10000; Iter 51/80; Loss: 0.7406
Epoch 788/10000; Iter 80/80; Training Loss: 0.7830, Test Loss: 0.134
Epoch 789/10000; Iter 1/80; Loss: 0.7767
Epoch 789/10000; Iter 51/80; Loss: 0.6943
Epoch 789/10000; Iter 80/80; Training Loss: 0.7820, Test Loss: 0.113
Epoch 790/10000; Iter 1/80; Loss: 0.8642
Epoch 790/10000; Iter 51/80; Loss: 0.8513
Epoch 790/10000; Iter 80/80; Training Loss: 0.7840, Test Loss: 0.119
Epoch 791/10000; Iter 1/80; Loss: 0.7396
Epoch 791/10000; Iter 51/80; Loss: 0.7235
Epoch 791/10000; Iter 80/80; Training Loss: 0.7700, Test Loss: 0.123
Epoch 792/10000; Iter 1/80; Loss: 0.8188
Epoch 792/10000; Iter 51/80; Loss: 0.8841
Epoch 792/10000; Iter 80/80; Training Loss: 0.7840, Test Loss: 0.108
Epoch 793/10000; Iter 1/80; Loss: 0.8297
Epoch 793/10000; Iter 51/80; Loss: 0.7495
Epoch 793/10000; Iter 80/80; Training Loss: 0.7790, Test Loss: 0.121
Epoch 794/10000; Iter 1/80; Loss: 0.7475
Epoch 794/10000; Iter 51/80; Loss: 0.8601
Epoch 794/10000; Iter 80/80; Training Loss: 0.7730, Test Loss: 0.128
Epoch 795/10000; Iter 1/80; Loss: 0.7396
Epoch 795/10000; Iter 51/80; Loss: 0.7396
Epoch 795/10000; Iter 80/80; Training Loss: 0.7780, Test Loss: 0.106
Epoch 796/10000; Iter 1/80; Loss: 0.8271
Epoch 796/10000; Iter 51/80; Loss: 0.8186
Epoch 796/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.109
Epoch 797/10000; Iter 1/80; Loss: 0.8323
Epoch 797/10000; Iter 51/80; Loss: 0.7379
Epoch 797/10000; Iter 80/80; Training Loss: 0.7740, Test Loss: 0.114
Epoch 798/10000; Iter 1/80; Loss: 0.7480
Epoch 798/10000; Iter 51/80; Loss: 0.8085
Epoch 798/10000; Iter 80/80; Training Loss: 0.7850, Test Loss: 0.102
Epoch 799/10000; Iter 1/80; Loss: 0.7070
Epoch 799/10000; Iter 51/80; Loss: 0.8057
Epoch 799/10000; Iter 80/80; Training Loss: 0.7700, Test Loss: 0.114
Epoch 800/10000; Iter 1/80; Loss: 0.7504
Epoch 800/10000; Iter 51/80; Loss: 0.8415
Epoch 800/10000; Iter 80/80; Training Loss: 0.7810, Test Loss: 0.106
Epoch 801/10000; Iter 1/80; Loss: 0.7163
Epoch 801/10000; Iter 51/80; Loss: 0.8707
Epoch 801/10000; Iter 80/80; Training Loss: 0.7770, Test Loss: 0.136
Model saved
Epoch 802/10000; Iter 1/80; Loss: 0.7607
Epoch 802/10000; Iter 51/80; Loss: 0.8201
Epoch 802/10000; Iter 80/80; Training Loss: 0.7770, Test Loss: 0.123
Epoch 803/10000; Iter 1/80; Loss: 0.7480
Epoch 803/10000; Iter 51/80; Loss: 0.8110
Epoch 803/10000; Iter 80/80; Training Loss: 0.7780, Test Loss: 0.12
Epoch 804/10000; Iter 1/80; Loss: 0.7060
Epoch 804/10000; Iter 51/80; Loss: 0.7669
Epoch 804/10000; Iter 80/80; Training Loss: 0.7650, Test Loss: 0.124
Epoch 805/10000; Iter 1/80; Loss: 0.8467
Epoch 805/10000; Iter 51/80; Loss: 0.7969
Epoch 805/10000; Iter 80/80; Training Loss: 0.7710, Test Loss: 0.132
Epoch 806/10000; Iter 1/80; Loss: 0.7826
Epoch 806/10000; Iter 51/80; Loss: 0.8570
Epoch 806/10000; Iter 80/80; Training Loss: 0.7750, Test Loss: 0.128
Epoch 807/10000; Iter 1/80; Loss: 0.7696
Epoch 807/10000; Iter 51/80; Loss: 0.7077
Epoch 807/10000; Iter 80/80; Training Loss: 0.7670, Test Loss: 0.103
Epoch 808/10000; Iter 1/80; Loss: 0.8052
Epoch 808/10000; Iter 51/80; Loss: 0.7706
Epoch 808/10000; Iter 80/80; Training Loss: 0.7720, Test Loss: 0.125
Epoch 809/10000; Iter 1/80; Loss: 0.8835
Epoch 809/10000; Iter 51/80; Loss: 0.7528
Epoch 809/10000; Iter 80/80; Training Loss: 0.7600, Test Loss: 0.109
Epoch 810/10000; Iter 1/80; Loss: 0.7533
Epoch 810/10000; Iter 51/80; Loss: 0.8127
Epoch 810/10000; Iter 80/80; Training Loss: 0.7720, Test Loss: 0.107
Epoch 811/10000; Iter 1/80; Loss: 0.8198
Epoch 811/10000; Iter 51/80; Loss: 0.8549
Epoch 811/10000; Iter 80/80; Training Loss: 0.7710, Test Loss: 0.108
Epoch 812/10000; Iter 1/80; Loss: 0.7796
Epoch 812/10000; Iter 51/80; Loss: 0.6747
Epoch 812/10000; Iter 80/80; Training Loss: 0.7680, Test Loss: 0.136
Epoch 813/10000; Iter 1/80; Loss: 0.8212
Epoch 813/10000; Iter 51/80; Loss: 0.7835
Epoch 813/10000; Iter 80/80; Training Loss: 0.7700, Test Loss: 0.117
Epoch 814/10000; Iter 1/80; Loss: 0.6959
Epoch 814/10000; Iter 51/80; Loss: 0.8153
Epoch 814/10000; Iter 80/80; Training Loss: 0.7700, Test Loss: 0.095
Epoch 815/10000; Iter 1/80; Loss: 0.7322
Epoch 815/10000; Iter 51/80; Loss: 0.7332
Epoch 815/10000; Iter 80/80; Training Loss: 0.7670, Test Loss: 0.105
Epoch 816/10000; Iter 1/80; Loss: 0.7337
Epoch 816/10000; Iter 51/80; Loss: 0.7671
Epoch 816/10000; Iter 80/80; Training Loss: 0.7610, Test Loss: 0.113
Epoch 817/10000; Iter 1/80; Loss: 0.7560
Epoch 817/10000; Iter 51/80; Loss: 0.7264
Epoch 817/10000; Iter 80/80; Training Loss: 0.7680, Test Loss: 0.119
Epoch 818/10000; Iter 1/80; Loss: 0.8483
Epoch 818/10000; Iter 51/80; Loss: 0.6668
Epoch 818/10000; Iter 80/80; Training Loss: 0.7770, Test Loss: 0.11
Epoch 819/10000; Iter 1/80; Loss: 0.7502
Epoch 819/10000; Iter 51/80; Loss: 0.8137
Epoch 819/10000; Iter 80/80; Training Loss: 0.7730, Test Loss: 0.113
Epoch 820/10000; Iter 1/80; Loss: 0.7867
Epoch 820/10000; Iter 51/80; Loss: 0.7720
Epoch 820/10000; Iter 80/80; Training Loss: 0.7640, Test Loss: 0.108
Epoch 821/10000; Iter 1/80; Loss: 0.7519
Epoch 821/10000; Iter 51/80; Loss: 0.7648
Epoch 821/10000; Iter 80/80; Training Loss: 0.7690, Test Loss: 0.125
Epoch 822/10000; Iter 1/80; Loss: 0.7832
Epoch 822/10000; Iter 51/80; Loss: 0.7658
Epoch 822/10000; Iter 80/80; Training Loss: 0.7510, Test Loss: 0.111
Epoch 823/10000; Iter 1/80; Loss: 0.6898
Epoch 823/10000; Iter 51/80; Loss: 0.7508
Epoch 823/10000; Iter 80/80; Training Loss: 0.7650, Test Loss: 0.121
Epoch 824/10000; Iter 1/80; Loss: 0.6875
Epoch 824/10000; Iter 51/80; Loss: 0.8067
Epoch 824/10000; Iter 80/80; Training Loss: 0.7760, Test Loss: 0.11
Epoch 825/10000; Iter 1/80; Loss: 0.7896
Epoch 825/10000; Iter 51/80; Loss: 0.7898
Epoch 825/10000; Iter 80/80; Training Loss: 0.7650, Test Loss: 0.129
Epoch 826/10000; Iter 1/80; Loss: 0.7668
Epoch 826/10000; Iter 51/80; Loss: 0.7830
Epoch 826/10000; Iter 80/80; Training Loss: 0.7610, Test Loss: 0.111
Epoch 827/10000; Iter 1/80; Loss: 0.8181
Epoch 827/10000; Iter 51/80; Loss: 0.7393
Epoch 827/10000; Iter 80/80; Training Loss: 0.7700, Test Loss: 0.12
Epoch 828/10000; Iter 1/80; Loss: 0.7770
Epoch 828/10000; Iter 51/80; Loss: 0.7380
Epoch 828/10000; Iter 80/80; Training Loss: 0.7580, Test Loss: 0.115
Epoch 829/10000; Iter 1/80; Loss: 0.7925
Epoch 829/10000; Iter 51/80; Loss: 0.7788
Epoch 829/10000; Iter 80/80; Training Loss: 0.7670, Test Loss: 0.115
Epoch 830/10000; Iter 1/80; Loss: 0.8154
Epoch 830/10000; Iter 51/80; Loss: 0.7495
Epoch 830/10000; Iter 80/80; Training Loss: 0.7510, Test Loss: 0.12
Epoch 831/10000; Iter 1/80; Loss: 0.7390
Epoch 831/10000; Iter 51/80; Loss: 0.7388
Epoch 831/10000; Iter 80/80; Training Loss: 0.7650, Test Loss: 0.117
Epoch 832/10000; Iter 1/80; Loss: 0.6942
Epoch 832/10000; Iter 51/80; Loss: 0.7347
Epoch 832/10000; Iter 80/80; Training Loss: 0.7580, Test Loss: 0.105
Epoch 833/10000; Iter 1/80; Loss: 0.7782
Epoch 833/10000; Iter 51/80; Loss: 0.7013
Epoch 833/10000; Iter 80/80; Training Loss: 0.7580, Test Loss: 0.109
Epoch 834/10000; Iter 1/80; Loss: 0.8910
Epoch 834/10000; Iter 51/80; Loss: 0.7038
Epoch 834/10000; Iter 80/80; Training Loss: 0.7580, Test Loss: 0.126
Epoch 835/10000; Iter 1/80; Loss: 0.7507
Epoch 835/10000; Iter 51/80; Loss: 0.6915
Epoch 835/10000; Iter 80/80; Training Loss: 0.7570, Test Loss: 0.116
Epoch 836/10000; Iter 1/80; Loss: 0.7650
Epoch 836/10000; Iter 51/80; Loss: 0.7001
Epoch 836/10000; Iter 80/80; Training Loss: 0.7610, Test Loss: 0.101
Epoch 837/10000; Iter 1/80; Loss: 0.7220
Epoch 837/10000; Iter 51/80; Loss: 0.7641
Epoch 837/10000; Iter 80/80; Training Loss: 0.7700, Test Loss: 0.12
Epoch 838/10000; Iter 1/80; Loss: 0.8356
Epoch 838/10000; Iter 51/80; Loss: 0.7479
Epoch 838/10000; Iter 80/80; Training Loss: 0.7630, Test Loss: 0.105
Epoch 839/10000; Iter 1/80; Loss: 0.7213
Epoch 839/10000; Iter 51/80; Loss: 0.6670
Epoch 839/10000; Iter 80/80; Training Loss: 0.7670, Test Loss: 0.105
Epoch 840/10000; Iter 1/80; Loss: 0.8236
Epoch 840/10000; Iter 51/80; Loss: 0.6639
Epoch 840/10000; Iter 80/80; Training Loss: 0.7530, Test Loss: 0.114
Epoch 841/10000; Iter 1/80; Loss: 0.8045
Epoch 841/10000; Iter 51/80; Loss: 0.8170
Epoch 841/10000; Iter 80/80; Training Loss: 0.7590, Test Loss: 0.109
Epoch 842/10000; Iter 1/80; Loss: 0.8113
Epoch 842/10000; Iter 51/80; Loss: 0.8029
Epoch 842/10000; Iter 80/80; Training Loss: 0.7540, Test Loss: 0.1
Epoch 843/10000; Iter 1/80; Loss: 0.7344
Epoch 843/10000; Iter 51/80; Loss: 0.8215
Epoch 843/10000; Iter 80/80; Training Loss: 0.7670, Test Loss: 0.121
Epoch 844/10000; Iter 1/80; Loss: 0.7552
Epoch 844/10000; Iter 51/80; Loss: 0.7658
Epoch 844/10000; Iter 80/80; Training Loss: 0.7460, Test Loss: 0.104
Epoch 845/10000; Iter 1/80; Loss: 0.6978
Epoch 845/10000; Iter 51/80; Loss: 0.7776
Epoch 845/10000; Iter 80/80; Training Loss: 0.7570, Test Loss: 0.106
Epoch 846/10000; Iter 1/80; Loss: 0.8060
Epoch 846/10000; Iter 51/80; Loss: 0.7027
Epoch 846/10000; Iter 80/80; Training Loss: 0.7560, Test Loss: 0.126
Epoch 847/10000; Iter 1/80; Loss: 0.7673
Epoch 847/10000; Iter 51/80; Loss: 0.7183
Epoch 847/10000; Iter 80/80; Training Loss: 0.7480, Test Loss: 0.097
Epoch 848/10000; Iter 1/80; Loss: 0.6693
Epoch 848/10000; Iter 51/80; Loss: 0.7922
Epoch 848/10000; Iter 80/80; Training Loss: 0.7550, Test Loss: 0.115
Epoch 849/10000; Iter 1/80; Loss: 0.7446
Epoch 849/10000; Iter 51/80; Loss: 0.7457
Epoch 849/10000; Iter 80/80; Training Loss: 0.7560, Test Loss: 0.11
Epoch 850/10000; Iter 1/80; Loss: 0.8385
Epoch 850/10000; Iter 51/80; Loss: 0.7119
Epoch 850/10000; Iter 80/80; Training Loss: 0.7500, Test Loss: 0.107
Epoch 851/10000; Iter 1/80; Loss: 0.8000
Epoch 851/10000; Iter 51/80; Loss: 0.7381
Epoch 851/10000; Iter 80/80; Training Loss: 0.7530, Test Loss: 0.112
Epoch 852/10000; Iter 1/80; Loss: 0.7308
Epoch 852/10000; Iter 51/80; Loss: 0.8317
Epoch 852/10000; Iter 80/80; Training Loss: 0.7710, Test Loss: 0.112
Epoch 853/10000; Iter 1/80; Loss: 0.7192
Epoch 853/10000; Iter 51/80; Loss: 0.7994
Epoch 853/10000; Iter 80/80; Training Loss: 0.7490, Test Loss: 0.109
Epoch 854/10000; Iter 1/80; Loss: 0.7585
Epoch 854/10000; Iter 51/80; Loss: 0.9542
Epoch 854/10000; Iter 80/80; Training Loss: 0.7450, Test Loss: 0.095
Epoch 855/10000; Iter 1/80; Loss: 0.8148
Epoch 855/10000; Iter 51/80; Loss: 0.8204
Epoch 855/10000; Iter 80/80; Training Loss: 0.7590, Test Loss: 0.116
Epoch 856/10000; Iter 1/80; Loss: 0.6425
Epoch 856/10000; Iter 51/80; Loss: 0.7459
Epoch 856/10000; Iter 80/80; Training Loss: 0.7470, Test Loss: 0.105
Epoch 857/10000; Iter 1/80; Loss: 0.7354
Epoch 857/10000; Iter 51/80; Loss: 0.8297
Epoch 857/10000; Iter 80/80; Training Loss: 0.7520, Test Loss: 0.111
Epoch 858/10000; Iter 1/80; Loss: 0.7454
Epoch 858/10000; Iter 51/80; Loss: 0.7531
Epoch 858/10000; Iter 80/80; Training Loss: 0.7580, Test Loss: 0.128
Epoch 859/10000; Iter 1/80; Loss: 0.6562
Epoch 859/10000; Iter 51/80; Loss: 0.7415
Epoch 859/10000; Iter 80/80; Training Loss: 0.7470, Test Loss: 0.119
Epoch 860/10000; Iter 1/80; Loss: 0.7572
Epoch 860/10000; Iter 51/80; Loss: 0.7746
Epoch 860/10000; Iter 80/80; Training Loss: 0.7590, Test Loss: 0.12
Epoch 861/10000; Iter 1/80; Loss: 0.8489
Epoch 861/10000; Iter 51/80; Loss: 0.7811
Epoch 861/10000; Iter 80/80; Training Loss: 0.7450, Test Loss: 0.103
Epoch 862/10000; Iter 1/80; Loss: 0.6290
Epoch 862/10000; Iter 51/80; Loss: 0.7076
Epoch 862/10000; Iter 80/80; Training Loss: 0.7500, Test Loss: 0.104
Epoch 863/10000; Iter 1/80; Loss: 0.7985
Epoch 863/10000; Iter 51/80; Loss: 0.7522
Epoch 863/10000; Iter 80/80; Training Loss: 0.7460, Test Loss: 0.116
Epoch 864/10000; Iter 1/80; Loss: 0.7558
Epoch 864/10000; Iter 51/80; Loss: 0.7467
Epoch 864/10000; Iter 80/80; Training Loss: 0.7610, Test Loss: 0.113
Epoch 865/10000; Iter 1/80; Loss: 0.8096
Epoch 865/10000; Iter 51/80; Loss: 0.6962
Epoch 865/10000; Iter 80/80; Training Loss: 0.7600, Test Loss: 0.12
Epoch 866/10000; Iter 1/80; Loss: 0.7550
Epoch 866/10000; Iter 51/80; Loss: 0.7953
Epoch 866/10000; Iter 80/80; Training Loss: 0.7430, Test Loss: 0.107
Epoch 867/10000; Iter 1/80; Loss: 0.7898
Epoch 867/10000; Iter 51/80; Loss: 0.8086
Epoch 867/10000; Iter 80/80; Training Loss: 0.7490, Test Loss: 0.11
Epoch 868/10000; Iter 1/80; Loss: 0.6812
Epoch 868/10000; Iter 51/80; Loss: 0.6932
Epoch 868/10000; Iter 80/80; Training Loss: 0.7440, Test Loss: 0.116
Epoch 869/10000; Iter 1/80; Loss: 0.7312
Epoch 869/10000; Iter 51/80; Loss: 0.6346
Epoch 869/10000; Iter 80/80; Training Loss: 0.7440, Test Loss: 0.11
Epoch 870/10000; Iter 1/80; Loss: 0.7541
Epoch 870/10000; Iter 51/80; Loss: 0.7294
Epoch 870/10000; Iter 80/80; Training Loss: 0.7580, Test Loss: 0.105
Epoch 871/10000; Iter 1/80; Loss: 0.8399
Epoch 871/10000; Iter 51/80; Loss: 0.8650
Epoch 871/10000; Iter 80/80; Training Loss: 0.7650, Test Loss: 0.103
Epoch 872/10000; Iter 1/80; Loss: 0.7991
Epoch 872/10000; Iter 51/80; Loss: 0.7449
Epoch 872/10000; Iter 80/80; Training Loss: 0.7430, Test Loss: 0.116
Epoch 873/10000; Iter 1/80; Loss: 0.7140
Epoch 873/10000; Iter 51/80; Loss: 0.7457
Epoch 873/10000; Iter 80/80; Training Loss: 0.7420, Test Loss: 0.116
Epoch 874/10000; Iter 1/80; Loss: 0.7566
Epoch 874/10000; Iter 51/80; Loss: 0.7784
Epoch 874/10000; Iter 80/80; Training Loss: 0.7450, Test Loss: 0.119
Epoch 875/10000; Iter 1/80; Loss: 0.7496
Epoch 875/10000; Iter 51/80; Loss: 0.7636
Epoch 875/10000; Iter 80/80; Training Loss: 0.7540, Test Loss: 0.112
Epoch 876/10000; Iter 1/80; Loss: 0.6937
Epoch 876/10000; Iter 51/80; Loss: 0.7459
Epoch 876/10000; Iter 80/80; Training Loss: 0.7510, Test Loss: 0.095
Epoch 877/10000; Iter 1/80; Loss: 0.8225
Epoch 877/10000; Iter 51/80; Loss: 0.7577
Epoch 877/10000; Iter 80/80; Training Loss: 0.7520, Test Loss: 0.113
Epoch 878/10000; Iter 1/80; Loss: 0.8010
Epoch 878/10000; Iter 51/80; Loss: 0.6825
Epoch 878/10000; Iter 80/80; Training Loss: 0.7510, Test Loss: 0.11
Epoch 879/10000; Iter 1/80; Loss: 0.7180
Epoch 879/10000; Iter 51/80; Loss: 0.6758
Epoch 879/10000; Iter 80/80; Training Loss: 0.7310, Test Loss: 0.103
Epoch 880/10000; Iter 1/80; Loss: 0.7944
Epoch 880/10000; Iter 51/80; Loss: 0.7716
Epoch 880/10000; Iter 80/80; Training Loss: 0.7480, Test Loss: 0.118
Epoch 881/10000; Iter 1/80; Loss: 0.6788
Epoch 881/10000; Iter 51/80; Loss: 0.6911
Epoch 881/10000; Iter 80/80; Training Loss: 0.7330, Test Loss: 0.108
Epoch 882/10000; Iter 1/80; Loss: 0.8227
Epoch 882/10000; Iter 51/80; Loss: 0.7590
Epoch 882/10000; Iter 80/80; Training Loss: 0.7450, Test Loss: 0.107
Epoch 883/10000; Iter 1/80; Loss: 0.6603
Epoch 883/10000; Iter 51/80; Loss: 0.9024
Epoch 883/10000; Iter 80/80; Training Loss: 0.7400, Test Loss: 0.113
Epoch 884/10000; Iter 1/80; Loss: 0.7463
Epoch 884/10000; Iter 51/80; Loss: 0.8084
Epoch 884/10000; Iter 80/80; Training Loss: 0.7460, Test Loss: 0.1
Epoch 885/10000; Iter 1/80; Loss: 0.7029
Epoch 885/10000; Iter 51/80; Loss: 0.6326
Epoch 885/10000; Iter 80/80; Training Loss: 0.7360, Test Loss: 0.103
Epoch 886/10000; Iter 1/80; Loss: 0.8056
Epoch 886/10000; Iter 51/80; Loss: 0.6998
Epoch 886/10000; Iter 80/80; Training Loss: 0.7380, Test Loss: 0.117
Epoch 887/10000; Iter 1/80; Loss: 0.8497
Epoch 887/10000; Iter 51/80; Loss: 0.7071
Epoch 887/10000; Iter 80/80; Training Loss: 0.7380, Test Loss: 0.11
Epoch 888/10000; Iter 1/80; Loss: 0.6489
Epoch 888/10000; Iter 51/80; Loss: 0.7394
Epoch 888/10000; Iter 80/80; Training Loss: 0.7390, Test Loss: 0.1
Epoch 889/10000; Iter 1/80; Loss: 0.8705
Epoch 889/10000; Iter 51/80; Loss: 0.8205
Epoch 889/10000; Iter 80/80; Training Loss: 0.7370, Test Loss: 0.101
Epoch 890/10000; Iter 1/80; Loss: 0.7447
Epoch 890/10000; Iter 51/80; Loss: 0.7055
Epoch 890/10000; Iter 80/80; Training Loss: 0.7270, Test Loss: 0.108
Epoch 891/10000; Iter 1/80; Loss: 0.9121
Epoch 891/10000; Iter 51/80; Loss: 0.6836
Epoch 891/10000; Iter 80/80; Training Loss: 0.7350, Test Loss: 0.108
Epoch 892/10000; Iter 1/80; Loss: 0.8395
Epoch 892/10000; Iter 51/80; Loss: 0.7439
Epoch 892/10000; Iter 80/80; Training Loss: 0.7340, Test Loss: 0.107
Epoch 893/10000; Iter 1/80; Loss: 0.6237
Epoch 893/10000; Iter 51/80; Loss: 0.7125
Epoch 893/10000; Iter 80/80; Training Loss: 0.7260, Test Loss: 0.108
Epoch 894/10000; Iter 1/80; Loss: 0.7951
Epoch 894/10000; Iter 51/80; Loss: 0.8715
Epoch 894/10000; Iter 80/80; Training Loss: 0.7420, Test Loss: 0.106
Epoch 895/10000; Iter 1/80; Loss: 0.6549
Epoch 895/10000; Iter 51/80; Loss: 0.6588
Epoch 895/10000; Iter 80/80; Training Loss: 0.7310, Test Loss: 0.108
Epoch 896/10000; Iter 1/80; Loss: 0.7034
Epoch 896/10000; Iter 51/80; Loss: 0.7459
Epoch 896/10000; Iter 80/80; Training Loss: 0.7390, Test Loss: 0.097
Epoch 897/10000; Iter 1/80; Loss: 0.7871
Epoch 897/10000; Iter 51/80; Loss: 0.7434
Epoch 897/10000; Iter 80/80; Training Loss: 0.7380, Test Loss: 0.098
Epoch 898/10000; Iter 1/80; Loss: 0.7138
Epoch 898/10000; Iter 51/80; Loss: 0.6783
Epoch 898/10000; Iter 80/80; Training Loss: 0.7330, Test Loss: 0.109
Epoch 899/10000; Iter 1/80; Loss: 0.7631
Epoch 899/10000; Iter 51/80; Loss: 0.7567
Epoch 899/10000; Iter 80/80; Training Loss: 0.7360, Test Loss: 0.095
Epoch 900/10000; Iter 1/80; Loss: 0.7567
Epoch 900/10000; Iter 51/80; Loss: 0.6976
Epoch 900/10000; Iter 80/80; Training Loss: 0.7480, Test Loss: 0.125
Epoch 901/10000; Iter 1/80; Loss: 0.7698
Epoch 901/10000; Iter 51/80; Loss: 0.7190
Epoch 901/10000; Iter 80/80; Training Loss: 0.7350, Test Loss: 0.102
Model saved
Epoch 902/10000; Iter 1/80; Loss: 0.7100
Epoch 902/10000; Iter 51/80; Loss: 0.7601
Epoch 902/10000; Iter 80/80; Training Loss: 0.7350, Test Loss: 0.108
Epoch 903/10000; Iter 1/80; Loss: 0.6826
Epoch 903/10000; Iter 51/80; Loss: 0.7124
Epoch 903/10000; Iter 80/80; Training Loss: 0.7310, Test Loss: 0.099
Epoch 904/10000; Iter 1/80; Loss: 0.7259
Epoch 904/10000; Iter 51/80; Loss: 0.7070
Epoch 904/10000; Iter 80/80; Training Loss: 0.7310, Test Loss: 0.102
Epoch 905/10000; Iter 1/80; Loss: 0.6977
Epoch 905/10000; Iter 51/80; Loss: 0.7525
Epoch 905/10000; Iter 80/80; Training Loss: 0.7370, Test Loss: 0.1
Epoch 906/10000; Iter 1/80; Loss: 0.7924
Epoch 906/10000; Iter 51/80; Loss: 0.7067
Epoch 906/10000; Iter 80/80; Training Loss: 0.7320, Test Loss: 0.123
Epoch 907/10000; Iter 1/80; Loss: 0.8388
Epoch 907/10000; Iter 51/80; Loss: 0.6887
Epoch 907/10000; Iter 80/80; Training Loss: 0.7340, Test Loss: 0.118
Epoch 908/10000; Iter 1/80; Loss: 0.7720
Epoch 908/10000; Iter 51/80; Loss: 0.7510
Epoch 908/10000; Iter 80/80; Training Loss: 0.7380, Test Loss: 0.108
Epoch 909/10000; Iter 1/80; Loss: 0.7782
Epoch 909/10000; Iter 51/80; Loss: 0.8010
Epoch 909/10000; Iter 80/80; Training Loss: 0.7320, Test Loss: 0.1
Epoch 910/10000; Iter 1/80; Loss: 0.8370
Epoch 910/10000; Iter 51/80; Loss: 0.7106
Epoch 910/10000; Iter 80/80; Training Loss: 0.7350, Test Loss: 0.122
Epoch 911/10000; Iter 1/80; Loss: 0.7479
Epoch 911/10000; Iter 51/80; Loss: 0.6489
Epoch 911/10000; Iter 80/80; Training Loss: 0.7290, Test Loss: 0.103
Epoch 912/10000; Iter 1/80; Loss: 0.7680
Epoch 912/10000; Iter 51/80; Loss: 0.7076
Epoch 912/10000; Iter 80/80; Training Loss: 0.7290, Test Loss: 0.104
Epoch 913/10000; Iter 1/80; Loss: 0.7114
Epoch 913/10000; Iter 51/80; Loss: 0.7812
Epoch 913/10000; Iter 80/80; Training Loss: 0.7260, Test Loss: 0.098
Epoch 914/10000; Iter 1/80; Loss: 0.7297
Epoch 914/10000; Iter 51/80; Loss: 0.7303
Epoch 914/10000; Iter 80/80; Training Loss: 0.7270, Test Loss: 0.115
Epoch 915/10000; Iter 1/80; Loss: 0.8041
Epoch 915/10000; Iter 51/80; Loss: 0.7731
Epoch 915/10000; Iter 80/80; Training Loss: 0.7270, Test Loss: 0.106
Epoch 916/10000; Iter 1/80; Loss: 0.6079
Epoch 916/10000; Iter 51/80; Loss: 0.7259
Epoch 916/10000; Iter 80/80; Training Loss: 0.7330, Test Loss: 0.103
Epoch 917/10000; Iter 1/80; Loss: 0.6954
Epoch 917/10000; Iter 51/80; Loss: 0.7417
Epoch 917/10000; Iter 80/80; Training Loss: 0.7300, Test Loss: 0.098
Epoch 918/10000; Iter 1/80; Loss: 0.7480
Epoch 918/10000; Iter 51/80; Loss: 0.7449
Epoch 918/10000; Iter 80/80; Training Loss: 0.7330, Test Loss: 0.123
Epoch 919/10000; Iter 1/80; Loss: 0.6876
Epoch 919/10000; Iter 51/80; Loss: 0.7995
Epoch 919/10000; Iter 80/80; Training Loss: 0.7240, Test Loss: 0.098
Epoch 920/10000; Iter 1/80; Loss: 0.7064
Epoch 920/10000; Iter 51/80; Loss: 0.6930
Epoch 920/10000; Iter 80/80; Training Loss: 0.7160, Test Loss: 0.103
Epoch 921/10000; Iter 1/80; Loss: 0.7475
Epoch 921/10000; Iter 51/80; Loss: 0.6580
Epoch 921/10000; Iter 80/80; Training Loss: 0.7260, Test Loss: 0.106
Epoch 922/10000; Iter 1/80; Loss: 0.6259
Epoch 922/10000; Iter 51/80; Loss: 0.7817
Epoch 922/10000; Iter 80/80; Training Loss: 0.7200, Test Loss: 0.123
Epoch 923/10000; Iter 1/80; Loss: 0.6511
Epoch 923/10000; Iter 51/80; Loss: 0.7044
Epoch 923/10000; Iter 80/80; Training Loss: 0.7240, Test Loss: 0.1
Epoch 924/10000; Iter 1/80; Loss: 0.7732
Epoch 924/10000; Iter 51/80; Loss: 0.7031
Epoch 924/10000; Iter 80/80; Training Loss: 0.7210, Test Loss: 0.107
Epoch 925/10000; Iter 1/80; Loss: 0.7078
Epoch 925/10000; Iter 51/80; Loss: 0.7192
Epoch 925/10000; Iter 80/80; Training Loss: 0.7250, Test Loss: 0.098
Epoch 926/10000; Iter 1/80; Loss: 0.7572
Epoch 926/10000; Iter 51/80; Loss: 0.7220
Epoch 926/10000; Iter 80/80; Training Loss: 0.7210, Test Loss: 0.105
Epoch 927/10000; Iter 1/80; Loss: 0.7397
Epoch 927/10000; Iter 51/80; Loss: 0.6296
Epoch 927/10000; Iter 80/80; Training Loss: 0.7230, Test Loss: 0.104
Epoch 928/10000; Iter 1/80; Loss: 0.7919
Epoch 928/10000; Iter 51/80; Loss: 0.6929
Epoch 928/10000; Iter 80/80; Training Loss: 0.7140, Test Loss: 0.099
Epoch 929/10000; Iter 1/80; Loss: 0.7714
Epoch 929/10000; Iter 51/80; Loss: 0.6898
Epoch 929/10000; Iter 80/80; Training Loss: 0.7140, Test Loss: 0.1
Epoch 930/10000; Iter 1/80; Loss: 0.7339
Epoch 930/10000; Iter 51/80; Loss: 0.8186
Epoch 930/10000; Iter 80/80; Training Loss: 0.7240, Test Loss: 0.106
Epoch 931/10000; Iter 1/80; Loss: 0.7558
Epoch 931/10000; Iter 51/80; Loss: 0.7234
Epoch 931/10000; Iter 80/80; Training Loss: 0.7160, Test Loss: 0.096
Epoch 932/10000; Iter 1/80; Loss: 0.7396
Epoch 932/10000; Iter 51/80; Loss: 0.7174
Epoch 932/10000; Iter 80/80; Training Loss: 0.7210, Test Loss: 0.103
Epoch 933/10000; Iter 1/80; Loss: 0.6339
Epoch 933/10000; Iter 51/80; Loss: 0.7801
Epoch 933/10000; Iter 80/80; Training Loss: 0.7320, Test Loss: 0.097
Epoch 934/10000; Iter 1/80; Loss: 0.7995
Epoch 934/10000; Iter 51/80; Loss: 0.8051
Epoch 934/10000; Iter 80/80; Training Loss: 0.7260, Test Loss: 0.118
Epoch 935/10000; Iter 1/80; Loss: 0.7534
Epoch 935/10000; Iter 51/80; Loss: 0.8378
Epoch 935/10000; Iter 80/80; Training Loss: 0.7230, Test Loss: 0.107
Epoch 936/10000; Iter 1/80; Loss: 0.6746
Epoch 936/10000; Iter 51/80; Loss: 0.7804
Epoch 936/10000; Iter 80/80; Training Loss: 0.7180, Test Loss: 0.09
Epoch 937/10000; Iter 1/80; Loss: 0.8454
Epoch 937/10000; Iter 51/80; Loss: 0.6889
Epoch 937/10000; Iter 80/80; Training Loss: 0.7210, Test Loss: 0.112
Epoch 938/10000; Iter 1/80; Loss: 0.6432
Epoch 938/10000; Iter 51/80; Loss: 0.7661
Epoch 938/10000; Iter 80/80; Training Loss: 0.7260, Test Loss: 0.097
Epoch 939/10000; Iter 1/80; Loss: 0.8238
Epoch 939/10000; Iter 51/80; Loss: 0.7887
Epoch 939/10000; Iter 80/80; Training Loss: 0.7200, Test Loss: 0.088
Epoch 940/10000; Iter 1/80; Loss: 0.7030
Epoch 940/10000; Iter 51/80; Loss: 0.7339
Epoch 940/10000; Iter 80/80; Training Loss: 0.7170, Test Loss: 0.103
Epoch 941/10000; Iter 1/80; Loss: 0.6633
Epoch 941/10000; Iter 51/80; Loss: 0.7885
Epoch 941/10000; Iter 80/80; Training Loss: 0.7150, Test Loss: 0.1
Epoch 942/10000; Iter 1/80; Loss: 0.7562
Epoch 942/10000; Iter 51/80; Loss: 0.7037
Epoch 942/10000; Iter 80/80; Training Loss: 0.7180, Test Loss: 0.096
Epoch 943/10000; Iter 1/80; Loss: 0.7003
Epoch 943/10000; Iter 51/80; Loss: 0.7872
Epoch 943/10000; Iter 80/80; Training Loss: 0.7270, Test Loss: 0.092
Epoch 944/10000; Iter 1/80; Loss: 0.7131
Epoch 944/10000; Iter 51/80; Loss: 0.6427
Epoch 944/10000; Iter 80/80; Training Loss: 0.7110, Test Loss: 0.107
Epoch 945/10000; Iter 1/80; Loss: 0.6659
Epoch 945/10000; Iter 51/80; Loss: 0.8361
Epoch 945/10000; Iter 80/80; Training Loss: 0.7270, Test Loss: 0.11
Epoch 946/10000; Iter 1/80; Loss: 0.7598
Epoch 946/10000; Iter 51/80; Loss: 0.7195
Epoch 946/10000; Iter 80/80; Training Loss: 0.7180, Test Loss: 0.102
Epoch 947/10000; Iter 1/80; Loss: 0.7439
Epoch 947/10000; Iter 51/80; Loss: 0.6782
Epoch 947/10000; Iter 80/80; Training Loss: 0.7050, Test Loss: 0.092
Epoch 948/10000; Iter 1/80; Loss: 0.7262
Epoch 948/10000; Iter 51/80; Loss: 0.6895
Epoch 948/10000; Iter 80/80; Training Loss: 0.7250, Test Loss: 0.109
Epoch 949/10000; Iter 1/80; Loss: 0.7147
Epoch 949/10000; Iter 51/80; Loss: 0.6616
Epoch 949/10000; Iter 80/80; Training Loss: 0.7160, Test Loss: 0.099
Epoch 950/10000; Iter 1/80; Loss: 0.6410
Epoch 950/10000; Iter 51/80; Loss: 0.7453
Epoch 950/10000; Iter 80/80; Training Loss: 0.7180, Test Loss: 0.112
Epoch 951/10000; Iter 1/80; Loss: 0.8337
Epoch 951/10000; Iter 51/80; Loss: 0.6850
Epoch 951/10000; Iter 80/80; Training Loss: 0.7140, Test Loss: 0.115
Epoch 952/10000; Iter 1/80; Loss: 0.7065
Epoch 952/10000; Iter 51/80; Loss: 0.7360
Epoch 952/10000; Iter 80/80; Training Loss: 0.7250, Test Loss: 0.098
Epoch 953/10000; Iter 1/80; Loss: 0.7199
Epoch 953/10000; Iter 51/80; Loss: 0.8053
Epoch 953/10000; Iter 80/80; Training Loss: 0.7180, Test Loss: 0.104
Epoch 954/10000; Iter 1/80; Loss: 0.7000
Epoch 954/10000; Iter 51/80; Loss: 0.6645
Epoch 954/10000; Iter 80/80; Training Loss: 0.7150, Test Loss: 0.097
Epoch 955/10000; Iter 1/80; Loss: 0.7669
Epoch 955/10000; Iter 51/80; Loss: 0.6813
Epoch 955/10000; Iter 80/80; Training Loss: 0.7080, Test Loss: 0.106
Epoch 956/10000; Iter 1/80; Loss: 0.6943
Epoch 956/10000; Iter 51/80; Loss: 0.6592
Epoch 956/10000; Iter 80/80; Training Loss: 0.7100, Test Loss: 0.099
Epoch 957/10000; Iter 1/80; Loss: 0.8647
Epoch 957/10000; Iter 51/80; Loss: 0.7201
Epoch 957/10000; Iter 80/80; Training Loss: 0.7100, Test Loss: 0.103
Epoch 958/10000; Iter 1/80; Loss: 0.7526
Epoch 958/10000; Iter 51/80; Loss: 0.7098
Epoch 958/10000; Iter 80/80; Training Loss: 0.7050, Test Loss: 0.089
Epoch 959/10000; Iter 1/80; Loss: 0.6771
Epoch 959/10000; Iter 51/80; Loss: 0.6800
Epoch 959/10000; Iter 80/80; Training Loss: 0.7120, Test Loss: 0.104
Epoch 960/10000; Iter 1/80; Loss: 0.6428
Epoch 960/10000; Iter 51/80; Loss: 0.8153
Epoch 960/10000; Iter 80/80; Training Loss: 0.7110, Test Loss: 0.101
Epoch 961/10000; Iter 1/80; Loss: 0.6909
Epoch 961/10000; Iter 51/80; Loss: 0.6832
Epoch 961/10000; Iter 80/80; Training Loss: 0.7150, Test Loss: 0.092
Epoch 962/10000; Iter 1/80; Loss: 0.7392
Epoch 962/10000; Iter 51/80; Loss: 0.6811
Epoch 962/10000; Iter 80/80; Training Loss: 0.7130, Test Loss: 0.093
Epoch 963/10000; Iter 1/80; Loss: 0.7259
Epoch 963/10000; Iter 51/80; Loss: 0.6942
Epoch 963/10000; Iter 80/80; Training Loss: 0.7040, Test Loss: 0.098
Epoch 964/10000; Iter 1/80; Loss: 0.7572
Epoch 964/10000; Iter 51/80; Loss: 0.7022
Epoch 964/10000; Iter 80/80; Training Loss: 0.7180, Test Loss: 0.107
Epoch 965/10000; Iter 1/80; Loss: 0.7720
Epoch 965/10000; Iter 51/80; Loss: 0.6742
Epoch 965/10000; Iter 80/80; Training Loss: 0.7230, Test Loss: 0.098
Epoch 966/10000; Iter 1/80; Loss: 0.7320
Epoch 966/10000; Iter 51/80; Loss: 0.7602
Epoch 966/10000; Iter 80/80; Training Loss: 0.7110, Test Loss: 0.093
Epoch 967/10000; Iter 1/80; Loss: 0.7519
Epoch 967/10000; Iter 51/80; Loss: 0.6740
Epoch 967/10000; Iter 80/80; Training Loss: 0.7060, Test Loss: 0.103
Epoch 968/10000; Iter 1/80; Loss: 0.6660
Epoch 968/10000; Iter 51/80; Loss: 0.6363
Epoch 968/10000; Iter 80/80; Training Loss: 0.7150, Test Loss: 0.1
Epoch 969/10000; Iter 1/80; Loss: 0.7061
Epoch 969/10000; Iter 51/80; Loss: 0.6722
Epoch 969/10000; Iter 80/80; Training Loss: 0.7210, Test Loss: 0.088
Epoch 970/10000; Iter 1/80; Loss: 0.6894
Epoch 970/10000; Iter 51/80; Loss: 0.6515
Epoch 970/10000; Iter 80/80; Training Loss: 0.7100, Test Loss: 0.086
Epoch 971/10000; Iter 1/80; Loss: 0.7064
Epoch 971/10000; Iter 51/80; Loss: 0.7639
Epoch 971/10000; Iter 80/80; Training Loss: 0.7030, Test Loss: 0.103
Epoch 972/10000; Iter 1/80; Loss: 0.6970
Epoch 972/10000; Iter 51/80; Loss: 0.6816
Epoch 972/10000; Iter 80/80; Training Loss: 0.7100, Test Loss: 0.101
Epoch 973/10000; Iter 1/80; Loss: 0.6969
Epoch 973/10000; Iter 51/80; Loss: 0.7946
Epoch 973/10000; Iter 80/80; Training Loss: 0.7110, Test Loss: 0.103
Epoch 974/10000; Iter 1/80; Loss: 0.7387
Epoch 974/10000; Iter 51/80; Loss: 0.6643
Epoch 974/10000; Iter 80/80; Training Loss: 0.7070, Test Loss: 0.104
Epoch 975/10000; Iter 1/80; Loss: 0.7068
Epoch 975/10000; Iter 51/80; Loss: 0.7511
Epoch 975/10000; Iter 80/80; Training Loss: 0.7000, Test Loss: 0.11
Epoch 976/10000; Iter 1/80; Loss: 0.6705
Epoch 976/10000; Iter 51/80; Loss: 0.7561
Epoch 976/10000; Iter 80/80; Training Loss: 0.7160, Test Loss: 0.097
Epoch 977/10000; Iter 1/80; Loss: 0.6956
Epoch 977/10000; Iter 51/80; Loss: 0.6931
Epoch 977/10000; Iter 80/80; Training Loss: 0.7070, Test Loss: 0.093
Epoch 978/10000; Iter 1/80; Loss: 0.7902
Epoch 978/10000; Iter 51/80; Loss: 0.7672
Epoch 978/10000; Iter 80/80; Training Loss: 0.7130, Test Loss: 0.101
Epoch 979/10000; Iter 1/80; Loss: 0.6880
Epoch 979/10000; Iter 51/80; Loss: 0.7178
Epoch 979/10000; Iter 80/80; Training Loss: 0.7050, Test Loss: 0.102
Epoch 980/10000; Iter 1/80; Loss: 0.7890
Epoch 980/10000; Iter 51/80; Loss: 0.8147
Epoch 980/10000; Iter 80/80; Training Loss: 0.7050, Test Loss: 0.125
Epoch 981/10000; Iter 1/80; Loss: 0.6993
Epoch 981/10000; Iter 51/80; Loss: 0.7352
Epoch 981/10000; Iter 80/80; Training Loss: 0.7020, Test Loss: 0.113
Epoch 982/10000; Iter 1/80; Loss: 0.6538
Epoch 982/10000; Iter 51/80; Loss: 0.6996
Epoch 982/10000; Iter 80/80; Training Loss: 0.7010, Test Loss: 0.1
Epoch 983/10000; Iter 1/80; Loss: 0.6846
Epoch 983/10000; Iter 51/80; Loss: 0.5959
Epoch 983/10000; Iter 80/80; Training Loss: 0.7140, Test Loss: 0.104
Epoch 984/10000; Iter 1/80; Loss: 0.6972
Epoch 984/10000; Iter 51/80; Loss: 0.7572
Epoch 984/10000; Iter 80/80; Training Loss: 0.7010, Test Loss: 0.097
Epoch 985/10000; Iter 1/80; Loss: 0.7161
Epoch 985/10000; Iter 51/80; Loss: 0.7324
Epoch 985/10000; Iter 80/80; Training Loss: 0.6950, Test Loss: 0.102
Epoch 986/10000; Iter 1/80; Loss: 0.7531
Epoch 986/10000; Iter 51/80; Loss: 0.6526
Epoch 986/10000; Iter 80/80; Training Loss: 0.6980, Test Loss: 0.108
Epoch 987/10000; Iter 1/80; Loss: 0.6311
Epoch 987/10000; Iter 51/80; Loss: 0.6384
Epoch 987/10000; Iter 80/80; Training Loss: 0.7140, Test Loss: 0.1
Epoch 988/10000; Iter 1/80; Loss: 0.6662
Epoch 988/10000; Iter 51/80; Loss: 0.6985
Epoch 988/10000; Iter 80/80; Training Loss: 0.7110, Test Loss: 0.101
Epoch 989/10000; Iter 1/80; Loss: 0.7120
Epoch 989/10000; Iter 51/80; Loss: 0.7125
Epoch 989/10000; Iter 80/80; Training Loss: 0.7010, Test Loss: 0.098
Epoch 990/10000; Iter 1/80; Loss: 0.7030
Epoch 990/10000; Iter 51/80; Loss: 0.6904
Epoch 990/10000; Iter 80/80; Training Loss: 0.7030, Test Loss: 0.097
Epoch 991/10000; Iter 1/80; Loss: 0.6505
Epoch 991/10000; Iter 51/80; Loss: 0.7327
Epoch 991/10000; Iter 80/80; Training Loss: 0.7070, Test Loss: 0.101
Epoch 992/10000; Iter 1/80; Loss: 0.6485
Epoch 992/10000; Iter 51/80; Loss: 0.6439
Epoch 992/10000; Iter 80/80; Training Loss: 0.6960, Test Loss: 0.102
Epoch 993/10000; Iter 1/80; Loss: 0.7472
Epoch 993/10000; Iter 51/80; Loss: 0.6927
Epoch 993/10000; Iter 80/80; Training Loss: 0.7080, Test Loss: 0.095
Epoch 994/10000; Iter 1/80; Loss: 0.7123
Epoch 994/10000; Iter 51/80; Loss: 0.6565
Epoch 994/10000; Iter 80/80; Training Loss: 0.6930, Test Loss: 0.11
Epoch 995/10000; Iter 1/80; Loss: 0.7243
Epoch 995/10000; Iter 51/80; Loss: 0.7639
Epoch 995/10000; Iter 80/80; Training Loss: 0.6970, Test Loss: 0.11
Epoch 996/10000; Iter 1/80; Loss: 0.7527
Epoch 996/10000; Iter 51/80; Loss: 0.6422
Epoch 996/10000; Iter 80/80; Training Loss: 0.6970, Test Loss: 0.098
Epoch 997/10000; Iter 1/80; Loss: 0.7086
Epoch 997/10000; Iter 51/80; Loss: 0.6719
Epoch 997/10000; Iter 80/80; Training Loss: 0.7040, Test Loss: 0.094
Epoch 998/10000; Iter 1/80; Loss: 0.6432
Epoch 998/10000; Iter 51/80; Loss: 0.6299
Epoch 998/10000; Iter 80/80; Training Loss: 0.7060, Test Loss: 0.096
Epoch 999/10000; Iter 1/80; Loss: 0.7194
Epoch 999/10000; Iter 51/80; Loss: 0.7054
Epoch 999/10000; Iter 80/80; Training Loss: 0.6950, Test Loss: 0.094
Epoch 1000/10000; Iter 1/80; Loss: 0.6640
Epoch 1000/10000; Iter 51/80; Loss: 0.6610
Epoch 1000/10000; Iter 80/80; Training Loss: 0.6890, Test Loss: 0.094
Epoch 1001/10000; Iter 1/80; Loss: 0.6589
Epoch 1001/10000; Iter 51/80; Loss: 0.6621
Epoch 1001/10000; Iter 80/80; Training Loss: 0.6960, Test Loss: 0.104
Model saved
Epoch 1002/10000; Iter 1/80; Loss: 0.6327
Epoch 1002/10000; Iter 51/80; Loss: 0.7562
Epoch 1002/10000; Iter 80/80; Training Loss: 0.7030, Test Loss: 0.107
Epoch 1003/10000; Iter 1/80; Loss: 0.6545
Epoch 1003/10000; Iter 51/80; Loss: 0.7908
Epoch 1003/10000; Iter 80/80; Training Loss: 0.6950, Test Loss: 0.107
Epoch 1004/10000; Iter 1/80; Loss: 0.6272
Epoch 1004/10000; Iter 51/80; Loss: 0.6938
Epoch 1004/10000; Iter 80/80; Training Loss: 0.7000, Test Loss: 0.089
Epoch 1005/10000; Iter 1/80; Loss: 0.7278
Epoch 1005/10000; Iter 51/80; Loss: 0.7466
Epoch 1005/10000; Iter 80/80; Training Loss: 0.6960, Test Loss: 0.113
Epoch 1006/10000; Iter 1/80; Loss: 0.6240
Epoch 1006/10000; Iter 51/80; Loss: 0.6887
Epoch 1006/10000; Iter 80/80; Training Loss: 0.6980, Test Loss: 0.107
Epoch 1007/10000; Iter 1/80; Loss: 0.6201
Epoch 1007/10000; Iter 51/80; Loss: 0.7029
Epoch 1007/10000; Iter 80/80; Training Loss: 0.6950, Test Loss: 0.09
Epoch 1008/10000; Iter 1/80; Loss: 0.7029
Epoch 1008/10000; Iter 51/80; Loss: 0.6235
Epoch 1008/10000; Iter 80/80; Training Loss: 0.6950, Test Loss: 0.088
Epoch 1009/10000; Iter 1/80; Loss: 0.6406
Epoch 1009/10000; Iter 51/80; Loss: 0.7217
Epoch 1009/10000; Iter 80/80; Training Loss: 0.6990, Test Loss: 0.102
Epoch 1010/10000; Iter 1/80; Loss: 0.6779
Epoch 1010/10000; Iter 51/80; Loss: 0.7682
Epoch 1010/10000; Iter 80/80; Training Loss: 0.6910, Test Loss: 0.094
Epoch 1011/10000; Iter 1/80; Loss: 0.6258
Epoch 1011/10000; Iter 51/80; Loss: 0.6537
Epoch 1011/10000; Iter 80/80; Training Loss: 0.6840, Test Loss: 0.115
Epoch 1012/10000; Iter 1/80; Loss: 0.7052
Epoch 1012/10000; Iter 51/80; Loss: 0.6991
Epoch 1012/10000; Iter 80/80; Training Loss: 0.7070, Test Loss: 0.088
Epoch 1013/10000; Iter 1/80; Loss: 0.6819
Epoch 1013/10000; Iter 51/80; Loss: 0.6697
Epoch 1013/10000; Iter 80/80; Training Loss: 0.6860, Test Loss: 0.113
Epoch 1014/10000; Iter 1/80; Loss: 0.6671
Epoch 1014/10000; Iter 51/80; Loss: 0.7726
Epoch 1014/10000; Iter 80/80; Training Loss: 0.6960, Test Loss: 0.095
Epoch 1015/10000; Iter 1/80; Loss: 0.6858
Epoch 1015/10000; Iter 51/80; Loss: 0.6392
Epoch 1015/10000; Iter 80/80; Training Loss: 0.6860, Test Loss: 0.1
Epoch 1016/10000; Iter 1/80; Loss: 0.6953
Epoch 1016/10000; Iter 51/80; Loss: 0.6585
Epoch 1016/10000; Iter 80/80; Training Loss: 0.6920, Test Loss: 0.093
Epoch 1017/10000; Iter 1/80; Loss: 0.8246
Epoch 1017/10000; Iter 51/80; Loss: 0.6672
Epoch 1017/10000; Iter 80/80; Training Loss: 0.6980, Test Loss: 0.094
Epoch 1018/10000; Iter 1/80; Loss: 0.7145
Epoch 1018/10000; Iter 51/80; Loss: 0.7365
Epoch 1018/10000; Iter 80/80; Training Loss: 0.6780, Test Loss: 0.097
Epoch 1019/10000; Iter 1/80; Loss: 0.7004
Epoch 1019/10000; Iter 51/80; Loss: 0.7519
Epoch 1019/10000; Iter 80/80; Training Loss: 0.6840, Test Loss: 0.086
Epoch 1020/10000; Iter 1/80; Loss: 0.6702
Epoch 1020/10000; Iter 51/80; Loss: 0.6833
Epoch 1020/10000; Iter 80/80; Training Loss: 0.6900, Test Loss: 0.09
Epoch 1021/10000; Iter 1/80; Loss: 0.7478
Epoch 1021/10000; Iter 51/80; Loss: 0.6087
Epoch 1021/10000; Iter 80/80; Training Loss: 0.6870, Test Loss: 0.1
Epoch 1022/10000; Iter 1/80; Loss: 0.6977
Epoch 1022/10000; Iter 51/80; Loss: 0.7798
Epoch 1022/10000; Iter 80/80; Training Loss: 0.6910, Test Loss: 0.09
Epoch 1023/10000; Iter 1/80; Loss: 0.6984
Epoch 1023/10000; Iter 51/80; Loss: 0.7754
Epoch 1023/10000; Iter 80/80; Training Loss: 0.6960, Test Loss: 0.093
Epoch 1024/10000; Iter 1/80; Loss: 0.7547
Epoch 1024/10000; Iter 51/80; Loss: 0.6194
Epoch 1024/10000; Iter 80/80; Training Loss: 0.6970, Test Loss: 0.097
Epoch 1025/10000; Iter 1/80; Loss: 0.6665
Epoch 1025/10000; Iter 51/80; Loss: 0.6778
Epoch 1025/10000; Iter 80/80; Training Loss: 0.6990, Test Loss: 0.106
Epoch 1026/10000; Iter 1/80; Loss: 0.6548
Epoch 1026/10000; Iter 51/80; Loss: 0.6709
Epoch 1026/10000; Iter 80/80; Training Loss: 0.6940, Test Loss: 0.093
Epoch 1027/10000; Iter 1/80; Loss: 0.6836
Epoch 1027/10000; Iter 51/80; Loss: 0.5995
Epoch 1027/10000; Iter 80/80; Training Loss: 0.6870, Test Loss: 0.091
Epoch 1028/10000; Iter 1/80; Loss: 0.6486
Epoch 1028/10000; Iter 51/80; Loss: 0.7048
Epoch 1028/10000; Iter 80/80; Training Loss: 0.6820, Test Loss: 0.101
Epoch 1029/10000; Iter 1/80; Loss: 0.6994
Epoch 1029/10000; Iter 51/80; Loss: 0.6792
Epoch 1029/10000; Iter 80/80; Training Loss: 0.6850, Test Loss: 0.1
Epoch 1030/10000; Iter 1/80; Loss: 0.6078
Epoch 1030/10000; Iter 51/80; Loss: 0.7391
Epoch 1030/10000; Iter 80/80; Training Loss: 0.6940, Test Loss: 0.096
Epoch 1031/10000; Iter 1/80; Loss: 0.6573
Epoch 1031/10000; Iter 51/80; Loss: 0.5916
Epoch 1031/10000; Iter 80/80; Training Loss: 0.6870, Test Loss: 0.084
Epoch 1032/10000; Iter 1/80; Loss: 0.6702
Epoch 1032/10000; Iter 51/80; Loss: 0.7067
Epoch 1032/10000; Iter 80/80; Training Loss: 0.6770, Test Loss: 0.103
Epoch 1033/10000; Iter 1/80; Loss: 0.6548
Epoch 1033/10000; Iter 51/80; Loss: 0.7920
Epoch 1033/10000; Iter 80/80; Training Loss: 0.6890, Test Loss: 0.095
Epoch 1034/10000; Iter 1/80; Loss: 0.7378
Epoch 1034/10000; Iter 51/80; Loss: 0.6463
Epoch 1034/10000; Iter 80/80; Training Loss: 0.6780, Test Loss: 0.102
Epoch 1035/10000; Iter 1/80; Loss: 0.6485
Epoch 1035/10000; Iter 51/80; Loss: 0.6881
Epoch 1035/10000; Iter 80/80; Training Loss: 0.6840, Test Loss: 0.104
Epoch 1036/10000; Iter 1/80; Loss: 0.7059
Epoch 1036/10000; Iter 51/80; Loss: 0.6621
Epoch 1036/10000; Iter 80/80; Training Loss: 0.6810, Test Loss: 0.103
Epoch 1037/10000; Iter 1/80; Loss: 0.7006
Epoch 1037/10000; Iter 51/80; Loss: 0.6046
Epoch 1037/10000; Iter 80/80; Training Loss: 0.6900, Test Loss: 0.092
Epoch 1038/10000; Iter 1/80; Loss: 0.7294
Epoch 1038/10000; Iter 51/80; Loss: 0.8809
Epoch 1038/10000; Iter 80/80; Training Loss: 0.6860, Test Loss: 0.087
Epoch 1039/10000; Iter 1/80; Loss: 0.6938
Epoch 1039/10000; Iter 51/80; Loss: 0.6298
Epoch 1039/10000; Iter 80/80; Training Loss: 0.6800, Test Loss: 0.096
Epoch 1040/10000; Iter 1/80; Loss: 0.7064
Epoch 1040/10000; Iter 51/80; Loss: 0.6963
Epoch 1040/10000; Iter 80/80; Training Loss: 0.6830, Test Loss: 0.093
Epoch 1041/10000; Iter 1/80; Loss: 0.6539
Epoch 1041/10000; Iter 51/80; Loss: 0.7445
Epoch 1041/10000; Iter 80/80; Training Loss: 0.6830, Test Loss: 0.106
Epoch 1042/10000; Iter 1/80; Loss: 0.6821
Epoch 1042/10000; Iter 51/80; Loss: 0.6358
Epoch 1042/10000; Iter 80/80; Training Loss: 0.6800, Test Loss: 0.101
Epoch 1043/10000; Iter 1/80; Loss: 0.6366
Epoch 1043/10000; Iter 51/80; Loss: 0.6751
Epoch 1043/10000; Iter 80/80; Training Loss: 0.6790, Test Loss: 0.098
Epoch 1044/10000; Iter 1/80; Loss: 0.6420
Epoch 1044/10000; Iter 51/80; Loss: 0.6164
Epoch 1044/10000; Iter 80/80; Training Loss: 0.6800, Test Loss: 0.097
Epoch 1045/10000; Iter 1/80; Loss: 0.6585
Epoch 1045/10000; Iter 51/80; Loss: 0.7271
Epoch 1045/10000; Iter 80/80; Training Loss: 0.6820, Test Loss: 0.087
Epoch 1046/10000; Iter 1/80; Loss: 0.5427
Epoch 1046/10000; Iter 51/80; Loss: 0.6999
Epoch 1046/10000; Iter 80/80; Training Loss: 0.6830, Test Loss: 0.088
Epoch 1047/10000; Iter 1/80; Loss: 0.6958
Epoch 1047/10000; Iter 51/80; Loss: 0.6888
Epoch 1047/10000; Iter 80/80; Training Loss: 0.6800, Test Loss: 0.086
Epoch 1048/10000; Iter 1/80; Loss: 0.6673
Epoch 1048/10000; Iter 51/80; Loss: 0.7644
Epoch 1048/10000; Iter 80/80; Training Loss: 0.6900, Test Loss: 0.1
Epoch 1049/10000; Iter 1/80; Loss: 0.8416
Epoch 1049/10000; Iter 51/80; Loss: 0.6785
Epoch 1049/10000; Iter 80/80; Training Loss: 0.6860, Test Loss: 0.088
Epoch 1050/10000; Iter 1/80; Loss: 0.6912
Epoch 1050/10000; Iter 51/80; Loss: 0.7228
Epoch 1050/10000; Iter 80/80; Training Loss: 0.6730, Test Loss: 0.085
Epoch 1051/10000; Iter 1/80; Loss: 0.7313
Epoch 1051/10000; Iter 51/80; Loss: 0.6599
Epoch 1051/10000; Iter 80/80; Training Loss: 0.6850, Test Loss: 0.097
Epoch 1052/10000; Iter 1/80; Loss: 0.7536
Epoch 1052/10000; Iter 51/80; Loss: 0.7195
Epoch 1052/10000; Iter 80/80; Training Loss: 0.6850, Test Loss: 0.093
Epoch 1053/10000; Iter 1/80; Loss: 0.7174
Epoch 1053/10000; Iter 51/80; Loss: 0.6807
Epoch 1053/10000; Iter 80/80; Training Loss: 0.6840, Test Loss: 0.087
Epoch 1054/10000; Iter 1/80; Loss: 0.7424
Epoch 1054/10000; Iter 51/80; Loss: 0.6906
Epoch 1054/10000; Iter 80/80; Training Loss: 0.6860, Test Loss: 0.111
Epoch 1055/10000; Iter 1/80; Loss: 0.6930
Epoch 1055/10000; Iter 51/80; Loss: 0.6965
Epoch 1055/10000; Iter 80/80; Training Loss: 0.6820, Test Loss: 0.093
Epoch 1056/10000; Iter 1/80; Loss: 0.7666
Epoch 1056/10000; Iter 51/80; Loss: 0.6545
Epoch 1056/10000; Iter 80/80; Training Loss: 0.6730, Test Loss: 0.091
Epoch 1057/10000; Iter 1/80; Loss: 0.7087
Epoch 1057/10000; Iter 51/80; Loss: 0.6707
Epoch 1057/10000; Iter 80/80; Training Loss: 0.6740, Test Loss: 0.1
Epoch 1058/10000; Iter 1/80; Loss: 0.7247
Epoch 1058/10000; Iter 51/80; Loss: 0.6630
Epoch 1058/10000; Iter 80/80; Training Loss: 0.6740, Test Loss: 0.088
Epoch 1059/10000; Iter 1/80; Loss: 0.6046
Epoch 1059/10000; Iter 51/80; Loss: 0.7183
Epoch 1059/10000; Iter 80/80; Training Loss: 0.6750, Test Loss: 0.1
Epoch 1060/10000; Iter 1/80; Loss: 0.6314
Epoch 1060/10000; Iter 51/80; Loss: 0.6803
Epoch 1060/10000; Iter 80/80; Training Loss: 0.6820, Test Loss: 0.101
Epoch 1061/10000; Iter 1/80; Loss: 0.7481
Epoch 1061/10000; Iter 51/80; Loss: 0.6587
Epoch 1061/10000; Iter 80/80; Training Loss: 0.6680, Test Loss: 0.096
Epoch 1062/10000; Iter 1/80; Loss: 0.7120
Epoch 1062/10000; Iter 51/80; Loss: 0.7811
Epoch 1062/10000; Iter 80/80; Training Loss: 0.6740, Test Loss: 0.097
Epoch 1063/10000; Iter 1/80; Loss: 0.5601
Epoch 1063/10000; Iter 51/80; Loss: 0.7020
Epoch 1063/10000; Iter 80/80; Training Loss: 0.6730, Test Loss: 0.088
Epoch 1064/10000; Iter 1/80; Loss: 0.6591
Epoch 1064/10000; Iter 51/80; Loss: 0.6608
Epoch 1064/10000; Iter 80/80; Training Loss: 0.6740, Test Loss: 0.095
Epoch 1065/10000; Iter 1/80; Loss: 0.6101
Epoch 1065/10000; Iter 51/80; Loss: 0.6042
Epoch 1065/10000; Iter 80/80; Training Loss: 0.6740, Test Loss: 0.096
Epoch 1066/10000; Iter 1/80; Loss: 0.6491
Epoch 1066/10000; Iter 51/80; Loss: 0.6073
Epoch 1066/10000; Iter 80/80; Training Loss: 0.6750, Test Loss: 0.086
Epoch 1067/10000; Iter 1/80; Loss: 0.6658
Epoch 1067/10000; Iter 51/80; Loss: 0.6316
Epoch 1067/10000; Iter 80/80; Training Loss: 0.6670, Test Loss: 0.106
Epoch 1068/10000; Iter 1/80; Loss: 0.6605
Epoch 1068/10000; Iter 51/80; Loss: 0.7114
Epoch 1068/10000; Iter 80/80; Training Loss: 0.6740, Test Loss: 0.098
Epoch 1069/10000; Iter 1/80; Loss: 0.6578
Epoch 1069/10000; Iter 51/80; Loss: 0.6392
Epoch 1069/10000; Iter 80/80; Training Loss: 0.6560, Test Loss: 0.094
Epoch 1070/10000; Iter 1/80; Loss: 0.6730
Epoch 1070/10000; Iter 51/80; Loss: 0.6709
Epoch 1070/10000; Iter 80/80; Training Loss: 0.6680, Test Loss: 0.097
Epoch 1071/10000; Iter 1/80; Loss: 0.6123
Epoch 1071/10000; Iter 51/80; Loss: 0.7382
Epoch 1071/10000; Iter 80/80; Training Loss: 0.6690, Test Loss: 0.095
Epoch 1072/10000; Iter 1/80; Loss: 0.6935
Epoch 1072/10000; Iter 51/80; Loss: 0.6220
Epoch 1072/10000; Iter 80/80; Training Loss: 0.6660, Test Loss: 0.089
Epoch 1073/10000; Iter 1/80; Loss: 0.7162
Epoch 1073/10000; Iter 51/80; Loss: 0.6871
Epoch 1073/10000; Iter 80/80; Training Loss: 0.6700, Test Loss: 0.09
Epoch 1074/10000; Iter 1/80; Loss: 0.7188
Epoch 1074/10000; Iter 51/80; Loss: 0.8136
Epoch 1074/10000; Iter 80/80; Training Loss: 0.6700, Test Loss: 0.102
Epoch 1075/10000; Iter 1/80; Loss: 0.6638
Epoch 1075/10000; Iter 51/80; Loss: 0.6970
Epoch 1075/10000; Iter 80/80; Training Loss: 0.6690, Test Loss: 0.093
Epoch 1076/10000; Iter 1/80; Loss: 0.6366
Epoch 1076/10000; Iter 51/80; Loss: 0.6882
Epoch 1076/10000; Iter 80/80; Training Loss: 0.6610, Test Loss: 0.106
Epoch 1077/10000; Iter 1/80; Loss: 0.6362
Epoch 1077/10000; Iter 51/80; Loss: 0.6878
Epoch 1077/10000; Iter 80/80; Training Loss: 0.6660, Test Loss: 0.095
Epoch 1078/10000; Iter 1/80; Loss: 0.6109
Epoch 1078/10000; Iter 51/80; Loss: 0.7307
Epoch 1078/10000; Iter 80/80; Training Loss: 0.6620, Test Loss: 0.093
Epoch 1079/10000; Iter 1/80; Loss: 0.7368
Epoch 1079/10000; Iter 51/80; Loss: 0.6625
Epoch 1079/10000; Iter 80/80; Training Loss: 0.6710, Test Loss: 0.103
Epoch 1080/10000; Iter 1/80; Loss: 0.6777
Epoch 1080/10000; Iter 51/80; Loss: 0.6947
Epoch 1080/10000; Iter 80/80; Training Loss: 0.6680, Test Loss: 0.091
Epoch 1081/10000; Iter 1/80; Loss: 0.7365
Epoch 1081/10000; Iter 51/80; Loss: 0.7384
Epoch 1081/10000; Iter 80/80; Training Loss: 0.6720, Test Loss: 0.095
Epoch 1082/10000; Iter 1/80; Loss: 0.6507
Epoch 1082/10000; Iter 51/80; Loss: 0.6958
Epoch 1082/10000; Iter 80/80; Training Loss: 0.6630, Test Loss: 0.091
Epoch 1083/10000; Iter 1/80; Loss: 0.6663
Epoch 1083/10000; Iter 51/80; Loss: 0.5964
Epoch 1083/10000; Iter 80/80; Training Loss: 0.6700, Test Loss: 0.091
Epoch 1084/10000; Iter 1/80; Loss: 0.7206
Epoch 1084/10000; Iter 51/80; Loss: 0.7851
Epoch 1084/10000; Iter 80/80; Training Loss: 0.6620, Test Loss: 0.095
Epoch 1085/10000; Iter 1/80; Loss: 0.6340
Epoch 1085/10000; Iter 51/80; Loss: 0.7094
Epoch 1085/10000; Iter 80/80; Training Loss: 0.6620, Test Loss: 0.088
Epoch 1086/10000; Iter 1/80; Loss: 0.7360
Epoch 1086/10000; Iter 51/80; Loss: 0.6598
Epoch 1086/10000; Iter 80/80; Training Loss: 0.6750, Test Loss: 0.103
Epoch 1087/10000; Iter 1/80; Loss: 0.6816
Epoch 1087/10000; Iter 51/80; Loss: 0.6458
Epoch 1087/10000; Iter 80/80; Training Loss: 0.6750, Test Loss: 0.091
Epoch 1088/10000; Iter 1/80; Loss: 0.7195
Epoch 1088/10000; Iter 51/80; Loss: 0.5738
Epoch 1088/10000; Iter 80/80; Training Loss: 0.6610, Test Loss: 0.096
Epoch 1089/10000; Iter 1/80; Loss: 0.6124
Epoch 1089/10000; Iter 51/80; Loss: 0.7423
Epoch 1089/10000; Iter 80/80; Training Loss: 0.6620, Test Loss: 0.115
Epoch 1090/10000; Iter 1/80; Loss: 0.6632
Epoch 1090/10000; Iter 51/80; Loss: 0.5614
Epoch 1090/10000; Iter 80/80; Training Loss: 0.6600, Test Loss: 0.108
Epoch 1091/10000; Iter 1/80; Loss: 0.5910
Epoch 1091/10000; Iter 51/80; Loss: 0.6858
Epoch 1091/10000; Iter 80/80; Training Loss: 0.6610, Test Loss: 0.112
Epoch 1092/10000; Iter 1/80; Loss: 0.6108
Epoch 1092/10000; Iter 51/80; Loss: 0.5819
Epoch 1092/10000; Iter 80/80; Training Loss: 0.6660, Test Loss: 0.098
Epoch 1093/10000; Iter 1/80; Loss: 0.6783
Epoch 1093/10000; Iter 51/80; Loss: 0.6775
Epoch 1093/10000; Iter 80/80; Training Loss: 0.6580, Test Loss: 0.087
Epoch 1094/10000; Iter 1/80; Loss: 0.6465
Epoch 1094/10000; Iter 51/80; Loss: 0.5451
Epoch 1094/10000; Iter 80/80; Training Loss: 0.6590, Test Loss: 0.091
Epoch 1095/10000; Iter 1/80; Loss: 0.6087
Epoch 1095/10000; Iter 51/80; Loss: 0.6386
Epoch 1095/10000; Iter 80/80; Training Loss: 0.6580, Test Loss: 0.089
Epoch 1096/10000; Iter 1/80; Loss: 0.7617
Epoch 1096/10000; Iter 51/80; Loss: 0.6221
Epoch 1096/10000; Iter 80/80; Training Loss: 0.6710, Test Loss: 0.09
Epoch 1097/10000; Iter 1/80; Loss: 0.6094
Epoch 1097/10000; Iter 51/80; Loss: 0.6761
Epoch 1097/10000; Iter 80/80; Training Loss: 0.6570, Test Loss: 0.089
Epoch 1098/10000; Iter 1/80; Loss: 0.7043
Epoch 1098/10000; Iter 51/80; Loss: 0.6719
Epoch 1098/10000; Iter 80/80; Training Loss: 0.6580, Test Loss: 0.099
Epoch 1099/10000; Iter 1/80; Loss: 0.6936
Epoch 1099/10000; Iter 51/80; Loss: 0.6251
Epoch 1099/10000; Iter 80/80; Training Loss: 0.6580, Test Loss: 0.084
Epoch 1100/10000; Iter 1/80; Loss: 0.6951
Epoch 1100/10000; Iter 51/80; Loss: 0.5875
Epoch 1100/10000; Iter 80/80; Training Loss: 0.6520, Test Loss: 0.083
Epoch 1101/10000; Iter 1/80; Loss: 0.6739
Epoch 1101/10000; Iter 51/80; Loss: 0.6443
Epoch 1101/10000; Iter 80/80; Training Loss: 0.6680, Test Loss: 0.088
Model saved
Epoch 1102/10000; Iter 1/80; Loss: 0.6847
Epoch 1102/10000; Iter 51/80; Loss: 0.6681
Epoch 1102/10000; Iter 80/80; Training Loss: 0.6650, Test Loss: 0.113
Epoch 1103/10000; Iter 1/80; Loss: 0.7090
Epoch 1103/10000; Iter 51/80; Loss: 0.6318
Epoch 1103/10000; Iter 80/80; Training Loss: 0.6580, Test Loss: 0.086
Epoch 1104/10000; Iter 1/80; Loss: 0.6711
Epoch 1104/10000; Iter 51/80; Loss: 0.7148
Epoch 1104/10000; Iter 80/80; Training Loss: 0.6640, Test Loss: 0.095
Epoch 1105/10000; Iter 1/80; Loss: 0.6654
Epoch 1105/10000; Iter 51/80; Loss: 0.6605
Epoch 1105/10000; Iter 80/80; Training Loss: 0.6470, Test Loss: 0.079
Epoch 1106/10000; Iter 1/80; Loss: 0.6129
Epoch 1106/10000; Iter 51/80; Loss: 0.6134
Epoch 1106/10000; Iter 80/80; Training Loss: 0.6590, Test Loss: 0.086
Epoch 1107/10000; Iter 1/80; Loss: 0.6218
Epoch 1107/10000; Iter 51/80; Loss: 0.7113
Epoch 1107/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.089
Epoch 1108/10000; Iter 1/80; Loss: 0.6794
Epoch 1108/10000; Iter 51/80; Loss: 0.6323
Epoch 1108/10000; Iter 80/80; Training Loss: 0.6610, Test Loss: 0.089
Epoch 1109/10000; Iter 1/80; Loss: 0.6554
Epoch 1109/10000; Iter 51/80; Loss: 0.7218
Epoch 1109/10000; Iter 80/80; Training Loss: 0.6560, Test Loss: 0.082
Epoch 1110/10000; Iter 1/80; Loss: 0.6374
Epoch 1110/10000; Iter 51/80; Loss: 0.6471
Epoch 1110/10000; Iter 80/80; Training Loss: 0.6660, Test Loss: 0.089
Epoch 1111/10000; Iter 1/80; Loss: 0.6215
Epoch 1111/10000; Iter 51/80; Loss: 0.6950
Epoch 1111/10000; Iter 80/80; Training Loss: 0.6550, Test Loss: 0.099
Epoch 1112/10000; Iter 1/80; Loss: 0.7160
Epoch 1112/10000; Iter 51/80; Loss: 0.6393
Epoch 1112/10000; Iter 80/80; Training Loss: 0.6540, Test Loss: 0.091
Epoch 1113/10000; Iter 1/80; Loss: 0.6211
Epoch 1113/10000; Iter 51/80; Loss: 0.6407
Epoch 1113/10000; Iter 80/80; Training Loss: 0.6510, Test Loss: 0.099
Epoch 1114/10000; Iter 1/80; Loss: 0.6290
Epoch 1114/10000; Iter 51/80; Loss: 0.6412
Epoch 1114/10000; Iter 80/80; Training Loss: 0.6560, Test Loss: 0.092
Epoch 1115/10000; Iter 1/80; Loss: 0.6537
Epoch 1115/10000; Iter 51/80; Loss: 0.5889
Epoch 1115/10000; Iter 80/80; Training Loss: 0.6530, Test Loss: 0.09
Epoch 1116/10000; Iter 1/80; Loss: 0.6645
Epoch 1116/10000; Iter 51/80; Loss: 0.6613
Epoch 1116/10000; Iter 80/80; Training Loss: 0.6570, Test Loss: 0.099
Epoch 1117/10000; Iter 1/80; Loss: 0.6599
Epoch 1117/10000; Iter 51/80; Loss: 0.5413
Epoch 1117/10000; Iter 80/80; Training Loss: 0.6500, Test Loss: 0.085
Epoch 1118/10000; Iter 1/80; Loss: 0.6711
Epoch 1118/10000; Iter 51/80; Loss: 0.5993
Epoch 1118/10000; Iter 80/80; Training Loss: 0.6500, Test Loss: 0.079
Epoch 1119/10000; Iter 1/80; Loss: 0.5885
Epoch 1119/10000; Iter 51/80; Loss: 0.6690
Epoch 1119/10000; Iter 80/80; Training Loss: 0.6480, Test Loss: 0.103
Epoch 1120/10000; Iter 1/80; Loss: 0.6029
Epoch 1120/10000; Iter 51/80; Loss: 0.6268
Epoch 1120/10000; Iter 80/80; Training Loss: 0.6570, Test Loss: 0.087
Epoch 1121/10000; Iter 1/80; Loss: 0.6237
Epoch 1121/10000; Iter 51/80; Loss: 0.6756
Epoch 1121/10000; Iter 80/80; Training Loss: 0.6630, Test Loss: 0.095
Epoch 1122/10000; Iter 1/80; Loss: 0.7191
Epoch 1122/10000; Iter 51/80; Loss: 0.6362
Epoch 1122/10000; Iter 80/80; Training Loss: 0.6450, Test Loss: 0.104
Epoch 1123/10000; Iter 1/80; Loss: 0.6065
Epoch 1123/10000; Iter 51/80; Loss: 0.6231
Epoch 1123/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.101
Epoch 1124/10000; Iter 1/80; Loss: 0.6003
Epoch 1124/10000; Iter 51/80; Loss: 0.7032
Epoch 1124/10000; Iter 80/80; Training Loss: 0.6510, Test Loss: 0.092
Epoch 1125/10000; Iter 1/80; Loss: 0.6339
Epoch 1125/10000; Iter 51/80; Loss: 0.5680
Epoch 1125/10000; Iter 80/80; Training Loss: 0.6470, Test Loss: 0.089
Epoch 1126/10000; Iter 1/80; Loss: 0.5836
Epoch 1126/10000; Iter 51/80; Loss: 0.7056
Epoch 1126/10000; Iter 80/80; Training Loss: 0.6570, Test Loss: 0.088
Epoch 1127/10000; Iter 1/80; Loss: 0.5977
Epoch 1127/10000; Iter 51/80; Loss: 0.6290
Epoch 1127/10000; Iter 80/80; Training Loss: 0.6420, Test Loss: 0.097
Epoch 1128/10000; Iter 1/80; Loss: 0.6643
Epoch 1128/10000; Iter 51/80; Loss: 0.6210
Epoch 1128/10000; Iter 80/80; Training Loss: 0.6480, Test Loss: 0.1
Epoch 1129/10000; Iter 1/80; Loss: 0.6002
Epoch 1129/10000; Iter 51/80; Loss: 0.5905
Epoch 1129/10000; Iter 80/80; Training Loss: 0.6570, Test Loss: 0.087
Epoch 1130/10000; Iter 1/80; Loss: 0.7287
Epoch 1130/10000; Iter 51/80; Loss: 0.6052
Epoch 1130/10000; Iter 80/80; Training Loss: 0.6530, Test Loss: 0.105
Epoch 1131/10000; Iter 1/80; Loss: 0.6830
Epoch 1131/10000; Iter 51/80; Loss: 0.6586
Epoch 1131/10000; Iter 80/80; Training Loss: 0.6520, Test Loss: 0.099
Epoch 1132/10000; Iter 1/80; Loss: 0.6503
Epoch 1132/10000; Iter 51/80; Loss: 0.5889
Epoch 1132/10000; Iter 80/80; Training Loss: 0.6520, Test Loss: 0.083
Epoch 1133/10000; Iter 1/80; Loss: 0.6083
Epoch 1133/10000; Iter 51/80; Loss: 0.5958
Epoch 1133/10000; Iter 80/80; Training Loss: 0.6450, Test Loss: 0.079
Epoch 1134/10000; Iter 1/80; Loss: 0.6153
Epoch 1134/10000; Iter 51/80; Loss: 0.6519
Epoch 1134/10000; Iter 80/80; Training Loss: 0.6380, Test Loss: 0.093
Epoch 1135/10000; Iter 1/80; Loss: 0.5615
Epoch 1135/10000; Iter 51/80; Loss: 0.6209
Epoch 1135/10000; Iter 80/80; Training Loss: 0.6450, Test Loss: 0.088
Epoch 1136/10000; Iter 1/80; Loss: 0.5796
Epoch 1136/10000; Iter 51/80; Loss: 0.6527
Epoch 1136/10000; Iter 80/80; Training Loss: 0.6500, Test Loss: 0.083
Epoch 1137/10000; Iter 1/80; Loss: 0.6462
Epoch 1137/10000; Iter 51/80; Loss: 0.6391
Epoch 1137/10000; Iter 80/80; Training Loss: 0.6500, Test Loss: 0.08
Epoch 1138/10000; Iter 1/80; Loss: 0.6395
Epoch 1138/10000; Iter 51/80; Loss: 0.6894
Epoch 1138/10000; Iter 80/80; Training Loss: 0.6410, Test Loss: 0.096
Epoch 1139/10000; Iter 1/80; Loss: 0.5467
Epoch 1139/10000; Iter 51/80; Loss: 0.6651
Epoch 1139/10000; Iter 80/80; Training Loss: 0.6390, Test Loss: 0.082
Epoch 1140/10000; Iter 1/80; Loss: 0.5868
Epoch 1140/10000; Iter 51/80; Loss: 0.6273
Epoch 1140/10000; Iter 80/80; Training Loss: 0.6520, Test Loss: 0.092
Epoch 1141/10000; Iter 1/80; Loss: 0.5867
Epoch 1141/10000; Iter 51/80; Loss: 0.6878
Epoch 1141/10000; Iter 80/80; Training Loss: 0.6470, Test Loss: 0.09
Epoch 1142/10000; Iter 1/80; Loss: 0.7117
Epoch 1142/10000; Iter 51/80; Loss: 0.5946
Epoch 1142/10000; Iter 80/80; Training Loss: 0.6530, Test Loss: 0.092
Epoch 1143/10000; Iter 1/80; Loss: 0.7084
Epoch 1143/10000; Iter 51/80; Loss: 0.6686
Epoch 1143/10000; Iter 80/80; Training Loss: 0.6410, Test Loss: 0.092
Epoch 1144/10000; Iter 1/80; Loss: 0.7661
Epoch 1144/10000; Iter 51/80; Loss: 0.6569
Epoch 1144/10000; Iter 80/80; Training Loss: 0.6490, Test Loss: 0.078
Epoch 1145/10000; Iter 1/80; Loss: 0.7131
Epoch 1145/10000; Iter 51/80; Loss: 0.6559
Epoch 1145/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.094
Epoch 1146/10000; Iter 1/80; Loss: 0.7365
Epoch 1146/10000; Iter 51/80; Loss: 0.6144
Epoch 1146/10000; Iter 80/80; Training Loss: 0.6420, Test Loss: 0.085
Epoch 1147/10000; Iter 1/80; Loss: 0.6966
Epoch 1147/10000; Iter 51/80; Loss: 0.6482
Epoch 1147/10000; Iter 80/80; Training Loss: 0.6350, Test Loss: 0.084
Epoch 1148/10000; Iter 1/80; Loss: 0.7152
Epoch 1148/10000; Iter 51/80; Loss: 0.7018
Epoch 1148/10000; Iter 80/80; Training Loss: 0.6410, Test Loss: 0.089
Epoch 1149/10000; Iter 1/80; Loss: 0.6467
Epoch 1149/10000; Iter 51/80; Loss: 0.7358
Epoch 1149/10000; Iter 80/80; Training Loss: 0.6500, Test Loss: 0.098
Epoch 1150/10000; Iter 1/80; Loss: 0.7040
Epoch 1150/10000; Iter 51/80; Loss: 0.6536
Epoch 1150/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.092
Epoch 1151/10000; Iter 1/80; Loss: 0.7051
Epoch 1151/10000; Iter 51/80; Loss: 0.6949
Epoch 1151/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.084
Epoch 1152/10000; Iter 1/80; Loss: 0.6525
Epoch 1152/10000; Iter 51/80; Loss: 0.5778
Epoch 1152/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.097
Epoch 1153/10000; Iter 1/80; Loss: 0.6882
Epoch 1153/10000; Iter 51/80; Loss: 0.6589
Epoch 1153/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.1
Epoch 1154/10000; Iter 1/80; Loss: 0.7051
Epoch 1154/10000; Iter 51/80; Loss: 0.5984
Epoch 1154/10000; Iter 80/80; Training Loss: 0.6420, Test Loss: 0.083
Epoch 1155/10000; Iter 1/80; Loss: 0.5787
Epoch 1155/10000; Iter 51/80; Loss: 0.5584
Epoch 1155/10000; Iter 80/80; Training Loss: 0.6370, Test Loss: 0.078
Epoch 1156/10000; Iter 1/80; Loss: 0.7108
Epoch 1156/10000; Iter 51/80; Loss: 0.6402
Epoch 1156/10000; Iter 80/80; Training Loss: 0.6380, Test Loss: 0.091
Epoch 1157/10000; Iter 1/80; Loss: 0.5993
Epoch 1157/10000; Iter 51/80; Loss: 0.6083
Epoch 1157/10000; Iter 80/80; Training Loss: 0.6430, Test Loss: 0.087
Epoch 1158/10000; Iter 1/80; Loss: 0.6834
Epoch 1158/10000; Iter 51/80; Loss: 0.6697
Epoch 1158/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.091
Epoch 1159/10000; Iter 1/80; Loss: 0.5814
Epoch 1159/10000; Iter 51/80; Loss: 0.6389
Epoch 1159/10000; Iter 80/80; Training Loss: 0.6380, Test Loss: 0.093
Epoch 1160/10000; Iter 1/80; Loss: 0.5568
Epoch 1160/10000; Iter 51/80; Loss: 0.6647
Epoch 1160/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.075
Epoch 1161/10000; Iter 1/80; Loss: 0.7095
Epoch 1161/10000; Iter 51/80; Loss: 0.7336
Epoch 1161/10000; Iter 80/80; Training Loss: 0.6520, Test Loss: 0.09
Epoch 1162/10000; Iter 1/80; Loss: 0.6796
Epoch 1162/10000; Iter 51/80; Loss: 0.5715
Epoch 1162/10000; Iter 80/80; Training Loss: 0.6420, Test Loss: 0.102
Epoch 1163/10000; Iter 1/80; Loss: 0.6477
Epoch 1163/10000; Iter 51/80; Loss: 0.6499
Epoch 1163/10000; Iter 80/80; Training Loss: 0.6360, Test Loss: 0.099
Epoch 1164/10000; Iter 1/80; Loss: 0.7397
Epoch 1164/10000; Iter 51/80; Loss: 0.5720
Epoch 1164/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.087
Epoch 1165/10000; Iter 1/80; Loss: 0.6143
Epoch 1165/10000; Iter 51/80; Loss: 0.6180
Epoch 1165/10000; Iter 80/80; Training Loss: 0.6410, Test Loss: 0.088
Epoch 1166/10000; Iter 1/80; Loss: 0.6081
Epoch 1166/10000; Iter 51/80; Loss: 0.6331
Epoch 1166/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.082
Epoch 1167/10000; Iter 1/80; Loss: 0.5934
Epoch 1167/10000; Iter 51/80; Loss: 0.5625
Epoch 1167/10000; Iter 80/80; Training Loss: 0.6360, Test Loss: 0.088
Epoch 1168/10000; Iter 1/80; Loss: 0.6823
Epoch 1168/10000; Iter 51/80; Loss: 0.6327
Epoch 1168/10000; Iter 80/80; Training Loss: 0.6390, Test Loss: 0.095
Epoch 1169/10000; Iter 1/80; Loss: 0.5961
Epoch 1169/10000; Iter 51/80; Loss: 0.5636
Epoch 1169/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.098
Epoch 1170/10000; Iter 1/80; Loss: 0.6678
Epoch 1170/10000; Iter 51/80; Loss: 0.7414
Epoch 1170/10000; Iter 80/80; Training Loss: 0.6320, Test Loss: 0.086
Epoch 1171/10000; Iter 1/80; Loss: 0.6337
Epoch 1171/10000; Iter 51/80; Loss: 0.6988
Epoch 1171/10000; Iter 80/80; Training Loss: 0.6350, Test Loss: 0.088
Epoch 1172/10000; Iter 1/80; Loss: 0.6458
Epoch 1172/10000; Iter 51/80; Loss: 0.5920
Epoch 1172/10000; Iter 80/80; Training Loss: 0.6460, Test Loss: 0.095
Epoch 1173/10000; Iter 1/80; Loss: 0.5910
Epoch 1173/10000; Iter 51/80; Loss: 0.6301
Epoch 1173/10000; Iter 80/80; Training Loss: 0.6350, Test Loss: 0.072
Epoch 1174/10000; Iter 1/80; Loss: 0.6314
Epoch 1174/10000; Iter 51/80; Loss: 0.6191
Epoch 1174/10000; Iter 80/80; Training Loss: 0.6320, Test Loss: 0.09
Epoch 1175/10000; Iter 1/80; Loss: 0.6038
Epoch 1175/10000; Iter 51/80; Loss: 0.5469
Epoch 1175/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.087
Epoch 1176/10000; Iter 1/80; Loss: 0.6978
Epoch 1176/10000; Iter 51/80; Loss: 0.6681
Epoch 1176/10000; Iter 80/80; Training Loss: 0.6380, Test Loss: 0.093
Epoch 1177/10000; Iter 1/80; Loss: 0.5786
Epoch 1177/10000; Iter 51/80; Loss: 0.6819
Epoch 1177/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.083
Epoch 1178/10000; Iter 1/80; Loss: 0.6212
Epoch 1178/10000; Iter 51/80; Loss: 0.6221
Epoch 1178/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.091
Epoch 1179/10000; Iter 1/80; Loss: 0.6097
Epoch 1179/10000; Iter 51/80; Loss: 0.6879
Epoch 1179/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.087
Epoch 1180/10000; Iter 1/80; Loss: 0.6423
Epoch 1180/10000; Iter 51/80; Loss: 0.5834
Epoch 1180/10000; Iter 80/80; Training Loss: 0.6280, Test Loss: 0.088
Epoch 1181/10000; Iter 1/80; Loss: 0.5259
Epoch 1181/10000; Iter 51/80; Loss: 0.5925
Epoch 1181/10000; Iter 80/80; Training Loss: 0.6260, Test Loss: 0.101
Epoch 1182/10000; Iter 1/80; Loss: 0.6242
Epoch 1182/10000; Iter 51/80; Loss: 0.6934
Epoch 1182/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.096
Epoch 1183/10000; Iter 1/80; Loss: 0.6458
Epoch 1183/10000; Iter 51/80; Loss: 0.5535
Epoch 1183/10000; Iter 80/80; Training Loss: 0.6340, Test Loss: 0.079
Epoch 1184/10000; Iter 1/80; Loss: 0.6139
Epoch 1184/10000; Iter 51/80; Loss: 0.5920
Epoch 1184/10000; Iter 80/80; Training Loss: 0.6240, Test Loss: 0.083
Epoch 1185/10000; Iter 1/80; Loss: 0.6014
Epoch 1185/10000; Iter 51/80; Loss: 0.6125
Epoch 1185/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.086
Epoch 1186/10000; Iter 1/80; Loss: 0.7400
Epoch 1186/10000; Iter 51/80; Loss: 0.6628
Epoch 1186/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.082
Epoch 1187/10000; Iter 1/80; Loss: 0.6282
Epoch 1187/10000; Iter 51/80; Loss: 0.6254
Epoch 1187/10000; Iter 80/80; Training Loss: 0.6320, Test Loss: 0.079
Epoch 1188/10000; Iter 1/80; Loss: 0.5943
Epoch 1188/10000; Iter 51/80; Loss: 0.6219
Epoch 1188/10000; Iter 80/80; Training Loss: 0.6350, Test Loss: 0.094
Epoch 1189/10000; Iter 1/80; Loss: 0.6538
Epoch 1189/10000; Iter 51/80; Loss: 0.5693
Epoch 1189/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.085
Epoch 1190/10000; Iter 1/80; Loss: 0.5629
Epoch 1190/10000; Iter 51/80; Loss: 0.6226
Epoch 1190/10000; Iter 80/80; Training Loss: 0.6290, Test Loss: 0.097
Epoch 1191/10000; Iter 1/80; Loss: 0.6953
Epoch 1191/10000; Iter 51/80; Loss: 0.6462
Epoch 1191/10000; Iter 80/80; Training Loss: 0.6300, Test Loss: 0.091
Epoch 1192/10000; Iter 1/80; Loss: 0.6989
Epoch 1192/10000; Iter 51/80; Loss: 0.6446
Epoch 1192/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.081
Epoch 1193/10000; Iter 1/80; Loss: 0.6575
Epoch 1193/10000; Iter 51/80; Loss: 0.5744
Epoch 1193/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.088
Epoch 1194/10000; Iter 1/80; Loss: 0.5398
Epoch 1194/10000; Iter 51/80; Loss: 0.6448
Epoch 1194/10000; Iter 80/80; Training Loss: 0.6330, Test Loss: 0.099
Epoch 1195/10000; Iter 1/80; Loss: 0.5717
Epoch 1195/10000; Iter 51/80; Loss: 0.7241
Epoch 1195/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.087
Epoch 1196/10000; Iter 1/80; Loss: 0.5924
Epoch 1196/10000; Iter 51/80; Loss: 0.5889
Epoch 1196/10000; Iter 80/80; Training Loss: 0.6210, Test Loss: 0.085
Epoch 1197/10000; Iter 1/80; Loss: 0.6575
Epoch 1197/10000; Iter 51/80; Loss: 0.6201
Epoch 1197/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.094
Epoch 1198/10000; Iter 1/80; Loss: 0.6244
Epoch 1198/10000; Iter 51/80; Loss: 0.5750
Epoch 1198/10000; Iter 80/80; Training Loss: 0.6300, Test Loss: 0.08
Epoch 1199/10000; Iter 1/80; Loss: 0.6150
Epoch 1199/10000; Iter 51/80; Loss: 0.6662
Epoch 1199/10000; Iter 80/80; Training Loss: 0.6360, Test Loss: 0.082
Epoch 1200/10000; Iter 1/80; Loss: 0.6389
Epoch 1200/10000; Iter 51/80; Loss: 0.6317
Epoch 1200/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.086
Epoch 1201/10000; Iter 1/80; Loss: 0.6687
Epoch 1201/10000; Iter 51/80; Loss: 0.6163
Epoch 1201/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.078
Model saved
Epoch 1202/10000; Iter 1/80; Loss: 0.6431
Epoch 1202/10000; Iter 51/80; Loss: 0.6242
Epoch 1202/10000; Iter 80/80; Training Loss: 0.6210, Test Loss: 0.086
Epoch 1203/10000; Iter 1/80; Loss: 0.5851
Epoch 1203/10000; Iter 51/80; Loss: 0.6527
Epoch 1203/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.078
Epoch 1204/10000; Iter 1/80; Loss: 0.6957
Epoch 1204/10000; Iter 51/80; Loss: 0.5639
Epoch 1204/10000; Iter 80/80; Training Loss: 0.6220, Test Loss: 0.082
Epoch 1205/10000; Iter 1/80; Loss: 0.5715
Epoch 1205/10000; Iter 51/80; Loss: 0.6191
Epoch 1205/10000; Iter 80/80; Training Loss: 0.6150, Test Loss: 0.07
Epoch 1206/10000; Iter 1/80; Loss: 0.5697
Epoch 1206/10000; Iter 51/80; Loss: 0.6042
Epoch 1206/10000; Iter 80/80; Training Loss: 0.6260, Test Loss: 0.08
Epoch 1207/10000; Iter 1/80; Loss: 0.6595
Epoch 1207/10000; Iter 51/80; Loss: 0.6496
Epoch 1207/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.08
Epoch 1208/10000; Iter 1/80; Loss: 0.6137
Epoch 1208/10000; Iter 51/80; Loss: 0.5621
Epoch 1208/10000; Iter 80/80; Training Loss: 0.6180, Test Loss: 0.082
Epoch 1209/10000; Iter 1/80; Loss: 0.5921
Epoch 1209/10000; Iter 51/80; Loss: 0.6699
Epoch 1209/10000; Iter 80/80; Training Loss: 0.6220, Test Loss: 0.086
Epoch 1210/10000; Iter 1/80; Loss: 0.5881
Epoch 1210/10000; Iter 51/80; Loss: 0.6217
Epoch 1210/10000; Iter 80/80; Training Loss: 0.6250, Test Loss: 0.084
Epoch 1211/10000; Iter 1/80; Loss: 0.6324
Epoch 1211/10000; Iter 51/80; Loss: 0.5348
Epoch 1211/10000; Iter 80/80; Training Loss: 0.6190, Test Loss: 0.09
Epoch 1212/10000; Iter 1/80; Loss: 0.5845
Epoch 1212/10000; Iter 51/80; Loss: 0.7554
Epoch 1212/10000; Iter 80/80; Training Loss: 0.6310, Test Loss: 0.072
Epoch 1213/10000; Iter 1/80; Loss: 0.6345
Epoch 1213/10000; Iter 51/80; Loss: 0.6519
Epoch 1213/10000; Iter 80/80; Training Loss: 0.6210, Test Loss: 0.095
Epoch 1214/10000; Iter 1/80; Loss: 0.6068
Epoch 1214/10000; Iter 51/80; Loss: 0.6023
Epoch 1214/10000; Iter 80/80; Training Loss: 0.6350, Test Loss: 0.068
Epoch 1215/10000; Iter 1/80; Loss: 0.5898
Epoch 1215/10000; Iter 51/80; Loss: 0.5210
Epoch 1215/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.089
Epoch 1216/10000; Iter 1/80; Loss: 0.6026
Epoch 1216/10000; Iter 51/80; Loss: 0.5934
Epoch 1216/10000; Iter 80/80; Training Loss: 0.6170, Test Loss: 0.094
Epoch 1217/10000; Iter 1/80; Loss: 0.6837
Epoch 1217/10000; Iter 51/80; Loss: 0.6258
Epoch 1217/10000; Iter 80/80; Training Loss: 0.6190, Test Loss: 0.101
Epoch 1218/10000; Iter 1/80; Loss: 0.5644
Epoch 1218/10000; Iter 51/80; Loss: 0.6818
Epoch 1218/10000; Iter 80/80; Training Loss: 0.6190, Test Loss: 0.09
Epoch 1219/10000; Iter 1/80; Loss: 0.6300
Epoch 1219/10000; Iter 51/80; Loss: 0.6050
Epoch 1219/10000; Iter 80/80; Training Loss: 0.6230, Test Loss: 0.078
Epoch 1220/10000; Iter 1/80; Loss: 0.5924
Epoch 1220/10000; Iter 51/80; Loss: 0.6311
Epoch 1220/10000; Iter 80/80; Training Loss: 0.6150, Test Loss: 0.091
Epoch 1221/10000; Iter 1/80; Loss: 0.6427
Epoch 1221/10000; Iter 51/80; Loss: 0.6815
Epoch 1221/10000; Iter 80/80; Training Loss: 0.6190, Test Loss: 0.088
Epoch 1222/10000; Iter 1/80; Loss: 0.6979
Epoch 1222/10000; Iter 51/80; Loss: 0.5520
Epoch 1222/10000; Iter 80/80; Training Loss: 0.6210, Test Loss: 0.08
Epoch 1223/10000; Iter 1/80; Loss: 0.6424
Epoch 1223/10000; Iter 51/80; Loss: 0.6173
Epoch 1223/10000; Iter 80/80; Training Loss: 0.6130, Test Loss: 0.091
Epoch 1224/10000; Iter 1/80; Loss: 0.6085
Epoch 1224/10000; Iter 51/80; Loss: 0.6209
Epoch 1224/10000; Iter 80/80; Training Loss: 0.6130, Test Loss: 0.091
Epoch 1225/10000; Iter 1/80; Loss: 0.6626
Epoch 1225/10000; Iter 51/80; Loss: 0.5508
Epoch 1225/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.082
Epoch 1226/10000; Iter 1/80; Loss: 0.6498
Epoch 1226/10000; Iter 51/80; Loss: 0.5529
Epoch 1226/10000; Iter 80/80; Training Loss: 0.6170, Test Loss: 0.084
Epoch 1227/10000; Iter 1/80; Loss: 0.5346
Epoch 1227/10000; Iter 51/80; Loss: 0.6350
Epoch 1227/10000; Iter 80/80; Training Loss: 0.6140, Test Loss: 0.081
Epoch 1228/10000; Iter 1/80; Loss: 0.6815
Epoch 1228/10000; Iter 51/80; Loss: 0.6483
Epoch 1228/10000; Iter 80/80; Training Loss: 0.6190, Test Loss: 0.092
Epoch 1229/10000; Iter 1/80; Loss: 0.7319
Epoch 1229/10000; Iter 51/80; Loss: 0.6123
Epoch 1229/10000; Iter 80/80; Training Loss: 0.6170, Test Loss: 0.071
Epoch 1230/10000; Iter 1/80; Loss: 0.5826
Epoch 1230/10000; Iter 51/80; Loss: 0.5462
Epoch 1230/10000; Iter 80/80; Training Loss: 0.6160, Test Loss: 0.078
Epoch 1231/10000; Iter 1/80; Loss: 0.5908
Epoch 1231/10000; Iter 51/80; Loss: 0.6029
Epoch 1231/10000; Iter 80/80; Training Loss: 0.6160, Test Loss: 0.085
Epoch 1232/10000; Iter 1/80; Loss: 0.5940
Epoch 1232/10000; Iter 51/80; Loss: 0.5910
Epoch 1232/10000; Iter 80/80; Training Loss: 0.6140, Test Loss: 0.084
Epoch 1233/10000; Iter 1/80; Loss: 0.6613
Epoch 1233/10000; Iter 51/80; Loss: 0.5982
Epoch 1233/10000; Iter 80/80; Training Loss: 0.6160, Test Loss: 0.084
Epoch 1234/10000; Iter 1/80; Loss: 0.5955
Epoch 1234/10000; Iter 51/80; Loss: 0.5760
Epoch 1234/10000; Iter 80/80; Training Loss: 0.6240, Test Loss: 0.098
Epoch 1235/10000; Iter 1/80; Loss: 0.6336
Epoch 1235/10000; Iter 51/80; Loss: 0.6243
Epoch 1235/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.095
Epoch 1236/10000; Iter 1/80; Loss: 0.6254
Epoch 1236/10000; Iter 51/80; Loss: 0.6779
Epoch 1236/10000; Iter 80/80; Training Loss: 0.6200, Test Loss: 0.087
Epoch 1237/10000; Iter 1/80; Loss: 0.6032
Epoch 1237/10000; Iter 51/80; Loss: 0.6317
Epoch 1237/10000; Iter 80/80; Training Loss: 0.6270, Test Loss: 0.075
Epoch 1238/10000; Iter 1/80; Loss: 0.6343
Epoch 1238/10000; Iter 51/80; Loss: 0.6857
Epoch 1238/10000; Iter 80/80; Training Loss: 0.6140, Test Loss: 0.085
Epoch 1239/10000; Iter 1/80; Loss: 0.5334
Epoch 1239/10000; Iter 51/80; Loss: 0.6583
Epoch 1239/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.087
Epoch 1240/10000; Iter 1/80; Loss: 0.6056
Epoch 1240/10000; Iter 51/80; Loss: 0.5599
Epoch 1240/10000; Iter 80/80; Training Loss: 0.6070, Test Loss: 0.079
Epoch 1241/10000; Iter 1/80; Loss: 0.6850
Epoch 1241/10000; Iter 51/80; Loss: 0.5737
Epoch 1241/10000; Iter 80/80; Training Loss: 0.6140, Test Loss: 0.091
Epoch 1242/10000; Iter 1/80; Loss: 0.5707
Epoch 1242/10000; Iter 51/80; Loss: 0.5510
Epoch 1242/10000; Iter 80/80; Training Loss: 0.6130, Test Loss: 0.09
Epoch 1243/10000; Iter 1/80; Loss: 0.6404
Epoch 1243/10000; Iter 51/80; Loss: 0.5813
Epoch 1243/10000; Iter 80/80; Training Loss: 0.6090, Test Loss: 0.08
Epoch 1244/10000; Iter 1/80; Loss: 0.5511
Epoch 1244/10000; Iter 51/80; Loss: 0.6652
Epoch 1244/10000; Iter 80/80; Training Loss: 0.6120, Test Loss: 0.078
Epoch 1245/10000; Iter 1/80; Loss: 0.5636
Epoch 1245/10000; Iter 51/80; Loss: 0.5578
Epoch 1245/10000; Iter 80/80; Training Loss: 0.6150, Test Loss: 0.087
Epoch 1246/10000; Iter 1/80; Loss: 0.6077
Epoch 1246/10000; Iter 51/80; Loss: 0.6419
Epoch 1246/10000; Iter 80/80; Training Loss: 0.6070, Test Loss: 0.084
Epoch 1247/10000; Iter 1/80; Loss: 0.6659
Epoch 1247/10000; Iter 51/80; Loss: 0.6143
Epoch 1247/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.079
Epoch 1248/10000; Iter 1/80; Loss: 0.5632
Epoch 1248/10000; Iter 51/80; Loss: 0.6272
Epoch 1248/10000; Iter 80/80; Training Loss: 0.6150, Test Loss: 0.087
Epoch 1249/10000; Iter 1/80; Loss: 0.5394
Epoch 1249/10000; Iter 51/80; Loss: 0.6018
Epoch 1249/10000; Iter 80/80; Training Loss: 0.6090, Test Loss: 0.086
Epoch 1250/10000; Iter 1/80; Loss: 0.6490
Epoch 1250/10000; Iter 51/80; Loss: 0.6541
Epoch 1250/10000; Iter 80/80; Training Loss: 0.6130, Test Loss: 0.077
Epoch 1251/10000; Iter 1/80; Loss: 0.6351
Epoch 1251/10000; Iter 51/80; Loss: 0.6795
Epoch 1251/10000; Iter 80/80; Training Loss: 0.6050, Test Loss: 0.095
Epoch 1252/10000; Iter 1/80; Loss: 0.6154
Epoch 1252/10000; Iter 51/80; Loss: 0.6211
Epoch 1252/10000; Iter 80/80; Training Loss: 0.6080, Test Loss: 0.087
Epoch 1253/10000; Iter 1/80; Loss: 0.5186
Epoch 1253/10000; Iter 51/80; Loss: 0.6408
Epoch 1253/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.082
Epoch 1254/10000; Iter 1/80; Loss: 0.6711
Epoch 1254/10000; Iter 51/80; Loss: 0.6968
Epoch 1254/10000; Iter 80/80; Training Loss: 0.6080, Test Loss: 0.093
Epoch 1255/10000; Iter 1/80; Loss: 0.6815
Epoch 1255/10000; Iter 51/80; Loss: 0.7287
Epoch 1255/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.076
Epoch 1256/10000; Iter 1/80; Loss: 0.5415
Epoch 1256/10000; Iter 51/80; Loss: 0.5632
Epoch 1256/10000; Iter 80/80; Training Loss: 0.6110, Test Loss: 0.077
Epoch 1257/10000; Iter 1/80; Loss: 0.6576
Epoch 1257/10000; Iter 51/80; Loss: 0.6242
Epoch 1257/10000; Iter 80/80; Training Loss: 0.6120, Test Loss: 0.088
Epoch 1258/10000; Iter 1/80; Loss: 0.6350
Epoch 1258/10000; Iter 51/80; Loss: 0.6332
Epoch 1258/10000; Iter 80/80; Training Loss: 0.6030, Test Loss: 0.078
Epoch 1259/10000; Iter 1/80; Loss: 0.5806
Epoch 1259/10000; Iter 51/80; Loss: 0.7047
Epoch 1259/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.076
Epoch 1260/10000; Iter 1/80; Loss: 0.6312
Epoch 1260/10000; Iter 51/80; Loss: 0.6676
Epoch 1260/10000; Iter 80/80; Training Loss: 0.6120, Test Loss: 0.079
Epoch 1261/10000; Iter 1/80; Loss: 0.5887
Epoch 1261/10000; Iter 51/80; Loss: 0.6331
Epoch 1261/10000; Iter 80/80; Training Loss: 0.6050, Test Loss: 0.084
Epoch 1262/10000; Iter 1/80; Loss: 0.6853
Epoch 1262/10000; Iter 51/80; Loss: 0.6401
Epoch 1262/10000; Iter 80/80; Training Loss: 0.6120, Test Loss: 0.081
Epoch 1263/10000; Iter 1/80; Loss: 0.5363
Epoch 1263/10000; Iter 51/80; Loss: 0.6293
Epoch 1263/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.081
Epoch 1264/10000; Iter 1/80; Loss: 0.5407
Epoch 1264/10000; Iter 51/80; Loss: 0.5686
Epoch 1264/10000; Iter 80/80; Training Loss: 0.6150, Test Loss: 0.073
Epoch 1265/10000; Iter 1/80; Loss: 0.5934
Epoch 1265/10000; Iter 51/80; Loss: 0.6383
Epoch 1265/10000; Iter 80/80; Training Loss: 0.6070, Test Loss: 0.069
Epoch 1266/10000; Iter 1/80; Loss: 0.6486
Epoch 1266/10000; Iter 51/80; Loss: 0.5500
Epoch 1266/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.097
Epoch 1267/10000; Iter 1/80; Loss: 0.5835
Epoch 1267/10000; Iter 51/80; Loss: 0.6141
Epoch 1267/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.09
Epoch 1268/10000; Iter 1/80; Loss: 0.6859
Epoch 1268/10000; Iter 51/80; Loss: 0.5677
Epoch 1268/10000; Iter 80/80; Training Loss: 0.6030, Test Loss: 0.084
Epoch 1269/10000; Iter 1/80; Loss: 0.5378
Epoch 1269/10000; Iter 51/80; Loss: 0.5620
Epoch 1269/10000; Iter 80/80; Training Loss: 0.6080, Test Loss: 0.089
Epoch 1270/10000; Iter 1/80; Loss: 0.5916
Epoch 1270/10000; Iter 51/80; Loss: 0.5669
Epoch 1270/10000; Iter 80/80; Training Loss: 0.6050, Test Loss: 0.088
Epoch 1271/10000; Iter 1/80; Loss: 0.6119
Epoch 1271/10000; Iter 51/80; Loss: 0.6537
Epoch 1271/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.089
Epoch 1272/10000; Iter 1/80; Loss: 0.6022
Epoch 1272/10000; Iter 51/80; Loss: 0.5639
Epoch 1272/10000; Iter 80/80; Training Loss: 0.6050, Test Loss: 0.078
Epoch 1273/10000; Iter 1/80; Loss: 0.5882
Epoch 1273/10000; Iter 51/80; Loss: 0.6137
Epoch 1273/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.079
Epoch 1274/10000; Iter 1/80; Loss: 0.5732
Epoch 1274/10000; Iter 51/80; Loss: 0.7041
Epoch 1274/10000; Iter 80/80; Training Loss: 0.6100, Test Loss: 0.076
Epoch 1275/10000; Iter 1/80; Loss: 0.5837
Epoch 1275/10000; Iter 51/80; Loss: 0.6384
Epoch 1275/10000; Iter 80/80; Training Loss: 0.6020, Test Loss: 0.09
Epoch 1276/10000; Iter 1/80; Loss: 0.5968
Epoch 1276/10000; Iter 51/80; Loss: 0.6812
Epoch 1276/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.088
Epoch 1277/10000; Iter 1/80; Loss: 0.6437
Epoch 1277/10000; Iter 51/80; Loss: 0.5488
Epoch 1277/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.084
Epoch 1278/10000; Iter 1/80; Loss: 0.6140
Epoch 1278/10000; Iter 51/80; Loss: 0.6518
Epoch 1278/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.084
Epoch 1279/10000; Iter 1/80; Loss: 0.5666
Epoch 1279/10000; Iter 51/80; Loss: 0.6120
Epoch 1279/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.081
Epoch 1280/10000; Iter 1/80; Loss: 0.5542
Epoch 1280/10000; Iter 51/80; Loss: 0.5667
Epoch 1280/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.088
Epoch 1281/10000; Iter 1/80; Loss: 0.6373
Epoch 1281/10000; Iter 51/80; Loss: 0.6484
Epoch 1281/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.076
Epoch 1282/10000; Iter 1/80; Loss: 0.5080
Epoch 1282/10000; Iter 51/80; Loss: 0.5681
Epoch 1282/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.077
Epoch 1283/10000; Iter 1/80; Loss: 0.5921
Epoch 1283/10000; Iter 51/80; Loss: 0.5840
Epoch 1283/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.083
Epoch 1284/10000; Iter 1/80; Loss: 0.5791
Epoch 1284/10000; Iter 51/80; Loss: 0.5841
Epoch 1284/10000; Iter 80/80; Training Loss: 0.6000, Test Loss: 0.081
Epoch 1285/10000; Iter 1/80; Loss: 0.6321
Epoch 1285/10000; Iter 51/80; Loss: 0.6122
Epoch 1285/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.079
Epoch 1286/10000; Iter 1/80; Loss: 0.6680
Epoch 1286/10000; Iter 51/80; Loss: 0.6189
Epoch 1286/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.086
Epoch 1287/10000; Iter 1/80; Loss: 0.6256
Epoch 1287/10000; Iter 51/80; Loss: 0.6124
Epoch 1287/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.074
Epoch 1288/10000; Iter 1/80; Loss: 0.5536
Epoch 1288/10000; Iter 51/80; Loss: 0.6237
Epoch 1288/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.086
Epoch 1289/10000; Iter 1/80; Loss: 0.6934
Epoch 1289/10000; Iter 51/80; Loss: 0.6674
Epoch 1289/10000; Iter 80/80; Training Loss: 0.5990, Test Loss: 0.077
Epoch 1290/10000; Iter 1/80; Loss: 0.6610
Epoch 1290/10000; Iter 51/80; Loss: 0.5911
Epoch 1290/10000; Iter 80/80; Training Loss: 0.6100, Test Loss: 0.088
Epoch 1291/10000; Iter 1/80; Loss: 0.6052
Epoch 1291/10000; Iter 51/80; Loss: 0.5625
Epoch 1291/10000; Iter 80/80; Training Loss: 0.5960, Test Loss: 0.074
Epoch 1292/10000; Iter 1/80; Loss: 0.5701
Epoch 1292/10000; Iter 51/80; Loss: 0.5846
Epoch 1292/10000; Iter 80/80; Training Loss: 0.6030, Test Loss: 0.087
Epoch 1293/10000; Iter 1/80; Loss: 0.5489
Epoch 1293/10000; Iter 51/80; Loss: 0.5958
Epoch 1293/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.073
Epoch 1294/10000; Iter 1/80; Loss: 0.6249
Epoch 1294/10000; Iter 51/80; Loss: 0.5502
Epoch 1294/10000; Iter 80/80; Training Loss: 0.5990, Test Loss: 0.087
Epoch 1295/10000; Iter 1/80; Loss: 0.6445
Epoch 1295/10000; Iter 51/80; Loss: 0.5992
Epoch 1295/10000; Iter 80/80; Training Loss: 0.6040, Test Loss: 0.083
Epoch 1296/10000; Iter 1/80; Loss: 0.5352
Epoch 1296/10000; Iter 51/80; Loss: 0.8022
Epoch 1296/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.081
Epoch 1297/10000; Iter 1/80; Loss: 0.6535
Epoch 1297/10000; Iter 51/80; Loss: 0.6086
Epoch 1297/10000; Iter 80/80; Training Loss: 0.5950, Test Loss: 0.088
Epoch 1298/10000; Iter 1/80; Loss: 0.5828
Epoch 1298/10000; Iter 51/80; Loss: 0.5983
Epoch 1298/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.073
Epoch 1299/10000; Iter 1/80; Loss: 0.6727
Epoch 1299/10000; Iter 51/80; Loss: 0.6222
Epoch 1299/10000; Iter 80/80; Training Loss: 0.5960, Test Loss: 0.085
Epoch 1300/10000; Iter 1/80; Loss: 0.5713
Epoch 1300/10000; Iter 51/80; Loss: 0.6210
Epoch 1300/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.079
Epoch 1301/10000; Iter 1/80; Loss: 0.6530
Epoch 1301/10000; Iter 51/80; Loss: 0.6064
Epoch 1301/10000; Iter 80/80; Training Loss: 0.5970, Test Loss: 0.08
Model saved
Epoch 1302/10000; Iter 1/80; Loss: 0.5351
Epoch 1302/10000; Iter 51/80; Loss: 0.6029
Epoch 1302/10000; Iter 80/80; Training Loss: 0.5890, Test Loss: 0.095
Epoch 1303/10000; Iter 1/80; Loss: 0.5324
Epoch 1303/10000; Iter 51/80; Loss: 0.6430
Epoch 1303/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.07
Epoch 1304/10000; Iter 1/80; Loss: 0.5959
Epoch 1304/10000; Iter 51/80; Loss: 0.5008
Epoch 1304/10000; Iter 80/80; Training Loss: 0.6000, Test Loss: 0.088
Epoch 1305/10000; Iter 1/80; Loss: 0.6644
Epoch 1305/10000; Iter 51/80; Loss: 0.5364
Epoch 1305/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.068
Epoch 1306/10000; Iter 1/80; Loss: 0.6412
Epoch 1306/10000; Iter 51/80; Loss: 0.6417
Epoch 1306/10000; Iter 80/80; Training Loss: 0.6010, Test Loss: 0.077
Epoch 1307/10000; Iter 1/80; Loss: 0.6844
Epoch 1307/10000; Iter 51/80; Loss: 0.5537
Epoch 1307/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.093
Epoch 1308/10000; Iter 1/80; Loss: 0.5948
Epoch 1308/10000; Iter 51/80; Loss: 0.5520
Epoch 1308/10000; Iter 80/80; Training Loss: 0.5960, Test Loss: 0.085
Epoch 1309/10000; Iter 1/80; Loss: 0.5204
Epoch 1309/10000; Iter 51/80; Loss: 0.5535
Epoch 1309/10000; Iter 80/80; Training Loss: 0.5920, Test Loss: 0.077
Epoch 1310/10000; Iter 1/80; Loss: 0.5678
Epoch 1310/10000; Iter 51/80; Loss: 0.5994
Epoch 1310/10000; Iter 80/80; Training Loss: 0.5930, Test Loss: 0.077
Epoch 1311/10000; Iter 1/80; Loss: 0.5390
Epoch 1311/10000; Iter 51/80; Loss: 0.6265
Epoch 1311/10000; Iter 80/80; Training Loss: 0.5920, Test Loss: 0.083
Epoch 1312/10000; Iter 1/80; Loss: 0.5894
Epoch 1312/10000; Iter 51/80; Loss: 0.5600
Epoch 1312/10000; Iter 80/80; Training Loss: 0.5850, Test Loss: 0.077
Epoch 1313/10000; Iter 1/80; Loss: 0.6080
Epoch 1313/10000; Iter 51/80; Loss: 0.5386
Epoch 1313/10000; Iter 80/80; Training Loss: 0.5950, Test Loss: 0.068
Epoch 1314/10000; Iter 1/80; Loss: 0.5675
Epoch 1314/10000; Iter 51/80; Loss: 0.6851
Epoch 1314/10000; Iter 80/80; Training Loss: 0.5900, Test Loss: 0.081
Epoch 1315/10000; Iter 1/80; Loss: 0.5518
Epoch 1315/10000; Iter 51/80; Loss: 0.5755
Epoch 1315/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.09
Epoch 1316/10000; Iter 1/80; Loss: 0.6981
Epoch 1316/10000; Iter 51/80; Loss: 0.5920
Epoch 1316/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.083
Epoch 1317/10000; Iter 1/80; Loss: 0.5381
Epoch 1317/10000; Iter 51/80; Loss: 0.6515
Epoch 1317/10000; Iter 80/80; Training Loss: 0.5940, Test Loss: 0.083
Epoch 1318/10000; Iter 1/80; Loss: 0.5656
Epoch 1318/10000; Iter 51/80; Loss: 0.6083
Epoch 1318/10000; Iter 80/80; Training Loss: 0.5930, Test Loss: 0.077
Epoch 1319/10000; Iter 1/80; Loss: 0.5956
Epoch 1319/10000; Iter 51/80; Loss: 0.5914
Epoch 1319/10000; Iter 80/80; Training Loss: 0.5890, Test Loss: 0.074
Epoch 1320/10000; Iter 1/80; Loss: 0.5312
Epoch 1320/10000; Iter 51/80; Loss: 0.5468
Epoch 1320/10000; Iter 80/80; Training Loss: 0.5940, Test Loss: 0.083
Epoch 1321/10000; Iter 1/80; Loss: 0.5760
Epoch 1321/10000; Iter 51/80; Loss: 0.5455
Epoch 1321/10000; Iter 80/80; Training Loss: 0.5880, Test Loss: 0.076
Epoch 1322/10000; Iter 1/80; Loss: 0.5823
Epoch 1322/10000; Iter 51/80; Loss: 0.5968
Epoch 1322/10000; Iter 80/80; Training Loss: 0.5920, Test Loss: 0.07
Epoch 1323/10000; Iter 1/80; Loss: 0.6050
Epoch 1323/10000; Iter 51/80; Loss: 0.5789
Epoch 1323/10000; Iter 80/80; Training Loss: 0.5970, Test Loss: 0.078
Epoch 1324/10000; Iter 1/80; Loss: 0.5692
Epoch 1324/10000; Iter 51/80; Loss: 0.5309
Epoch 1324/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.08
Epoch 1325/10000; Iter 1/80; Loss: 0.5451
Epoch 1325/10000; Iter 51/80; Loss: 0.5911
Epoch 1325/10000; Iter 80/80; Training Loss: 0.5970, Test Loss: 0.069
Epoch 1326/10000; Iter 1/80; Loss: 0.5676
Epoch 1326/10000; Iter 51/80; Loss: 0.5622
Epoch 1326/10000; Iter 80/80; Training Loss: 0.5850, Test Loss: 0.085
Epoch 1327/10000; Iter 1/80; Loss: 0.6284
Epoch 1327/10000; Iter 51/80; Loss: 0.5632
Epoch 1327/10000; Iter 80/80; Training Loss: 0.5930, Test Loss: 0.078
Epoch 1328/10000; Iter 1/80; Loss: 0.5412
Epoch 1328/10000; Iter 51/80; Loss: 0.5904
Epoch 1328/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.072
Epoch 1329/10000; Iter 1/80; Loss: 0.6202
Epoch 1329/10000; Iter 51/80; Loss: 0.5914
Epoch 1329/10000; Iter 80/80; Training Loss: 0.5890, Test Loss: 0.074
Epoch 1330/10000; Iter 1/80; Loss: 0.5522
Epoch 1330/10000; Iter 51/80; Loss: 0.5985
Epoch 1330/10000; Iter 80/80; Training Loss: 0.5980, Test Loss: 0.082
Epoch 1331/10000; Iter 1/80; Loss: 0.6507
Epoch 1331/10000; Iter 51/80; Loss: 0.6368
Epoch 1331/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.076
Epoch 1332/10000; Iter 1/80; Loss: 0.6067
Epoch 1332/10000; Iter 51/80; Loss: 0.6480
Epoch 1332/10000; Iter 80/80; Training Loss: 0.5970, Test Loss: 0.073
Epoch 1333/10000; Iter 1/80; Loss: 0.6140
Epoch 1333/10000; Iter 51/80; Loss: 0.5346
Epoch 1333/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.076
Epoch 1334/10000; Iter 1/80; Loss: 0.5971
Epoch 1334/10000; Iter 51/80; Loss: 0.6000
Epoch 1334/10000; Iter 80/80; Training Loss: 0.5860, Test Loss: 0.094
Epoch 1335/10000; Iter 1/80; Loss: 0.5199
Epoch 1335/10000; Iter 51/80; Loss: 0.6414
Epoch 1335/10000; Iter 80/80; Training Loss: 0.5930, Test Loss: 0.081
Epoch 1336/10000; Iter 1/80; Loss: 0.7086
Epoch 1336/10000; Iter 51/80; Loss: 0.5417
Epoch 1336/10000; Iter 80/80; Training Loss: 0.5830, Test Loss: 0.071
Epoch 1337/10000; Iter 1/80; Loss: 0.5347
Epoch 1337/10000; Iter 51/80; Loss: 0.5544
Epoch 1337/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.072
Epoch 1338/10000; Iter 1/80; Loss: 0.6060
Epoch 1338/10000; Iter 51/80; Loss: 0.5555
Epoch 1338/10000; Iter 80/80; Training Loss: 0.5900, Test Loss: 0.091
Epoch 1339/10000; Iter 1/80; Loss: 0.5972
Epoch 1339/10000; Iter 51/80; Loss: 0.6059
Epoch 1339/10000; Iter 80/80; Training Loss: 0.5880, Test Loss: 0.074
Epoch 1340/10000; Iter 1/80; Loss: 0.6701
Epoch 1340/10000; Iter 51/80; Loss: 0.5854
Epoch 1340/10000; Iter 80/80; Training Loss: 0.5890, Test Loss: 0.083
Epoch 1341/10000; Iter 1/80; Loss: 0.6041
Epoch 1341/10000; Iter 51/80; Loss: 0.6030
Epoch 1341/10000; Iter 80/80; Training Loss: 0.5850, Test Loss: 0.081
Epoch 1342/10000; Iter 1/80; Loss: 0.5866
Epoch 1342/10000; Iter 51/80; Loss: 0.5313
Epoch 1342/10000; Iter 80/80; Training Loss: 0.5880, Test Loss: 0.082
Epoch 1343/10000; Iter 1/80; Loss: 0.6274
Epoch 1343/10000; Iter 51/80; Loss: 0.5504
Epoch 1343/10000; Iter 80/80; Training Loss: 0.5830, Test Loss: 0.088
Epoch 1344/10000; Iter 1/80; Loss: 0.6336
Epoch 1344/10000; Iter 51/80; Loss: 0.5874
Epoch 1344/10000; Iter 80/80; Training Loss: 0.5810, Test Loss: 0.075
Epoch 1345/10000; Iter 1/80; Loss: 0.5615
Epoch 1345/10000; Iter 51/80; Loss: 0.5923
Epoch 1345/10000; Iter 80/80; Training Loss: 0.5910, Test Loss: 0.075
Epoch 1346/10000; Iter 1/80; Loss: 0.5837
Epoch 1346/10000; Iter 51/80; Loss: 0.5747
Epoch 1346/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.082
Epoch 1347/10000; Iter 1/80; Loss: 0.5951
Epoch 1347/10000; Iter 51/80; Loss: 0.5653
Epoch 1347/10000; Iter 80/80; Training Loss: 0.5790, Test Loss: 0.073
Epoch 1348/10000; Iter 1/80; Loss: 0.5798
Epoch 1348/10000; Iter 51/80; Loss: 0.6388
Epoch 1348/10000; Iter 80/80; Training Loss: 0.5860, Test Loss: 0.088
Epoch 1349/10000; Iter 1/80; Loss: 0.5113
Epoch 1349/10000; Iter 51/80; Loss: 0.6489
Epoch 1349/10000; Iter 80/80; Training Loss: 0.5900, Test Loss: 0.07
Epoch 1350/10000; Iter 1/80; Loss: 0.5224
Epoch 1350/10000; Iter 51/80; Loss: 0.6032
Epoch 1350/10000; Iter 80/80; Training Loss: 0.5790, Test Loss: 0.08
Epoch 1351/10000; Iter 1/80; Loss: 0.5817
Epoch 1351/10000; Iter 51/80; Loss: 0.5861
Epoch 1351/10000; Iter 80/80; Training Loss: 0.5880, Test Loss: 0.073
Epoch 1352/10000; Iter 1/80; Loss: 0.5576
Epoch 1352/10000; Iter 51/80; Loss: 0.5773
Epoch 1352/10000; Iter 80/80; Training Loss: 0.5880, Test Loss: 0.078
Epoch 1353/10000; Iter 1/80; Loss: 0.5952
Epoch 1353/10000; Iter 51/80; Loss: 0.6775
Epoch 1353/10000; Iter 80/80; Training Loss: 0.5790, Test Loss: 0.078
Epoch 1354/10000; Iter 1/80; Loss: 0.6986
Epoch 1354/10000; Iter 51/80; Loss: 0.6075
Epoch 1354/10000; Iter 80/80; Training Loss: 0.5820, Test Loss: 0.073
Epoch 1355/10000; Iter 1/80; Loss: 0.5010
Epoch 1355/10000; Iter 51/80; Loss: 0.6866
Epoch 1355/10000; Iter 80/80; Training Loss: 0.5810, Test Loss: 0.076
Epoch 1356/10000; Iter 1/80; Loss: 0.5844
Epoch 1356/10000; Iter 51/80; Loss: 0.5221
Epoch 1356/10000; Iter 80/80; Training Loss: 0.5860, Test Loss: 0.075
Epoch 1357/10000; Iter 1/80; Loss: 0.5196
Epoch 1357/10000; Iter 51/80; Loss: 0.6147
Epoch 1357/10000; Iter 80/80; Training Loss: 0.5820, Test Loss: 0.092
Epoch 1358/10000; Iter 1/80; Loss: 0.5767
Epoch 1358/10000; Iter 51/80; Loss: 0.5819
Epoch 1358/10000; Iter 80/80; Training Loss: 0.5770, Test Loss: 0.076
Epoch 1359/10000; Iter 1/80; Loss: 0.5804
Epoch 1359/10000; Iter 51/80; Loss: 0.5693
Epoch 1359/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.084
Epoch 1360/10000; Iter 1/80; Loss: 0.6649
Epoch 1360/10000; Iter 51/80; Loss: 0.5925
Epoch 1360/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.087
Epoch 1361/10000; Iter 1/80; Loss: 0.5216
Epoch 1361/10000; Iter 51/80; Loss: 0.5522
Epoch 1361/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.083
Epoch 1362/10000; Iter 1/80; Loss: 0.5329
Epoch 1362/10000; Iter 51/80; Loss: 0.6177
Epoch 1362/10000; Iter 80/80; Training Loss: 0.5820, Test Loss: 0.07
Epoch 1363/10000; Iter 1/80; Loss: 0.5586
Epoch 1363/10000; Iter 51/80; Loss: 0.6214
Epoch 1363/10000; Iter 80/80; Training Loss: 0.5820, Test Loss: 0.072
Epoch 1364/10000; Iter 1/80; Loss: 0.5353
Epoch 1364/10000; Iter 51/80; Loss: 0.6886
Epoch 1364/10000; Iter 80/80; Training Loss: 0.5750, Test Loss: 0.071
Epoch 1365/10000; Iter 1/80; Loss: 0.6173
Epoch 1365/10000; Iter 51/80; Loss: 0.6453
Epoch 1365/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.063
Epoch 1366/10000; Iter 1/80; Loss: 0.5597
Epoch 1366/10000; Iter 51/80; Loss: 0.5531
Epoch 1366/10000; Iter 80/80; Training Loss: 0.5780, Test Loss: 0.075
Epoch 1367/10000; Iter 1/80; Loss: 0.5999
Epoch 1367/10000; Iter 51/80; Loss: 0.5852
Epoch 1367/10000; Iter 80/80; Training Loss: 0.5700, Test Loss: 0.068
Epoch 1368/10000; Iter 1/80; Loss: 0.6509
Epoch 1368/10000; Iter 51/80; Loss: 0.6177
Epoch 1368/10000; Iter 80/80; Training Loss: 0.5830, Test Loss: 0.076
Epoch 1369/10000; Iter 1/80; Loss: 0.5481
Epoch 1369/10000; Iter 51/80; Loss: 0.5093
Epoch 1369/10000; Iter 80/80; Training Loss: 0.5800, Test Loss: 0.081
Epoch 1370/10000; Iter 1/80; Loss: 0.5574
Epoch 1370/10000; Iter 51/80; Loss: 0.6231
Epoch 1370/10000; Iter 80/80; Training Loss: 0.5770, Test Loss: 0.072
Epoch 1371/10000; Iter 1/80; Loss: 0.5373
Epoch 1371/10000; Iter 51/80; Loss: 0.5984
Epoch 1371/10000; Iter 80/80; Training Loss: 0.5870, Test Loss: 0.072
Epoch 1372/10000; Iter 1/80; Loss: 0.6497
Epoch 1372/10000; Iter 51/80; Loss: 0.5629
Epoch 1372/10000; Iter 80/80; Training Loss: 0.5880, Test Loss: 0.062
Epoch 1373/10000; Iter 1/80; Loss: 0.6102
Epoch 1373/10000; Iter 51/80; Loss: 0.5129
Epoch 1373/10000; Iter 80/80; Training Loss: 0.5770, Test Loss: 0.089
Epoch 1374/10000; Iter 1/80; Loss: 0.5870
Epoch 1374/10000; Iter 51/80; Loss: 0.6168
Epoch 1374/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.067
Epoch 1375/10000; Iter 1/80; Loss: 0.5531
Epoch 1375/10000; Iter 51/80; Loss: 0.5629
Epoch 1375/10000; Iter 80/80; Training Loss: 0.5780, Test Loss: 0.074
Epoch 1376/10000; Iter 1/80; Loss: 0.5494
Epoch 1376/10000; Iter 51/80; Loss: 0.6120
Epoch 1376/10000; Iter 80/80; Training Loss: 0.5770, Test Loss: 0.061
Epoch 1377/10000; Iter 1/80; Loss: 0.5989
Epoch 1377/10000; Iter 51/80; Loss: 0.5415
Epoch 1377/10000; Iter 80/80; Training Loss: 0.5760, Test Loss: 0.071
Epoch 1378/10000; Iter 1/80; Loss: 0.5595
Epoch 1378/10000; Iter 51/80; Loss: 0.5933
Epoch 1378/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.074
Epoch 1379/10000; Iter 1/80; Loss: 0.5279
Epoch 1379/10000; Iter 51/80; Loss: 0.5136
Epoch 1379/10000; Iter 80/80; Training Loss: 0.5810, Test Loss: 0.071
Epoch 1380/10000; Iter 1/80; Loss: 0.6408
Epoch 1380/10000; Iter 51/80; Loss: 0.5960
Epoch 1380/10000; Iter 80/80; Training Loss: 0.5780, Test Loss: 0.091
Epoch 1381/10000; Iter 1/80; Loss: 0.5283
Epoch 1381/10000; Iter 51/80; Loss: 0.6343
Epoch 1381/10000; Iter 80/80; Training Loss: 0.5770, Test Loss: 0.081
Epoch 1382/10000; Iter 1/80; Loss: 0.5971
Epoch 1382/10000; Iter 51/80; Loss: 0.5427
Epoch 1382/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.084
Epoch 1383/10000; Iter 1/80; Loss: 0.5620
Epoch 1383/10000; Iter 51/80; Loss: 0.4870
Epoch 1383/10000; Iter 80/80; Training Loss: 0.5700, Test Loss: 0.086
Epoch 1384/10000; Iter 1/80; Loss: 0.4940
Epoch 1384/10000; Iter 51/80; Loss: 0.6006
Epoch 1384/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.081
Epoch 1385/10000; Iter 1/80; Loss: 0.6198
Epoch 1385/10000; Iter 51/80; Loss: 0.6022
Epoch 1385/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.071
Epoch 1386/10000; Iter 1/80; Loss: 0.6050
Epoch 1386/10000; Iter 51/80; Loss: 0.5685
Epoch 1386/10000; Iter 80/80; Training Loss: 0.5780, Test Loss: 0.072
Epoch 1387/10000; Iter 1/80; Loss: 0.5704
Epoch 1387/10000; Iter 51/80; Loss: 0.5790
Epoch 1387/10000; Iter 80/80; Training Loss: 0.5750, Test Loss: 0.077
Epoch 1388/10000; Iter 1/80; Loss: 0.6381
Epoch 1388/10000; Iter 51/80; Loss: 0.5626
Epoch 1388/10000; Iter 80/80; Training Loss: 0.5810, Test Loss: 0.066
Epoch 1389/10000; Iter 1/80; Loss: 0.5322
Epoch 1389/10000; Iter 51/80; Loss: 0.6060
Epoch 1389/10000; Iter 80/80; Training Loss: 0.5680, Test Loss: 0.079
Epoch 1390/10000; Iter 1/80; Loss: 0.5779
Epoch 1390/10000; Iter 51/80; Loss: 0.4657
Epoch 1390/10000; Iter 80/80; Training Loss: 0.5760, Test Loss: 0.068
Epoch 1391/10000; Iter 1/80; Loss: 0.5904
Epoch 1391/10000; Iter 51/80; Loss: 0.5557
Epoch 1391/10000; Iter 80/80; Training Loss: 0.5760, Test Loss: 0.075
Epoch 1392/10000; Iter 1/80; Loss: 0.6643
Epoch 1392/10000; Iter 51/80; Loss: 0.5184
Epoch 1392/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.072
Epoch 1393/10000; Iter 1/80; Loss: 0.5650
Epoch 1393/10000; Iter 51/80; Loss: 0.5471
Epoch 1393/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.077
Epoch 1394/10000; Iter 1/80; Loss: 0.5900
Epoch 1394/10000; Iter 51/80; Loss: 0.6661
Epoch 1394/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.086
Epoch 1395/10000; Iter 1/80; Loss: 0.5517
Epoch 1395/10000; Iter 51/80; Loss: 0.5744
Epoch 1395/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.08
Epoch 1396/10000; Iter 1/80; Loss: 0.6275
Epoch 1396/10000; Iter 51/80; Loss: 0.5310
Epoch 1396/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.08
Epoch 1397/10000; Iter 1/80; Loss: 0.5236
Epoch 1397/10000; Iter 51/80; Loss: 0.5281
Epoch 1397/10000; Iter 80/80; Training Loss: 0.5680, Test Loss: 0.075
Epoch 1398/10000; Iter 1/80; Loss: 0.6527
Epoch 1398/10000; Iter 51/80; Loss: 0.5775
Epoch 1398/10000; Iter 80/80; Training Loss: 0.5830, Test Loss: 0.073
Epoch 1399/10000; Iter 1/80; Loss: 0.6594
Epoch 1399/10000; Iter 51/80; Loss: 0.5166
Epoch 1399/10000; Iter 80/80; Training Loss: 0.5750, Test Loss: 0.075
Epoch 1400/10000; Iter 1/80; Loss: 0.4774
Epoch 1400/10000; Iter 51/80; Loss: 0.5335
Epoch 1400/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.084
Epoch 1401/10000; Iter 1/80; Loss: 0.5204
Epoch 1401/10000; Iter 51/80; Loss: 0.5709
Epoch 1401/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.085
Model saved
Epoch 1402/10000; Iter 1/80; Loss: 0.5504
Epoch 1402/10000; Iter 51/80; Loss: 0.5567
Epoch 1402/10000; Iter 80/80; Training Loss: 0.5740, Test Loss: 0.071
Epoch 1403/10000; Iter 1/80; Loss: 0.5717
Epoch 1403/10000; Iter 51/80; Loss: 0.5312
Epoch 1403/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.069
Epoch 1404/10000; Iter 1/80; Loss: 0.6412
Epoch 1404/10000; Iter 51/80; Loss: 0.5584
Epoch 1404/10000; Iter 80/80; Training Loss: 0.5750, Test Loss: 0.069
Epoch 1405/10000; Iter 1/80; Loss: 0.5622
Epoch 1405/10000; Iter 51/80; Loss: 0.6077
Epoch 1405/10000; Iter 80/80; Training Loss: 0.5750, Test Loss: 0.078
Epoch 1406/10000; Iter 1/80; Loss: 0.4956
Epoch 1406/10000; Iter 51/80; Loss: 0.7006
Epoch 1406/10000; Iter 80/80; Training Loss: 0.5680, Test Loss: 0.089
Epoch 1407/10000; Iter 1/80; Loss: 0.5484
Epoch 1407/10000; Iter 51/80; Loss: 0.5401
Epoch 1407/10000; Iter 80/80; Training Loss: 0.5680, Test Loss: 0.067
Epoch 1408/10000; Iter 1/80; Loss: 0.6171
Epoch 1408/10000; Iter 51/80; Loss: 0.5372
Epoch 1408/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.07
Epoch 1409/10000; Iter 1/80; Loss: 0.5551
Epoch 1409/10000; Iter 51/80; Loss: 0.5342
Epoch 1409/10000; Iter 80/80; Training Loss: 0.5710, Test Loss: 0.077
Epoch 1410/10000; Iter 1/80; Loss: 0.5268
Epoch 1410/10000; Iter 51/80; Loss: 0.5296
Epoch 1410/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.067
Epoch 1411/10000; Iter 1/80; Loss: 0.5099
Epoch 1411/10000; Iter 51/80; Loss: 0.4905
Epoch 1411/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.066
Epoch 1412/10000; Iter 1/80; Loss: 0.5608
Epoch 1412/10000; Iter 51/80; Loss: 0.5186
Epoch 1412/10000; Iter 80/80; Training Loss: 0.5710, Test Loss: 0.063
Epoch 1413/10000; Iter 1/80; Loss: 0.5307
Epoch 1413/10000; Iter 51/80; Loss: 0.6020
Epoch 1413/10000; Iter 80/80; Training Loss: 0.5700, Test Loss: 0.091
Epoch 1414/10000; Iter 1/80; Loss: 0.6261
Epoch 1414/10000; Iter 51/80; Loss: 0.5371
Epoch 1414/10000; Iter 80/80; Training Loss: 0.5770, Test Loss: 0.077
Epoch 1415/10000; Iter 1/80; Loss: 0.5931
Epoch 1415/10000; Iter 51/80; Loss: 0.5432
Epoch 1415/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.078
Epoch 1416/10000; Iter 1/80; Loss: 0.5173
Epoch 1416/10000; Iter 51/80; Loss: 0.4819
Epoch 1416/10000; Iter 80/80; Training Loss: 0.5680, Test Loss: 0.069
Epoch 1417/10000; Iter 1/80; Loss: 0.5540
Epoch 1417/10000; Iter 51/80; Loss: 0.5476
Epoch 1417/10000; Iter 80/80; Training Loss: 0.5670, Test Loss: 0.079
Epoch 1418/10000; Iter 1/80; Loss: 0.5325
Epoch 1418/10000; Iter 51/80; Loss: 0.5445
Epoch 1418/10000; Iter 80/80; Training Loss: 0.5840, Test Loss: 0.077
Epoch 1419/10000; Iter 1/80; Loss: 0.5717
Epoch 1419/10000; Iter 51/80; Loss: 0.5089
Epoch 1419/10000; Iter 80/80; Training Loss: 0.5700, Test Loss: 0.07
Epoch 1420/10000; Iter 1/80; Loss: 0.5514
Epoch 1420/10000; Iter 51/80; Loss: 0.6152
Epoch 1420/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.061
Epoch 1421/10000; Iter 1/80; Loss: 0.6157
Epoch 1421/10000; Iter 51/80; Loss: 0.6038
Epoch 1421/10000; Iter 80/80; Training Loss: 0.5620, Test Loss: 0.063
Epoch 1422/10000; Iter 1/80; Loss: 0.6078
Epoch 1422/10000; Iter 51/80; Loss: 0.5677
Epoch 1422/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.068
Epoch 1423/10000; Iter 1/80; Loss: 0.6666
Epoch 1423/10000; Iter 51/80; Loss: 0.6057
Epoch 1423/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.088
Epoch 1424/10000; Iter 1/80; Loss: 0.6114
Epoch 1424/10000; Iter 51/80; Loss: 0.5655
Epoch 1424/10000; Iter 80/80; Training Loss: 0.5660, Test Loss: 0.074
Epoch 1425/10000; Iter 1/80; Loss: 0.6241
Epoch 1425/10000; Iter 51/80; Loss: 0.5833
Epoch 1425/10000; Iter 80/80; Training Loss: 0.5560, Test Loss: 0.067
Epoch 1426/10000; Iter 1/80; Loss: 0.5816
Epoch 1426/10000; Iter 51/80; Loss: 0.5446
Epoch 1426/10000; Iter 80/80; Training Loss: 0.5640, Test Loss: 0.065
Epoch 1427/10000; Iter 1/80; Loss: 0.6437
Epoch 1427/10000; Iter 51/80; Loss: 0.6378
Epoch 1427/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.064
Epoch 1428/10000; Iter 1/80; Loss: 0.5587
Epoch 1428/10000; Iter 51/80; Loss: 0.5790
Epoch 1428/10000; Iter 80/80; Training Loss: 0.5590, Test Loss: 0.075
Epoch 1429/10000; Iter 1/80; Loss: 0.5457
Epoch 1429/10000; Iter 51/80; Loss: 0.5577
Epoch 1429/10000; Iter 80/80; Training Loss: 0.5740, Test Loss: 0.071
Epoch 1430/10000; Iter 1/80; Loss: 0.5646
Epoch 1430/10000; Iter 51/80; Loss: 0.5334
Epoch 1430/10000; Iter 80/80; Training Loss: 0.5650, Test Loss: 0.073
Epoch 1431/10000; Iter 1/80; Loss: 0.5565
Epoch 1431/10000; Iter 51/80; Loss: 0.5525
Epoch 1431/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.076
Epoch 1432/10000; Iter 1/80; Loss: 0.4942
Epoch 1432/10000; Iter 51/80; Loss: 0.5673
Epoch 1432/10000; Iter 80/80; Training Loss: 0.5660, Test Loss: 0.08
Epoch 1433/10000; Iter 1/80; Loss: 0.5849
Epoch 1433/10000; Iter 51/80; Loss: 0.5503
Epoch 1433/10000; Iter 80/80; Training Loss: 0.5640, Test Loss: 0.073
Epoch 1434/10000; Iter 1/80; Loss: 0.6574
Epoch 1434/10000; Iter 51/80; Loss: 0.5612
Epoch 1434/10000; Iter 80/80; Training Loss: 0.5720, Test Loss: 0.065
Epoch 1435/10000; Iter 1/80; Loss: 0.6012
Epoch 1435/10000; Iter 51/80; Loss: 0.5509
Epoch 1435/10000; Iter 80/80; Training Loss: 0.5640, Test Loss: 0.065
Epoch 1436/10000; Iter 1/80; Loss: 0.5696
Epoch 1436/10000; Iter 51/80; Loss: 0.5710
Epoch 1436/10000; Iter 80/80; Training Loss: 0.5670, Test Loss: 0.074
Epoch 1437/10000; Iter 1/80; Loss: 0.5593
Epoch 1437/10000; Iter 51/80; Loss: 0.5596
Epoch 1437/10000; Iter 80/80; Training Loss: 0.5600, Test Loss: 0.059
Epoch 1438/10000; Iter 1/80; Loss: 0.5612
Epoch 1438/10000; Iter 51/80; Loss: 0.5839
Epoch 1438/10000; Iter 80/80; Training Loss: 0.5650, Test Loss: 0.07
Epoch 1439/10000; Iter 1/80; Loss: 0.5087
Epoch 1439/10000; Iter 51/80; Loss: 0.5628
Epoch 1439/10000; Iter 80/80; Training Loss: 0.5580, Test Loss: 0.065
Epoch 1440/10000; Iter 1/80; Loss: 0.6255
Epoch 1440/10000; Iter 51/80; Loss: 0.6496
Epoch 1440/10000; Iter 80/80; Training Loss: 0.5780, Test Loss: 0.07
Epoch 1441/10000; Iter 1/80; Loss: 0.5418
Epoch 1441/10000; Iter 51/80; Loss: 0.5216
Epoch 1441/10000; Iter 80/80; Training Loss: 0.5630, Test Loss: 0.063
Epoch 1442/10000; Iter 1/80; Loss: 0.5547
Epoch 1442/10000; Iter 51/80; Loss: 0.5659
Epoch 1442/10000; Iter 80/80; Training Loss: 0.5620, Test Loss: 0.074
Epoch 1443/10000; Iter 1/80; Loss: 0.5564
Epoch 1443/10000; Iter 51/80; Loss: 0.5768
Epoch 1443/10000; Iter 80/80; Training Loss: 0.5590, Test Loss: 0.064
Epoch 1444/10000; Iter 1/80; Loss: 0.6013
Epoch 1444/10000; Iter 51/80; Loss: 0.5382
Epoch 1444/10000; Iter 80/80; Training Loss: 0.5670, Test Loss: 0.074
Epoch 1445/10000; Iter 1/80; Loss: 0.5412
Epoch 1445/10000; Iter 51/80; Loss: 0.5891
Epoch 1445/10000; Iter 80/80; Training Loss: 0.5700, Test Loss: 0.065
Epoch 1446/10000; Iter 1/80; Loss: 0.5703
Epoch 1446/10000; Iter 51/80; Loss: 0.5240
Epoch 1446/10000; Iter 80/80; Training Loss: 0.5640, Test Loss: 0.07
Epoch 1447/10000; Iter 1/80; Loss: 0.6573
Epoch 1447/10000; Iter 51/80; Loss: 0.5106
Epoch 1447/10000; Iter 80/80; Training Loss: 0.5640, Test Loss: 0.062
Epoch 1448/10000; Iter 1/80; Loss: 0.6029
Epoch 1448/10000; Iter 51/80; Loss: 0.5458
Epoch 1448/10000; Iter 80/80; Training Loss: 0.5560, Test Loss: 0.067
Epoch 1449/10000; Iter 1/80; Loss: 0.5521
Epoch 1449/10000; Iter 51/80; Loss: 0.5947
Epoch 1449/10000; Iter 80/80; Training Loss: 0.5610, Test Loss: 0.067
Epoch 1450/10000; Iter 1/80; Loss: 0.5052
Epoch 1450/10000; Iter 51/80; Loss: 0.5086
Epoch 1450/10000; Iter 80/80; Training Loss: 0.5660, Test Loss: 0.071
Epoch 1451/10000; Iter 1/80; Loss: 0.5120
Epoch 1451/10000; Iter 51/80; Loss: 0.5636
Epoch 1451/10000; Iter 80/80; Training Loss: 0.5670, Test Loss: 0.064
Epoch 1452/10000; Iter 1/80; Loss: 0.6195
Epoch 1452/10000; Iter 51/80; Loss: 0.5581
Epoch 1452/10000; Iter 80/80; Training Loss: 0.5630, Test Loss: 0.095
Epoch 1453/10000; Iter 1/80; Loss: 0.5763
Epoch 1453/10000; Iter 51/80; Loss: 0.5333
Epoch 1453/10000; Iter 80/80; Training Loss: 0.5640, Test Loss: 0.07
Epoch 1454/10000; Iter 1/80; Loss: 0.4885
Epoch 1454/10000; Iter 51/80; Loss: 0.6171
Epoch 1454/10000; Iter 80/80; Training Loss: 0.5560, Test Loss: 0.072
Epoch 1455/10000; Iter 1/80; Loss: 0.4783
Epoch 1455/10000; Iter 51/80; Loss: 0.4762
Epoch 1455/10000; Iter 80/80; Training Loss: 0.5580, Test Loss: 0.073
Epoch 1456/10000; Iter 1/80; Loss: 0.6009
Epoch 1456/10000; Iter 51/80; Loss: 0.5409
Epoch 1456/10000; Iter 80/80; Training Loss: 0.5730, Test Loss: 0.074
Epoch 1457/10000; Iter 1/80; Loss: 0.5014
Epoch 1457/10000; Iter 51/80; Loss: 0.5466
Epoch 1457/10000; Iter 80/80; Training Loss: 0.5590, Test Loss: 0.062
Epoch 1458/10000; Iter 1/80; Loss: 0.5826
Epoch 1458/10000; Iter 51/80; Loss: 0.4919
Epoch 1458/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.065
Epoch 1459/10000; Iter 1/80; Loss: 0.5138
Epoch 1459/10000; Iter 51/80; Loss: 0.6616
Epoch 1459/10000; Iter 80/80; Training Loss: 0.5570, Test Loss: 0.067
Epoch 1460/10000; Iter 1/80; Loss: 0.5510
Epoch 1460/10000; Iter 51/80; Loss: 0.5495
Epoch 1460/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.067
Epoch 1461/10000; Iter 1/80; Loss: 0.5230
Epoch 1461/10000; Iter 51/80; Loss: 0.5919
Epoch 1461/10000; Iter 80/80; Training Loss: 0.5660, Test Loss: 0.071
Epoch 1462/10000; Iter 1/80; Loss: 0.5253
Epoch 1462/10000; Iter 51/80; Loss: 0.4823
Epoch 1462/10000; Iter 80/80; Training Loss: 0.5680, Test Loss: 0.076
Epoch 1463/10000; Iter 1/80; Loss: 0.5330
Epoch 1463/10000; Iter 51/80; Loss: 0.5787
Epoch 1463/10000; Iter 80/80; Training Loss: 0.5600, Test Loss: 0.075
Epoch 1464/10000; Iter 1/80; Loss: 0.5703
Epoch 1464/10000; Iter 51/80; Loss: 0.5293
Epoch 1464/10000; Iter 80/80; Training Loss: 0.5560, Test Loss: 0.071
Epoch 1465/10000; Iter 1/80; Loss: 0.5584
Epoch 1465/10000; Iter 51/80; Loss: 0.5479
Epoch 1465/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.07
Epoch 1466/10000; Iter 1/80; Loss: 0.4587
Epoch 1466/10000; Iter 51/80; Loss: 0.6664
Epoch 1466/10000; Iter 80/80; Training Loss: 0.5630, Test Loss: 0.076
Epoch 1467/10000; Iter 1/80; Loss: 0.4864
Epoch 1467/10000; Iter 51/80; Loss: 0.5648
Epoch 1467/10000; Iter 80/80; Training Loss: 0.5570, Test Loss: 0.056
Epoch 1468/10000; Iter 1/80; Loss: 0.5356
Epoch 1468/10000; Iter 51/80; Loss: 0.5805
Epoch 1468/10000; Iter 80/80; Training Loss: 0.5670, Test Loss: 0.078
Epoch 1469/10000; Iter 1/80; Loss: 0.5622
Epoch 1469/10000; Iter 51/80; Loss: 0.5113
Epoch 1469/10000; Iter 80/80; Training Loss: 0.5520, Test Loss: 0.071
Epoch 1470/10000; Iter 1/80; Loss: 0.5270
Epoch 1470/10000; Iter 51/80; Loss: 0.5287
Epoch 1470/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.069
Epoch 1471/10000; Iter 1/80; Loss: 0.5764
Epoch 1471/10000; Iter 51/80; Loss: 0.5438
Epoch 1471/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.068
Epoch 1472/10000; Iter 1/80; Loss: 0.5679
Epoch 1472/10000; Iter 51/80; Loss: 0.5680
Epoch 1472/10000; Iter 80/80; Training Loss: 0.5540, Test Loss: 0.074
Epoch 1473/10000; Iter 1/80; Loss: 0.5357
Epoch 1473/10000; Iter 51/80; Loss: 0.5918
Epoch 1473/10000; Iter 80/80; Training Loss: 0.5620, Test Loss: 0.07
Epoch 1474/10000; Iter 1/80; Loss: 0.4467
Epoch 1474/10000; Iter 51/80; Loss: 0.5723
Epoch 1474/10000; Iter 80/80; Training Loss: 0.5480, Test Loss: 0.074
Epoch 1475/10000; Iter 1/80; Loss: 0.5172
Epoch 1475/10000; Iter 51/80; Loss: 0.5341
Epoch 1475/10000; Iter 80/80; Training Loss: 0.5690, Test Loss: 0.076
Epoch 1476/10000; Iter 1/80; Loss: 0.5199
Epoch 1476/10000; Iter 51/80; Loss: 0.5311
Epoch 1476/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.071
Epoch 1477/10000; Iter 1/80; Loss: 0.5811
Epoch 1477/10000; Iter 51/80; Loss: 0.5753
Epoch 1477/10000; Iter 80/80; Training Loss: 0.5610, Test Loss: 0.073
Epoch 1478/10000; Iter 1/80; Loss: 0.6016
Epoch 1478/10000; Iter 51/80; Loss: 0.5435
Epoch 1478/10000; Iter 80/80; Training Loss: 0.5580, Test Loss: 0.075
Epoch 1479/10000; Iter 1/80; Loss: 0.5240
Epoch 1479/10000; Iter 51/80; Loss: 0.6484
Epoch 1479/10000; Iter 80/80; Training Loss: 0.5630, Test Loss: 0.08
Epoch 1480/10000; Iter 1/80; Loss: 0.5785
Epoch 1480/10000; Iter 51/80; Loss: 0.5640
Epoch 1480/10000; Iter 80/80; Training Loss: 0.5540, Test Loss: 0.066
Epoch 1481/10000; Iter 1/80; Loss: 0.5437
Epoch 1481/10000; Iter 51/80; Loss: 0.5442
Epoch 1481/10000; Iter 80/80; Training Loss: 0.5600, Test Loss: 0.076
Epoch 1482/10000; Iter 1/80; Loss: 0.4980
Epoch 1482/10000; Iter 51/80; Loss: 0.5594
Epoch 1482/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.069
Epoch 1483/10000; Iter 1/80; Loss: 0.4849
Epoch 1483/10000; Iter 51/80; Loss: 0.5671
Epoch 1483/10000; Iter 80/80; Training Loss: 0.5570, Test Loss: 0.068
Epoch 1484/10000; Iter 1/80; Loss: 0.5133
Epoch 1484/10000; Iter 51/80; Loss: 0.5080
Epoch 1484/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.07
Epoch 1485/10000; Iter 1/80; Loss: 0.5362
Epoch 1485/10000; Iter 51/80; Loss: 0.5636
Epoch 1485/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.059
Epoch 1486/10000; Iter 1/80; Loss: 0.5263
Epoch 1486/10000; Iter 51/80; Loss: 0.5153
Epoch 1486/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.064
Epoch 1487/10000; Iter 1/80; Loss: 0.5955
Epoch 1487/10000; Iter 51/80; Loss: 0.5260
Epoch 1487/10000; Iter 80/80; Training Loss: 0.5580, Test Loss: 0.068
Epoch 1488/10000; Iter 1/80; Loss: 0.5145
Epoch 1488/10000; Iter 51/80; Loss: 0.5720
Epoch 1488/10000; Iter 80/80; Training Loss: 0.5580, Test Loss: 0.071
Epoch 1489/10000; Iter 1/80; Loss: 0.5625
Epoch 1489/10000; Iter 51/80; Loss: 0.5555
Epoch 1489/10000; Iter 80/80; Training Loss: 0.5580, Test Loss: 0.079
Epoch 1490/10000; Iter 1/80; Loss: 0.5629
Epoch 1490/10000; Iter 51/80; Loss: 0.5132
Epoch 1490/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.075
Epoch 1491/10000; Iter 1/80; Loss: 0.5894
Epoch 1491/10000; Iter 51/80; Loss: 0.5133
Epoch 1491/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.071
Epoch 1492/10000; Iter 1/80; Loss: 0.5488
Epoch 1492/10000; Iter 51/80; Loss: 0.5155
Epoch 1492/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.065
Epoch 1493/10000; Iter 1/80; Loss: 0.6179
Epoch 1493/10000; Iter 51/80; Loss: 0.5796
Epoch 1493/10000; Iter 80/80; Training Loss: 0.5620, Test Loss: 0.062
Epoch 1494/10000; Iter 1/80; Loss: 0.5280
Epoch 1494/10000; Iter 51/80; Loss: 0.4965
Epoch 1494/10000; Iter 80/80; Training Loss: 0.5480, Test Loss: 0.064
Epoch 1495/10000; Iter 1/80; Loss: 0.5832
Epoch 1495/10000; Iter 51/80; Loss: 0.5605
Epoch 1495/10000; Iter 80/80; Training Loss: 0.5590, Test Loss: 0.073
Epoch 1496/10000; Iter 1/80; Loss: 0.6706
Epoch 1496/10000; Iter 51/80; Loss: 0.5032
Epoch 1496/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.082
Epoch 1497/10000; Iter 1/80; Loss: 0.5800
Epoch 1497/10000; Iter 51/80; Loss: 0.5737
Epoch 1497/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.07
Epoch 1498/10000; Iter 1/80; Loss: 0.5602
Epoch 1498/10000; Iter 51/80; Loss: 0.5949
Epoch 1498/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.073
Epoch 1499/10000; Iter 1/80; Loss: 0.4734
Epoch 1499/10000; Iter 51/80; Loss: 0.5144
Epoch 1499/10000; Iter 80/80; Training Loss: 0.5570, Test Loss: 0.075
Epoch 1500/10000; Iter 1/80; Loss: 0.5661
Epoch 1500/10000; Iter 51/80; Loss: 0.5346
Epoch 1500/10000; Iter 80/80; Training Loss: 0.5610, Test Loss: 0.072
Epoch 1501/10000; Iter 1/80; Loss: 0.5219
Epoch 1501/10000; Iter 51/80; Loss: 0.5747
Epoch 1501/10000; Iter 80/80; Training Loss: 0.5570, Test Loss: 0.079
Model saved
Epoch 1502/10000; Iter 1/80; Loss: 0.5044
Epoch 1502/10000; Iter 51/80; Loss: 0.5604
Epoch 1502/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.064
Epoch 1503/10000; Iter 1/80; Loss: 0.5924
Epoch 1503/10000; Iter 51/80; Loss: 0.6286
Epoch 1503/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.069
Epoch 1504/10000; Iter 1/80; Loss: 0.6654
Epoch 1504/10000; Iter 51/80; Loss: 0.5952
Epoch 1504/10000; Iter 80/80; Training Loss: 0.5470, Test Loss: 0.062
Epoch 1505/10000; Iter 1/80; Loss: 0.5857
Epoch 1505/10000; Iter 51/80; Loss: 0.6233
Epoch 1505/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.076
Epoch 1506/10000; Iter 1/80; Loss: 0.5212
Epoch 1506/10000; Iter 51/80; Loss: 0.5641
Epoch 1506/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.066
Epoch 1507/10000; Iter 1/80; Loss: 0.5394
Epoch 1507/10000; Iter 51/80; Loss: 0.6243
Epoch 1507/10000; Iter 80/80; Training Loss: 0.5570, Test Loss: 0.073
Epoch 1508/10000; Iter 1/80; Loss: 0.5756
Epoch 1508/10000; Iter 51/80; Loss: 0.5457
Epoch 1508/10000; Iter 80/80; Training Loss: 0.5520, Test Loss: 0.071
Epoch 1509/10000; Iter 1/80; Loss: 0.5642
Epoch 1509/10000; Iter 51/80; Loss: 0.5415
Epoch 1509/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.069
Epoch 1510/10000; Iter 1/80; Loss: 0.5104
Epoch 1510/10000; Iter 51/80; Loss: 0.5432
Epoch 1510/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.072
Epoch 1511/10000; Iter 1/80; Loss: 0.6120
Epoch 1511/10000; Iter 51/80; Loss: 0.5885
Epoch 1511/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.072
Epoch 1512/10000; Iter 1/80; Loss: 0.5572
Epoch 1512/10000; Iter 51/80; Loss: 0.5204
Epoch 1512/10000; Iter 80/80; Training Loss: 0.5480, Test Loss: 0.062
Epoch 1513/10000; Iter 1/80; Loss: 0.5719
Epoch 1513/10000; Iter 51/80; Loss: 0.5089
Epoch 1513/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.069
Epoch 1514/10000; Iter 1/80; Loss: 0.5622
Epoch 1514/10000; Iter 51/80; Loss: 0.5571
Epoch 1514/10000; Iter 80/80; Training Loss: 0.5450, Test Loss: 0.08
Epoch 1515/10000; Iter 1/80; Loss: 0.5504
Epoch 1515/10000; Iter 51/80; Loss: 0.5508
Epoch 1515/10000; Iter 80/80; Training Loss: 0.5520, Test Loss: 0.077
Epoch 1516/10000; Iter 1/80; Loss: 0.6758
Epoch 1516/10000; Iter 51/80; Loss: 0.4929
Epoch 1516/10000; Iter 80/80; Training Loss: 0.5550, Test Loss: 0.079
Epoch 1517/10000; Iter 1/80; Loss: 0.6347
Epoch 1517/10000; Iter 51/80; Loss: 0.5436
Epoch 1517/10000; Iter 80/80; Training Loss: 0.5470, Test Loss: 0.069
Epoch 1518/10000; Iter 1/80; Loss: 0.5130
Epoch 1518/10000; Iter 51/80; Loss: 0.5073
Epoch 1518/10000; Iter 80/80; Training Loss: 0.5460, Test Loss: 0.067
Epoch 1519/10000; Iter 1/80; Loss: 0.5122
Epoch 1519/10000; Iter 51/80; Loss: 0.5757
Epoch 1519/10000; Iter 80/80; Training Loss: 0.5460, Test Loss: 0.058
Epoch 1520/10000; Iter 1/80; Loss: 0.4923
Epoch 1520/10000; Iter 51/80; Loss: 0.5358
Epoch 1520/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.065
Epoch 1521/10000; Iter 1/80; Loss: 0.5344
Epoch 1521/10000; Iter 51/80; Loss: 0.5462
Epoch 1521/10000; Iter 80/80; Training Loss: 0.5490, Test Loss: 0.065
Epoch 1522/10000; Iter 1/80; Loss: 0.5665
Epoch 1522/10000; Iter 51/80; Loss: 0.6197
Epoch 1522/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.067
Epoch 1523/10000; Iter 1/80; Loss: 0.5210
Epoch 1523/10000; Iter 51/80; Loss: 0.5666
Epoch 1523/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.061
Epoch 1524/10000; Iter 1/80; Loss: 0.5601
Epoch 1524/10000; Iter 51/80; Loss: 0.5239
Epoch 1524/10000; Iter 80/80; Training Loss: 0.5460, Test Loss: 0.077
Epoch 1525/10000; Iter 1/80; Loss: 0.5156
Epoch 1525/10000; Iter 51/80; Loss: 0.4850
Epoch 1525/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.072
Epoch 1526/10000; Iter 1/80; Loss: 0.5502
Epoch 1526/10000; Iter 51/80; Loss: 0.5413
Epoch 1526/10000; Iter 80/80; Training Loss: 0.5460, Test Loss: 0.072
Epoch 1527/10000; Iter 1/80; Loss: 0.5583
Epoch 1527/10000; Iter 51/80; Loss: 0.5188
Epoch 1527/10000; Iter 80/80; Training Loss: 0.5460, Test Loss: 0.074
Epoch 1528/10000; Iter 1/80; Loss: 0.5429
Epoch 1528/10000; Iter 51/80; Loss: 0.5260
Epoch 1528/10000; Iter 80/80; Training Loss: 0.5430, Test Loss: 0.064
Epoch 1529/10000; Iter 1/80; Loss: 0.5255
Epoch 1529/10000; Iter 51/80; Loss: 0.5821
Epoch 1529/10000; Iter 80/80; Training Loss: 0.5470, Test Loss: 0.069
Epoch 1530/10000; Iter 1/80; Loss: 0.6032
Epoch 1530/10000; Iter 51/80; Loss: 0.5235
Epoch 1530/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.064
Epoch 1531/10000; Iter 1/80; Loss: 0.5372
Epoch 1531/10000; Iter 51/80; Loss: 0.5822
Epoch 1531/10000; Iter 80/80; Training Loss: 0.5480, Test Loss: 0.073
Epoch 1532/10000; Iter 1/80; Loss: 0.5756
Epoch 1532/10000; Iter 51/80; Loss: 0.4995
Epoch 1532/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.068
Epoch 1533/10000; Iter 1/80; Loss: 0.5688
Epoch 1533/10000; Iter 51/80; Loss: 0.5456
Epoch 1533/10000; Iter 80/80; Training Loss: 0.5510, Test Loss: 0.071
Epoch 1534/10000; Iter 1/80; Loss: 0.5067
Epoch 1534/10000; Iter 51/80; Loss: 0.5450
Epoch 1534/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.078
Epoch 1535/10000; Iter 1/80; Loss: 0.5147
Epoch 1535/10000; Iter 51/80; Loss: 0.5202
Epoch 1535/10000; Iter 80/80; Training Loss: 0.5460, Test Loss: 0.073
Epoch 1536/10000; Iter 1/80; Loss: 0.5279
Epoch 1536/10000; Iter 51/80; Loss: 0.4927
Epoch 1536/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.066
Epoch 1537/10000; Iter 1/80; Loss: 0.4824
Epoch 1537/10000; Iter 51/80; Loss: 0.5248
Epoch 1537/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.064
Epoch 1538/10000; Iter 1/80; Loss: 0.5278
Epoch 1538/10000; Iter 51/80; Loss: 0.6527
Epoch 1538/10000; Iter 80/80; Training Loss: 0.5490, Test Loss: 0.067
Epoch 1539/10000; Iter 1/80; Loss: 0.5912
Epoch 1539/10000; Iter 51/80; Loss: 0.4837
Epoch 1539/10000; Iter 80/80; Training Loss: 0.5480, Test Loss: 0.074
Epoch 1540/10000; Iter 1/80; Loss: 0.5584
Epoch 1540/10000; Iter 51/80; Loss: 0.5971
Epoch 1540/10000; Iter 80/80; Training Loss: 0.5500, Test Loss: 0.075
Epoch 1541/10000; Iter 1/80; Loss: 0.5499
Epoch 1541/10000; Iter 51/80; Loss: 0.5180
Epoch 1541/10000; Iter 80/80; Training Loss: 0.5530, Test Loss: 0.065
Epoch 1542/10000; Iter 1/80; Loss: 0.5703
Epoch 1542/10000; Iter 51/80; Loss: 0.6204
Epoch 1542/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.069
Epoch 1543/10000; Iter 1/80; Loss: 0.5874
Epoch 1543/10000; Iter 51/80; Loss: 0.5388
Epoch 1543/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.066
Epoch 1544/10000; Iter 1/80; Loss: 0.5491
Epoch 1544/10000; Iter 51/80; Loss: 0.4820
Epoch 1544/10000; Iter 80/80; Training Loss: 0.5600, Test Loss: 0.065
Epoch 1545/10000; Iter 1/80; Loss: 0.4981
Epoch 1545/10000; Iter 51/80; Loss: 0.5394
Epoch 1545/10000; Iter 80/80; Training Loss: 0.5420, Test Loss: 0.059
Epoch 1546/10000; Iter 1/80; Loss: 0.5610
Epoch 1546/10000; Iter 51/80; Loss: 0.5155
Epoch 1546/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.059
Epoch 1547/10000; Iter 1/80; Loss: 0.5586
Epoch 1547/10000; Iter 51/80; Loss: 0.5149
Epoch 1547/10000; Iter 80/80; Training Loss: 0.5430, Test Loss: 0.068
Epoch 1548/10000; Iter 1/80; Loss: 0.5947
Epoch 1548/10000; Iter 51/80; Loss: 0.4941
Epoch 1548/10000; Iter 80/80; Training Loss: 0.5470, Test Loss: 0.067
Epoch 1549/10000; Iter 1/80; Loss: 0.5260
Epoch 1549/10000; Iter 51/80; Loss: 0.5351
Epoch 1549/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.065
Epoch 1550/10000; Iter 1/80; Loss: 0.5375
Epoch 1550/10000; Iter 51/80; Loss: 0.5422
Epoch 1550/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.068
Epoch 1551/10000; Iter 1/80; Loss: 0.5133
Epoch 1551/10000; Iter 51/80; Loss: 0.5799
Epoch 1551/10000; Iter 80/80; Training Loss: 0.5480, Test Loss: 0.066
Epoch 1552/10000; Iter 1/80; Loss: 0.5002
Epoch 1552/10000; Iter 51/80; Loss: 0.5685
Epoch 1552/10000; Iter 80/80; Training Loss: 0.5380, Test Loss: 0.066
Epoch 1553/10000; Iter 1/80; Loss: 0.5910
Epoch 1553/10000; Iter 51/80; Loss: 0.5368
Epoch 1553/10000; Iter 80/80; Training Loss: 0.5470, Test Loss: 0.067
Epoch 1554/10000; Iter 1/80; Loss: 0.6454
Epoch 1554/10000; Iter 51/80; Loss: 0.4816
Epoch 1554/10000; Iter 80/80; Training Loss: 0.5430, Test Loss: 0.078
Epoch 1555/10000; Iter 1/80; Loss: 0.5889
Epoch 1555/10000; Iter 51/80; Loss: 0.5871
Epoch 1555/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.066
Epoch 1556/10000; Iter 1/80; Loss: 0.5315
Epoch 1556/10000; Iter 51/80; Loss: 0.5935
Epoch 1556/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.069
Epoch 1557/10000; Iter 1/80; Loss: 0.5188
Epoch 1557/10000; Iter 51/80; Loss: 0.5269
Epoch 1557/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.073
Epoch 1558/10000; Iter 1/80; Loss: 0.5797
Epoch 1558/10000; Iter 51/80; Loss: 0.6010
Epoch 1558/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.065
Epoch 1559/10000; Iter 1/80; Loss: 0.5358
Epoch 1559/10000; Iter 51/80; Loss: 0.5462
Epoch 1559/10000; Iter 80/80; Training Loss: 0.5450, Test Loss: 0.07
Epoch 1560/10000; Iter 1/80; Loss: 0.5479
Epoch 1560/10000; Iter 51/80; Loss: 0.5785
Epoch 1560/10000; Iter 80/80; Training Loss: 0.5450, Test Loss: 0.073
Epoch 1561/10000; Iter 1/80; Loss: 0.5127
Epoch 1561/10000; Iter 51/80; Loss: 0.5671
Epoch 1561/10000; Iter 80/80; Training Loss: 0.5430, Test Loss: 0.076
Epoch 1562/10000; Iter 1/80; Loss: 0.6265
Epoch 1562/10000; Iter 51/80; Loss: 0.5466
Epoch 1562/10000; Iter 80/80; Training Loss: 0.5410, Test Loss: 0.064
Epoch 1563/10000; Iter 1/80; Loss: 0.5471
Epoch 1563/10000; Iter 51/80; Loss: 0.5195
Epoch 1563/10000; Iter 80/80; Training Loss: 0.5380, Test Loss: 0.066
Epoch 1564/10000; Iter 1/80; Loss: 0.5237
Epoch 1564/10000; Iter 51/80; Loss: 0.5253
Epoch 1564/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.078
Epoch 1565/10000; Iter 1/80; Loss: 0.5130
Epoch 1565/10000; Iter 51/80; Loss: 0.5703
Epoch 1565/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.075
Epoch 1566/10000; Iter 1/80; Loss: 0.5249
Epoch 1566/10000; Iter 51/80; Loss: 0.5793
Epoch 1566/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.069
Epoch 1567/10000; Iter 1/80; Loss: 0.4931
Epoch 1567/10000; Iter 51/80; Loss: 0.5253
Epoch 1567/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.071
Epoch 1568/10000; Iter 1/80; Loss: 0.5747
Epoch 1568/10000; Iter 51/80; Loss: 0.5090
Epoch 1568/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.071
Epoch 1569/10000; Iter 1/80; Loss: 0.5291
Epoch 1569/10000; Iter 51/80; Loss: 0.5770
Epoch 1569/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.07
Epoch 1570/10000; Iter 1/80; Loss: 0.5570
Epoch 1570/10000; Iter 51/80; Loss: 0.5655
Epoch 1570/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.069
Epoch 1571/10000; Iter 1/80; Loss: 0.5131
Epoch 1571/10000; Iter 51/80; Loss: 0.5057
Epoch 1571/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.064
Epoch 1572/10000; Iter 1/80; Loss: 0.5045
Epoch 1572/10000; Iter 51/80; Loss: 0.5513
Epoch 1572/10000; Iter 80/80; Training Loss: 0.5400, Test Loss: 0.07
Epoch 1573/10000; Iter 1/80; Loss: 0.5200
Epoch 1573/10000; Iter 51/80; Loss: 0.5355
Epoch 1573/10000; Iter 80/80; Training Loss: 0.5450, Test Loss: 0.064
Epoch 1574/10000; Iter 1/80; Loss: 0.5104
Epoch 1574/10000; Iter 51/80; Loss: 0.4946
Epoch 1574/10000; Iter 80/80; Training Loss: 0.5440, Test Loss: 0.062
Epoch 1575/10000; Iter 1/80; Loss: 0.5580
Epoch 1575/10000; Iter 51/80; Loss: 0.5445
Epoch 1575/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.059
Epoch 1576/10000; Iter 1/80; Loss: 0.4864
Epoch 1576/10000; Iter 51/80; Loss: 0.5834
Epoch 1576/10000; Iter 80/80; Training Loss: 0.5390, Test Loss: 0.077
Epoch 1577/10000; Iter 1/80; Loss: 0.5043
Epoch 1577/10000; Iter 51/80; Loss: 0.5127
Epoch 1577/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.065
Epoch 1578/10000; Iter 1/80; Loss: 0.5146
Epoch 1578/10000; Iter 51/80; Loss: 0.5402
Epoch 1578/10000; Iter 80/80; Training Loss: 0.5450, Test Loss: 0.069
Epoch 1579/10000; Iter 1/80; Loss: 0.5046
Epoch 1579/10000; Iter 51/80; Loss: 0.5633
Epoch 1579/10000; Iter 80/80; Training Loss: 0.5430, Test Loss: 0.066
Epoch 1580/10000; Iter 1/80; Loss: 0.4882
Epoch 1580/10000; Iter 51/80; Loss: 0.5209
Epoch 1580/10000; Iter 80/80; Training Loss: 0.5420, Test Loss: 0.056
Epoch 1581/10000; Iter 1/80; Loss: 0.5625
Epoch 1581/10000; Iter 51/80; Loss: 0.5501
Epoch 1581/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.055
Epoch 1582/10000; Iter 1/80; Loss: 0.5212
Epoch 1582/10000; Iter 51/80; Loss: 0.5641
Epoch 1582/10000; Iter 80/80; Training Loss: 0.5390, Test Loss: 0.068
Epoch 1583/10000; Iter 1/80; Loss: 0.5238
Epoch 1583/10000; Iter 51/80; Loss: 0.4623
Epoch 1583/10000; Iter 80/80; Training Loss: 0.5350, Test Loss: 0.061
Epoch 1584/10000; Iter 1/80; Loss: 0.5107
Epoch 1584/10000; Iter 51/80; Loss: 0.5795
Epoch 1584/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.055
Epoch 1585/10000; Iter 1/80; Loss: 0.5069
Epoch 1585/10000; Iter 51/80; Loss: 0.5548
Epoch 1585/10000; Iter 80/80; Training Loss: 0.5350, Test Loss: 0.069
Epoch 1586/10000; Iter 1/80; Loss: 0.5602
Epoch 1586/10000; Iter 51/80; Loss: 0.5744
Epoch 1586/10000; Iter 80/80; Training Loss: 0.5330, Test Loss: 0.069
Epoch 1587/10000; Iter 1/80; Loss: 0.5866
Epoch 1587/10000; Iter 51/80; Loss: 0.5444
Epoch 1587/10000; Iter 80/80; Training Loss: 0.5410, Test Loss: 0.065
Epoch 1588/10000; Iter 1/80; Loss: 0.4779
Epoch 1588/10000; Iter 51/80; Loss: 0.4829
Epoch 1588/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.059
Epoch 1589/10000; Iter 1/80; Loss: 0.5123
Epoch 1589/10000; Iter 51/80; Loss: 0.5431
Epoch 1589/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.057
Epoch 1590/10000; Iter 1/80; Loss: 0.5396
Epoch 1590/10000; Iter 51/80; Loss: 0.4742
Epoch 1590/10000; Iter 80/80; Training Loss: 0.5420, Test Loss: 0.071
Epoch 1591/10000; Iter 1/80; Loss: 0.5385
Epoch 1591/10000; Iter 51/80; Loss: 0.5425
Epoch 1591/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.068
Epoch 1592/10000; Iter 1/80; Loss: 0.5907
Epoch 1592/10000; Iter 51/80; Loss: 0.5241
Epoch 1592/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.07
Epoch 1593/10000; Iter 1/80; Loss: 0.5634
Epoch 1593/10000; Iter 51/80; Loss: 0.5476
Epoch 1593/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.066
Epoch 1594/10000; Iter 1/80; Loss: 0.5151
Epoch 1594/10000; Iter 51/80; Loss: 0.5277
Epoch 1594/10000; Iter 80/80; Training Loss: 0.5320, Test Loss: 0.071
Epoch 1595/10000; Iter 1/80; Loss: 0.5251
Epoch 1595/10000; Iter 51/80; Loss: 0.6120
Epoch 1595/10000; Iter 80/80; Training Loss: 0.5330, Test Loss: 0.062
Epoch 1596/10000; Iter 1/80; Loss: 0.5799
Epoch 1596/10000; Iter 51/80; Loss: 0.4929
Epoch 1596/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.069
Epoch 1597/10000; Iter 1/80; Loss: 0.5101
Epoch 1597/10000; Iter 51/80; Loss: 0.5192
Epoch 1597/10000; Iter 80/80; Training Loss: 0.5320, Test Loss: 0.069
Epoch 1598/10000; Iter 1/80; Loss: 0.5252
Epoch 1598/10000; Iter 51/80; Loss: 0.5303
Epoch 1598/10000; Iter 80/80; Training Loss: 0.5380, Test Loss: 0.06
Epoch 1599/10000; Iter 1/80; Loss: 0.5255
Epoch 1599/10000; Iter 51/80; Loss: 0.4974
Epoch 1599/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.073
Epoch 1600/10000; Iter 1/80; Loss: 0.5567
Epoch 1600/10000; Iter 51/80; Loss: 0.5483
Epoch 1600/10000; Iter 80/80; Training Loss: 0.5390, Test Loss: 0.07
Epoch 1601/10000; Iter 1/80; Loss: 0.5143
Epoch 1601/10000; Iter 51/80; Loss: 0.4667
Epoch 1601/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.064
Model saved
Epoch 1602/10000; Iter 1/80; Loss: 0.5126
Epoch 1602/10000; Iter 51/80; Loss: 0.4800
Epoch 1602/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.069
Epoch 1603/10000; Iter 1/80; Loss: 0.5359
Epoch 1603/10000; Iter 51/80; Loss: 0.5619
Epoch 1603/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.056
Epoch 1604/10000; Iter 1/80; Loss: 0.5390
Epoch 1604/10000; Iter 51/80; Loss: 0.4715
Epoch 1604/10000; Iter 80/80; Training Loss: 0.5320, Test Loss: 0.07
Epoch 1605/10000; Iter 1/80; Loss: 0.5659
Epoch 1605/10000; Iter 51/80; Loss: 0.6407
Epoch 1605/10000; Iter 80/80; Training Loss: 0.5370, Test Loss: 0.069
Epoch 1606/10000; Iter 1/80; Loss: 0.5073
Epoch 1606/10000; Iter 51/80; Loss: 0.5100
Epoch 1606/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.072
Epoch 1607/10000; Iter 1/80; Loss: 0.4554
Epoch 1607/10000; Iter 51/80; Loss: 0.5955
Epoch 1607/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.08
Epoch 1608/10000; Iter 1/80; Loss: 0.5617
Epoch 1608/10000; Iter 51/80; Loss: 0.4590
Epoch 1608/10000; Iter 80/80; Training Loss: 0.5300, Test Loss: 0.062
Epoch 1609/10000; Iter 1/80; Loss: 0.4255
Epoch 1609/10000; Iter 51/80; Loss: 0.6124
Epoch 1609/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.061
Epoch 1610/10000; Iter 1/80; Loss: 0.5006
Epoch 1610/10000; Iter 51/80; Loss: 0.5161
Epoch 1610/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.056
Epoch 1611/10000; Iter 1/80; Loss: 0.5347
Epoch 1611/10000; Iter 51/80; Loss: 0.4985
Epoch 1611/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.068
Epoch 1612/10000; Iter 1/80; Loss: 0.4936
Epoch 1612/10000; Iter 51/80; Loss: 0.4659
Epoch 1612/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.066
Epoch 1613/10000; Iter 1/80; Loss: 0.5661
Epoch 1613/10000; Iter 51/80; Loss: 0.4809
Epoch 1613/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.073
Epoch 1614/10000; Iter 1/80; Loss: 0.5412
Epoch 1614/10000; Iter 51/80; Loss: 0.4824
Epoch 1614/10000; Iter 80/80; Training Loss: 0.5330, Test Loss: 0.07
Epoch 1615/10000; Iter 1/80; Loss: 0.5878
Epoch 1615/10000; Iter 51/80; Loss: 0.5651
Epoch 1615/10000; Iter 80/80; Training Loss: 0.5390, Test Loss: 0.061
Epoch 1616/10000; Iter 1/80; Loss: 0.5149
Epoch 1616/10000; Iter 51/80; Loss: 0.5568
Epoch 1616/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.069
Epoch 1617/10000; Iter 1/80; Loss: 0.5291
Epoch 1617/10000; Iter 51/80; Loss: 0.5766
Epoch 1617/10000; Iter 80/80; Training Loss: 0.5360, Test Loss: 0.054
Epoch 1618/10000; Iter 1/80; Loss: 0.5408
Epoch 1618/10000; Iter 51/80; Loss: 0.5347
Epoch 1618/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.062
Epoch 1619/10000; Iter 1/80; Loss: 0.5387
Epoch 1619/10000; Iter 51/80; Loss: 0.6131
Epoch 1619/10000; Iter 80/80; Training Loss: 0.5300, Test Loss: 0.063
Epoch 1620/10000; Iter 1/80; Loss: 0.5477
Epoch 1620/10000; Iter 51/80; Loss: 0.4865
Epoch 1620/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.078
Epoch 1621/10000; Iter 1/80; Loss: 0.5365
Epoch 1621/10000; Iter 51/80; Loss: 0.4991
Epoch 1621/10000; Iter 80/80; Training Loss: 0.5240, Test Loss: 0.057
Epoch 1622/10000; Iter 1/80; Loss: 0.5260
Epoch 1622/10000; Iter 51/80; Loss: 0.5748
Epoch 1622/10000; Iter 80/80; Training Loss: 0.5300, Test Loss: 0.071
Epoch 1623/10000; Iter 1/80; Loss: 0.5209
Epoch 1623/10000; Iter 51/80; Loss: 0.5460
Epoch 1623/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.063
Epoch 1624/10000; Iter 1/80; Loss: 0.4791
Epoch 1624/10000; Iter 51/80; Loss: 0.5040
Epoch 1624/10000; Iter 80/80; Training Loss: 0.5320, Test Loss: 0.067
Epoch 1625/10000; Iter 1/80; Loss: 0.4774
Epoch 1625/10000; Iter 51/80; Loss: 0.5497
Epoch 1625/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.07
Epoch 1626/10000; Iter 1/80; Loss: 0.5103
Epoch 1626/10000; Iter 51/80; Loss: 0.4758
Epoch 1626/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.076
Epoch 1627/10000; Iter 1/80; Loss: 0.5077
Epoch 1627/10000; Iter 51/80; Loss: 0.5354
Epoch 1627/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.068
Epoch 1628/10000; Iter 1/80; Loss: 0.5017
Epoch 1628/10000; Iter 51/80; Loss: 0.5003
Epoch 1628/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.06
Epoch 1629/10000; Iter 1/80; Loss: 0.4840
Epoch 1629/10000; Iter 51/80; Loss: 0.5795
Epoch 1629/10000; Iter 80/80; Training Loss: 0.5300, Test Loss: 0.075
Epoch 1630/10000; Iter 1/80; Loss: 0.5726
Epoch 1630/10000; Iter 51/80; Loss: 0.4467
Epoch 1630/10000; Iter 80/80; Training Loss: 0.5330, Test Loss: 0.069
Epoch 1631/10000; Iter 1/80; Loss: 0.5060
Epoch 1631/10000; Iter 51/80; Loss: 0.5470
Epoch 1631/10000; Iter 80/80; Training Loss: 0.5300, Test Loss: 0.063
Epoch 1632/10000; Iter 1/80; Loss: 0.5481
Epoch 1632/10000; Iter 51/80; Loss: 0.5201
Epoch 1632/10000; Iter 80/80; Training Loss: 0.5320, Test Loss: 0.059
Epoch 1633/10000; Iter 1/80; Loss: 0.5154
Epoch 1633/10000; Iter 51/80; Loss: 0.4953
Epoch 1633/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.059
Epoch 1634/10000; Iter 1/80; Loss: 0.5212
Epoch 1634/10000; Iter 51/80; Loss: 0.5494
Epoch 1634/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.068
Epoch 1635/10000; Iter 1/80; Loss: 0.5692
Epoch 1635/10000; Iter 51/80; Loss: 0.5360
Epoch 1635/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.055
Epoch 1636/10000; Iter 1/80; Loss: 0.4884
Epoch 1636/10000; Iter 51/80; Loss: 0.5286
Epoch 1636/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.07
Epoch 1637/10000; Iter 1/80; Loss: 0.5228
Epoch 1637/10000; Iter 51/80; Loss: 0.5711
Epoch 1637/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.065
Epoch 1638/10000; Iter 1/80; Loss: 0.4795
Epoch 1638/10000; Iter 51/80; Loss: 0.5121
Epoch 1638/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.062
Epoch 1639/10000; Iter 1/80; Loss: 0.5472
Epoch 1639/10000; Iter 51/80; Loss: 0.5439
Epoch 1639/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.06
Epoch 1640/10000; Iter 1/80; Loss: 0.6172
Epoch 1640/10000; Iter 51/80; Loss: 0.5495
Epoch 1640/10000; Iter 80/80; Training Loss: 0.5310, Test Loss: 0.067
Epoch 1641/10000; Iter 1/80; Loss: 0.5142
Epoch 1641/10000; Iter 51/80; Loss: 0.5997
Epoch 1641/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.068
Epoch 1642/10000; Iter 1/80; Loss: 0.4979
Epoch 1642/10000; Iter 51/80; Loss: 0.4929
Epoch 1642/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.063
Epoch 1643/10000; Iter 1/80; Loss: 0.5651
Epoch 1643/10000; Iter 51/80; Loss: 0.5103
Epoch 1643/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.063
Epoch 1644/10000; Iter 1/80; Loss: 0.5398
Epoch 1644/10000; Iter 51/80; Loss: 0.5249
Epoch 1644/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.077
Epoch 1645/10000; Iter 1/80; Loss: 0.5109
Epoch 1645/10000; Iter 51/80; Loss: 0.5694
Epoch 1645/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.055
Epoch 1646/10000; Iter 1/80; Loss: 0.4960
Epoch 1646/10000; Iter 51/80; Loss: 0.5459
Epoch 1646/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.067
Epoch 1647/10000; Iter 1/80; Loss: 0.4520
Epoch 1647/10000; Iter 51/80; Loss: 0.5306
Epoch 1647/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.068
Epoch 1648/10000; Iter 1/80; Loss: 0.5471
Epoch 1648/10000; Iter 51/80; Loss: 0.5040
Epoch 1648/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.059
Epoch 1649/10000; Iter 1/80; Loss: 0.5076
Epoch 1649/10000; Iter 51/80; Loss: 0.5878
Epoch 1649/10000; Iter 80/80; Training Loss: 0.5380, Test Loss: 0.074
Epoch 1650/10000; Iter 1/80; Loss: 0.5008
Epoch 1650/10000; Iter 51/80; Loss: 0.5406
Epoch 1650/10000; Iter 80/80; Training Loss: 0.5240, Test Loss: 0.063
Epoch 1651/10000; Iter 1/80; Loss: 0.5509
Epoch 1651/10000; Iter 51/80; Loss: 0.6019
Epoch 1651/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.066
Epoch 1652/10000; Iter 1/80; Loss: 0.5376
Epoch 1652/10000; Iter 51/80; Loss: 0.4574
Epoch 1652/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.081
Epoch 1653/10000; Iter 1/80; Loss: 0.5292
Epoch 1653/10000; Iter 51/80; Loss: 0.5075
Epoch 1653/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.062
Epoch 1654/10000; Iter 1/80; Loss: 0.5406
Epoch 1654/10000; Iter 51/80; Loss: 0.5218
Epoch 1654/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.06
Epoch 1655/10000; Iter 1/80; Loss: 0.5212
Epoch 1655/10000; Iter 51/80; Loss: 0.5773
Epoch 1655/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.065
Epoch 1656/10000; Iter 1/80; Loss: 0.4666
Epoch 1656/10000; Iter 51/80; Loss: 0.4595
Epoch 1656/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.066
Epoch 1657/10000; Iter 1/80; Loss: 0.5270
Epoch 1657/10000; Iter 51/80; Loss: 0.5188
Epoch 1657/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.067
Epoch 1658/10000; Iter 1/80; Loss: 0.5103
Epoch 1658/10000; Iter 51/80; Loss: 0.5465
Epoch 1658/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.061
Epoch 1659/10000; Iter 1/80; Loss: 0.4699
Epoch 1659/10000; Iter 51/80; Loss: 0.4922
Epoch 1659/10000; Iter 80/80; Training Loss: 0.5320, Test Loss: 0.073
Epoch 1660/10000; Iter 1/80; Loss: 0.5055
Epoch 1660/10000; Iter 51/80; Loss: 0.5221
Epoch 1660/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.067
Epoch 1661/10000; Iter 1/80; Loss: 0.5315
Epoch 1661/10000; Iter 51/80; Loss: 0.5044
Epoch 1661/10000; Iter 80/80; Training Loss: 0.5200, Test Loss: 0.068
Epoch 1662/10000; Iter 1/80; Loss: 0.5474
Epoch 1662/10000; Iter 51/80; Loss: 0.6224
Epoch 1662/10000; Iter 80/80; Training Loss: 0.5270, Test Loss: 0.052
Epoch 1663/10000; Iter 1/80; Loss: 0.5202
Epoch 1663/10000; Iter 51/80; Loss: 0.5381
Epoch 1663/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.059
Epoch 1664/10000; Iter 1/80; Loss: 0.5275
Epoch 1664/10000; Iter 51/80; Loss: 0.5121
Epoch 1664/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.067
Epoch 1665/10000; Iter 1/80; Loss: 0.5304
Epoch 1665/10000; Iter 51/80; Loss: 0.5552
Epoch 1665/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.066
Epoch 1666/10000; Iter 1/80; Loss: 0.5246
Epoch 1666/10000; Iter 51/80; Loss: 0.4888
Epoch 1666/10000; Iter 80/80; Training Loss: 0.5240, Test Loss: 0.06
Epoch 1667/10000; Iter 1/80; Loss: 0.4825
Epoch 1667/10000; Iter 51/80; Loss: 0.5203
Epoch 1667/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.06
Epoch 1668/10000; Iter 1/80; Loss: 0.5300
Epoch 1668/10000; Iter 51/80; Loss: 0.5309
Epoch 1668/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.066
Epoch 1669/10000; Iter 1/80; Loss: 0.5019
Epoch 1669/10000; Iter 51/80; Loss: 0.4707
Epoch 1669/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.065
Epoch 1670/10000; Iter 1/80; Loss: 0.4865
Epoch 1670/10000; Iter 51/80; Loss: 0.5190
Epoch 1670/10000; Iter 80/80; Training Loss: 0.5240, Test Loss: 0.061
Epoch 1671/10000; Iter 1/80; Loss: 0.5294
Epoch 1671/10000; Iter 51/80; Loss: 0.4648
Epoch 1671/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.063
Epoch 1672/10000; Iter 1/80; Loss: 0.4279
Epoch 1672/10000; Iter 51/80; Loss: 0.5440
Epoch 1672/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.07
Epoch 1673/10000; Iter 1/80; Loss: 0.5418
Epoch 1673/10000; Iter 51/80; Loss: 0.5592
Epoch 1673/10000; Iter 80/80; Training Loss: 0.5180, Test Loss: 0.073
Epoch 1674/10000; Iter 1/80; Loss: 0.5535
Epoch 1674/10000; Iter 51/80; Loss: 0.5000
Epoch 1674/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.068
Epoch 1675/10000; Iter 1/80; Loss: 0.5317
Epoch 1675/10000; Iter 51/80; Loss: 0.4925
Epoch 1675/10000; Iter 80/80; Training Loss: 0.5150, Test Loss: 0.06
Epoch 1676/10000; Iter 1/80; Loss: 0.5266
Epoch 1676/10000; Iter 51/80; Loss: 0.5562
Epoch 1676/10000; Iter 80/80; Training Loss: 0.5290, Test Loss: 0.07
Epoch 1677/10000; Iter 1/80; Loss: 0.5344
Epoch 1677/10000; Iter 51/80; Loss: 0.5427
Epoch 1677/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.071
Epoch 1678/10000; Iter 1/80; Loss: 0.5312
Epoch 1678/10000; Iter 51/80; Loss: 0.5261
Epoch 1678/10000; Iter 80/80; Training Loss: 0.5340, Test Loss: 0.067
Epoch 1679/10000; Iter 1/80; Loss: 0.5545
Epoch 1679/10000; Iter 51/80; Loss: 0.4748
Epoch 1679/10000; Iter 80/80; Training Loss: 0.5280, Test Loss: 0.069
Epoch 1680/10000; Iter 1/80; Loss: 0.4626
Epoch 1680/10000; Iter 51/80; Loss: 0.4753
Epoch 1680/10000; Iter 80/80; Training Loss: 0.5200, Test Loss: 0.059
Epoch 1681/10000; Iter 1/80; Loss: 0.5076
Epoch 1681/10000; Iter 51/80; Loss: 0.4977
Epoch 1681/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.059
Epoch 1682/10000; Iter 1/80; Loss: 0.5119
Epoch 1682/10000; Iter 51/80; Loss: 0.5069
Epoch 1682/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.065
Epoch 1683/10000; Iter 1/80; Loss: 0.4967
Epoch 1683/10000; Iter 51/80; Loss: 0.4903
Epoch 1683/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.059
Epoch 1684/10000; Iter 1/80; Loss: 0.5601
Epoch 1684/10000; Iter 51/80; Loss: 0.4621
Epoch 1684/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.062
Epoch 1685/10000; Iter 1/80; Loss: 0.4585
Epoch 1685/10000; Iter 51/80; Loss: 0.5080
Epoch 1685/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.063
Epoch 1686/10000; Iter 1/80; Loss: 0.5162
Epoch 1686/10000; Iter 51/80; Loss: 0.5411
Epoch 1686/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.059
Epoch 1687/10000; Iter 1/80; Loss: 0.4386
Epoch 1687/10000; Iter 51/80; Loss: 0.5390
Epoch 1687/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.078
Epoch 1688/10000; Iter 1/80; Loss: 0.5122
Epoch 1688/10000; Iter 51/80; Loss: 0.5297
Epoch 1688/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.055
Epoch 1689/10000; Iter 1/80; Loss: 0.4742
Epoch 1689/10000; Iter 51/80; Loss: 0.4597
Epoch 1689/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.064
Epoch 1690/10000; Iter 1/80; Loss: 0.5393
Epoch 1690/10000; Iter 51/80; Loss: 0.5256
Epoch 1690/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.081
Epoch 1691/10000; Iter 1/80; Loss: 0.4608
Epoch 1691/10000; Iter 51/80; Loss: 0.5144
Epoch 1691/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.054
Epoch 1692/10000; Iter 1/80; Loss: 0.5500
Epoch 1692/10000; Iter 51/80; Loss: 0.5875
Epoch 1692/10000; Iter 80/80; Training Loss: 0.5150, Test Loss: 0.059
Epoch 1693/10000; Iter 1/80; Loss: 0.5221
Epoch 1693/10000; Iter 51/80; Loss: 0.4548
Epoch 1693/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.067
Epoch 1694/10000; Iter 1/80; Loss: 0.5155
Epoch 1694/10000; Iter 51/80; Loss: 0.4958
Epoch 1694/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.063
Epoch 1695/10000; Iter 1/80; Loss: 0.5313
Epoch 1695/10000; Iter 51/80; Loss: 0.4968
Epoch 1695/10000; Iter 80/80; Training Loss: 0.5260, Test Loss: 0.065
Epoch 1696/10000; Iter 1/80; Loss: 0.5495
Epoch 1696/10000; Iter 51/80; Loss: 0.4646
Epoch 1696/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.064
Epoch 1697/10000; Iter 1/80; Loss: 0.5996
Epoch 1697/10000; Iter 51/80; Loss: 0.5220
Epoch 1697/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.059
Epoch 1698/10000; Iter 1/80; Loss: 0.5643
Epoch 1698/10000; Iter 51/80; Loss: 0.4207
Epoch 1698/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.06
Epoch 1699/10000; Iter 1/80; Loss: 0.4881
Epoch 1699/10000; Iter 51/80; Loss: 0.5230
Epoch 1699/10000; Iter 80/80; Training Loss: 0.5150, Test Loss: 0.067
Epoch 1700/10000; Iter 1/80; Loss: 0.5180
Epoch 1700/10000; Iter 51/80; Loss: 0.5482
Epoch 1700/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.07
Epoch 1701/10000; Iter 1/80; Loss: 0.5349
Epoch 1701/10000; Iter 51/80; Loss: 0.4777
Epoch 1701/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.071
Model saved
Epoch 1702/10000; Iter 1/80; Loss: 0.5410
Epoch 1702/10000; Iter 51/80; Loss: 0.5157
Epoch 1702/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.064
Epoch 1703/10000; Iter 1/80; Loss: 0.5869
Epoch 1703/10000; Iter 51/80; Loss: 0.6051
Epoch 1703/10000; Iter 80/80; Training Loss: 0.5210, Test Loss: 0.066
Epoch 1704/10000; Iter 1/80; Loss: 0.6084
Epoch 1704/10000; Iter 51/80; Loss: 0.6010
Epoch 1704/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.063
Epoch 1705/10000; Iter 1/80; Loss: 0.5802
Epoch 1705/10000; Iter 51/80; Loss: 0.4950
Epoch 1705/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.059
Epoch 1706/10000; Iter 1/80; Loss: 0.4947
Epoch 1706/10000; Iter 51/80; Loss: 0.5228
Epoch 1706/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.066
Epoch 1707/10000; Iter 1/80; Loss: 0.5533
Epoch 1707/10000; Iter 51/80; Loss: 0.5036
Epoch 1707/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.067
Epoch 1708/10000; Iter 1/80; Loss: 0.5560
Epoch 1708/10000; Iter 51/80; Loss: 0.5002
Epoch 1708/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.062
Epoch 1709/10000; Iter 1/80; Loss: 0.5026
Epoch 1709/10000; Iter 51/80; Loss: 0.4845
Epoch 1709/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.071
Epoch 1710/10000; Iter 1/80; Loss: 0.5565
Epoch 1710/10000; Iter 51/80; Loss: 0.4818
Epoch 1710/10000; Iter 80/80; Training Loss: 0.5230, Test Loss: 0.063
Epoch 1711/10000; Iter 1/80; Loss: 0.4500
Epoch 1711/10000; Iter 51/80; Loss: 0.5834
Epoch 1711/10000; Iter 80/80; Training Loss: 0.5150, Test Loss: 0.062
Epoch 1712/10000; Iter 1/80; Loss: 0.5289
Epoch 1712/10000; Iter 51/80; Loss: 0.5616
Epoch 1712/10000; Iter 80/80; Training Loss: 0.5250, Test Loss: 0.058
Epoch 1713/10000; Iter 1/80; Loss: 0.5845
Epoch 1713/10000; Iter 51/80; Loss: 0.4734
Epoch 1713/10000; Iter 80/80; Training Loss: 0.5200, Test Loss: 0.065
Epoch 1714/10000; Iter 1/80; Loss: 0.4843
Epoch 1714/10000; Iter 51/80; Loss: 0.5660
Epoch 1714/10000; Iter 80/80; Training Loss: 0.5150, Test Loss: 0.06
Epoch 1715/10000; Iter 1/80; Loss: 0.5220
Epoch 1715/10000; Iter 51/80; Loss: 0.4935
Epoch 1715/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.064
Epoch 1716/10000; Iter 1/80; Loss: 0.5094
Epoch 1716/10000; Iter 51/80; Loss: 0.5131
Epoch 1716/10000; Iter 80/80; Training Loss: 0.5150, Test Loss: 0.063
Epoch 1717/10000; Iter 1/80; Loss: 0.5023
Epoch 1717/10000; Iter 51/80; Loss: 0.4986
Epoch 1717/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.065
Epoch 1718/10000; Iter 1/80; Loss: 0.5025
Epoch 1718/10000; Iter 51/80; Loss: 0.4944
Epoch 1718/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.058
Epoch 1719/10000; Iter 1/80; Loss: 0.5690
Epoch 1719/10000; Iter 51/80; Loss: 0.4804
Epoch 1719/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.057
Epoch 1720/10000; Iter 1/80; Loss: 0.5507
Epoch 1720/10000; Iter 51/80; Loss: 0.5372
Epoch 1720/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.068
Epoch 1721/10000; Iter 1/80; Loss: 0.4703
Epoch 1721/10000; Iter 51/80; Loss: 0.4958
Epoch 1721/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.059
Epoch 1722/10000; Iter 1/80; Loss: 0.5654
Epoch 1722/10000; Iter 51/80; Loss: 0.5479
Epoch 1722/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.056
Epoch 1723/10000; Iter 1/80; Loss: 0.4759
Epoch 1723/10000; Iter 51/80; Loss: 0.5230
Epoch 1723/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.057
Epoch 1724/10000; Iter 1/80; Loss: 0.5703
Epoch 1724/10000; Iter 51/80; Loss: 0.5420
Epoch 1724/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.069
Epoch 1725/10000; Iter 1/80; Loss: 0.5097
Epoch 1725/10000; Iter 51/80; Loss: 0.4968
Epoch 1725/10000; Iter 80/80; Training Loss: 0.5220, Test Loss: 0.06
Epoch 1726/10000; Iter 1/80; Loss: 0.4638
Epoch 1726/10000; Iter 51/80; Loss: 0.5631
Epoch 1726/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.055
Epoch 1727/10000; Iter 1/80; Loss: 0.5077
Epoch 1727/10000; Iter 51/80; Loss: 0.4466
Epoch 1727/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.065
Epoch 1728/10000; Iter 1/80; Loss: 0.4577
Epoch 1728/10000; Iter 51/80; Loss: 0.5009
Epoch 1728/10000; Iter 80/80; Training Loss: 0.5200, Test Loss: 0.06
Epoch 1729/10000; Iter 1/80; Loss: 0.5276
Epoch 1729/10000; Iter 51/80; Loss: 0.4846
Epoch 1729/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.063
Epoch 1730/10000; Iter 1/80; Loss: 0.5468
Epoch 1730/10000; Iter 51/80; Loss: 0.4920
Epoch 1730/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.07
Epoch 1731/10000; Iter 1/80; Loss: 0.4596
Epoch 1731/10000; Iter 51/80; Loss: 0.5116
Epoch 1731/10000; Iter 80/80; Training Loss: 0.5110, Test Loss: 0.055
Epoch 1732/10000; Iter 1/80; Loss: 0.5100
Epoch 1732/10000; Iter 51/80; Loss: 0.5202
Epoch 1732/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.061
Epoch 1733/10000; Iter 1/80; Loss: 0.5462
Epoch 1733/10000; Iter 51/80; Loss: 0.5454
Epoch 1733/10000; Iter 80/80; Training Loss: 0.5110, Test Loss: 0.055
Epoch 1734/10000; Iter 1/80; Loss: 0.5664
Epoch 1734/10000; Iter 51/80; Loss: 0.5554
Epoch 1734/10000; Iter 80/80; Training Loss: 0.5090, Test Loss: 0.059
Epoch 1735/10000; Iter 1/80; Loss: 0.4894
Epoch 1735/10000; Iter 51/80; Loss: 0.4977
Epoch 1735/10000; Iter 80/80; Training Loss: 0.5180, Test Loss: 0.049
Epoch 1736/10000; Iter 1/80; Loss: 0.4709
Epoch 1736/10000; Iter 51/80; Loss: 0.4682
Epoch 1736/10000; Iter 80/80; Training Loss: 0.5170, Test Loss: 0.068
Epoch 1737/10000; Iter 1/80; Loss: 0.5553
Epoch 1737/10000; Iter 51/80; Loss: 0.5110
Epoch 1737/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.051
Epoch 1738/10000; Iter 1/80; Loss: 0.4621
Epoch 1738/10000; Iter 51/80; Loss: 0.5123
Epoch 1738/10000; Iter 80/80; Training Loss: 0.5120, Test Loss: 0.064
Epoch 1739/10000; Iter 1/80; Loss: 0.5284
Epoch 1739/10000; Iter 51/80; Loss: 0.5109
Epoch 1739/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.067
Epoch 1740/10000; Iter 1/80; Loss: 0.4692
Epoch 1740/10000; Iter 51/80; Loss: 0.4419
Epoch 1740/10000; Iter 80/80; Training Loss: 0.5160, Test Loss: 0.059
Epoch 1741/10000; Iter 1/80; Loss: 0.4739
Epoch 1741/10000; Iter 51/80; Loss: 0.5199
Epoch 1741/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.062
Epoch 1742/10000; Iter 1/80; Loss: 0.5077
Epoch 1742/10000; Iter 51/80; Loss: 0.6161
Epoch 1742/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.07
Epoch 1743/10000; Iter 1/80; Loss: 0.4977
Epoch 1743/10000; Iter 51/80; Loss: 0.5762
Epoch 1743/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.059
Epoch 1744/10000; Iter 1/80; Loss: 0.4792
Epoch 1744/10000; Iter 51/80; Loss: 0.5113
Epoch 1744/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.067
Epoch 1745/10000; Iter 1/80; Loss: 0.5465
Epoch 1745/10000; Iter 51/80; Loss: 0.4898
Epoch 1745/10000; Iter 80/80; Training Loss: 0.5070, Test Loss: 0.058
Epoch 1746/10000; Iter 1/80; Loss: 0.4978
Epoch 1746/10000; Iter 51/80; Loss: 0.5373
Epoch 1746/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.056
Epoch 1747/10000; Iter 1/80; Loss: 0.5281
Epoch 1747/10000; Iter 51/80; Loss: 0.5619
Epoch 1747/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.053
Epoch 1748/10000; Iter 1/80; Loss: 0.4761
Epoch 1748/10000; Iter 51/80; Loss: 0.4792
Epoch 1748/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.064
Epoch 1749/10000; Iter 1/80; Loss: 0.5238
Epoch 1749/10000; Iter 51/80; Loss: 0.5181
Epoch 1749/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.074
Epoch 1750/10000; Iter 1/80; Loss: 0.5199
Epoch 1750/10000; Iter 51/80; Loss: 0.4705
Epoch 1750/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.063
Epoch 1751/10000; Iter 1/80; Loss: 0.5168
Epoch 1751/10000; Iter 51/80; Loss: 0.5059
Epoch 1751/10000; Iter 80/80; Training Loss: 0.5120, Test Loss: 0.058
Epoch 1752/10000; Iter 1/80; Loss: 0.5505
Epoch 1752/10000; Iter 51/80; Loss: 0.5339
Epoch 1752/10000; Iter 80/80; Training Loss: 0.5110, Test Loss: 0.062
Epoch 1753/10000; Iter 1/80; Loss: 0.5240
Epoch 1753/10000; Iter 51/80; Loss: 0.4796
Epoch 1753/10000; Iter 80/80; Training Loss: 0.5180, Test Loss: 0.058
Epoch 1754/10000; Iter 1/80; Loss: 0.5391
Epoch 1754/10000; Iter 51/80; Loss: 0.5406
Epoch 1754/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.059
Epoch 1755/10000; Iter 1/80; Loss: 0.5321
Epoch 1755/10000; Iter 51/80; Loss: 0.5077
Epoch 1755/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.065
Epoch 1756/10000; Iter 1/80; Loss: 0.4936
Epoch 1756/10000; Iter 51/80; Loss: 0.5123
Epoch 1756/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.068
Epoch 1757/10000; Iter 1/80; Loss: 0.4718
Epoch 1757/10000; Iter 51/80; Loss: 0.4758
Epoch 1757/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.057
Epoch 1758/10000; Iter 1/80; Loss: 0.5001
Epoch 1758/10000; Iter 51/80; Loss: 0.4975
Epoch 1758/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.07
Epoch 1759/10000; Iter 1/80; Loss: 0.5242
Epoch 1759/10000; Iter 51/80; Loss: 0.5299
Epoch 1759/10000; Iter 80/80; Training Loss: 0.5070, Test Loss: 0.058
Epoch 1760/10000; Iter 1/80; Loss: 0.5256
Epoch 1760/10000; Iter 51/80; Loss: 0.5011
Epoch 1760/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.057
Epoch 1761/10000; Iter 1/80; Loss: 0.5300
Epoch 1761/10000; Iter 51/80; Loss: 0.5211
Epoch 1761/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.062
Epoch 1762/10000; Iter 1/80; Loss: 0.6246
Epoch 1762/10000; Iter 51/80; Loss: 0.5290
Epoch 1762/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.054
Epoch 1763/10000; Iter 1/80; Loss: 0.4506
Epoch 1763/10000; Iter 51/80; Loss: 0.5270
Epoch 1763/10000; Iter 80/80; Training Loss: 0.5140, Test Loss: 0.059
Epoch 1764/10000; Iter 1/80; Loss: 0.5138
Epoch 1764/10000; Iter 51/80; Loss: 0.4981
Epoch 1764/10000; Iter 80/80; Training Loss: 0.5040, Test Loss: 0.062
Epoch 1765/10000; Iter 1/80; Loss: 0.4833
Epoch 1765/10000; Iter 51/80; Loss: 0.4632
Epoch 1765/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.064
Epoch 1766/10000; Iter 1/80; Loss: 0.5528
Epoch 1766/10000; Iter 51/80; Loss: 0.5001
Epoch 1766/10000; Iter 80/80; Training Loss: 0.5070, Test Loss: 0.064
Epoch 1767/10000; Iter 1/80; Loss: 0.5559
Epoch 1767/10000; Iter 51/80; Loss: 0.4968
Epoch 1767/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.064
Epoch 1768/10000; Iter 1/80; Loss: 0.5165
Epoch 1768/10000; Iter 51/80; Loss: 0.4764
Epoch 1768/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.071
Epoch 1769/10000; Iter 1/80; Loss: 0.4246
Epoch 1769/10000; Iter 51/80; Loss: 0.6030
Epoch 1769/10000; Iter 80/80; Training Loss: 0.5190, Test Loss: 0.079
Epoch 1770/10000; Iter 1/80; Loss: 0.4751
Epoch 1770/10000; Iter 51/80; Loss: 0.5525
Epoch 1770/10000; Iter 80/80; Training Loss: 0.5040, Test Loss: 0.048
Epoch 1771/10000; Iter 1/80; Loss: 0.5748
Epoch 1771/10000; Iter 51/80; Loss: 0.6324
Epoch 1771/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.059
Epoch 1772/10000; Iter 1/80; Loss: 0.5238
Epoch 1772/10000; Iter 51/80; Loss: 0.4858
Epoch 1772/10000; Iter 80/80; Training Loss: 0.5130, Test Loss: 0.061
Epoch 1773/10000; Iter 1/80; Loss: 0.5669
Epoch 1773/10000; Iter 51/80; Loss: 0.4296
Epoch 1773/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.064
Epoch 1774/10000; Iter 1/80; Loss: 0.4877
Epoch 1774/10000; Iter 51/80; Loss: 0.5656
Epoch 1774/10000; Iter 80/80; Training Loss: 0.5070, Test Loss: 0.061
Epoch 1775/10000; Iter 1/80; Loss: 0.4816
Epoch 1775/10000; Iter 51/80; Loss: 0.4766
Epoch 1775/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.064
Epoch 1776/10000; Iter 1/80; Loss: 0.5044
Epoch 1776/10000; Iter 51/80; Loss: 0.5108
Epoch 1776/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.073
Epoch 1777/10000; Iter 1/80; Loss: 0.5444
Epoch 1777/10000; Iter 51/80; Loss: 0.5479
Epoch 1777/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.067
Epoch 1778/10000; Iter 1/80; Loss: 0.4977
Epoch 1778/10000; Iter 51/80; Loss: 0.5143
Epoch 1778/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.059
Epoch 1779/10000; Iter 1/80; Loss: 0.4956
Epoch 1779/10000; Iter 51/80; Loss: 0.5044
Epoch 1779/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.056
Epoch 1780/10000; Iter 1/80; Loss: 0.4637
Epoch 1780/10000; Iter 51/80; Loss: 0.4630
Epoch 1780/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.06
Epoch 1781/10000; Iter 1/80; Loss: 0.5089
Epoch 1781/10000; Iter 51/80; Loss: 0.5058
Epoch 1781/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.051
Epoch 1782/10000; Iter 1/80; Loss: 0.4897
Epoch 1782/10000; Iter 51/80; Loss: 0.5852
Epoch 1782/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.053
Epoch 1783/10000; Iter 1/80; Loss: 0.4544
Epoch 1783/10000; Iter 51/80; Loss: 0.5099
Epoch 1783/10000; Iter 80/80; Training Loss: 0.5090, Test Loss: 0.063
Epoch 1784/10000; Iter 1/80; Loss: 0.4642
Epoch 1784/10000; Iter 51/80; Loss: 0.5209
Epoch 1784/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.064
Epoch 1785/10000; Iter 1/80; Loss: 0.4534
Epoch 1785/10000; Iter 51/80; Loss: 0.5542
Epoch 1785/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.05
Epoch 1786/10000; Iter 1/80; Loss: 0.4861
Epoch 1786/10000; Iter 51/80; Loss: 0.4963
Epoch 1786/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.062
Epoch 1787/10000; Iter 1/80; Loss: 0.5059
Epoch 1787/10000; Iter 51/80; Loss: 0.4770
Epoch 1787/10000; Iter 80/80; Training Loss: 0.5040, Test Loss: 0.056
Epoch 1788/10000; Iter 1/80; Loss: 0.5490
Epoch 1788/10000; Iter 51/80; Loss: 0.5299
Epoch 1788/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.053
Epoch 1789/10000; Iter 1/80; Loss: 0.5091
Epoch 1789/10000; Iter 51/80; Loss: 0.4660
Epoch 1789/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.056
Epoch 1790/10000; Iter 1/80; Loss: 0.4099
Epoch 1790/10000; Iter 51/80; Loss: 0.4729
Epoch 1790/10000; Iter 80/80; Training Loss: 0.5070, Test Loss: 0.062
Epoch 1791/10000; Iter 1/80; Loss: 0.5026
Epoch 1791/10000; Iter 51/80; Loss: 0.4859
Epoch 1791/10000; Iter 80/80; Training Loss: 0.5040, Test Loss: 0.051
Epoch 1792/10000; Iter 1/80; Loss: 0.5429
Epoch 1792/10000; Iter 51/80; Loss: 0.5008
Epoch 1792/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.053
Epoch 1793/10000; Iter 1/80; Loss: 0.4610
Epoch 1793/10000; Iter 51/80; Loss: 0.4877
Epoch 1793/10000; Iter 80/80; Training Loss: 0.5120, Test Loss: 0.071
Epoch 1794/10000; Iter 1/80; Loss: 0.4830
Epoch 1794/10000; Iter 51/80; Loss: 0.4901
Epoch 1794/10000; Iter 80/80; Training Loss: 0.5110, Test Loss: 0.06
Epoch 1795/10000; Iter 1/80; Loss: 0.4981
Epoch 1795/10000; Iter 51/80; Loss: 0.4798
Epoch 1795/10000; Iter 80/80; Training Loss: 0.5070, Test Loss: 0.062
Epoch 1796/10000; Iter 1/80; Loss: 0.4902
Epoch 1796/10000; Iter 51/80; Loss: 0.4807
Epoch 1796/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.061
Epoch 1797/10000; Iter 1/80; Loss: 0.4952
Epoch 1797/10000; Iter 51/80; Loss: 0.4291
Epoch 1797/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.054
Epoch 1798/10000; Iter 1/80; Loss: 0.4903
Epoch 1798/10000; Iter 51/80; Loss: 0.4631
Epoch 1798/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.061
Epoch 1799/10000; Iter 1/80; Loss: 0.4846
Epoch 1799/10000; Iter 51/80; Loss: 0.4978
Epoch 1799/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.066
Epoch 1800/10000; Iter 1/80; Loss: 0.4431
Epoch 1800/10000; Iter 51/80; Loss: 0.5218
Epoch 1800/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.053
Epoch 1801/10000; Iter 1/80; Loss: 0.5576
Epoch 1801/10000; Iter 51/80; Loss: 0.4895
Epoch 1801/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.058
Model saved
Epoch 1802/10000; Iter 1/80; Loss: 0.4949
Epoch 1802/10000; Iter 51/80; Loss: 0.4961
Epoch 1802/10000; Iter 80/80; Training Loss: 0.5010, Test Loss: 0.06
Epoch 1803/10000; Iter 1/80; Loss: 0.4524
Epoch 1803/10000; Iter 51/80; Loss: 0.4713
Epoch 1803/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.061
Epoch 1804/10000; Iter 1/80; Loss: 0.4764
Epoch 1804/10000; Iter 51/80; Loss: 0.5293
Epoch 1804/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.068
Epoch 1805/10000; Iter 1/80; Loss: 0.4871
Epoch 1805/10000; Iter 51/80; Loss: 0.5043
Epoch 1805/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.064
Epoch 1806/10000; Iter 1/80; Loss: 0.5160
Epoch 1806/10000; Iter 51/80; Loss: 0.5250
Epoch 1806/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.06
Epoch 1807/10000; Iter 1/80; Loss: 0.5407
Epoch 1807/10000; Iter 51/80; Loss: 0.4959
Epoch 1807/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.056
Epoch 1808/10000; Iter 1/80; Loss: 0.5007
Epoch 1808/10000; Iter 51/80; Loss: 0.5672
Epoch 1808/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.063
Epoch 1809/10000; Iter 1/80; Loss: 0.5933
Epoch 1809/10000; Iter 51/80; Loss: 0.5200
Epoch 1809/10000; Iter 80/80; Training Loss: 0.5090, Test Loss: 0.062
Epoch 1810/10000; Iter 1/80; Loss: 0.5788
Epoch 1810/10000; Iter 51/80; Loss: 0.4680
Epoch 1810/10000; Iter 80/80; Training Loss: 0.5080, Test Loss: 0.065
Epoch 1811/10000; Iter 1/80; Loss: 0.5350
Epoch 1811/10000; Iter 51/80; Loss: 0.4673
Epoch 1811/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.056
Epoch 1812/10000; Iter 1/80; Loss: 0.5514
Epoch 1812/10000; Iter 51/80; Loss: 0.5620
Epoch 1812/10000; Iter 80/80; Training Loss: 0.5100, Test Loss: 0.071
Epoch 1813/10000; Iter 1/80; Loss: 0.4193
Epoch 1813/10000; Iter 51/80; Loss: 0.4783
Epoch 1813/10000; Iter 80/80; Training Loss: 0.5040, Test Loss: 0.059
Epoch 1814/10000; Iter 1/80; Loss: 0.4538
Epoch 1814/10000; Iter 51/80; Loss: 0.4765
Epoch 1814/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.057
Epoch 1815/10000; Iter 1/80; Loss: 0.4759
Epoch 1815/10000; Iter 51/80; Loss: 0.4939
Epoch 1815/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.064
Epoch 1816/10000; Iter 1/80; Loss: 0.5217
Epoch 1816/10000; Iter 51/80; Loss: 0.5130
Epoch 1816/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.06
Epoch 1817/10000; Iter 1/80; Loss: 0.4805
Epoch 1817/10000; Iter 51/80; Loss: 0.5083
Epoch 1817/10000; Iter 80/80; Training Loss: 0.5110, Test Loss: 0.058
Epoch 1818/10000; Iter 1/80; Loss: 0.4971
Epoch 1818/10000; Iter 51/80; Loss: 0.5416
Epoch 1818/10000; Iter 80/80; Training Loss: 0.5010, Test Loss: 0.057
Epoch 1819/10000; Iter 1/80; Loss: 0.5132
Epoch 1819/10000; Iter 51/80; Loss: 0.4843
Epoch 1819/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.053
Epoch 1820/10000; Iter 1/80; Loss: 0.4431
Epoch 1820/10000; Iter 51/80; Loss: 0.5189
Epoch 1820/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.052
Epoch 1821/10000; Iter 1/80; Loss: 0.5294
Epoch 1821/10000; Iter 51/80; Loss: 0.5537
Epoch 1821/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.052
Epoch 1822/10000; Iter 1/80; Loss: 0.5021
Epoch 1822/10000; Iter 51/80; Loss: 0.4623
Epoch 1822/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.056
Epoch 1823/10000; Iter 1/80; Loss: 0.4872
Epoch 1823/10000; Iter 51/80; Loss: 0.4478
Epoch 1823/10000; Iter 80/80; Training Loss: 0.5090, Test Loss: 0.062
Epoch 1824/10000; Iter 1/80; Loss: 0.4638
Epoch 1824/10000; Iter 51/80; Loss: 0.4551
Epoch 1824/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.063
Epoch 1825/10000; Iter 1/80; Loss: 0.5083
Epoch 1825/10000; Iter 51/80; Loss: 0.4670
Epoch 1825/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.061
Epoch 1826/10000; Iter 1/80; Loss: 0.4476
Epoch 1826/10000; Iter 51/80; Loss: 0.4761
Epoch 1826/10000; Iter 80/80; Training Loss: 0.4960, Test Loss: 0.068
Epoch 1827/10000; Iter 1/80; Loss: 0.4855
Epoch 1827/10000; Iter 51/80; Loss: 0.5003
Epoch 1827/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.061
Epoch 1828/10000; Iter 1/80; Loss: 0.4951
Epoch 1828/10000; Iter 51/80; Loss: 0.4388
Epoch 1828/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.055
Epoch 1829/10000; Iter 1/80; Loss: 0.5442
Epoch 1829/10000; Iter 51/80; Loss: 0.4553
Epoch 1829/10000; Iter 80/80; Training Loss: 0.5090, Test Loss: 0.065
Epoch 1830/10000; Iter 1/80; Loss: 0.6192
Epoch 1830/10000; Iter 51/80; Loss: 0.5062
Epoch 1830/10000; Iter 80/80; Training Loss: 0.5010, Test Loss: 0.062
Epoch 1831/10000; Iter 1/80; Loss: 0.5005
Epoch 1831/10000; Iter 51/80; Loss: 0.5709
Epoch 1831/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.056
Epoch 1832/10000; Iter 1/80; Loss: 0.4598
Epoch 1832/10000; Iter 51/80; Loss: 0.4912
Epoch 1832/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.059
Epoch 1833/10000; Iter 1/80; Loss: 0.4762
Epoch 1833/10000; Iter 51/80; Loss: 0.4736
Epoch 1833/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.062
Epoch 1834/10000; Iter 1/80; Loss: 0.4840
Epoch 1834/10000; Iter 51/80; Loss: 0.4913
Epoch 1834/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.065
Epoch 1835/10000; Iter 1/80; Loss: 0.5281
Epoch 1835/10000; Iter 51/80; Loss: 0.4609
Epoch 1835/10000; Iter 80/80; Training Loss: 0.5010, Test Loss: 0.062
Epoch 1836/10000; Iter 1/80; Loss: 0.5080
Epoch 1836/10000; Iter 51/80; Loss: 0.4843
Epoch 1836/10000; Iter 80/80; Training Loss: 0.5060, Test Loss: 0.058
Epoch 1837/10000; Iter 1/80; Loss: 0.5092
Epoch 1837/10000; Iter 51/80; Loss: 0.4612
Epoch 1837/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.061
Epoch 1838/10000; Iter 1/80; Loss: 0.5464
Epoch 1838/10000; Iter 51/80; Loss: 0.4315
Epoch 1838/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.06
Epoch 1839/10000; Iter 1/80; Loss: 0.4618
Epoch 1839/10000; Iter 51/80; Loss: 0.5270
Epoch 1839/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.052
Epoch 1840/10000; Iter 1/80; Loss: 0.4510
Epoch 1840/10000; Iter 51/80; Loss: 0.4751
Epoch 1840/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.062
Epoch 1841/10000; Iter 1/80; Loss: 0.5052
Epoch 1841/10000; Iter 51/80; Loss: 0.5093
Epoch 1841/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.062
Epoch 1842/10000; Iter 1/80; Loss: 0.5100
Epoch 1842/10000; Iter 51/80; Loss: 0.5204
Epoch 1842/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.058
Epoch 1843/10000; Iter 1/80; Loss: 0.5439
Epoch 1843/10000; Iter 51/80; Loss: 0.5553
Epoch 1843/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.056
Epoch 1844/10000; Iter 1/80; Loss: 0.5131
Epoch 1844/10000; Iter 51/80; Loss: 0.4872
Epoch 1844/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.051
Epoch 1845/10000; Iter 1/80; Loss: 0.5093
Epoch 1845/10000; Iter 51/80; Loss: 0.5874
Epoch 1845/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.055
Epoch 1846/10000; Iter 1/80; Loss: 0.5147
Epoch 1846/10000; Iter 51/80; Loss: 0.5001
Epoch 1846/10000; Iter 80/80; Training Loss: 0.5040, Test Loss: 0.072
Epoch 1847/10000; Iter 1/80; Loss: 0.4984
Epoch 1847/10000; Iter 51/80; Loss: 0.5206
Epoch 1847/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.055
Epoch 1848/10000; Iter 1/80; Loss: 0.5844
Epoch 1848/10000; Iter 51/80; Loss: 0.5102
Epoch 1848/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.065
Epoch 1849/10000; Iter 1/80; Loss: 0.5545
Epoch 1849/10000; Iter 51/80; Loss: 0.5732
Epoch 1849/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.052
Epoch 1850/10000; Iter 1/80; Loss: 0.4526
Epoch 1850/10000; Iter 51/80; Loss: 0.5216
Epoch 1850/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.055
Epoch 1851/10000; Iter 1/80; Loss: 0.5168
Epoch 1851/10000; Iter 51/80; Loss: 0.4763
Epoch 1851/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.059
Epoch 1852/10000; Iter 1/80; Loss: 0.4683
Epoch 1852/10000; Iter 51/80; Loss: 0.5531
Epoch 1852/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.068
Epoch 1853/10000; Iter 1/80; Loss: 0.4841
Epoch 1853/10000; Iter 51/80; Loss: 0.4796
Epoch 1853/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.068
Epoch 1854/10000; Iter 1/80; Loss: 0.5463
Epoch 1854/10000; Iter 51/80; Loss: 0.4469
Epoch 1854/10000; Iter 80/80; Training Loss: 0.4980, Test Loss: 0.061
Epoch 1855/10000; Iter 1/80; Loss: 0.4960
Epoch 1855/10000; Iter 51/80; Loss: 0.5224
Epoch 1855/10000; Iter 80/80; Training Loss: 0.5010, Test Loss: 0.054
Epoch 1856/10000; Iter 1/80; Loss: 0.5204
Epoch 1856/10000; Iter 51/80; Loss: 0.5534
Epoch 1856/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.066
Epoch 1857/10000; Iter 1/80; Loss: 0.4566
Epoch 1857/10000; Iter 51/80; Loss: 0.4594
Epoch 1857/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.06
Epoch 1858/10000; Iter 1/80; Loss: 0.4385
Epoch 1858/10000; Iter 51/80; Loss: 0.4492
Epoch 1858/10000; Iter 80/80; Training Loss: 0.4980, Test Loss: 0.061
Epoch 1859/10000; Iter 1/80; Loss: 0.5052
Epoch 1859/10000; Iter 51/80; Loss: 0.4733
Epoch 1859/10000; Iter 80/80; Training Loss: 0.4940, Test Loss: 0.07
Epoch 1860/10000; Iter 1/80; Loss: 0.5046
Epoch 1860/10000; Iter 51/80; Loss: 0.4647
Epoch 1860/10000; Iter 80/80; Training Loss: 0.5010, Test Loss: 0.053
Epoch 1861/10000; Iter 1/80; Loss: 0.4877
Epoch 1861/10000; Iter 51/80; Loss: 0.5510
Epoch 1861/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.057
Epoch 1862/10000; Iter 1/80; Loss: 0.4855
Epoch 1862/10000; Iter 51/80; Loss: 0.5414
Epoch 1862/10000; Iter 80/80; Training Loss: 0.4880, Test Loss: 0.058
Epoch 1863/10000; Iter 1/80; Loss: 0.5204
Epoch 1863/10000; Iter 51/80; Loss: 0.4780
Epoch 1863/10000; Iter 80/80; Training Loss: 0.5050, Test Loss: 0.061
Epoch 1864/10000; Iter 1/80; Loss: 0.4597
Epoch 1864/10000; Iter 51/80; Loss: 0.4794
Epoch 1864/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.06
Epoch 1865/10000; Iter 1/80; Loss: 0.5239
Epoch 1865/10000; Iter 51/80; Loss: 0.4770
Epoch 1865/10000; Iter 80/80; Training Loss: 0.4900, Test Loss: 0.065
Epoch 1866/10000; Iter 1/80; Loss: 0.4704
Epoch 1866/10000; Iter 51/80; Loss: 0.4700
Epoch 1866/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.051
Epoch 1867/10000; Iter 1/80; Loss: 0.5406
Epoch 1867/10000; Iter 51/80; Loss: 0.5054
Epoch 1867/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.063
Epoch 1868/10000; Iter 1/80; Loss: 0.4346
Epoch 1868/10000; Iter 51/80; Loss: 0.5221
Epoch 1868/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.061
Epoch 1869/10000; Iter 1/80; Loss: 0.4966
Epoch 1869/10000; Iter 51/80; Loss: 0.4785
Epoch 1869/10000; Iter 80/80; Training Loss: 0.4880, Test Loss: 0.06
Epoch 1870/10000; Iter 1/80; Loss: 0.5156
Epoch 1870/10000; Iter 51/80; Loss: 0.4686
Epoch 1870/10000; Iter 80/80; Training Loss: 0.4960, Test Loss: 0.066
Epoch 1871/10000; Iter 1/80; Loss: 0.5148
Epoch 1871/10000; Iter 51/80; Loss: 0.4659
Epoch 1871/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.06
Epoch 1872/10000; Iter 1/80; Loss: 0.5083
Epoch 1872/10000; Iter 51/80; Loss: 0.5268
Epoch 1872/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.05
Epoch 1873/10000; Iter 1/80; Loss: 0.4452
Epoch 1873/10000; Iter 51/80; Loss: 0.5839
Epoch 1873/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.06
Epoch 1874/10000; Iter 1/80; Loss: 0.5258
Epoch 1874/10000; Iter 51/80; Loss: 0.4817
Epoch 1874/10000; Iter 80/80; Training Loss: 0.5020, Test Loss: 0.058
Epoch 1875/10000; Iter 1/80; Loss: 0.4652
Epoch 1875/10000; Iter 51/80; Loss: 0.4765
Epoch 1875/10000; Iter 80/80; Training Loss: 0.4940, Test Loss: 0.052
Epoch 1876/10000; Iter 1/80; Loss: 0.5210
Epoch 1876/10000; Iter 51/80; Loss: 0.5096
Epoch 1876/10000; Iter 80/80; Training Loss: 0.4960, Test Loss: 0.055
Epoch 1877/10000; Iter 1/80; Loss: 0.4431
Epoch 1877/10000; Iter 51/80; Loss: 0.4645
Epoch 1877/10000; Iter 80/80; Training Loss: 0.4940, Test Loss: 0.056
Epoch 1878/10000; Iter 1/80; Loss: 0.5001
Epoch 1878/10000; Iter 51/80; Loss: 0.4758
Epoch 1878/10000; Iter 80/80; Training Loss: 0.4980, Test Loss: 0.062
Epoch 1879/10000; Iter 1/80; Loss: 0.4277
Epoch 1879/10000; Iter 51/80; Loss: 0.4552
Epoch 1879/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.057
Epoch 1880/10000; Iter 1/80; Loss: 0.5442
Epoch 1880/10000; Iter 51/80; Loss: 0.4719
Epoch 1880/10000; Iter 80/80; Training Loss: 0.4990, Test Loss: 0.068
Epoch 1881/10000; Iter 1/80; Loss: 0.4199
Epoch 1881/10000; Iter 51/80; Loss: 0.4254
Epoch 1881/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.056
Epoch 1882/10000; Iter 1/80; Loss: 0.4926
Epoch 1882/10000; Iter 51/80; Loss: 0.4704
Epoch 1882/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.058
Epoch 1883/10000; Iter 1/80; Loss: 0.4354
Epoch 1883/10000; Iter 51/80; Loss: 0.5181
Epoch 1883/10000; Iter 80/80; Training Loss: 0.5030, Test Loss: 0.053
Epoch 1884/10000; Iter 1/80; Loss: 0.4831
Epoch 1884/10000; Iter 51/80; Loss: 0.4843
Epoch 1884/10000; Iter 80/80; Training Loss: 0.4940, Test Loss: 0.056
Epoch 1885/10000; Iter 1/80; Loss: 0.4901
Epoch 1885/10000; Iter 51/80; Loss: 0.4765
Epoch 1885/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.059
Epoch 1886/10000; Iter 1/80; Loss: 0.4399
Epoch 1886/10000; Iter 51/80; Loss: 0.4797
Epoch 1886/10000; Iter 80/80; Training Loss: 0.4890, Test Loss: 0.054
Epoch 1887/10000; Iter 1/80; Loss: 0.4524
Epoch 1887/10000; Iter 51/80; Loss: 0.4809
Epoch 1887/10000; Iter 80/80; Training Loss: 0.5000, Test Loss: 0.055
Epoch 1888/10000; Iter 1/80; Loss: 0.5325
Epoch 1888/10000; Iter 51/80; Loss: 0.5276
Epoch 1888/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.058
Epoch 1889/10000; Iter 1/80; Loss: 0.4718
Epoch 1889/10000; Iter 51/80; Loss: 0.4644
Epoch 1889/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.061
Epoch 1890/10000; Iter 1/80; Loss: 0.4857
Epoch 1890/10000; Iter 51/80; Loss: 0.5237
Epoch 1890/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.057
Epoch 1891/10000; Iter 1/80; Loss: 0.5596
Epoch 1891/10000; Iter 51/80; Loss: 0.4854
Epoch 1891/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.059
Epoch 1892/10000; Iter 1/80; Loss: 0.5241
Epoch 1892/10000; Iter 51/80; Loss: 0.5110
Epoch 1892/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.057
Epoch 1893/10000; Iter 1/80; Loss: 0.5040
Epoch 1893/10000; Iter 51/80; Loss: 0.5217
Epoch 1893/10000; Iter 80/80; Training Loss: 0.4940, Test Loss: 0.051
Epoch 1894/10000; Iter 1/80; Loss: 0.4916
Epoch 1894/10000; Iter 51/80; Loss: 0.5007
Epoch 1894/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.059
Epoch 1895/10000; Iter 1/80; Loss: 0.4897
Epoch 1895/10000; Iter 51/80; Loss: 0.4641
Epoch 1895/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.058
Epoch 1896/10000; Iter 1/80; Loss: 0.4276
Epoch 1896/10000; Iter 51/80; Loss: 0.5696
Epoch 1896/10000; Iter 80/80; Training Loss: 0.4960, Test Loss: 0.057
Epoch 1897/10000; Iter 1/80; Loss: 0.4759
Epoch 1897/10000; Iter 51/80; Loss: 0.4831
Epoch 1897/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.063
Epoch 1898/10000; Iter 1/80; Loss: 0.4954
Epoch 1898/10000; Iter 51/80; Loss: 0.5192
Epoch 1898/10000; Iter 80/80; Training Loss: 0.4880, Test Loss: 0.058
Epoch 1899/10000; Iter 1/80; Loss: 0.4803
Epoch 1899/10000; Iter 51/80; Loss: 0.5300
Epoch 1899/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.053
Epoch 1900/10000; Iter 1/80; Loss: 0.5773
Epoch 1900/10000; Iter 51/80; Loss: 0.5566
Epoch 1900/10000; Iter 80/80; Training Loss: 0.4940, Test Loss: 0.059
Epoch 1901/10000; Iter 1/80; Loss: 0.5289
Epoch 1901/10000; Iter 51/80; Loss: 0.4453
Epoch 1901/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.065
Model saved
Epoch 1902/10000; Iter 1/80; Loss: 0.5885
Epoch 1902/10000; Iter 51/80; Loss: 0.5540
Epoch 1902/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.058
Epoch 1903/10000; Iter 1/80; Loss: 0.4582
Epoch 1903/10000; Iter 51/80; Loss: 0.4274
Epoch 1903/10000; Iter 80/80; Training Loss: 0.4890, Test Loss: 0.063
Epoch 1904/10000; Iter 1/80; Loss: 0.4365
Epoch 1904/10000; Iter 51/80; Loss: 0.5107
Epoch 1904/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.054
Epoch 1905/10000; Iter 1/80; Loss: 0.4252
Epoch 1905/10000; Iter 51/80; Loss: 0.4374
Epoch 1905/10000; Iter 80/80; Training Loss: 0.4900, Test Loss: 0.059
Epoch 1906/10000; Iter 1/80; Loss: 0.4817
Epoch 1906/10000; Iter 51/80; Loss: 0.5380
Epoch 1906/10000; Iter 80/80; Training Loss: 0.4900, Test Loss: 0.054
Epoch 1907/10000; Iter 1/80; Loss: 0.4983
Epoch 1907/10000; Iter 51/80; Loss: 0.5394
Epoch 1907/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.057
Epoch 1908/10000; Iter 1/80; Loss: 0.4208
Epoch 1908/10000; Iter 51/80; Loss: 0.4081
Epoch 1908/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.057
Epoch 1909/10000; Iter 1/80; Loss: 0.4800
Epoch 1909/10000; Iter 51/80; Loss: 0.5382
Epoch 1909/10000; Iter 80/80; Training Loss: 0.4900, Test Loss: 0.063
Epoch 1910/10000; Iter 1/80; Loss: 0.4554
Epoch 1910/10000; Iter 51/80; Loss: 0.4378
Epoch 1910/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.052
Epoch 1911/10000; Iter 1/80; Loss: 0.4630
Epoch 1911/10000; Iter 51/80; Loss: 0.5035
Epoch 1911/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.064
Epoch 1912/10000; Iter 1/80; Loss: 0.5055
Epoch 1912/10000; Iter 51/80; Loss: 0.4930
Epoch 1912/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.062
Epoch 1913/10000; Iter 1/80; Loss: 0.4403
Epoch 1913/10000; Iter 51/80; Loss: 0.4678
Epoch 1913/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.056
Epoch 1914/10000; Iter 1/80; Loss: 0.5007
Epoch 1914/10000; Iter 51/80; Loss: 0.4903
Epoch 1914/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.055
Epoch 1915/10000; Iter 1/80; Loss: 0.4388
Epoch 1915/10000; Iter 51/80; Loss: 0.5641
Epoch 1915/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.057
Epoch 1916/10000; Iter 1/80; Loss: 0.4612
Epoch 1916/10000; Iter 51/80; Loss: 0.4634
Epoch 1916/10000; Iter 80/80; Training Loss: 0.4900, Test Loss: 0.064
Epoch 1917/10000; Iter 1/80; Loss: 0.5277
Epoch 1917/10000; Iter 51/80; Loss: 0.4236
Epoch 1917/10000; Iter 80/80; Training Loss: 0.4880, Test Loss: 0.056
Epoch 1918/10000; Iter 1/80; Loss: 0.4986
Epoch 1918/10000; Iter 51/80; Loss: 0.4588
Epoch 1918/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.058
Epoch 1919/10000; Iter 1/80; Loss: 0.5029
Epoch 1919/10000; Iter 51/80; Loss: 0.4154
Epoch 1919/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.061
Epoch 1920/10000; Iter 1/80; Loss: 0.4489
Epoch 1920/10000; Iter 51/80; Loss: 0.4654
Epoch 1920/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.06
Epoch 1921/10000; Iter 1/80; Loss: 0.4761
Epoch 1921/10000; Iter 51/80; Loss: 0.5289
Epoch 1921/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.062
Epoch 1922/10000; Iter 1/80; Loss: 0.4387
Epoch 1922/10000; Iter 51/80; Loss: 0.5326
Epoch 1922/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.057
Epoch 1923/10000; Iter 1/80; Loss: 0.5474
Epoch 1923/10000; Iter 51/80; Loss: 0.4583
Epoch 1923/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.056
Epoch 1924/10000; Iter 1/80; Loss: 0.4696
Epoch 1924/10000; Iter 51/80; Loss: 0.4565
Epoch 1924/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.06
Epoch 1925/10000; Iter 1/80; Loss: 0.4740
Epoch 1925/10000; Iter 51/80; Loss: 0.5327
Epoch 1925/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.064
Epoch 1926/10000; Iter 1/80; Loss: 0.4575
Epoch 1926/10000; Iter 51/80; Loss: 0.4425
Epoch 1926/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.054
Epoch 1927/10000; Iter 1/80; Loss: 0.4828
Epoch 1927/10000; Iter 51/80; Loss: 0.5469
Epoch 1927/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.047
Epoch 1928/10000; Iter 1/80; Loss: 0.5062
Epoch 1928/10000; Iter 51/80; Loss: 0.4520
Epoch 1928/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.058
Epoch 1929/10000; Iter 1/80; Loss: 0.4774
Epoch 1929/10000; Iter 51/80; Loss: 0.4992
Epoch 1929/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.061
Epoch 1930/10000; Iter 1/80; Loss: 0.4819
Epoch 1930/10000; Iter 51/80; Loss: 0.6305
Epoch 1930/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.052
Epoch 1931/10000; Iter 1/80; Loss: 0.4733
Epoch 1931/10000; Iter 51/80; Loss: 0.4769
Epoch 1931/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.059
Epoch 1932/10000; Iter 1/80; Loss: 0.4168
Epoch 1932/10000; Iter 51/80; Loss: 0.4108
Epoch 1932/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.067
Epoch 1933/10000; Iter 1/80; Loss: 0.5105
Epoch 1933/10000; Iter 51/80; Loss: 0.5064
Epoch 1933/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.058
Epoch 1934/10000; Iter 1/80; Loss: 0.4771
Epoch 1934/10000; Iter 51/80; Loss: 0.4686
Epoch 1934/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.053
Epoch 1935/10000; Iter 1/80; Loss: 0.4887
Epoch 1935/10000; Iter 51/80; Loss: 0.5014
Epoch 1935/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.061
Epoch 1936/10000; Iter 1/80; Loss: 0.5009
Epoch 1936/10000; Iter 51/80; Loss: 0.4648
Epoch 1936/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.052
Epoch 1937/10000; Iter 1/80; Loss: 0.4992
Epoch 1937/10000; Iter 51/80; Loss: 0.4586
Epoch 1937/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.061
Epoch 1938/10000; Iter 1/80; Loss: 0.4910
Epoch 1938/10000; Iter 51/80; Loss: 0.5094
Epoch 1938/10000; Iter 80/80; Training Loss: 0.4920, Test Loss: 0.052
Epoch 1939/10000; Iter 1/80; Loss: 0.4653
Epoch 1939/10000; Iter 51/80; Loss: 0.4589
Epoch 1939/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.057
Epoch 1940/10000; Iter 1/80; Loss: 0.5338
Epoch 1940/10000; Iter 51/80; Loss: 0.4697
Epoch 1940/10000; Iter 80/80; Training Loss: 0.4970, Test Loss: 0.044
Epoch 1941/10000; Iter 1/80; Loss: 0.4542
Epoch 1941/10000; Iter 51/80; Loss: 0.5163
Epoch 1941/10000; Iter 80/80; Training Loss: 0.4930, Test Loss: 0.05
Epoch 1942/10000; Iter 1/80; Loss: 0.4921
Epoch 1942/10000; Iter 51/80; Loss: 0.4852
Epoch 1942/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.05
Epoch 1943/10000; Iter 1/80; Loss: 0.4365
Epoch 1943/10000; Iter 51/80; Loss: 0.5248
Epoch 1943/10000; Iter 80/80; Training Loss: 0.4900, Test Loss: 0.053
Epoch 1944/10000; Iter 1/80; Loss: 0.4414
Epoch 1944/10000; Iter 51/80; Loss: 0.5063
Epoch 1944/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.058
Epoch 1945/10000; Iter 1/80; Loss: 0.4421
Epoch 1945/10000; Iter 51/80; Loss: 0.5301
Epoch 1945/10000; Iter 80/80; Training Loss: 0.4880, Test Loss: 0.069
Epoch 1946/10000; Iter 1/80; Loss: 0.5101
Epoch 1946/10000; Iter 51/80; Loss: 0.5607
Epoch 1946/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.055
Epoch 1947/10000; Iter 1/80; Loss: 0.4680
Epoch 1947/10000; Iter 51/80; Loss: 0.4753
Epoch 1947/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.053
Epoch 1948/10000; Iter 1/80; Loss: 0.4564
Epoch 1948/10000; Iter 51/80; Loss: 0.5480
Epoch 1948/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.048
Epoch 1949/10000; Iter 1/80; Loss: 0.4368
Epoch 1949/10000; Iter 51/80; Loss: 0.4558
Epoch 1949/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.059
Epoch 1950/10000; Iter 1/80; Loss: 0.4703
Epoch 1950/10000; Iter 51/80; Loss: 0.4450
Epoch 1950/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.061
Epoch 1951/10000; Iter 1/80; Loss: 0.4849
Epoch 1951/10000; Iter 51/80; Loss: 0.5170
Epoch 1951/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.055
Epoch 1952/10000; Iter 1/80; Loss: 0.4544
Epoch 1952/10000; Iter 51/80; Loss: 0.4816
Epoch 1952/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.061
Epoch 1953/10000; Iter 1/80; Loss: 0.5322
Epoch 1953/10000; Iter 51/80; Loss: 0.4608
Epoch 1953/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.059
Epoch 1954/10000; Iter 1/80; Loss: 0.5290
Epoch 1954/10000; Iter 51/80; Loss: 0.4589
Epoch 1954/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.051
Epoch 1955/10000; Iter 1/80; Loss: 0.4603
Epoch 1955/10000; Iter 51/80; Loss: 0.4975
Epoch 1955/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.05
Epoch 1956/10000; Iter 1/80; Loss: 0.4453
Epoch 1956/10000; Iter 51/80; Loss: 0.5042
Epoch 1956/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.054
Epoch 1957/10000; Iter 1/80; Loss: 0.4365
Epoch 1957/10000; Iter 51/80; Loss: 0.4158
Epoch 1957/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.058
Epoch 1958/10000; Iter 1/80; Loss: 0.4765
Epoch 1958/10000; Iter 51/80; Loss: 0.5370
Epoch 1958/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.055
Epoch 1959/10000; Iter 1/80; Loss: 0.4552
Epoch 1959/10000; Iter 51/80; Loss: 0.4195
Epoch 1959/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.055
Epoch 1960/10000; Iter 1/80; Loss: 0.4935
Epoch 1960/10000; Iter 51/80; Loss: 0.5000
Epoch 1960/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.046
Epoch 1961/10000; Iter 1/80; Loss: 0.4746
Epoch 1961/10000; Iter 51/80; Loss: 0.4587
Epoch 1961/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.055
Epoch 1962/10000; Iter 1/80; Loss: 0.4246
Epoch 1962/10000; Iter 51/80; Loss: 0.4972
Epoch 1962/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.052
Epoch 1963/10000; Iter 1/80; Loss: 0.5597
Epoch 1963/10000; Iter 51/80; Loss: 0.4856
Epoch 1963/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.05
Epoch 1964/10000; Iter 1/80; Loss: 0.4861
Epoch 1964/10000; Iter 51/80; Loss: 0.4402
Epoch 1964/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.063
Epoch 1965/10000; Iter 1/80; Loss: 0.5057
Epoch 1965/10000; Iter 51/80; Loss: 0.4999
Epoch 1965/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.057
Epoch 1966/10000; Iter 1/80; Loss: 0.4566
Epoch 1966/10000; Iter 51/80; Loss: 0.4276
Epoch 1966/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.053
Epoch 1967/10000; Iter 1/80; Loss: 0.5225
Epoch 1967/10000; Iter 51/80; Loss: 0.5359
Epoch 1967/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.057
Epoch 1968/10000; Iter 1/80; Loss: 0.4962
Epoch 1968/10000; Iter 51/80; Loss: 0.4910
Epoch 1968/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.052
Epoch 1969/10000; Iter 1/80; Loss: 0.4545
Epoch 1969/10000; Iter 51/80; Loss: 0.5113
Epoch 1969/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.055
Epoch 1970/10000; Iter 1/80; Loss: 0.5232
Epoch 1970/10000; Iter 51/80; Loss: 0.5144
Epoch 1970/10000; Iter 80/80; Training Loss: 0.4870, Test Loss: 0.048
Epoch 1971/10000; Iter 1/80; Loss: 0.4786
Epoch 1971/10000; Iter 51/80; Loss: 0.5374
Epoch 1971/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.054
Epoch 1972/10000; Iter 1/80; Loss: 0.4600
Epoch 1972/10000; Iter 51/80; Loss: 0.4452
Epoch 1972/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.052
Epoch 1973/10000; Iter 1/80; Loss: 0.4698
Epoch 1973/10000; Iter 51/80; Loss: 0.4564
Epoch 1973/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.055
Epoch 1974/10000; Iter 1/80; Loss: 0.4180
Epoch 1974/10000; Iter 51/80; Loss: 0.4818
Epoch 1974/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.066
Epoch 1975/10000; Iter 1/80; Loss: 0.4837
Epoch 1975/10000; Iter 51/80; Loss: 0.4996
Epoch 1975/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.065
Epoch 1976/10000; Iter 1/80; Loss: 0.4563
Epoch 1976/10000; Iter 51/80; Loss: 0.4335
Epoch 1976/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.057
Epoch 1977/10000; Iter 1/80; Loss: 0.4817
Epoch 1977/10000; Iter 51/80; Loss: 0.4920
Epoch 1977/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.057
Epoch 1978/10000; Iter 1/80; Loss: 0.4756
Epoch 1978/10000; Iter 51/80; Loss: 0.4510
Epoch 1978/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.052
Epoch 1979/10000; Iter 1/80; Loss: 0.4911
Epoch 1979/10000; Iter 51/80; Loss: 0.5089
Epoch 1979/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.065
Epoch 1980/10000; Iter 1/80; Loss: 0.4397
Epoch 1980/10000; Iter 51/80; Loss: 0.4929
Epoch 1980/10000; Iter 80/80; Training Loss: 0.4890, Test Loss: 0.06
Epoch 1981/10000; Iter 1/80; Loss: 0.5302
Epoch 1981/10000; Iter 51/80; Loss: 0.4703
Epoch 1981/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.054
Epoch 1982/10000; Iter 1/80; Loss: 0.4529
Epoch 1982/10000; Iter 51/80; Loss: 0.5110
Epoch 1982/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.055
Epoch 1983/10000; Iter 1/80; Loss: 0.4781
Epoch 1983/10000; Iter 51/80; Loss: 0.4241
Epoch 1983/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.049
Epoch 1984/10000; Iter 1/80; Loss: 0.5167
Epoch 1984/10000; Iter 51/80; Loss: 0.4805
Epoch 1984/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.051
Epoch 1985/10000; Iter 1/80; Loss: 0.4708
Epoch 1985/10000; Iter 51/80; Loss: 0.4918
Epoch 1985/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.062
Epoch 1986/10000; Iter 1/80; Loss: 0.4249
Epoch 1986/10000; Iter 51/80; Loss: 0.4789
Epoch 1986/10000; Iter 80/80; Training Loss: 0.4910, Test Loss: 0.049
Epoch 1987/10000; Iter 1/80; Loss: 0.5331
Epoch 1987/10000; Iter 51/80; Loss: 0.4679
Epoch 1987/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.051
Epoch 1988/10000; Iter 1/80; Loss: 0.5035
Epoch 1988/10000; Iter 51/80; Loss: 0.4861
Epoch 1988/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.064
Epoch 1989/10000; Iter 1/80; Loss: 0.4284
Epoch 1989/10000; Iter 51/80; Loss: 0.4304
Epoch 1989/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.062
Epoch 1990/10000; Iter 1/80; Loss: 0.4186
Epoch 1990/10000; Iter 51/80; Loss: 0.4701
Epoch 1990/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.061
Epoch 1991/10000; Iter 1/80; Loss: 0.4799
Epoch 1991/10000; Iter 51/80; Loss: 0.4395
Epoch 1991/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.051
Epoch 1992/10000; Iter 1/80; Loss: 0.5016
Epoch 1992/10000; Iter 51/80; Loss: 0.4879
Epoch 1992/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.049
Epoch 1993/10000; Iter 1/80; Loss: 0.4581
Epoch 1993/10000; Iter 51/80; Loss: 0.5640
Epoch 1993/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.057
Epoch 1994/10000; Iter 1/80; Loss: 0.4316
Epoch 1994/10000; Iter 51/80; Loss: 0.4433
Epoch 1994/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.065
Epoch 1995/10000; Iter 1/80; Loss: 0.5802
Epoch 1995/10000; Iter 51/80; Loss: 0.5112
Epoch 1995/10000; Iter 80/80; Training Loss: 0.4890, Test Loss: 0.054
Epoch 1996/10000; Iter 1/80; Loss: 0.4735
Epoch 1996/10000; Iter 51/80; Loss: 0.5917
Epoch 1996/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.057
Epoch 1997/10000; Iter 1/80; Loss: 0.5471
Epoch 1997/10000; Iter 51/80; Loss: 0.5330
Epoch 1997/10000; Iter 80/80; Training Loss: 0.4860, Test Loss: 0.056
Epoch 1998/10000; Iter 1/80; Loss: 0.4131
Epoch 1998/10000; Iter 51/80; Loss: 0.4835
Epoch 1998/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.06
Epoch 1999/10000; Iter 1/80; Loss: 0.5257
Epoch 1999/10000; Iter 51/80; Loss: 0.4660
Epoch 1999/10000; Iter 80/80; Training Loss: 0.4950, Test Loss: 0.061
Epoch 2000/10000; Iter 1/80; Loss: 0.5144
Epoch 2000/10000; Iter 51/80; Loss: 0.4443
Epoch 2000/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.06
Epoch 2001/10000; Iter 1/80; Loss: 0.4965
Epoch 2001/10000; Iter 51/80; Loss: 0.5214
Epoch 2001/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.054
Model saved
Epoch 2002/10000; Iter 1/80; Loss: 0.5314
Epoch 2002/10000; Iter 51/80; Loss: 0.4068
Epoch 2002/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.058
Epoch 2003/10000; Iter 1/80; Loss: 0.4381
Epoch 2003/10000; Iter 51/80; Loss: 0.5104
Epoch 2003/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.054
Epoch 2004/10000; Iter 1/80; Loss: 0.5177
Epoch 2004/10000; Iter 51/80; Loss: 0.4829
Epoch 2004/10000; Iter 80/80; Training Loss: 0.4840, Test Loss: 0.056
Epoch 2005/10000; Iter 1/80; Loss: 0.4723
Epoch 2005/10000; Iter 51/80; Loss: 0.4856
Epoch 2005/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.049
Epoch 2006/10000; Iter 1/80; Loss: 0.4696
Epoch 2006/10000; Iter 51/80; Loss: 0.4102
Epoch 2006/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.047
Epoch 2007/10000; Iter 1/80; Loss: 0.5419
Epoch 2007/10000; Iter 51/80; Loss: 0.4489
Epoch 2007/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.046
Epoch 2008/10000; Iter 1/80; Loss: 0.5145
Epoch 2008/10000; Iter 51/80; Loss: 0.4393
Epoch 2008/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.048
Epoch 2009/10000; Iter 1/80; Loss: 0.4920
Epoch 2009/10000; Iter 51/80; Loss: 0.5433
Epoch 2009/10000; Iter 80/80; Training Loss: 0.4890, Test Loss: 0.053
Epoch 2010/10000; Iter 1/80; Loss: 0.4905
Epoch 2010/10000; Iter 51/80; Loss: 0.4980
Epoch 2010/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.057
Epoch 2011/10000; Iter 1/80; Loss: 0.4615
Epoch 2011/10000; Iter 51/80; Loss: 0.4797
Epoch 2011/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.066
Epoch 2012/10000; Iter 1/80; Loss: 0.4510
Epoch 2012/10000; Iter 51/80; Loss: 0.5088
Epoch 2012/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.051
Epoch 2013/10000; Iter 1/80; Loss: 0.5103
Epoch 2013/10000; Iter 51/80; Loss: 0.4949
Epoch 2013/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.047
Epoch 2014/10000; Iter 1/80; Loss: 0.4390
Epoch 2014/10000; Iter 51/80; Loss: 0.4321
Epoch 2014/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.05
Epoch 2015/10000; Iter 1/80; Loss: 0.4513
Epoch 2015/10000; Iter 51/80; Loss: 0.3967
Epoch 2015/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.047
Epoch 2016/10000; Iter 1/80; Loss: 0.4486
Epoch 2016/10000; Iter 51/80; Loss: 0.4822
Epoch 2016/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.048
Epoch 2017/10000; Iter 1/80; Loss: 0.4789
Epoch 2017/10000; Iter 51/80; Loss: 0.4374
Epoch 2017/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.059
Epoch 2018/10000; Iter 1/80; Loss: 0.4521
Epoch 2018/10000; Iter 51/80; Loss: 0.5626
Epoch 2018/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.052
Epoch 2019/10000; Iter 1/80; Loss: 0.5459
Epoch 2019/10000; Iter 51/80; Loss: 0.5291
Epoch 2019/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.052
Epoch 2020/10000; Iter 1/80; Loss: 0.4584
Epoch 2020/10000; Iter 51/80; Loss: 0.4422
Epoch 2020/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.054
Epoch 2021/10000; Iter 1/80; Loss: 0.5353
Epoch 2021/10000; Iter 51/80; Loss: 0.6021
Epoch 2021/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.048
Epoch 2022/10000; Iter 1/80; Loss: 0.4695
Epoch 2022/10000; Iter 51/80; Loss: 0.5140
Epoch 2022/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.05
Epoch 2023/10000; Iter 1/80; Loss: 0.4841
Epoch 2023/10000; Iter 51/80; Loss: 0.5335
Epoch 2023/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.06
Epoch 2024/10000; Iter 1/80; Loss: 0.5425
Epoch 2024/10000; Iter 51/80; Loss: 0.4913
Epoch 2024/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.051
Epoch 2025/10000; Iter 1/80; Loss: 0.4855
Epoch 2025/10000; Iter 51/80; Loss: 0.4594
Epoch 2025/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.05
Epoch 2026/10000; Iter 1/80; Loss: 0.5129
Epoch 2026/10000; Iter 51/80; Loss: 0.4653
Epoch 2026/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.041
Epoch 2027/10000; Iter 1/80; Loss: 0.5043
Epoch 2027/10000; Iter 51/80; Loss: 0.4772
Epoch 2027/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.053
Epoch 2028/10000; Iter 1/80; Loss: 0.4817
Epoch 2028/10000; Iter 51/80; Loss: 0.5065
Epoch 2028/10000; Iter 80/80; Training Loss: 0.4830, Test Loss: 0.053
Epoch 2029/10000; Iter 1/80; Loss: 0.4632
Epoch 2029/10000; Iter 51/80; Loss: 0.4578
Epoch 2029/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.045
Epoch 2030/10000; Iter 1/80; Loss: 0.4653
Epoch 2030/10000; Iter 51/80; Loss: 0.4593
Epoch 2030/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.051
Epoch 2031/10000; Iter 1/80; Loss: 0.4085
Epoch 2031/10000; Iter 51/80; Loss: 0.5348
Epoch 2031/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.045
Epoch 2032/10000; Iter 1/80; Loss: 0.4191
Epoch 2032/10000; Iter 51/80; Loss: 0.4534
Epoch 2032/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.053
Epoch 2033/10000; Iter 1/80; Loss: 0.4585
Epoch 2033/10000; Iter 51/80; Loss: 0.5638
Epoch 2033/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.046
Epoch 2034/10000; Iter 1/80; Loss: 0.4103
Epoch 2034/10000; Iter 51/80; Loss: 0.4866
Epoch 2034/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.05
Epoch 2035/10000; Iter 1/80; Loss: 0.5062
Epoch 2035/10000; Iter 51/80; Loss: 0.4777
Epoch 2035/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.057
Epoch 2036/10000; Iter 1/80; Loss: 0.4807
Epoch 2036/10000; Iter 51/80; Loss: 0.4231
Epoch 2036/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.046
Epoch 2037/10000; Iter 1/80; Loss: 0.4923
Epoch 2037/10000; Iter 51/80; Loss: 0.4533
Epoch 2037/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.049
Epoch 2038/10000; Iter 1/80; Loss: 0.4203
Epoch 2038/10000; Iter 51/80; Loss: 0.4337
Epoch 2038/10000; Iter 80/80; Training Loss: 0.4790, Test Loss: 0.051
Epoch 2039/10000; Iter 1/80; Loss: 0.4692
Epoch 2039/10000; Iter 51/80; Loss: 0.4356
Epoch 2039/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.056
Epoch 2040/10000; Iter 1/80; Loss: 0.4672
Epoch 2040/10000; Iter 51/80; Loss: 0.4860
Epoch 2040/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.057
Epoch 2041/10000; Iter 1/80; Loss: 0.4590
Epoch 2041/10000; Iter 51/80; Loss: 0.4489
Epoch 2041/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.058
Epoch 2042/10000; Iter 1/80; Loss: 0.4971
Epoch 2042/10000; Iter 51/80; Loss: 0.4319
Epoch 2042/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.059
Epoch 2043/10000; Iter 1/80; Loss: 0.4949
Epoch 2043/10000; Iter 51/80; Loss: 0.4278
Epoch 2043/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.052
Epoch 2044/10000; Iter 1/80; Loss: 0.5220
Epoch 2044/10000; Iter 51/80; Loss: 0.5298
Epoch 2044/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.048
Epoch 2045/10000; Iter 1/80; Loss: 0.4589
Epoch 2045/10000; Iter 51/80; Loss: 0.4259
Epoch 2045/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.047
Epoch 2046/10000; Iter 1/80; Loss: 0.4413
Epoch 2046/10000; Iter 51/80; Loss: 0.4607
Epoch 2046/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.054
Epoch 2047/10000; Iter 1/80; Loss: 0.4510
Epoch 2047/10000; Iter 51/80; Loss: 0.4446
Epoch 2047/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.053
Epoch 2048/10000; Iter 1/80; Loss: 0.4197
Epoch 2048/10000; Iter 51/80; Loss: 0.4463
Epoch 2048/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.05
Epoch 2049/10000; Iter 1/80; Loss: 0.4184
Epoch 2049/10000; Iter 51/80; Loss: 0.4840
Epoch 2049/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.054
Epoch 2050/10000; Iter 1/80; Loss: 0.4744
Epoch 2050/10000; Iter 51/80; Loss: 0.5144
Epoch 2050/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.053
Epoch 2051/10000; Iter 1/80; Loss: 0.4520
Epoch 2051/10000; Iter 51/80; Loss: 0.5122
Epoch 2051/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.056
Epoch 2052/10000; Iter 1/80; Loss: 0.5077
Epoch 2052/10000; Iter 51/80; Loss: 0.4880
Epoch 2052/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.051
Epoch 2053/10000; Iter 1/80; Loss: 0.5328
Epoch 2053/10000; Iter 51/80; Loss: 0.5221
Epoch 2053/10000; Iter 80/80; Training Loss: 0.4850, Test Loss: 0.058
Epoch 2054/10000; Iter 1/80; Loss: 0.5045
Epoch 2054/10000; Iter 51/80; Loss: 0.4728
Epoch 2054/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.055
Epoch 2055/10000; Iter 1/80; Loss: 0.5414
Epoch 2055/10000; Iter 51/80; Loss: 0.4263
Epoch 2055/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.05
Epoch 2056/10000; Iter 1/80; Loss: 0.4864
Epoch 2056/10000; Iter 51/80; Loss: 0.4163
Epoch 2056/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.053
Epoch 2057/10000; Iter 1/80; Loss: 0.4982
Epoch 2057/10000; Iter 51/80; Loss: 0.4314
Epoch 2057/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.053
Epoch 2058/10000; Iter 1/80; Loss: 0.4489
Epoch 2058/10000; Iter 51/80; Loss: 0.4227
Epoch 2058/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.056
Epoch 2059/10000; Iter 1/80; Loss: 0.5263
Epoch 2059/10000; Iter 51/80; Loss: 0.4447
Epoch 2059/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.047
Epoch 2060/10000; Iter 1/80; Loss: 0.5015
Epoch 2060/10000; Iter 51/80; Loss: 0.5012
Epoch 2060/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.056
Epoch 2061/10000; Iter 1/80; Loss: 0.5110
Epoch 2061/10000; Iter 51/80; Loss: 0.4298
Epoch 2061/10000; Iter 80/80; Training Loss: 0.4780, Test Loss: 0.063
Epoch 2062/10000; Iter 1/80; Loss: 0.4689
Epoch 2062/10000; Iter 51/80; Loss: 0.5087
Epoch 2062/10000; Iter 80/80; Training Loss: 0.4800, Test Loss: 0.053
Epoch 2063/10000; Iter 1/80; Loss: 0.4732
Epoch 2063/10000; Iter 51/80; Loss: 0.4501
Epoch 2063/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.059
Epoch 2064/10000; Iter 1/80; Loss: 0.4834
Epoch 2064/10000; Iter 51/80; Loss: 0.4713
Epoch 2064/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.061
Epoch 2065/10000; Iter 1/80; Loss: 0.4248
Epoch 2065/10000; Iter 51/80; Loss: 0.4417
Epoch 2065/10000; Iter 80/80; Training Loss: 0.4820, Test Loss: 0.046
Epoch 2066/10000; Iter 1/80; Loss: 0.4897
Epoch 2066/10000; Iter 51/80; Loss: 0.5092
Epoch 2066/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.057
Epoch 2067/10000; Iter 1/80; Loss: 0.4512
Epoch 2067/10000; Iter 51/80; Loss: 0.5142
Epoch 2067/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.059
Epoch 2068/10000; Iter 1/80; Loss: 0.4631
Epoch 2068/10000; Iter 51/80; Loss: 0.4965
Epoch 2068/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.048
Epoch 2069/10000; Iter 1/80; Loss: 0.5321
Epoch 2069/10000; Iter 51/80; Loss: 0.4174
Epoch 2069/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.055
Epoch 2070/10000; Iter 1/80; Loss: 0.4481
Epoch 2070/10000; Iter 51/80; Loss: 0.4787
Epoch 2070/10000; Iter 80/80; Training Loss: 0.4810, Test Loss: 0.058
Epoch 2071/10000; Iter 1/80; Loss: 0.4573
Epoch 2071/10000; Iter 51/80; Loss: 0.4285
Epoch 2071/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.048
Epoch 2072/10000; Iter 1/80; Loss: 0.4768
Epoch 2072/10000; Iter 51/80; Loss: 0.3999
Epoch 2072/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.048
Epoch 2073/10000; Iter 1/80; Loss: 0.4107
Epoch 2073/10000; Iter 51/80; Loss: 0.4564
Epoch 2073/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.053
Epoch 2074/10000; Iter 1/80; Loss: 0.4672
Epoch 2074/10000; Iter 51/80; Loss: 0.4984
Epoch 2074/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.049
Epoch 2075/10000; Iter 1/80; Loss: 0.4440
Epoch 2075/10000; Iter 51/80; Loss: 0.5200
Epoch 2075/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.049
Epoch 2076/10000; Iter 1/80; Loss: 0.4617
Epoch 2076/10000; Iter 51/80; Loss: 0.4774
Epoch 2076/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.055
Epoch 2077/10000; Iter 1/80; Loss: 0.5130
Epoch 2077/10000; Iter 51/80; Loss: 0.4805
Epoch 2077/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.052
Epoch 2078/10000; Iter 1/80; Loss: 0.4950
Epoch 2078/10000; Iter 51/80; Loss: 0.4463
Epoch 2078/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.051
Epoch 2079/10000; Iter 1/80; Loss: 0.4870
Epoch 2079/10000; Iter 51/80; Loss: 0.4293
Epoch 2079/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.056
Epoch 2080/10000; Iter 1/80; Loss: 0.4609
Epoch 2080/10000; Iter 51/80; Loss: 0.4467
Epoch 2080/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.053
Epoch 2081/10000; Iter 1/80; Loss: 0.4699
Epoch 2081/10000; Iter 51/80; Loss: 0.5213
Epoch 2081/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.055
Epoch 2082/10000; Iter 1/80; Loss: 0.4819
Epoch 2082/10000; Iter 51/80; Loss: 0.4054
Epoch 2082/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.056
Epoch 2083/10000; Iter 1/80; Loss: 0.4277
Epoch 2083/10000; Iter 51/80; Loss: 0.5100
Epoch 2083/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.063
Epoch 2084/10000; Iter 1/80; Loss: 0.5069
Epoch 2084/10000; Iter 51/80; Loss: 0.5155
Epoch 2084/10000; Iter 80/80; Training Loss: 0.4760, Test Loss: 0.055
Epoch 2085/10000; Iter 1/80; Loss: 0.5165
Epoch 2085/10000; Iter 51/80; Loss: 0.4604
Epoch 2085/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.052
Epoch 2086/10000; Iter 1/80; Loss: 0.4747
Epoch 2086/10000; Iter 51/80; Loss: 0.4494
Epoch 2086/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.049
Epoch 2087/10000; Iter 1/80; Loss: 0.4191
Epoch 2087/10000; Iter 51/80; Loss: 0.5150
Epoch 2087/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.054
Epoch 2088/10000; Iter 1/80; Loss: 0.4711
Epoch 2088/10000; Iter 51/80; Loss: 0.4257
Epoch 2088/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.049
Epoch 2089/10000; Iter 1/80; Loss: 0.4454
Epoch 2089/10000; Iter 51/80; Loss: 0.4568
Epoch 2089/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.047
Epoch 2090/10000; Iter 1/80; Loss: 0.5391
Epoch 2090/10000; Iter 51/80; Loss: 0.4555
Epoch 2090/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.053
Epoch 2091/10000; Iter 1/80; Loss: 0.4431
Epoch 2091/10000; Iter 51/80; Loss: 0.3863
Epoch 2091/10000; Iter 80/80; Training Loss: 0.4750, Test Loss: 0.052
Epoch 2092/10000; Iter 1/80; Loss: 0.4885
Epoch 2092/10000; Iter 51/80; Loss: 0.4506
Epoch 2092/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.054
Epoch 2093/10000; Iter 1/80; Loss: 0.4474
Epoch 2093/10000; Iter 51/80; Loss: 0.4251
Epoch 2093/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.048
Epoch 2094/10000; Iter 1/80; Loss: 0.4516
Epoch 2094/10000; Iter 51/80; Loss: 0.5044
Epoch 2094/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.054
Epoch 2095/10000; Iter 1/80; Loss: 0.5366
Epoch 2095/10000; Iter 51/80; Loss: 0.4757
Epoch 2095/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.049
Epoch 2096/10000; Iter 1/80; Loss: 0.4655
Epoch 2096/10000; Iter 51/80; Loss: 0.4995
Epoch 2096/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.053
Epoch 2097/10000; Iter 1/80; Loss: 0.4679
Epoch 2097/10000; Iter 51/80; Loss: 0.4351
Epoch 2097/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.061
Epoch 2098/10000; Iter 1/80; Loss: 0.4639
Epoch 2098/10000; Iter 51/80; Loss: 0.4430
Epoch 2098/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.048
Epoch 2099/10000; Iter 1/80; Loss: 0.4912
Epoch 2099/10000; Iter 51/80; Loss: 0.4652
Epoch 2099/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.057
Epoch 2100/10000; Iter 1/80; Loss: 0.4494
Epoch 2100/10000; Iter 51/80; Loss: 0.4951
Epoch 2100/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.061
Epoch 2101/10000; Iter 1/80; Loss: 0.5082
Epoch 2101/10000; Iter 51/80; Loss: 0.5140
Epoch 2101/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.055
Model saved
Epoch 2102/10000; Iter 1/80; Loss: 0.4768
Epoch 2102/10000; Iter 51/80; Loss: 0.4493
Epoch 2102/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.055
Epoch 2103/10000; Iter 1/80; Loss: 0.4724
Epoch 2103/10000; Iter 51/80; Loss: 0.4830
Epoch 2103/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.057
Epoch 2104/10000; Iter 1/80; Loss: 0.4587
Epoch 2104/10000; Iter 51/80; Loss: 0.4721
Epoch 2104/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.055
Epoch 2105/10000; Iter 1/80; Loss: 0.4557
Epoch 2105/10000; Iter 51/80; Loss: 0.4730
Epoch 2105/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.051
Epoch 2106/10000; Iter 1/80; Loss: 0.5031
Epoch 2106/10000; Iter 51/80; Loss: 0.4450
Epoch 2106/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.064
Epoch 2107/10000; Iter 1/80; Loss: 0.4881
Epoch 2107/10000; Iter 51/80; Loss: 0.3894
Epoch 2107/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.057
Epoch 2108/10000; Iter 1/80; Loss: 0.3954
Epoch 2108/10000; Iter 51/80; Loss: 0.4971
Epoch 2108/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.048
Epoch 2109/10000; Iter 1/80; Loss: 0.4488
Epoch 2109/10000; Iter 51/80; Loss: 0.5076
Epoch 2109/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.048
Epoch 2110/10000; Iter 1/80; Loss: 0.4857
Epoch 2110/10000; Iter 51/80; Loss: 0.4562
Epoch 2110/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.049
Epoch 2111/10000; Iter 1/80; Loss: 0.4855
Epoch 2111/10000; Iter 51/80; Loss: 0.5488
Epoch 2111/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.046
Epoch 2112/10000; Iter 1/80; Loss: 0.5256
Epoch 2112/10000; Iter 51/80; Loss: 0.4706
Epoch 2112/10000; Iter 80/80; Training Loss: 0.4730, Test Loss: 0.048
Epoch 2113/10000; Iter 1/80; Loss: 0.4331
Epoch 2113/10000; Iter 51/80; Loss: 0.5382
Epoch 2113/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.055
Epoch 2114/10000; Iter 1/80; Loss: 0.4877
Epoch 2114/10000; Iter 51/80; Loss: 0.4861
Epoch 2114/10000; Iter 80/80; Training Loss: 0.4770, Test Loss: 0.048
Epoch 2115/10000; Iter 1/80; Loss: 0.5502
Epoch 2115/10000; Iter 51/80; Loss: 0.4476
Epoch 2115/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.055
Epoch 2116/10000; Iter 1/80; Loss: 0.5006
Epoch 2116/10000; Iter 51/80; Loss: 0.4928
Epoch 2116/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.057
Epoch 2117/10000; Iter 1/80; Loss: 0.4609
Epoch 2117/10000; Iter 51/80; Loss: 0.3878
Epoch 2117/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.055
Epoch 2118/10000; Iter 1/80; Loss: 0.4216
Epoch 2118/10000; Iter 51/80; Loss: 0.5030
Epoch 2118/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.056
Epoch 2119/10000; Iter 1/80; Loss: 0.4458
Epoch 2119/10000; Iter 51/80; Loss: 0.4743
Epoch 2119/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.056
Epoch 2120/10000; Iter 1/80; Loss: 0.4826
Epoch 2120/10000; Iter 51/80; Loss: 0.5081
Epoch 2120/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.049
Epoch 2121/10000; Iter 1/80; Loss: 0.4759
Epoch 2121/10000; Iter 51/80; Loss: 0.4705
Epoch 2121/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.053
Epoch 2122/10000; Iter 1/80; Loss: 0.4961
Epoch 2122/10000; Iter 51/80; Loss: 0.4418
Epoch 2122/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.051
Epoch 2123/10000; Iter 1/80; Loss: 0.4376
Epoch 2123/10000; Iter 51/80; Loss: 0.4616
Epoch 2123/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.054
Epoch 2124/10000; Iter 1/80; Loss: 0.4943
Epoch 2124/10000; Iter 51/80; Loss: 0.4360
Epoch 2124/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.056
Epoch 2125/10000; Iter 1/80; Loss: 0.4291
Epoch 2125/10000; Iter 51/80; Loss: 0.4192
Epoch 2125/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.054
Epoch 2126/10000; Iter 1/80; Loss: 0.4014
Epoch 2126/10000; Iter 51/80; Loss: 0.4749
Epoch 2126/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.056
Epoch 2127/10000; Iter 1/80; Loss: 0.5338
Epoch 2127/10000; Iter 51/80; Loss: 0.4169
Epoch 2127/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.062
Epoch 2128/10000; Iter 1/80; Loss: 0.4621
Epoch 2128/10000; Iter 51/80; Loss: 0.4945
Epoch 2128/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.05
Epoch 2129/10000; Iter 1/80; Loss: 0.4269
Epoch 2129/10000; Iter 51/80; Loss: 0.4685
Epoch 2129/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.055
Epoch 2130/10000; Iter 1/80; Loss: 0.5136
Epoch 2130/10000; Iter 51/80; Loss: 0.4383
Epoch 2130/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.052
Epoch 2131/10000; Iter 1/80; Loss: 0.4269
Epoch 2131/10000; Iter 51/80; Loss: 0.3978
Epoch 2131/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.055
Epoch 2132/10000; Iter 1/80; Loss: 0.4240
Epoch 2132/10000; Iter 51/80; Loss: 0.4848
Epoch 2132/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.062
Epoch 2133/10000; Iter 1/80; Loss: 0.4718
Epoch 2133/10000; Iter 51/80; Loss: 0.5456
Epoch 2133/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.056
Epoch 2134/10000; Iter 1/80; Loss: 0.5026
Epoch 2134/10000; Iter 51/80; Loss: 0.6029
Epoch 2134/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.049
Epoch 2135/10000; Iter 1/80; Loss: 0.5656
Epoch 2135/10000; Iter 51/80; Loss: 0.4755
Epoch 2135/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.054
Epoch 2136/10000; Iter 1/80; Loss: 0.5064
Epoch 2136/10000; Iter 51/80; Loss: 0.4780
Epoch 2136/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.051
Epoch 2137/10000; Iter 1/80; Loss: 0.4621
Epoch 2137/10000; Iter 51/80; Loss: 0.4880
Epoch 2137/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.048
Epoch 2138/10000; Iter 1/80; Loss: 0.4760
Epoch 2138/10000; Iter 51/80; Loss: 0.4523
Epoch 2138/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.055
Epoch 2139/10000; Iter 1/80; Loss: 0.4931
Epoch 2139/10000; Iter 51/80; Loss: 0.5306
Epoch 2139/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.057
Epoch 2140/10000; Iter 1/80; Loss: 0.3938
Epoch 2140/10000; Iter 51/80; Loss: 0.4558
Epoch 2140/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.053
Epoch 2141/10000; Iter 1/80; Loss: 0.4392
Epoch 2141/10000; Iter 51/80; Loss: 0.4687
Epoch 2141/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.055
Epoch 2142/10000; Iter 1/80; Loss: 0.5160
Epoch 2142/10000; Iter 51/80; Loss: 0.4663
Epoch 2142/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.056
Epoch 2143/10000; Iter 1/80; Loss: 0.5380
Epoch 2143/10000; Iter 51/80; Loss: 0.4538
Epoch 2143/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.052
Epoch 2144/10000; Iter 1/80; Loss: 0.4720
Epoch 2144/10000; Iter 51/80; Loss: 0.4711
Epoch 2144/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.056
Epoch 2145/10000; Iter 1/80; Loss: 0.4503
Epoch 2145/10000; Iter 51/80; Loss: 0.4662
Epoch 2145/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.049
Epoch 2146/10000; Iter 1/80; Loss: 0.4366
Epoch 2146/10000; Iter 51/80; Loss: 0.4709
Epoch 2146/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.055
Epoch 2147/10000; Iter 1/80; Loss: 0.4586
Epoch 2147/10000; Iter 51/80; Loss: 0.4969
Epoch 2147/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.059
Epoch 2148/10000; Iter 1/80; Loss: 0.4610
Epoch 2148/10000; Iter 51/80; Loss: 0.4506
Epoch 2148/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.054
Epoch 2149/10000; Iter 1/80; Loss: 0.4305
Epoch 2149/10000; Iter 51/80; Loss: 0.4757
Epoch 2149/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.052
Epoch 2150/10000; Iter 1/80; Loss: 0.4267
Epoch 2150/10000; Iter 51/80; Loss: 0.4698
Epoch 2150/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.056
Epoch 2151/10000; Iter 1/80; Loss: 0.4820
Epoch 2151/10000; Iter 51/80; Loss: 0.3629
Epoch 2151/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.058
Epoch 2152/10000; Iter 1/80; Loss: 0.4850
Epoch 2152/10000; Iter 51/80; Loss: 0.4654
Epoch 2152/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.056
Epoch 2153/10000; Iter 1/80; Loss: 0.4761
Epoch 2153/10000; Iter 51/80; Loss: 0.4587
Epoch 2153/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.048
Epoch 2154/10000; Iter 1/80; Loss: 0.4491
Epoch 2154/10000; Iter 51/80; Loss: 0.4989
Epoch 2154/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.058
Epoch 2155/10000; Iter 1/80; Loss: 0.5096
Epoch 2155/10000; Iter 51/80; Loss: 0.4413
Epoch 2155/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.046
Epoch 2156/10000; Iter 1/80; Loss: 0.4443
Epoch 2156/10000; Iter 51/80; Loss: 0.4666
Epoch 2156/10000; Iter 80/80; Training Loss: 0.4740, Test Loss: 0.054
Epoch 2157/10000; Iter 1/80; Loss: 0.4448
Epoch 2157/10000; Iter 51/80; Loss: 0.5344
Epoch 2157/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.048
Epoch 2158/10000; Iter 1/80; Loss: 0.4966
Epoch 2158/10000; Iter 51/80; Loss: 0.4786
Epoch 2158/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.045
Epoch 2159/10000; Iter 1/80; Loss: 0.4445
Epoch 2159/10000; Iter 51/80; Loss: 0.4336
Epoch 2159/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.045
Epoch 2160/10000; Iter 1/80; Loss: 0.5103
Epoch 2160/10000; Iter 51/80; Loss: 0.4363
Epoch 2160/10000; Iter 80/80; Training Loss: 0.4700, Test Loss: 0.052
Epoch 2161/10000; Iter 1/80; Loss: 0.4427
Epoch 2161/10000; Iter 51/80; Loss: 0.5088
Epoch 2161/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.054
Epoch 2162/10000; Iter 1/80; Loss: 0.3921
Epoch 2162/10000; Iter 51/80; Loss: 0.4011
Epoch 2162/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.049
Epoch 2163/10000; Iter 1/80; Loss: 0.4956
Epoch 2163/10000; Iter 51/80; Loss: 0.5204
Epoch 2163/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.054
Epoch 2164/10000; Iter 1/80; Loss: 0.3920
Epoch 2164/10000; Iter 51/80; Loss: 0.4379
Epoch 2164/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.047
Epoch 2165/10000; Iter 1/80; Loss: 0.4228
Epoch 2165/10000; Iter 51/80; Loss: 0.4546
Epoch 2165/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.042
Epoch 2166/10000; Iter 1/80; Loss: 0.4216
Epoch 2166/10000; Iter 51/80; Loss: 0.4843
Epoch 2166/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.05
Epoch 2167/10000; Iter 1/80; Loss: 0.4296
Epoch 2167/10000; Iter 51/80; Loss: 0.4416
Epoch 2167/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.042
Epoch 2168/10000; Iter 1/80; Loss: 0.4714
Epoch 2168/10000; Iter 51/80; Loss: 0.4819
Epoch 2168/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.051
Epoch 2169/10000; Iter 1/80; Loss: 0.4652
Epoch 2169/10000; Iter 51/80; Loss: 0.5236
Epoch 2169/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.062
Epoch 2170/10000; Iter 1/80; Loss: 0.4174
Epoch 2170/10000; Iter 51/80; Loss: 0.4977
Epoch 2170/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.054
Epoch 2171/10000; Iter 1/80; Loss: 0.4526
Epoch 2171/10000; Iter 51/80; Loss: 0.4609
Epoch 2171/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.052
Epoch 2172/10000; Iter 1/80; Loss: 0.4339
Epoch 2172/10000; Iter 51/80; Loss: 0.4723
Epoch 2172/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.046
Epoch 2173/10000; Iter 1/80; Loss: 0.4583
Epoch 2173/10000; Iter 51/80; Loss: 0.4644
Epoch 2173/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.047
Epoch 2174/10000; Iter 1/80; Loss: 0.4611
Epoch 2174/10000; Iter 51/80; Loss: 0.4945
Epoch 2174/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.058
Epoch 2175/10000; Iter 1/80; Loss: 0.4168
Epoch 2175/10000; Iter 51/80; Loss: 0.4980
Epoch 2175/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.063
Epoch 2176/10000; Iter 1/80; Loss: 0.4710
Epoch 2176/10000; Iter 51/80; Loss: 0.4325
Epoch 2176/10000; Iter 80/80; Training Loss: 0.4690, Test Loss: 0.048
Epoch 2177/10000; Iter 1/80; Loss: 0.3967
Epoch 2177/10000; Iter 51/80; Loss: 0.4607
Epoch 2177/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.046
Epoch 2178/10000; Iter 1/80; Loss: 0.4411
Epoch 2178/10000; Iter 51/80; Loss: 0.4373
Epoch 2178/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.055
Epoch 2179/10000; Iter 1/80; Loss: 0.4363
Epoch 2179/10000; Iter 51/80; Loss: 0.4418
Epoch 2179/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.056
Epoch 2180/10000; Iter 1/80; Loss: 0.4619
Epoch 2180/10000; Iter 51/80; Loss: 0.4347
Epoch 2180/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.052
Epoch 2181/10000; Iter 1/80; Loss: 0.4848
Epoch 2181/10000; Iter 51/80; Loss: 0.4506
Epoch 2181/10000; Iter 80/80; Training Loss: 0.4610, Test Loss: 0.049
Epoch 2182/10000; Iter 1/80; Loss: 0.4776
Epoch 2182/10000; Iter 51/80; Loss: 0.4599
Epoch 2182/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.053
Epoch 2183/10000; Iter 1/80; Loss: 0.4193
Epoch 2183/10000; Iter 51/80; Loss: 0.4798
Epoch 2183/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.057
Epoch 2184/10000; Iter 1/80; Loss: 0.4808
Epoch 2184/10000; Iter 51/80; Loss: 0.4820
Epoch 2184/10000; Iter 80/80; Training Loss: 0.4710, Test Loss: 0.049
Epoch 2185/10000; Iter 1/80; Loss: 0.4673
Epoch 2185/10000; Iter 51/80; Loss: 0.4195
Epoch 2185/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.058
Epoch 2186/10000; Iter 1/80; Loss: 0.4464
Epoch 2186/10000; Iter 51/80; Loss: 0.5050
Epoch 2186/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.043
Epoch 2187/10000; Iter 1/80; Loss: 0.4827
Epoch 2187/10000; Iter 51/80; Loss: 0.4798
Epoch 2187/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.059
Epoch 2188/10000; Iter 1/80; Loss: 0.4281
Epoch 2188/10000; Iter 51/80; Loss: 0.4122
Epoch 2188/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.046
Epoch 2189/10000; Iter 1/80; Loss: 0.4908
Epoch 2189/10000; Iter 51/80; Loss: 0.4942
Epoch 2189/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.051
Epoch 2190/10000; Iter 1/80; Loss: 0.4905
Epoch 2190/10000; Iter 51/80; Loss: 0.4092
Epoch 2190/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.047
Epoch 2191/10000; Iter 1/80; Loss: 0.4410
Epoch 2191/10000; Iter 51/80; Loss: 0.4618
Epoch 2191/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.053
Epoch 2192/10000; Iter 1/80; Loss: 0.4096
Epoch 2192/10000; Iter 51/80; Loss: 0.4600
Epoch 2192/10000; Iter 80/80; Training Loss: 0.4720, Test Loss: 0.048
Epoch 2193/10000; Iter 1/80; Loss: 0.4557
Epoch 2193/10000; Iter 51/80; Loss: 0.4560
Epoch 2193/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.05
Epoch 2194/10000; Iter 1/80; Loss: 0.4833
Epoch 2194/10000; Iter 51/80; Loss: 0.4353
Epoch 2194/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.055
Epoch 2195/10000; Iter 1/80; Loss: 0.3734
Epoch 2195/10000; Iter 51/80; Loss: 0.5431
Epoch 2195/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.047
Epoch 2196/10000; Iter 1/80; Loss: 0.4135
Epoch 2196/10000; Iter 51/80; Loss: 0.5144
Epoch 2196/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.055
Epoch 2197/10000; Iter 1/80; Loss: 0.4924
Epoch 2197/10000; Iter 51/80; Loss: 0.5095
Epoch 2197/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.051
Epoch 2198/10000; Iter 1/80; Loss: 0.5226
Epoch 2198/10000; Iter 51/80; Loss: 0.4193
Epoch 2198/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.044
Epoch 2199/10000; Iter 1/80; Loss: 0.4456
Epoch 2199/10000; Iter 51/80; Loss: 0.3742
Epoch 2199/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.059
Epoch 2200/10000; Iter 1/80; Loss: 0.4120
Epoch 2200/10000; Iter 51/80; Loss: 0.5606
Epoch 2200/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.055
Epoch 2201/10000; Iter 1/80; Loss: 0.4378
Epoch 2201/10000; Iter 51/80; Loss: 0.4309
Epoch 2201/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.051
Model saved
Epoch 2202/10000; Iter 1/80; Loss: 0.4605
Epoch 2202/10000; Iter 51/80; Loss: 0.4770
Epoch 2202/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.058
Epoch 2203/10000; Iter 1/80; Loss: 0.4702
Epoch 2203/10000; Iter 51/80; Loss: 0.4404
Epoch 2203/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.055
Epoch 2204/10000; Iter 1/80; Loss: 0.4636
Epoch 2204/10000; Iter 51/80; Loss: 0.4417
Epoch 2204/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.044
Epoch 2205/10000; Iter 1/80; Loss: 0.4480
Epoch 2205/10000; Iter 51/80; Loss: 0.4533
Epoch 2205/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.049
Epoch 2206/10000; Iter 1/80; Loss: 0.4466
Epoch 2206/10000; Iter 51/80; Loss: 0.4426
Epoch 2206/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.059
Epoch 2207/10000; Iter 1/80; Loss: 0.5036
Epoch 2207/10000; Iter 51/80; Loss: 0.4667
Epoch 2207/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.062
Epoch 2208/10000; Iter 1/80; Loss: 0.5498
Epoch 2208/10000; Iter 51/80; Loss: 0.5231
Epoch 2208/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.046
Epoch 2209/10000; Iter 1/80; Loss: 0.4497
Epoch 2209/10000; Iter 51/80; Loss: 0.4549
Epoch 2209/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.054
Epoch 2210/10000; Iter 1/80; Loss: 0.5103
Epoch 2210/10000; Iter 51/80; Loss: 0.4944
Epoch 2210/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.046
Epoch 2211/10000; Iter 1/80; Loss: 0.5074
Epoch 2211/10000; Iter 51/80; Loss: 0.4141
Epoch 2211/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.05
Epoch 2212/10000; Iter 1/80; Loss: 0.3999
Epoch 2212/10000; Iter 51/80; Loss: 0.5045
Epoch 2212/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.051
Epoch 2213/10000; Iter 1/80; Loss: 0.3934
Epoch 2213/10000; Iter 51/80; Loss: 0.4325
Epoch 2213/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.056
Epoch 2214/10000; Iter 1/80; Loss: 0.4453
Epoch 2214/10000; Iter 51/80; Loss: 0.4533
Epoch 2214/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.047
Epoch 2215/10000; Iter 1/80; Loss: 0.4710
Epoch 2215/10000; Iter 51/80; Loss: 0.5275
Epoch 2215/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.053
Epoch 2216/10000; Iter 1/80; Loss: 0.4014
Epoch 2216/10000; Iter 51/80; Loss: 0.4991
Epoch 2216/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.06
Epoch 2217/10000; Iter 1/80; Loss: 0.4557
Epoch 2217/10000; Iter 51/80; Loss: 0.5064
Epoch 2217/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.046
Epoch 2218/10000; Iter 1/80; Loss: 0.5453
Epoch 2218/10000; Iter 51/80; Loss: 0.4571
Epoch 2218/10000; Iter 80/80; Training Loss: 0.4670, Test Loss: 0.047
Epoch 2219/10000; Iter 1/80; Loss: 0.4119
Epoch 2219/10000; Iter 51/80; Loss: 0.4848
Epoch 2219/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.061
Epoch 2220/10000; Iter 1/80; Loss: 0.4547
Epoch 2220/10000; Iter 51/80; Loss: 0.4375
Epoch 2220/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.056
Epoch 2221/10000; Iter 1/80; Loss: 0.4589
Epoch 2221/10000; Iter 51/80; Loss: 0.4457
Epoch 2221/10000; Iter 80/80; Training Loss: 0.4680, Test Loss: 0.051
Epoch 2222/10000; Iter 1/80; Loss: 0.4498
Epoch 2222/10000; Iter 51/80; Loss: 0.4575
Epoch 2222/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.053
Epoch 2223/10000; Iter 1/80; Loss: 0.4274
Epoch 2223/10000; Iter 51/80; Loss: 0.4338
Epoch 2223/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.055
Epoch 2224/10000; Iter 1/80; Loss: 0.4638
Epoch 2224/10000; Iter 51/80; Loss: 0.4624
Epoch 2224/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.052
Epoch 2225/10000; Iter 1/80; Loss: 0.4356
Epoch 2225/10000; Iter 51/80; Loss: 0.4517
Epoch 2225/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.051
Epoch 2226/10000; Iter 1/80; Loss: 0.4777
Epoch 2226/10000; Iter 51/80; Loss: 0.4866
Epoch 2226/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.048
Epoch 2227/10000; Iter 1/80; Loss: 0.5067
Epoch 2227/10000; Iter 51/80; Loss: 0.4354
Epoch 2227/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.05
Epoch 2228/10000; Iter 1/80; Loss: 0.4647
Epoch 2228/10000; Iter 51/80; Loss: 0.5252
Epoch 2228/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.058
Epoch 2229/10000; Iter 1/80; Loss: 0.4816
Epoch 2229/10000; Iter 51/80; Loss: 0.4702
Epoch 2229/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.053
Epoch 2230/10000; Iter 1/80; Loss: 0.3575
Epoch 2230/10000; Iter 51/80; Loss: 0.4395
Epoch 2230/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.049
Epoch 2231/10000; Iter 1/80; Loss: 0.4821
Epoch 2231/10000; Iter 51/80; Loss: 0.4644
Epoch 2231/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.053
Epoch 2232/10000; Iter 1/80; Loss: 0.4948
Epoch 2232/10000; Iter 51/80; Loss: 0.4204
Epoch 2232/10000; Iter 80/80; Training Loss: 0.4610, Test Loss: 0.048
Epoch 2233/10000; Iter 1/80; Loss: 0.4830
Epoch 2233/10000; Iter 51/80; Loss: 0.5198
Epoch 2233/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.056
Epoch 2234/10000; Iter 1/80; Loss: 0.4311
Epoch 2234/10000; Iter 51/80; Loss: 0.4859
Epoch 2234/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.047
Epoch 2235/10000; Iter 1/80; Loss: 0.4629
Epoch 2235/10000; Iter 51/80; Loss: 0.4196
Epoch 2235/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.057
Epoch 2236/10000; Iter 1/80; Loss: 0.4069
Epoch 2236/10000; Iter 51/80; Loss: 0.4431
Epoch 2236/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.05
Epoch 2237/10000; Iter 1/80; Loss: 0.4218
Epoch 2237/10000; Iter 51/80; Loss: 0.4268
Epoch 2237/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.048
Epoch 2238/10000; Iter 1/80; Loss: 0.4106
Epoch 2238/10000; Iter 51/80; Loss: 0.5005
Epoch 2238/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.052
Epoch 2239/10000; Iter 1/80; Loss: 0.4194
Epoch 2239/10000; Iter 51/80; Loss: 0.4049
Epoch 2239/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.05
Epoch 2240/10000; Iter 1/80; Loss: 0.4429
Epoch 2240/10000; Iter 51/80; Loss: 0.5061
Epoch 2240/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.052
Epoch 2241/10000; Iter 1/80; Loss: 0.4262
Epoch 2241/10000; Iter 51/80; Loss: 0.4754
Epoch 2241/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.053
Epoch 2242/10000; Iter 1/80; Loss: 0.4848
Epoch 2242/10000; Iter 51/80; Loss: 0.4626
Epoch 2242/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.058
Epoch 2243/10000; Iter 1/80; Loss: 0.4626
Epoch 2243/10000; Iter 51/80; Loss: 0.5174
Epoch 2243/10000; Iter 80/80; Training Loss: 0.4610, Test Loss: 0.05
Epoch 2244/10000; Iter 1/80; Loss: 0.4558
Epoch 2244/10000; Iter 51/80; Loss: 0.4498
Epoch 2244/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.051
Epoch 2245/10000; Iter 1/80; Loss: 0.4701
Epoch 2245/10000; Iter 51/80; Loss: 0.4549
Epoch 2245/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.045
Epoch 2246/10000; Iter 1/80; Loss: 0.4577
Epoch 2246/10000; Iter 51/80; Loss: 0.4397
Epoch 2246/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.05
Epoch 2247/10000; Iter 1/80; Loss: 0.4372
Epoch 2247/10000; Iter 51/80; Loss: 0.4572
Epoch 2247/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.056
Epoch 2248/10000; Iter 1/80; Loss: 0.4224
Epoch 2248/10000; Iter 51/80; Loss: 0.4578
Epoch 2248/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.051
Epoch 2249/10000; Iter 1/80; Loss: 0.4511
Epoch 2249/10000; Iter 51/80; Loss: 0.4970
Epoch 2249/10000; Iter 80/80; Training Loss: 0.4610, Test Loss: 0.057
Epoch 2250/10000; Iter 1/80; Loss: 0.4441
Epoch 2250/10000; Iter 51/80; Loss: 0.3935
Epoch 2250/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.05
Epoch 2251/10000; Iter 1/80; Loss: 0.4824
Epoch 2251/10000; Iter 51/80; Loss: 0.4200
Epoch 2251/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.049
Epoch 2252/10000; Iter 1/80; Loss: 0.4738
Epoch 2252/10000; Iter 51/80; Loss: 0.4036
Epoch 2252/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.057
Epoch 2253/10000; Iter 1/80; Loss: 0.4443
Epoch 2253/10000; Iter 51/80; Loss: 0.4900
Epoch 2253/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.049
Epoch 2254/10000; Iter 1/80; Loss: 0.4938
Epoch 2254/10000; Iter 51/80; Loss: 0.5003
Epoch 2254/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.049
Epoch 2255/10000; Iter 1/80; Loss: 0.4401
Epoch 2255/10000; Iter 51/80; Loss: 0.5226
Epoch 2255/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.046
Epoch 2256/10000; Iter 1/80; Loss: 0.4919
Epoch 2256/10000; Iter 51/80; Loss: 0.4626
Epoch 2256/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.053
Epoch 2257/10000; Iter 1/80; Loss: 0.5115
Epoch 2257/10000; Iter 51/80; Loss: 0.4352
Epoch 2257/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.056
Epoch 2258/10000; Iter 1/80; Loss: 0.4839
Epoch 2258/10000; Iter 51/80; Loss: 0.4600
Epoch 2258/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.049
Epoch 2259/10000; Iter 1/80; Loss: 0.4367
Epoch 2259/10000; Iter 51/80; Loss: 0.4696
Epoch 2259/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.058
Epoch 2260/10000; Iter 1/80; Loss: 0.4760
Epoch 2260/10000; Iter 51/80; Loss: 0.4426
Epoch 2260/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.051
Epoch 2261/10000; Iter 1/80; Loss: 0.4589
Epoch 2261/10000; Iter 51/80; Loss: 0.4252
Epoch 2261/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.055
Epoch 2262/10000; Iter 1/80; Loss: 0.4559
Epoch 2262/10000; Iter 51/80; Loss: 0.4479
Epoch 2262/10000; Iter 80/80; Training Loss: 0.4640, Test Loss: 0.055
Epoch 2263/10000; Iter 1/80; Loss: 0.4673
Epoch 2263/10000; Iter 51/80; Loss: 0.4717
Epoch 2263/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.051
Epoch 2264/10000; Iter 1/80; Loss: 0.4684
Epoch 2264/10000; Iter 51/80; Loss: 0.5095
Epoch 2264/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.048
Epoch 2265/10000; Iter 1/80; Loss: 0.4743
Epoch 2265/10000; Iter 51/80; Loss: 0.4479
Epoch 2265/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.048
Epoch 2266/10000; Iter 1/80; Loss: 0.4283
Epoch 2266/10000; Iter 51/80; Loss: 0.3985
Epoch 2266/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.054
Epoch 2267/10000; Iter 1/80; Loss: 0.4488
Epoch 2267/10000; Iter 51/80; Loss: 0.5648
Epoch 2267/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.052
Epoch 2268/10000; Iter 1/80; Loss: 0.4166
Epoch 2268/10000; Iter 51/80; Loss: 0.3698
Epoch 2268/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.043
Epoch 2269/10000; Iter 1/80; Loss: 0.4201
Epoch 2269/10000; Iter 51/80; Loss: 0.4531
Epoch 2269/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.041
Epoch 2270/10000; Iter 1/80; Loss: 0.4803
Epoch 2270/10000; Iter 51/80; Loss: 0.4314
Epoch 2270/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.052
Epoch 2271/10000; Iter 1/80; Loss: 0.4851
Epoch 2271/10000; Iter 51/80; Loss: 0.4509
Epoch 2271/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.055
Epoch 2272/10000; Iter 1/80; Loss: 0.5435
Epoch 2272/10000; Iter 51/80; Loss: 0.4553
Epoch 2272/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.052
Epoch 2273/10000; Iter 1/80; Loss: 0.4783
Epoch 2273/10000; Iter 51/80; Loss: 0.4160
Epoch 2273/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.056
Epoch 2274/10000; Iter 1/80; Loss: 0.4593
Epoch 2274/10000; Iter 51/80; Loss: 0.4750
Epoch 2274/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.052
Epoch 2275/10000; Iter 1/80; Loss: 0.4742
Epoch 2275/10000; Iter 51/80; Loss: 0.5002
Epoch 2275/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.054
Epoch 2276/10000; Iter 1/80; Loss: 0.4087
Epoch 2276/10000; Iter 51/80; Loss: 0.5111
Epoch 2276/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.051
Epoch 2277/10000; Iter 1/80; Loss: 0.4336
Epoch 2277/10000; Iter 51/80; Loss: 0.4246
Epoch 2277/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.052
Epoch 2278/10000; Iter 1/80; Loss: 0.4291
Epoch 2278/10000; Iter 51/80; Loss: 0.4353
Epoch 2278/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.055
Epoch 2279/10000; Iter 1/80; Loss: 0.4100
Epoch 2279/10000; Iter 51/80; Loss: 0.4200
Epoch 2279/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.057
Epoch 2280/10000; Iter 1/80; Loss: 0.4030
Epoch 2280/10000; Iter 51/80; Loss: 0.4444
Epoch 2280/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.046
Epoch 2281/10000; Iter 1/80; Loss: 0.4332
Epoch 2281/10000; Iter 51/80; Loss: 0.4590
Epoch 2281/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.051
Epoch 2282/10000; Iter 1/80; Loss: 0.4935
Epoch 2282/10000; Iter 51/80; Loss: 0.4885
Epoch 2282/10000; Iter 80/80; Training Loss: 0.4650, Test Loss: 0.052
Epoch 2283/10000; Iter 1/80; Loss: 0.4347
Epoch 2283/10000; Iter 51/80; Loss: 0.4757
Epoch 2283/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.041
Epoch 2284/10000; Iter 1/80; Loss: 0.4745
Epoch 2284/10000; Iter 51/80; Loss: 0.4311
Epoch 2284/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.052
Epoch 2285/10000; Iter 1/80; Loss: 0.4489
Epoch 2285/10000; Iter 51/80; Loss: 0.3825
Epoch 2285/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.057
Epoch 2286/10000; Iter 1/80; Loss: 0.4328
Epoch 2286/10000; Iter 51/80; Loss: 0.4576
Epoch 2286/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.046
Epoch 2287/10000; Iter 1/80; Loss: 0.5364
Epoch 2287/10000; Iter 51/80; Loss: 0.4150
Epoch 2287/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.051
Epoch 2288/10000; Iter 1/80; Loss: 0.4055
Epoch 2288/10000; Iter 51/80; Loss: 0.4390
Epoch 2288/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.052
Epoch 2289/10000; Iter 1/80; Loss: 0.4807
Epoch 2289/10000; Iter 51/80; Loss: 0.4504
Epoch 2289/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.054
Epoch 2290/10000; Iter 1/80; Loss: 0.4229
Epoch 2290/10000; Iter 51/80; Loss: 0.4558
Epoch 2290/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.049
Epoch 2291/10000; Iter 1/80; Loss: 0.4603
Epoch 2291/10000; Iter 51/80; Loss: 0.4353
Epoch 2291/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.05
Epoch 2292/10000; Iter 1/80; Loss: 0.5512
Epoch 2292/10000; Iter 51/80; Loss: 0.4341
Epoch 2292/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.05
Epoch 2293/10000; Iter 1/80; Loss: 0.4505
Epoch 2293/10000; Iter 51/80; Loss: 0.4584
Epoch 2293/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.056
Epoch 2294/10000; Iter 1/80; Loss: 0.4481
Epoch 2294/10000; Iter 51/80; Loss: 0.5050
Epoch 2294/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.05
Epoch 2295/10000; Iter 1/80; Loss: 0.4849
Epoch 2295/10000; Iter 51/80; Loss: 0.3924
Epoch 2295/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.043
Epoch 2296/10000; Iter 1/80; Loss: 0.4864
Epoch 2296/10000; Iter 51/80; Loss: 0.3948
Epoch 2296/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.057
Epoch 2297/10000; Iter 1/80; Loss: 0.4346
Epoch 2297/10000; Iter 51/80; Loss: 0.4234
Epoch 2297/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.046
Epoch 2298/10000; Iter 1/80; Loss: 0.4286
Epoch 2298/10000; Iter 51/80; Loss: 0.4591
Epoch 2298/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.047
Epoch 2299/10000; Iter 1/80; Loss: 0.4566
Epoch 2299/10000; Iter 51/80; Loss: 0.4468
Epoch 2299/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.044
Epoch 2300/10000; Iter 1/80; Loss: 0.4205
Epoch 2300/10000; Iter 51/80; Loss: 0.4634
Epoch 2300/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.047
Epoch 2301/10000; Iter 1/80; Loss: 0.4889
Epoch 2301/10000; Iter 51/80; Loss: 0.5014
Epoch 2301/10000; Iter 80/80; Training Loss: 0.4660, Test Loss: 0.048
Model saved
Epoch 2302/10000; Iter 1/80; Loss: 0.4872
Epoch 2302/10000; Iter 51/80; Loss: 0.4174
Epoch 2302/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.049
Epoch 2303/10000; Iter 1/80; Loss: 0.4552
Epoch 2303/10000; Iter 51/80; Loss: 0.4667
Epoch 2303/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.053
Epoch 2304/10000; Iter 1/80; Loss: 0.4364
Epoch 2304/10000; Iter 51/80; Loss: 0.4473
Epoch 2304/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.051
Epoch 2305/10000; Iter 1/80; Loss: 0.4978
Epoch 2305/10000; Iter 51/80; Loss: 0.5019
Epoch 2305/10000; Iter 80/80; Training Loss: 0.4620, Test Loss: 0.046
Epoch 2306/10000; Iter 1/80; Loss: 0.4593
Epoch 2306/10000; Iter 51/80; Loss: 0.4850
Epoch 2306/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.047
Epoch 2307/10000; Iter 1/80; Loss: 0.5282
Epoch 2307/10000; Iter 51/80; Loss: 0.4827
Epoch 2307/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.05
Epoch 2308/10000; Iter 1/80; Loss: 0.4897
Epoch 2308/10000; Iter 51/80; Loss: 0.4245
Epoch 2308/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.045
Epoch 2309/10000; Iter 1/80; Loss: 0.4718
Epoch 2309/10000; Iter 51/80; Loss: 0.4310
Epoch 2309/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.049
Epoch 2310/10000; Iter 1/80; Loss: 0.4782
Epoch 2310/10000; Iter 51/80; Loss: 0.4480
Epoch 2310/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.053
Epoch 2311/10000; Iter 1/80; Loss: 0.4311
Epoch 2311/10000; Iter 51/80; Loss: 0.4613
Epoch 2311/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.045
Epoch 2312/10000; Iter 1/80; Loss: 0.4219
Epoch 2312/10000; Iter 51/80; Loss: 0.4112
Epoch 2312/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.048
Epoch 2313/10000; Iter 1/80; Loss: 0.4781
Epoch 2313/10000; Iter 51/80; Loss: 0.4645
Epoch 2313/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.055
Epoch 2314/10000; Iter 1/80; Loss: 0.5556
Epoch 2314/10000; Iter 51/80; Loss: 0.5167
Epoch 2314/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.054
Epoch 2315/10000; Iter 1/80; Loss: 0.4772
Epoch 2315/10000; Iter 51/80; Loss: 0.4535
Epoch 2315/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.049
Epoch 2316/10000; Iter 1/80; Loss: 0.4869
Epoch 2316/10000; Iter 51/80; Loss: 0.4695
Epoch 2316/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.046
Epoch 2317/10000; Iter 1/80; Loss: 0.4420
Epoch 2317/10000; Iter 51/80; Loss: 0.3953
Epoch 2317/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.041
Epoch 2318/10000; Iter 1/80; Loss: 0.4736
Epoch 2318/10000; Iter 51/80; Loss: 0.3874
Epoch 2318/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.061
Epoch 2319/10000; Iter 1/80; Loss: 0.4715
Epoch 2319/10000; Iter 51/80; Loss: 0.5412
Epoch 2319/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.046
Epoch 2320/10000; Iter 1/80; Loss: 0.4563
Epoch 2320/10000; Iter 51/80; Loss: 0.3910
Epoch 2320/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.048
Epoch 2321/10000; Iter 1/80; Loss: 0.4336
Epoch 2321/10000; Iter 51/80; Loss: 0.4453
Epoch 2321/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.053
Epoch 2322/10000; Iter 1/80; Loss: 0.4578
Epoch 2322/10000; Iter 51/80; Loss: 0.4678
Epoch 2322/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.047
Epoch 2323/10000; Iter 1/80; Loss: 0.4406
Epoch 2323/10000; Iter 51/80; Loss: 0.5496
Epoch 2323/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.043
Epoch 2324/10000; Iter 1/80; Loss: 0.4621
Epoch 2324/10000; Iter 51/80; Loss: 0.4972
Epoch 2324/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.053
Epoch 2325/10000; Iter 1/80; Loss: 0.3879
Epoch 2325/10000; Iter 51/80; Loss: 0.4549
Epoch 2325/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.048
Epoch 2326/10000; Iter 1/80; Loss: 0.4085
Epoch 2326/10000; Iter 51/80; Loss: 0.4228
Epoch 2326/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.045
Epoch 2327/10000; Iter 1/80; Loss: 0.3938
Epoch 2327/10000; Iter 51/80; Loss: 0.4501
Epoch 2327/10000; Iter 80/80; Training Loss: 0.4580, Test Loss: 0.052
Epoch 2328/10000; Iter 1/80; Loss: 0.4282
Epoch 2328/10000; Iter 51/80; Loss: 0.4420
Epoch 2328/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.053
Epoch 2329/10000; Iter 1/80; Loss: 0.4428
Epoch 2329/10000; Iter 51/80; Loss: 0.4446
Epoch 2329/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.047
Epoch 2330/10000; Iter 1/80; Loss: 0.4170
Epoch 2330/10000; Iter 51/80; Loss: 0.4512
Epoch 2330/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.048
Epoch 2331/10000; Iter 1/80; Loss: 0.3925
Epoch 2331/10000; Iter 51/80; Loss: 0.4943
Epoch 2331/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.049
Epoch 2332/10000; Iter 1/80; Loss: 0.4301
Epoch 2332/10000; Iter 51/80; Loss: 0.4115
Epoch 2332/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.05
Epoch 2333/10000; Iter 1/80; Loss: 0.4631
Epoch 2333/10000; Iter 51/80; Loss: 0.4411
Epoch 2333/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.05
Epoch 2334/10000; Iter 1/80; Loss: 0.4298
Epoch 2334/10000; Iter 51/80; Loss: 0.4864
Epoch 2334/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.043
Epoch 2335/10000; Iter 1/80; Loss: 0.4043
Epoch 2335/10000; Iter 51/80; Loss: 0.4206
Epoch 2335/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.044
Epoch 2336/10000; Iter 1/80; Loss: 0.4580
Epoch 2336/10000; Iter 51/80; Loss: 0.5173
Epoch 2336/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.049
Epoch 2337/10000; Iter 1/80; Loss: 0.4529
Epoch 2337/10000; Iter 51/80; Loss: 0.4876
Epoch 2337/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.049
Epoch 2338/10000; Iter 1/80; Loss: 0.3841
Epoch 2338/10000; Iter 51/80; Loss: 0.4016
Epoch 2338/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.052
Epoch 2339/10000; Iter 1/80; Loss: 0.4773
Epoch 2339/10000; Iter 51/80; Loss: 0.4803
Epoch 2339/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.05
Epoch 2340/10000; Iter 1/80; Loss: 0.4229
Epoch 2340/10000; Iter 51/80; Loss: 0.4003
Epoch 2340/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.046
Epoch 2341/10000; Iter 1/80; Loss: 0.4622
Epoch 2341/10000; Iter 51/80; Loss: 0.4039
Epoch 2341/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.057
Epoch 2342/10000; Iter 1/80; Loss: 0.5042
Epoch 2342/10000; Iter 51/80; Loss: 0.5394
Epoch 2342/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.05
Epoch 2343/10000; Iter 1/80; Loss: 0.4823
Epoch 2343/10000; Iter 51/80; Loss: 0.4411
Epoch 2343/10000; Iter 80/80; Training Loss: 0.4610, Test Loss: 0.043
Epoch 2344/10000; Iter 1/80; Loss: 0.4604
Epoch 2344/10000; Iter 51/80; Loss: 0.4081
Epoch 2344/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.041
Epoch 2345/10000; Iter 1/80; Loss: 0.5046
Epoch 2345/10000; Iter 51/80; Loss: 0.4848
Epoch 2345/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.052
Epoch 2346/10000; Iter 1/80; Loss: 0.4687
Epoch 2346/10000; Iter 51/80; Loss: 0.5040
Epoch 2346/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.045
Epoch 2347/10000; Iter 1/80; Loss: 0.4417
Epoch 2347/10000; Iter 51/80; Loss: 0.4501
Epoch 2347/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.046
Epoch 2348/10000; Iter 1/80; Loss: 0.4548
Epoch 2348/10000; Iter 51/80; Loss: 0.4524
Epoch 2348/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.051
Epoch 2349/10000; Iter 1/80; Loss: 0.4040
Epoch 2349/10000; Iter 51/80; Loss: 0.5024
Epoch 2349/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.056
Epoch 2350/10000; Iter 1/80; Loss: 0.4853
Epoch 2350/10000; Iter 51/80; Loss: 0.4550
Epoch 2350/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.046
Epoch 2351/10000; Iter 1/80; Loss: 0.4583
Epoch 2351/10000; Iter 51/80; Loss: 0.5092
Epoch 2351/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.049
Epoch 2352/10000; Iter 1/80; Loss: 0.4220
Epoch 2352/10000; Iter 51/80; Loss: 0.4479
Epoch 2352/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.044
Epoch 2353/10000; Iter 1/80; Loss: 0.3956
Epoch 2353/10000; Iter 51/80; Loss: 0.4716
Epoch 2353/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.046
Epoch 2354/10000; Iter 1/80; Loss: 0.4382
Epoch 2354/10000; Iter 51/80; Loss: 0.5259
Epoch 2354/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.048
Epoch 2355/10000; Iter 1/80; Loss: 0.4091
Epoch 2355/10000; Iter 51/80; Loss: 0.4545
Epoch 2355/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.051
Epoch 2356/10000; Iter 1/80; Loss: 0.4557
Epoch 2356/10000; Iter 51/80; Loss: 0.4212
Epoch 2356/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.047
Epoch 2357/10000; Iter 1/80; Loss: 0.4586
Epoch 2357/10000; Iter 51/80; Loss: 0.4556
Epoch 2357/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.048
Epoch 2358/10000; Iter 1/80; Loss: 0.4657
Epoch 2358/10000; Iter 51/80; Loss: 0.4675
Epoch 2358/10000; Iter 80/80; Training Loss: 0.4530, Test Loss: 0.061
Epoch 2359/10000; Iter 1/80; Loss: 0.3995
Epoch 2359/10000; Iter 51/80; Loss: 0.4523
Epoch 2359/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.052
Epoch 2360/10000; Iter 1/80; Loss: 0.4807
Epoch 2360/10000; Iter 51/80; Loss: 0.4519
Epoch 2360/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.041
Epoch 2361/10000; Iter 1/80; Loss: 0.4314
Epoch 2361/10000; Iter 51/80; Loss: 0.4401
Epoch 2361/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.046
Epoch 2362/10000; Iter 1/80; Loss: 0.5172
Epoch 2362/10000; Iter 51/80; Loss: 0.5007
Epoch 2362/10000; Iter 80/80; Training Loss: 0.4610, Test Loss: 0.049
Epoch 2363/10000; Iter 1/80; Loss: 0.4503
Epoch 2363/10000; Iter 51/80; Loss: 0.4271
Epoch 2363/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.046
Epoch 2364/10000; Iter 1/80; Loss: 0.5037
Epoch 2364/10000; Iter 51/80; Loss: 0.4725
Epoch 2364/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.052
Epoch 2365/10000; Iter 1/80; Loss: 0.5111
Epoch 2365/10000; Iter 51/80; Loss: 0.4574
Epoch 2365/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.048
Epoch 2366/10000; Iter 1/80; Loss: 0.4471
Epoch 2366/10000; Iter 51/80; Loss: 0.4281
Epoch 2366/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.055
Epoch 2367/10000; Iter 1/80; Loss: 0.4512
Epoch 2367/10000; Iter 51/80; Loss: 0.5324
Epoch 2367/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.046
Epoch 2368/10000; Iter 1/80; Loss: 0.4139
Epoch 2368/10000; Iter 51/80; Loss: 0.3562
Epoch 2368/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.049
Epoch 2369/10000; Iter 1/80; Loss: 0.4023
Epoch 2369/10000; Iter 51/80; Loss: 0.4086
Epoch 2369/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.051
Epoch 2370/10000; Iter 1/80; Loss: 0.4630
Epoch 2370/10000; Iter 51/80; Loss: 0.4171
Epoch 2370/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.049
Epoch 2371/10000; Iter 1/80; Loss: 0.4106
Epoch 2371/10000; Iter 51/80; Loss: 0.4072
Epoch 2371/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.047
Epoch 2372/10000; Iter 1/80; Loss: 0.4842
Epoch 2372/10000; Iter 51/80; Loss: 0.4476
Epoch 2372/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.062
Epoch 2373/10000; Iter 1/80; Loss: 0.4586
Epoch 2373/10000; Iter 51/80; Loss: 0.5774
Epoch 2373/10000; Iter 80/80; Training Loss: 0.4590, Test Loss: 0.047
Epoch 2374/10000; Iter 1/80; Loss: 0.4914
Epoch 2374/10000; Iter 51/80; Loss: 0.4145
Epoch 2374/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.051
Epoch 2375/10000; Iter 1/80; Loss: 0.4608
Epoch 2375/10000; Iter 51/80; Loss: 0.5086
Epoch 2375/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.052
Epoch 2376/10000; Iter 1/80; Loss: 0.4369
Epoch 2376/10000; Iter 51/80; Loss: 0.4230
Epoch 2376/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.051
Epoch 2377/10000; Iter 1/80; Loss: 0.4654
Epoch 2377/10000; Iter 51/80; Loss: 0.4840
Epoch 2377/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.044
Epoch 2378/10000; Iter 1/80; Loss: 0.4121
Epoch 2378/10000; Iter 51/80; Loss: 0.4308
Epoch 2378/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.045
Epoch 2379/10000; Iter 1/80; Loss: 0.3995
Epoch 2379/10000; Iter 51/80; Loss: 0.3963
Epoch 2379/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.04
Epoch 2380/10000; Iter 1/80; Loss: 0.3663
Epoch 2380/10000; Iter 51/80; Loss: 0.4347
Epoch 2380/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.051
Epoch 2381/10000; Iter 1/80; Loss: 0.4630
Epoch 2381/10000; Iter 51/80; Loss: 0.3926
Epoch 2381/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.049
Epoch 2382/10000; Iter 1/80; Loss: 0.4611
Epoch 2382/10000; Iter 51/80; Loss: 0.4378
Epoch 2382/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.052
Epoch 2383/10000; Iter 1/80; Loss: 0.3721
Epoch 2383/10000; Iter 51/80; Loss: 0.4047
Epoch 2383/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.055
Epoch 2384/10000; Iter 1/80; Loss: 0.4375
Epoch 2384/10000; Iter 51/80; Loss: 0.4778
Epoch 2384/10000; Iter 80/80; Training Loss: 0.4600, Test Loss: 0.049
Epoch 2385/10000; Iter 1/80; Loss: 0.4557
Epoch 2385/10000; Iter 51/80; Loss: 0.4493
Epoch 2385/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.051
Epoch 2386/10000; Iter 1/80; Loss: 0.4474
Epoch 2386/10000; Iter 51/80; Loss: 0.5506
Epoch 2386/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.044
Epoch 2387/10000; Iter 1/80; Loss: 0.5007
Epoch 2387/10000; Iter 51/80; Loss: 0.3785
Epoch 2387/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.043
Epoch 2388/10000; Iter 1/80; Loss: 0.4494
Epoch 2388/10000; Iter 51/80; Loss: 0.4788
Epoch 2388/10000; Iter 80/80; Training Loss: 0.4630, Test Loss: 0.054
Epoch 2389/10000; Iter 1/80; Loss: 0.4570
Epoch 2389/10000; Iter 51/80; Loss: 0.4212
Epoch 2389/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.045
Epoch 2390/10000; Iter 1/80; Loss: 0.4831
Epoch 2390/10000; Iter 51/80; Loss: 0.5049
Epoch 2390/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.041
Epoch 2391/10000; Iter 1/80; Loss: 0.4923
Epoch 2391/10000; Iter 51/80; Loss: 0.4465
Epoch 2391/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.047
Epoch 2392/10000; Iter 1/80; Loss: 0.4259
Epoch 2392/10000; Iter 51/80; Loss: 0.4306
Epoch 2392/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.048
Epoch 2393/10000; Iter 1/80; Loss: 0.4161
Epoch 2393/10000; Iter 51/80; Loss: 0.4298
Epoch 2393/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.054
Epoch 2394/10000; Iter 1/80; Loss: 0.4699
Epoch 2394/10000; Iter 51/80; Loss: 0.4667
Epoch 2394/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.048
Epoch 2395/10000; Iter 1/80; Loss: 0.4445
Epoch 2395/10000; Iter 51/80; Loss: 0.3945
Epoch 2395/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.057
Epoch 2396/10000; Iter 1/80; Loss: 0.4951
Epoch 2396/10000; Iter 51/80; Loss: 0.4696
Epoch 2396/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.044
Epoch 2397/10000; Iter 1/80; Loss: 0.4715
Epoch 2397/10000; Iter 51/80; Loss: 0.3983
Epoch 2397/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.047
Epoch 2398/10000; Iter 1/80; Loss: 0.4135
Epoch 2398/10000; Iter 51/80; Loss: 0.4518
Epoch 2398/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.048
Epoch 2399/10000; Iter 1/80; Loss: 0.3794
Epoch 2399/10000; Iter 51/80; Loss: 0.4122
Epoch 2399/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.052
Epoch 2400/10000; Iter 1/80; Loss: 0.4278
Epoch 2400/10000; Iter 51/80; Loss: 0.4567
Epoch 2400/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.049
Epoch 2401/10000; Iter 1/80; Loss: 0.3671
Epoch 2401/10000; Iter 51/80; Loss: 0.5174
Epoch 2401/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.048
Model saved
Epoch 2402/10000; Iter 1/80; Loss: 0.4707
Epoch 2402/10000; Iter 51/80; Loss: 0.3907
Epoch 2402/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.057
Epoch 2403/10000; Iter 1/80; Loss: 0.5122
Epoch 2403/10000; Iter 51/80; Loss: 0.4951
Epoch 2403/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.054
Epoch 2404/10000; Iter 1/80; Loss: 0.4428
Epoch 2404/10000; Iter 51/80; Loss: 0.4223
Epoch 2404/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.052
Epoch 2405/10000; Iter 1/80; Loss: 0.4671
Epoch 2405/10000; Iter 51/80; Loss: 0.3820
Epoch 2405/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.056
Epoch 2406/10000; Iter 1/80; Loss: 0.4236
Epoch 2406/10000; Iter 51/80; Loss: 0.5032
Epoch 2406/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.053
Epoch 2407/10000; Iter 1/80; Loss: 0.4529
Epoch 2407/10000; Iter 51/80; Loss: 0.4006
Epoch 2407/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.047
Epoch 2408/10000; Iter 1/80; Loss: 0.4365
Epoch 2408/10000; Iter 51/80; Loss: 0.4629
Epoch 2408/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.051
Epoch 2409/10000; Iter 1/80; Loss: 0.4284
Epoch 2409/10000; Iter 51/80; Loss: 0.4240
Epoch 2409/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.047
Epoch 2410/10000; Iter 1/80; Loss: 0.4259
Epoch 2410/10000; Iter 51/80; Loss: 0.4776
Epoch 2410/10000; Iter 80/80; Training Loss: 0.4540, Test Loss: 0.051
Epoch 2411/10000; Iter 1/80; Loss: 0.4674
Epoch 2411/10000; Iter 51/80; Loss: 0.5310
Epoch 2411/10000; Iter 80/80; Training Loss: 0.4560, Test Loss: 0.046
Epoch 2412/10000; Iter 1/80; Loss: 0.4479
Epoch 2412/10000; Iter 51/80; Loss: 0.4207
Epoch 2412/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.043
Epoch 2413/10000; Iter 1/80; Loss: 0.4498
Epoch 2413/10000; Iter 51/80; Loss: 0.3879
Epoch 2413/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.046
Epoch 2414/10000; Iter 1/80; Loss: 0.4681
Epoch 2414/10000; Iter 51/80; Loss: 0.5035
Epoch 2414/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.041
Epoch 2415/10000; Iter 1/80; Loss: 0.4186
Epoch 2415/10000; Iter 51/80; Loss: 0.4198
Epoch 2415/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.052
Epoch 2416/10000; Iter 1/80; Loss: 0.4545
Epoch 2416/10000; Iter 51/80; Loss: 0.4644
Epoch 2416/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.049
Epoch 2417/10000; Iter 1/80; Loss: 0.4278
Epoch 2417/10000; Iter 51/80; Loss: 0.4448
Epoch 2417/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.047
Epoch 2418/10000; Iter 1/80; Loss: 0.4483
Epoch 2418/10000; Iter 51/80; Loss: 0.4116
Epoch 2418/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.05
Epoch 2419/10000; Iter 1/80; Loss: 0.3892
Epoch 2419/10000; Iter 51/80; Loss: 0.4602
Epoch 2419/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.055
Epoch 2420/10000; Iter 1/80; Loss: 0.3942
Epoch 2420/10000; Iter 51/80; Loss: 0.4584
Epoch 2420/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.048
Epoch 2421/10000; Iter 1/80; Loss: 0.4891
Epoch 2421/10000; Iter 51/80; Loss: 0.4550
Epoch 2421/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.048
Epoch 2422/10000; Iter 1/80; Loss: 0.4323
Epoch 2422/10000; Iter 51/80; Loss: 0.3974
Epoch 2422/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.048
Epoch 2423/10000; Iter 1/80; Loss: 0.3972
Epoch 2423/10000; Iter 51/80; Loss: 0.4803
Epoch 2423/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.044
Epoch 2424/10000; Iter 1/80; Loss: 0.4490
Epoch 2424/10000; Iter 51/80; Loss: 0.4473
Epoch 2424/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.048
Epoch 2425/10000; Iter 1/80; Loss: 0.4207
Epoch 2425/10000; Iter 51/80; Loss: 0.4624
Epoch 2425/10000; Iter 80/80; Training Loss: 0.4570, Test Loss: 0.051
Epoch 2426/10000; Iter 1/80; Loss: 0.4469
Epoch 2426/10000; Iter 51/80; Loss: 0.4715
Epoch 2426/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.046
Epoch 2427/10000; Iter 1/80; Loss: 0.4528
Epoch 2427/10000; Iter 51/80; Loss: 0.4858
Epoch 2427/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.051
Epoch 2428/10000; Iter 1/80; Loss: 0.3611
Epoch 2428/10000; Iter 51/80; Loss: 0.4117
Epoch 2428/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.047
Epoch 2429/10000; Iter 1/80; Loss: 0.4347
Epoch 2429/10000; Iter 51/80; Loss: 0.4483
Epoch 2429/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.04
Epoch 2430/10000; Iter 1/80; Loss: 0.4327
Epoch 2430/10000; Iter 51/80; Loss: 0.4365
Epoch 2430/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.048
Epoch 2431/10000; Iter 1/80; Loss: 0.4207
Epoch 2431/10000; Iter 51/80; Loss: 0.4138
Epoch 2431/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.044
Epoch 2432/10000; Iter 1/80; Loss: 0.3959
Epoch 2432/10000; Iter 51/80; Loss: 0.4370
Epoch 2432/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.049
Epoch 2433/10000; Iter 1/80; Loss: 0.4647
Epoch 2433/10000; Iter 51/80; Loss: 0.4028
Epoch 2433/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.046
Epoch 2434/10000; Iter 1/80; Loss: 0.3701
Epoch 2434/10000; Iter 51/80; Loss: 0.4025
Epoch 2434/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.044
Epoch 2435/10000; Iter 1/80; Loss: 0.4466
Epoch 2435/10000; Iter 51/80; Loss: 0.4222
Epoch 2435/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.057
Epoch 2436/10000; Iter 1/80; Loss: 0.4687
Epoch 2436/10000; Iter 51/80; Loss: 0.4676
Epoch 2436/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.047
Epoch 2437/10000; Iter 1/80; Loss: 0.4558
Epoch 2437/10000; Iter 51/80; Loss: 0.4570
Epoch 2437/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.046
Epoch 2438/10000; Iter 1/80; Loss: 0.4287
Epoch 2438/10000; Iter 51/80; Loss: 0.4379
Epoch 2438/10000; Iter 80/80; Training Loss: 0.4550, Test Loss: 0.052
Epoch 2439/10000; Iter 1/80; Loss: 0.3940
Epoch 2439/10000; Iter 51/80; Loss: 0.3950
Epoch 2439/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.056
Epoch 2440/10000; Iter 1/80; Loss: 0.4293
Epoch 2440/10000; Iter 51/80; Loss: 0.4533
Epoch 2440/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.048
Epoch 2441/10000; Iter 1/80; Loss: 0.4484
Epoch 2441/10000; Iter 51/80; Loss: 0.4455
Epoch 2441/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.049
Epoch 2442/10000; Iter 1/80; Loss: 0.4705
Epoch 2442/10000; Iter 51/80; Loss: 0.4381
Epoch 2442/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.048
Epoch 2443/10000; Iter 1/80; Loss: 0.3862
Epoch 2443/10000; Iter 51/80; Loss: 0.5129
Epoch 2443/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.047
Epoch 2444/10000; Iter 1/80; Loss: 0.4367
Epoch 2444/10000; Iter 51/80; Loss: 0.4036
Epoch 2444/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.05
Epoch 2445/10000; Iter 1/80; Loss: 0.4077
Epoch 2445/10000; Iter 51/80; Loss: 0.4651
Epoch 2445/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.048
Epoch 2446/10000; Iter 1/80; Loss: 0.4414
Epoch 2446/10000; Iter 51/80; Loss: 0.4540
Epoch 2446/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.049
Epoch 2447/10000; Iter 1/80; Loss: 0.4424
Epoch 2447/10000; Iter 51/80; Loss: 0.4569
Epoch 2447/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.052
Epoch 2448/10000; Iter 1/80; Loss: 0.4377
Epoch 2448/10000; Iter 51/80; Loss: 0.4155
Epoch 2448/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.054
Epoch 2449/10000; Iter 1/80; Loss: 0.4886
Epoch 2449/10000; Iter 51/80; Loss: 0.4545
Epoch 2449/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.049
Epoch 2450/10000; Iter 1/80; Loss: 0.4380
Epoch 2450/10000; Iter 51/80; Loss: 0.4367
Epoch 2450/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.043
Epoch 2451/10000; Iter 1/80; Loss: 0.4803
Epoch 2451/10000; Iter 51/80; Loss: 0.4406
Epoch 2451/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.052
Epoch 2452/10000; Iter 1/80; Loss: 0.4140
Epoch 2452/10000; Iter 51/80; Loss: 0.4835
Epoch 2452/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.053
Epoch 2453/10000; Iter 1/80; Loss: 0.4595
Epoch 2453/10000; Iter 51/80; Loss: 0.4114
Epoch 2453/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.047
Epoch 2454/10000; Iter 1/80; Loss: 0.4480
Epoch 2454/10000; Iter 51/80; Loss: 0.4181
Epoch 2454/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.047
Epoch 2455/10000; Iter 1/80; Loss: 0.4821
Epoch 2455/10000; Iter 51/80; Loss: 0.4055
Epoch 2455/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.047
Epoch 2456/10000; Iter 1/80; Loss: 0.4545
Epoch 2456/10000; Iter 51/80; Loss: 0.3978
Epoch 2456/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.049
Epoch 2457/10000; Iter 1/80; Loss: 0.4817
Epoch 2457/10000; Iter 51/80; Loss: 0.4350
Epoch 2457/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.05
Epoch 2458/10000; Iter 1/80; Loss: 0.4268
Epoch 2458/10000; Iter 51/80; Loss: 0.4337
Epoch 2458/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.05
Epoch 2459/10000; Iter 1/80; Loss: 0.4398
Epoch 2459/10000; Iter 51/80; Loss: 0.4384
Epoch 2459/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.059
Epoch 2460/10000; Iter 1/80; Loss: 0.4260
Epoch 2460/10000; Iter 51/80; Loss: 0.4228
Epoch 2460/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.048
Epoch 2461/10000; Iter 1/80; Loss: 0.4496
Epoch 2461/10000; Iter 51/80; Loss: 0.4565
Epoch 2461/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.056
Epoch 2462/10000; Iter 1/80; Loss: 0.4045
Epoch 2462/10000; Iter 51/80; Loss: 0.4385
Epoch 2462/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.043
Epoch 2463/10000; Iter 1/80; Loss: 0.4366
Epoch 2463/10000; Iter 51/80; Loss: 0.4906
Epoch 2463/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.051
Epoch 2464/10000; Iter 1/80; Loss: 0.4377
Epoch 2464/10000; Iter 51/80; Loss: 0.4552
Epoch 2464/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.043
Epoch 2465/10000; Iter 1/80; Loss: 0.4719
Epoch 2465/10000; Iter 51/80; Loss: 0.4511
Epoch 2465/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.043
Epoch 2466/10000; Iter 1/80; Loss: 0.4115
Epoch 2466/10000; Iter 51/80; Loss: 0.4443
Epoch 2466/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.046
Epoch 2467/10000; Iter 1/80; Loss: 0.4316
Epoch 2467/10000; Iter 51/80; Loss: 0.4218
Epoch 2467/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.051
Epoch 2468/10000; Iter 1/80; Loss: 0.4101
Epoch 2468/10000; Iter 51/80; Loss: 0.5449
Epoch 2468/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.047
Epoch 2469/10000; Iter 1/80; Loss: 0.3887
Epoch 2469/10000; Iter 51/80; Loss: 0.4765
Epoch 2469/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.051
Epoch 2470/10000; Iter 1/80; Loss: 0.3822
Epoch 2470/10000; Iter 51/80; Loss: 0.3611
Epoch 2470/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.051
Epoch 2471/10000; Iter 1/80; Loss: 0.5607
Epoch 2471/10000; Iter 51/80; Loss: 0.4220
Epoch 2471/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.054
Epoch 2472/10000; Iter 1/80; Loss: 0.4316
Epoch 2472/10000; Iter 51/80; Loss: 0.4474
Epoch 2472/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.048
Epoch 2473/10000; Iter 1/80; Loss: 0.5010
Epoch 2473/10000; Iter 51/80; Loss: 0.3788
Epoch 2473/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.05
Epoch 2474/10000; Iter 1/80; Loss: 0.4388
Epoch 2474/10000; Iter 51/80; Loss: 0.4589
Epoch 2474/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.051
Epoch 2475/10000; Iter 1/80; Loss: 0.4068
Epoch 2475/10000; Iter 51/80; Loss: 0.5153
Epoch 2475/10000; Iter 80/80; Training Loss: 0.4510, Test Loss: 0.048
Epoch 2476/10000; Iter 1/80; Loss: 0.5165
Epoch 2476/10000; Iter 51/80; Loss: 0.4037
Epoch 2476/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.052
Epoch 2477/10000; Iter 1/80; Loss: 0.4920
Epoch 2477/10000; Iter 51/80; Loss: 0.4477
Epoch 2477/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.048
Epoch 2478/10000; Iter 1/80; Loss: 0.4252
Epoch 2478/10000; Iter 51/80; Loss: 0.4421
Epoch 2478/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.046
Epoch 2479/10000; Iter 1/80; Loss: 0.4012
Epoch 2479/10000; Iter 51/80; Loss: 0.4492
Epoch 2479/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.045
Epoch 2480/10000; Iter 1/80; Loss: 0.4030
Epoch 2480/10000; Iter 51/80; Loss: 0.4277
Epoch 2480/10000; Iter 80/80; Training Loss: 0.4520, Test Loss: 0.054
Epoch 2481/10000; Iter 1/80; Loss: 0.4147
Epoch 2481/10000; Iter 51/80; Loss: 0.4323
Epoch 2481/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.05
Epoch 2482/10000; Iter 1/80; Loss: 0.4114
Epoch 2482/10000; Iter 51/80; Loss: 0.4629
Epoch 2482/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.051
Epoch 2483/10000; Iter 1/80; Loss: 0.4119
Epoch 2483/10000; Iter 51/80; Loss: 0.4232
Epoch 2483/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.052
Epoch 2484/10000; Iter 1/80; Loss: 0.3926
Epoch 2484/10000; Iter 51/80; Loss: 0.4153
Epoch 2484/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.046
Epoch 2485/10000; Iter 1/80; Loss: 0.4897
Epoch 2485/10000; Iter 51/80; Loss: 0.3886
Epoch 2485/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.045
Epoch 2486/10000; Iter 1/80; Loss: 0.4606
Epoch 2486/10000; Iter 51/80; Loss: 0.4776
Epoch 2486/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.047
Epoch 2487/10000; Iter 1/80; Loss: 0.4514
Epoch 2487/10000; Iter 51/80; Loss: 0.4033
Epoch 2487/10000; Iter 80/80; Training Loss: 0.4480, Test Loss: 0.052
Epoch 2488/10000; Iter 1/80; Loss: 0.4335
Epoch 2488/10000; Iter 51/80; Loss: 0.4626
Epoch 2488/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.049
Epoch 2489/10000; Iter 1/80; Loss: 0.4201
Epoch 2489/10000; Iter 51/80; Loss: 0.4396
Epoch 2489/10000; Iter 80/80; Training Loss: 0.4500, Test Loss: 0.047
Epoch 2490/10000; Iter 1/80; Loss: 0.4618
Epoch 2490/10000; Iter 51/80; Loss: 0.4327
Epoch 2490/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.055
Epoch 2491/10000; Iter 1/80; Loss: 0.4473
Epoch 2491/10000; Iter 51/80; Loss: 0.4093
Epoch 2491/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.046
Epoch 2492/10000; Iter 1/80; Loss: 0.4047
Epoch 2492/10000; Iter 51/80; Loss: 0.3931
Epoch 2492/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.049
Epoch 2493/10000; Iter 1/80; Loss: 0.4809
Epoch 2493/10000; Iter 51/80; Loss: 0.4948
Epoch 2493/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.06
Epoch 2494/10000; Iter 1/80; Loss: 0.4800
Epoch 2494/10000; Iter 51/80; Loss: 0.4875
Epoch 2494/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.045
Epoch 2495/10000; Iter 1/80; Loss: 0.5001
Epoch 2495/10000; Iter 51/80; Loss: 0.3938
Epoch 2495/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.043
Epoch 2496/10000; Iter 1/80; Loss: 0.4305
Epoch 2496/10000; Iter 51/80; Loss: 0.4510
Epoch 2496/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.041
Epoch 2497/10000; Iter 1/80; Loss: 0.3740
Epoch 2497/10000; Iter 51/80; Loss: 0.4098
Epoch 2497/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.056
Epoch 2498/10000; Iter 1/80; Loss: 0.4191
Epoch 2498/10000; Iter 51/80; Loss: 0.4300
Epoch 2498/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.049
Epoch 2499/10000; Iter 1/80; Loss: 0.4933
Epoch 2499/10000; Iter 51/80; Loss: 0.3908
Epoch 2499/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.057
Epoch 2500/10000; Iter 1/80; Loss: 0.4433
Epoch 2500/10000; Iter 51/80; Loss: 0.4381
Epoch 2500/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.048
Epoch 2501/10000; Iter 1/80; Loss: 0.3839
Epoch 2501/10000; Iter 51/80; Loss: 0.4111
Epoch 2501/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.046
Model saved
Epoch 2502/10000; Iter 1/80; Loss: 0.4326
Epoch 2502/10000; Iter 51/80; Loss: 0.4518
Epoch 2502/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.051
Epoch 2503/10000; Iter 1/80; Loss: 0.4310
Epoch 2503/10000; Iter 51/80; Loss: 0.4574
Epoch 2503/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.055
Epoch 2504/10000; Iter 1/80; Loss: 0.3956
Epoch 2504/10000; Iter 51/80; Loss: 0.4376
Epoch 2504/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.054
Epoch 2505/10000; Iter 1/80; Loss: 0.3989
Epoch 2505/10000; Iter 51/80; Loss: 0.4662
Epoch 2505/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.052
Epoch 2506/10000; Iter 1/80; Loss: 0.4173
Epoch 2506/10000; Iter 51/80; Loss: 0.4458
Epoch 2506/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.053
Epoch 2507/10000; Iter 1/80; Loss: 0.3924
Epoch 2507/10000; Iter 51/80; Loss: 0.4052
Epoch 2507/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.053
Epoch 2508/10000; Iter 1/80; Loss: 0.3965
Epoch 2508/10000; Iter 51/80; Loss: 0.4368
Epoch 2508/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.049
Epoch 2509/10000; Iter 1/80; Loss: 0.4023
Epoch 2509/10000; Iter 51/80; Loss: 0.4352
Epoch 2509/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.043
Epoch 2510/10000; Iter 1/80; Loss: 0.4548
Epoch 2510/10000; Iter 51/80; Loss: 0.3749
Epoch 2510/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.05
Epoch 2511/10000; Iter 1/80; Loss: 0.5081
Epoch 2511/10000; Iter 51/80; Loss: 0.3993
Epoch 2511/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.042
Epoch 2512/10000; Iter 1/80; Loss: 0.3799
Epoch 2512/10000; Iter 51/80; Loss: 0.4106
Epoch 2512/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.045
Epoch 2513/10000; Iter 1/80; Loss: 0.4651
Epoch 2513/10000; Iter 51/80; Loss: 0.3898
Epoch 2513/10000; Iter 80/80; Training Loss: 0.4490, Test Loss: 0.041
Epoch 2514/10000; Iter 1/80; Loss: 0.4133
Epoch 2514/10000; Iter 51/80; Loss: 0.5655
Epoch 2514/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.048
Epoch 2515/10000; Iter 1/80; Loss: 0.3619
Epoch 2515/10000; Iter 51/80; Loss: 0.4121
Epoch 2515/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.047
Epoch 2516/10000; Iter 1/80; Loss: 0.4076
Epoch 2516/10000; Iter 51/80; Loss: 0.5012
Epoch 2516/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.049
Epoch 2517/10000; Iter 1/80; Loss: 0.4563
Epoch 2517/10000; Iter 51/80; Loss: 0.3928
Epoch 2517/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.055
Epoch 2518/10000; Iter 1/80; Loss: 0.5048
Epoch 2518/10000; Iter 51/80; Loss: 0.3838
Epoch 2518/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.052
Epoch 2519/10000; Iter 1/80; Loss: 0.3739
Epoch 2519/10000; Iter 51/80; Loss: 0.4473
Epoch 2519/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.044
Epoch 2520/10000; Iter 1/80; Loss: 0.5412
Epoch 2520/10000; Iter 51/80; Loss: 0.4575
Epoch 2520/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.036
Epoch 2521/10000; Iter 1/80; Loss: 0.4654
Epoch 2521/10000; Iter 51/80; Loss: 0.4690
Epoch 2521/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.041
Epoch 2522/10000; Iter 1/80; Loss: 0.4580
Epoch 2522/10000; Iter 51/80; Loss: 0.3984
Epoch 2522/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.05
Epoch 2523/10000; Iter 1/80; Loss: 0.4983
Epoch 2523/10000; Iter 51/80; Loss: 0.5054
Epoch 2523/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.051
Epoch 2524/10000; Iter 1/80; Loss: 0.4503
Epoch 2524/10000; Iter 51/80; Loss: 0.4489
Epoch 2524/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.053
Epoch 2525/10000; Iter 1/80; Loss: 0.4175
Epoch 2525/10000; Iter 51/80; Loss: 0.4697
Epoch 2525/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.054
Epoch 2526/10000; Iter 1/80; Loss: 0.4119
Epoch 2526/10000; Iter 51/80; Loss: 0.4024
Epoch 2526/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.039
Epoch 2527/10000; Iter 1/80; Loss: 0.4286
Epoch 2527/10000; Iter 51/80; Loss: 0.4368
Epoch 2527/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.056
Epoch 2528/10000; Iter 1/80; Loss: 0.4275
Epoch 2528/10000; Iter 51/80; Loss: 0.4506
Epoch 2528/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.052
Epoch 2529/10000; Iter 1/80; Loss: 0.4016
Epoch 2529/10000; Iter 51/80; Loss: 0.4651
Epoch 2529/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.047
Epoch 2530/10000; Iter 1/80; Loss: 0.4380
Epoch 2530/10000; Iter 51/80; Loss: 0.4280
Epoch 2530/10000; Iter 80/80; Training Loss: 0.4470, Test Loss: 0.048
Epoch 2531/10000; Iter 1/80; Loss: 0.4356
Epoch 2531/10000; Iter 51/80; Loss: 0.4576
Epoch 2531/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.047
Epoch 2532/10000; Iter 1/80; Loss: 0.3986
Epoch 2532/10000; Iter 51/80; Loss: 0.4999
Epoch 2532/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.049
Epoch 2533/10000; Iter 1/80; Loss: 0.4600
Epoch 2533/10000; Iter 51/80; Loss: 0.4684
Epoch 2533/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.055
Epoch 2534/10000; Iter 1/80; Loss: 0.3945
Epoch 2534/10000; Iter 51/80; Loss: 0.4671
Epoch 2534/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.048
Epoch 2535/10000; Iter 1/80; Loss: 0.4191
Epoch 2535/10000; Iter 51/80; Loss: 0.4366
Epoch 2535/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.041
Epoch 2536/10000; Iter 1/80; Loss: 0.4025
Epoch 2536/10000; Iter 51/80; Loss: 0.4345
Epoch 2536/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.054
Epoch 2537/10000; Iter 1/80; Loss: 0.4280
Epoch 2537/10000; Iter 51/80; Loss: 0.4417
Epoch 2537/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.047
Epoch 2538/10000; Iter 1/80; Loss: 0.4121
Epoch 2538/10000; Iter 51/80; Loss: 0.4808
Epoch 2538/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.044
Epoch 2539/10000; Iter 1/80; Loss: 0.3956
Epoch 2539/10000; Iter 51/80; Loss: 0.4214
Epoch 2539/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.047
Epoch 2540/10000; Iter 1/80; Loss: 0.4132
Epoch 2540/10000; Iter 51/80; Loss: 0.5165
Epoch 2540/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.043
Epoch 2541/10000; Iter 1/80; Loss: 0.4215
Epoch 2541/10000; Iter 51/80; Loss: 0.5420
Epoch 2541/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.049
Epoch 2542/10000; Iter 1/80; Loss: 0.4114
Epoch 2542/10000; Iter 51/80; Loss: 0.4396
Epoch 2542/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.051
Epoch 2543/10000; Iter 1/80; Loss: 0.4517
Epoch 2543/10000; Iter 51/80; Loss: 0.3840
Epoch 2543/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.048
Epoch 2544/10000; Iter 1/80; Loss: 0.4574
Epoch 2544/10000; Iter 51/80; Loss: 0.3793
Epoch 2544/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.055
Epoch 2545/10000; Iter 1/80; Loss: 0.4283
Epoch 2545/10000; Iter 51/80; Loss: 0.4412
Epoch 2545/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.047
Epoch 2546/10000; Iter 1/80; Loss: 0.4260
Epoch 2546/10000; Iter 51/80; Loss: 0.4206
Epoch 2546/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.05
Epoch 2547/10000; Iter 1/80; Loss: 0.4879
Epoch 2547/10000; Iter 51/80; Loss: 0.4448
Epoch 2547/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.052
Epoch 2548/10000; Iter 1/80; Loss: 0.3891
Epoch 2548/10000; Iter 51/80; Loss: 0.4413
Epoch 2548/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.046
Epoch 2549/10000; Iter 1/80; Loss: 0.4469
Epoch 2549/10000; Iter 51/80; Loss: 0.4397
Epoch 2549/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.046
Epoch 2550/10000; Iter 1/80; Loss: 0.4518
Epoch 2550/10000; Iter 51/80; Loss: 0.4135
Epoch 2550/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.046
Epoch 2551/10000; Iter 1/80; Loss: 0.5230
Epoch 2551/10000; Iter 51/80; Loss: 0.4257
Epoch 2551/10000; Iter 80/80; Training Loss: 0.4450, Test Loss: 0.052
Epoch 2552/10000; Iter 1/80; Loss: 0.4715
Epoch 2552/10000; Iter 51/80; Loss: 0.4422
Epoch 2552/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.051
Epoch 2553/10000; Iter 1/80; Loss: 0.4310
Epoch 2553/10000; Iter 51/80; Loss: 0.4406
Epoch 2553/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.047
Epoch 2554/10000; Iter 1/80; Loss: 0.4228
Epoch 2554/10000; Iter 51/80; Loss: 0.4060
Epoch 2554/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.046
Epoch 2555/10000; Iter 1/80; Loss: 0.4342
Epoch 2555/10000; Iter 51/80; Loss: 0.3867
Epoch 2555/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.05
Epoch 2556/10000; Iter 1/80; Loss: 0.3943
Epoch 2556/10000; Iter 51/80; Loss: 0.4353
Epoch 2556/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.041
Epoch 2557/10000; Iter 1/80; Loss: 0.5100
Epoch 2557/10000; Iter 51/80; Loss: 0.4139
Epoch 2557/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.048
Epoch 2558/10000; Iter 1/80; Loss: 0.5035
Epoch 2558/10000; Iter 51/80; Loss: 0.4411
Epoch 2558/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.052
Epoch 2559/10000; Iter 1/80; Loss: 0.4265
Epoch 2559/10000; Iter 51/80; Loss: 0.4000
Epoch 2559/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.052
Epoch 2560/10000; Iter 1/80; Loss: 0.5361
Epoch 2560/10000; Iter 51/80; Loss: 0.4233
Epoch 2560/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.047
Epoch 2561/10000; Iter 1/80; Loss: 0.4246
Epoch 2561/10000; Iter 51/80; Loss: 0.4169
Epoch 2561/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.054
Epoch 2562/10000; Iter 1/80; Loss: 0.4189
Epoch 2562/10000; Iter 51/80; Loss: 0.3867
Epoch 2562/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.047
Epoch 2563/10000; Iter 1/80; Loss: 0.4056
Epoch 2563/10000; Iter 51/80; Loss: 0.5089
Epoch 2563/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.049
Epoch 2564/10000; Iter 1/80; Loss: 0.4554
Epoch 2564/10000; Iter 51/80; Loss: 0.4726
Epoch 2564/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.05
Epoch 2565/10000; Iter 1/80; Loss: 0.4239
Epoch 2565/10000; Iter 51/80; Loss: 0.4247
Epoch 2565/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.044
Epoch 2566/10000; Iter 1/80; Loss: 0.4966
Epoch 2566/10000; Iter 51/80; Loss: 0.4143
Epoch 2566/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.055
Epoch 2567/10000; Iter 1/80; Loss: 0.4654
Epoch 2567/10000; Iter 51/80; Loss: 0.4703
Epoch 2567/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.047
Epoch 2568/10000; Iter 1/80; Loss: 0.4235
Epoch 2568/10000; Iter 51/80; Loss: 0.4067
Epoch 2568/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.05
Epoch 2569/10000; Iter 1/80; Loss: 0.3722
Epoch 2569/10000; Iter 51/80; Loss: 0.4593
Epoch 2569/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.043
Epoch 2570/10000; Iter 1/80; Loss: 0.4389
Epoch 2570/10000; Iter 51/80; Loss: 0.4314
Epoch 2570/10000; Iter 80/80; Training Loss: 0.4460, Test Loss: 0.046
Epoch 2571/10000; Iter 1/80; Loss: 0.4519
Epoch 2571/10000; Iter 51/80; Loss: 0.3716
Epoch 2571/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.048
Epoch 2572/10000; Iter 1/80; Loss: 0.4071
Epoch 2572/10000; Iter 51/80; Loss: 0.4494
Epoch 2572/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.039
Epoch 2573/10000; Iter 1/80; Loss: 0.4238
Epoch 2573/10000; Iter 51/80; Loss: 0.4086
Epoch 2573/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.043
Epoch 2574/10000; Iter 1/80; Loss: 0.4560
Epoch 2574/10000; Iter 51/80; Loss: 0.4415
Epoch 2574/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.05
Epoch 2575/10000; Iter 1/80; Loss: 0.4850
Epoch 2575/10000; Iter 51/80; Loss: 0.4256
Epoch 2575/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.043
Epoch 2576/10000; Iter 1/80; Loss: 0.4382
Epoch 2576/10000; Iter 51/80; Loss: 0.4102
Epoch 2576/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.056
Epoch 2577/10000; Iter 1/80; Loss: 0.4494
Epoch 2577/10000; Iter 51/80; Loss: 0.3972
Epoch 2577/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.047
Epoch 2578/10000; Iter 1/80; Loss: 0.4417
Epoch 2578/10000; Iter 51/80; Loss: 0.4334
Epoch 2578/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.049
Epoch 2579/10000; Iter 1/80; Loss: 0.4100
Epoch 2579/10000; Iter 51/80; Loss: 0.4315
Epoch 2579/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.05
Epoch 2580/10000; Iter 1/80; Loss: 0.4312
Epoch 2580/10000; Iter 51/80; Loss: 0.3997
Epoch 2580/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.05
Epoch 2581/10000; Iter 1/80; Loss: 0.4545
Epoch 2581/10000; Iter 51/80; Loss: 0.4485
Epoch 2581/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.05
Epoch 2582/10000; Iter 1/80; Loss: 0.4074
Epoch 2582/10000; Iter 51/80; Loss: 0.4524
Epoch 2582/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.045
Epoch 2583/10000; Iter 1/80; Loss: 0.3958
Epoch 2583/10000; Iter 51/80; Loss: 0.4085
Epoch 2583/10000; Iter 80/80; Training Loss: 0.4420, Test Loss: 0.054
Epoch 2584/10000; Iter 1/80; Loss: 0.4146
Epoch 2584/10000; Iter 51/80; Loss: 0.4727
Epoch 2584/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.05
Epoch 2585/10000; Iter 1/80; Loss: 0.4339
Epoch 2585/10000; Iter 51/80; Loss: 0.4976
Epoch 2585/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.043
Epoch 2586/10000; Iter 1/80; Loss: 0.4266
Epoch 2586/10000; Iter 51/80; Loss: 0.5413
Epoch 2586/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.058
Epoch 2587/10000; Iter 1/80; Loss: 0.4174
Epoch 2587/10000; Iter 51/80; Loss: 0.4481
Epoch 2587/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.044
Epoch 2588/10000; Iter 1/80; Loss: 0.4829
Epoch 2588/10000; Iter 51/80; Loss: 0.4816
Epoch 2588/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.044
Epoch 2589/10000; Iter 1/80; Loss: 0.5143
Epoch 2589/10000; Iter 51/80; Loss: 0.3854
Epoch 2589/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.047
Epoch 2590/10000; Iter 1/80; Loss: 0.4226
Epoch 2590/10000; Iter 51/80; Loss: 0.3763
Epoch 2590/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.04
Epoch 2591/10000; Iter 1/80; Loss: 0.4332
Epoch 2591/10000; Iter 51/80; Loss: 0.4782
Epoch 2591/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.046
Epoch 2592/10000; Iter 1/80; Loss: 0.4375
Epoch 2592/10000; Iter 51/80; Loss: 0.4602
Epoch 2592/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.046
Epoch 2593/10000; Iter 1/80; Loss: 0.4518
Epoch 2593/10000; Iter 51/80; Loss: 0.4797
Epoch 2593/10000; Iter 80/80; Training Loss: 0.4430, Test Loss: 0.058
Epoch 2594/10000; Iter 1/80; Loss: 0.4349
Epoch 2594/10000; Iter 51/80; Loss: 0.3763
Epoch 2594/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.05
Epoch 2595/10000; Iter 1/80; Loss: 0.4781
Epoch 2595/10000; Iter 51/80; Loss: 0.4473
Epoch 2595/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.057
Epoch 2596/10000; Iter 1/80; Loss: 0.4267
Epoch 2596/10000; Iter 51/80; Loss: 0.4855
Epoch 2596/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.044
Epoch 2597/10000; Iter 1/80; Loss: 0.4042
Epoch 2597/10000; Iter 51/80; Loss: 0.4518
Epoch 2597/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.052
Epoch 2598/10000; Iter 1/80; Loss: 0.3872
Epoch 2598/10000; Iter 51/80; Loss: 0.4390
Epoch 2598/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.048
Epoch 2599/10000; Iter 1/80; Loss: 0.4132
Epoch 2599/10000; Iter 51/80; Loss: 0.3669
Epoch 2599/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.059
Epoch 2600/10000; Iter 1/80; Loss: 0.4467
Epoch 2600/10000; Iter 51/80; Loss: 0.4525
Epoch 2600/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.045
Epoch 2601/10000; Iter 1/80; Loss: 0.4485
Epoch 2601/10000; Iter 51/80; Loss: 0.3896
Epoch 2601/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.048
Model saved
Epoch 2602/10000; Iter 1/80; Loss: 0.4249
Epoch 2602/10000; Iter 51/80; Loss: 0.3985
Epoch 2602/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.044
Epoch 2603/10000; Iter 1/80; Loss: 0.4788
Epoch 2603/10000; Iter 51/80; Loss: 0.5446
Epoch 2603/10000; Iter 80/80; Training Loss: 0.4440, Test Loss: 0.046
Epoch 2604/10000; Iter 1/80; Loss: 0.4316
Epoch 2604/10000; Iter 51/80; Loss: 0.3814
Epoch 2604/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.05
Epoch 2605/10000; Iter 1/80; Loss: 0.4557
Epoch 2605/10000; Iter 51/80; Loss: 0.4517
Epoch 2605/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.044
Epoch 2606/10000; Iter 1/80; Loss: 0.4650
Epoch 2606/10000; Iter 51/80; Loss: 0.4345
Epoch 2606/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.052
Epoch 2607/10000; Iter 1/80; Loss: 0.4807
Epoch 2607/10000; Iter 51/80; Loss: 0.3809
Epoch 2607/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.048
Epoch 2608/10000; Iter 1/80; Loss: 0.4156
Epoch 2608/10000; Iter 51/80; Loss: 0.4071
Epoch 2608/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.047
Epoch 2609/10000; Iter 1/80; Loss: 0.4656
Epoch 2609/10000; Iter 51/80; Loss: 0.4601
Epoch 2609/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.052
Epoch 2610/10000; Iter 1/80; Loss: 0.4561
Epoch 2610/10000; Iter 51/80; Loss: 0.3865
Epoch 2610/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.048
Epoch 2611/10000; Iter 1/80; Loss: 0.4000
Epoch 2611/10000; Iter 51/80; Loss: 0.4282
Epoch 2611/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.051
Epoch 2612/10000; Iter 1/80; Loss: 0.4261
Epoch 2612/10000; Iter 51/80; Loss: 0.4606
Epoch 2612/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.053
Epoch 2613/10000; Iter 1/80; Loss: 0.4052
Epoch 2613/10000; Iter 51/80; Loss: 0.4473
Epoch 2613/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.047
Epoch 2614/10000; Iter 1/80; Loss: 0.4080
Epoch 2614/10000; Iter 51/80; Loss: 0.4701
Epoch 2614/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.05
Epoch 2615/10000; Iter 1/80; Loss: 0.4647
Epoch 2615/10000; Iter 51/80; Loss: 0.4621
Epoch 2615/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.039
Epoch 2616/10000; Iter 1/80; Loss: 0.4184
Epoch 2616/10000; Iter 51/80; Loss: 0.4284
Epoch 2616/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.052
Epoch 2617/10000; Iter 1/80; Loss: 0.4531
Epoch 2617/10000; Iter 51/80; Loss: 0.4801
Epoch 2617/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.048
Epoch 2618/10000; Iter 1/80; Loss: 0.4084
Epoch 2618/10000; Iter 51/80; Loss: 0.3929
Epoch 2618/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.05
Epoch 2619/10000; Iter 1/80; Loss: 0.4796
Epoch 2619/10000; Iter 51/80; Loss: 0.4335
Epoch 2619/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.044
Epoch 2620/10000; Iter 1/80; Loss: 0.4698
Epoch 2620/10000; Iter 51/80; Loss: 0.4264
Epoch 2620/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.053
Epoch 2621/10000; Iter 1/80; Loss: 0.4040
Epoch 2621/10000; Iter 51/80; Loss: 0.4619
Epoch 2621/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.052
Epoch 2622/10000; Iter 1/80; Loss: 0.4599
Epoch 2622/10000; Iter 51/80; Loss: 0.3851
Epoch 2622/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.048
Epoch 2623/10000; Iter 1/80; Loss: 0.4922
Epoch 2623/10000; Iter 51/80; Loss: 0.4109
Epoch 2623/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.047
Epoch 2624/10000; Iter 1/80; Loss: 0.4447
Epoch 2624/10000; Iter 51/80; Loss: 0.4393
Epoch 2624/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.05
Epoch 2625/10000; Iter 1/80; Loss: 0.4917
Epoch 2625/10000; Iter 51/80; Loss: 0.3798
Epoch 2625/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.042
Epoch 2626/10000; Iter 1/80; Loss: 0.4671
Epoch 2626/10000; Iter 51/80; Loss: 0.4155
Epoch 2626/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.055
Epoch 2627/10000; Iter 1/80; Loss: 0.4283
Epoch 2627/10000; Iter 51/80; Loss: 0.4221
Epoch 2627/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.044
Epoch 2628/10000; Iter 1/80; Loss: 0.4673
Epoch 2628/10000; Iter 51/80; Loss: 0.5073
Epoch 2628/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.053
Epoch 2629/10000; Iter 1/80; Loss: 0.4262
Epoch 2629/10000; Iter 51/80; Loss: 0.3818
Epoch 2629/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.051
Epoch 2630/10000; Iter 1/80; Loss: 0.4470
Epoch 2630/10000; Iter 51/80; Loss: 0.4439
Epoch 2630/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.05
Epoch 2631/10000; Iter 1/80; Loss: 0.4265
Epoch 2631/10000; Iter 51/80; Loss: 0.4073
Epoch 2631/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.047
Epoch 2632/10000; Iter 1/80; Loss: 0.4314
Epoch 2632/10000; Iter 51/80; Loss: 0.4462
Epoch 2632/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.041
Epoch 2633/10000; Iter 1/80; Loss: 0.4422
Epoch 2633/10000; Iter 51/80; Loss: 0.4200
Epoch 2633/10000; Iter 80/80; Training Loss: 0.4380, Test Loss: 0.051
Epoch 2634/10000; Iter 1/80; Loss: 0.3685
Epoch 2634/10000; Iter 51/80; Loss: 0.4073
Epoch 2634/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.049
Epoch 2635/10000; Iter 1/80; Loss: 0.4182
Epoch 2635/10000; Iter 51/80; Loss: 0.3836
Epoch 2635/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.056
Epoch 2636/10000; Iter 1/80; Loss: 0.3741
Epoch 2636/10000; Iter 51/80; Loss: 0.4165
Epoch 2636/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.043
Epoch 2637/10000; Iter 1/80; Loss: 0.4428
Epoch 2637/10000; Iter 51/80; Loss: 0.4567
Epoch 2637/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.051
Epoch 2638/10000; Iter 1/80; Loss: 0.4638
Epoch 2638/10000; Iter 51/80; Loss: 0.4084
Epoch 2638/10000; Iter 80/80; Training Loss: 0.4400, Test Loss: 0.045
Epoch 2639/10000; Iter 1/80; Loss: 0.4359
Epoch 2639/10000; Iter 51/80; Loss: 0.4086
Epoch 2639/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.048
Epoch 2640/10000; Iter 1/80; Loss: 0.4853
Epoch 2640/10000; Iter 51/80; Loss: 0.4421
Epoch 2640/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.047
Epoch 2641/10000; Iter 1/80; Loss: 0.4249
Epoch 2641/10000; Iter 51/80; Loss: 0.4063
Epoch 2641/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.045
Epoch 2642/10000; Iter 1/80; Loss: 0.3957
Epoch 2642/10000; Iter 51/80; Loss: 0.4025
Epoch 2642/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.042
Epoch 2643/10000; Iter 1/80; Loss: 0.4264
Epoch 2643/10000; Iter 51/80; Loss: 0.4061
Epoch 2643/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.047
Epoch 2644/10000; Iter 1/80; Loss: 0.4248
Epoch 2644/10000; Iter 51/80; Loss: 0.4046
Epoch 2644/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.044
Epoch 2645/10000; Iter 1/80; Loss: 0.3684
Epoch 2645/10000; Iter 51/80; Loss: 0.3899
Epoch 2645/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.044
Epoch 2646/10000; Iter 1/80; Loss: 0.4861
Epoch 2646/10000; Iter 51/80; Loss: 0.4233
Epoch 2646/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.042
Epoch 2647/10000; Iter 1/80; Loss: 0.4946
Epoch 2647/10000; Iter 51/80; Loss: 0.4301
Epoch 2647/10000; Iter 80/80; Training Loss: 0.4390, Test Loss: 0.047
Epoch 2648/10000; Iter 1/80; Loss: 0.4172
Epoch 2648/10000; Iter 51/80; Loss: 0.3708
Epoch 2648/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.045
Epoch 2649/10000; Iter 1/80; Loss: 0.4351
Epoch 2649/10000; Iter 51/80; Loss: 0.4154
Epoch 2649/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.046
Epoch 2650/10000; Iter 1/80; Loss: 0.4875
Epoch 2650/10000; Iter 51/80; Loss: 0.4157
Epoch 2650/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.045
Epoch 2651/10000; Iter 1/80; Loss: 0.4218
Epoch 2651/10000; Iter 51/80; Loss: 0.4480
Epoch 2651/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.05
Epoch 2652/10000; Iter 1/80; Loss: 0.4535
Epoch 2652/10000; Iter 51/80; Loss: 0.4538
Epoch 2652/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.05
Epoch 2653/10000; Iter 1/80; Loss: 0.4182
Epoch 2653/10000; Iter 51/80; Loss: 0.4399
Epoch 2653/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.04
Epoch 2654/10000; Iter 1/80; Loss: 0.4977
Epoch 2654/10000; Iter 51/80; Loss: 0.4304
Epoch 2654/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.044
Epoch 2655/10000; Iter 1/80; Loss: 0.4339
Epoch 2655/10000; Iter 51/80; Loss: 0.4306
Epoch 2655/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.046
Epoch 2656/10000; Iter 1/80; Loss: 0.4237
Epoch 2656/10000; Iter 51/80; Loss: 0.4469
Epoch 2656/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.047
Epoch 2657/10000; Iter 1/80; Loss: 0.4245
Epoch 2657/10000; Iter 51/80; Loss: 0.4046
Epoch 2657/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.049
Epoch 2658/10000; Iter 1/80; Loss: 0.3492
Epoch 2658/10000; Iter 51/80; Loss: 0.4004
Epoch 2658/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.043
Epoch 2659/10000; Iter 1/80; Loss: 0.3797
Epoch 2659/10000; Iter 51/80; Loss: 0.4689
Epoch 2659/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.049
Epoch 2660/10000; Iter 1/80; Loss: 0.3964
Epoch 2660/10000; Iter 51/80; Loss: 0.4518
Epoch 2660/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.048
Epoch 2661/10000; Iter 1/80; Loss: 0.4306
Epoch 2661/10000; Iter 51/80; Loss: 0.4230
Epoch 2661/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.056
Epoch 2662/10000; Iter 1/80; Loss: 0.4791
Epoch 2662/10000; Iter 51/80; Loss: 0.4290
Epoch 2662/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.045
Epoch 2663/10000; Iter 1/80; Loss: 0.4930
Epoch 2663/10000; Iter 51/80; Loss: 0.4446
Epoch 2663/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.039
Epoch 2664/10000; Iter 1/80; Loss: 0.3943
Epoch 2664/10000; Iter 51/80; Loss: 0.3923
Epoch 2664/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.048
Epoch 2665/10000; Iter 1/80; Loss: 0.4120
Epoch 2665/10000; Iter 51/80; Loss: 0.4408
Epoch 2665/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.049
Epoch 2666/10000; Iter 1/80; Loss: 0.4450
Epoch 2666/10000; Iter 51/80; Loss: 0.4193
Epoch 2666/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.052
Epoch 2667/10000; Iter 1/80; Loss: 0.4081
Epoch 2667/10000; Iter 51/80; Loss: 0.3654
Epoch 2667/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.048
Epoch 2668/10000; Iter 1/80; Loss: 0.4336
Epoch 2668/10000; Iter 51/80; Loss: 0.4058
Epoch 2668/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.045
Epoch 2669/10000; Iter 1/80; Loss: 0.4500
Epoch 2669/10000; Iter 51/80; Loss: 0.4853
Epoch 2669/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.045
Epoch 2670/10000; Iter 1/80; Loss: 0.4679
Epoch 2670/10000; Iter 51/80; Loss: 0.4006
Epoch 2670/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.044
Epoch 2671/10000; Iter 1/80; Loss: 0.4368
Epoch 2671/10000; Iter 51/80; Loss: 0.3630
Epoch 2671/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.04
Epoch 2672/10000; Iter 1/80; Loss: 0.4544
Epoch 2672/10000; Iter 51/80; Loss: 0.5065
Epoch 2672/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.044
Epoch 2673/10000; Iter 1/80; Loss: 0.4413
Epoch 2673/10000; Iter 51/80; Loss: 0.4862
Epoch 2673/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.041
Epoch 2674/10000; Iter 1/80; Loss: 0.4560
Epoch 2674/10000; Iter 51/80; Loss: 0.3782
Epoch 2674/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.054
Epoch 2675/10000; Iter 1/80; Loss: 0.4235
Epoch 2675/10000; Iter 51/80; Loss: 0.4515
Epoch 2675/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.047
Epoch 2676/10000; Iter 1/80; Loss: 0.5099
Epoch 2676/10000; Iter 51/80; Loss: 0.4028
Epoch 2676/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.047
Epoch 2677/10000; Iter 1/80; Loss: 0.3960
Epoch 2677/10000; Iter 51/80; Loss: 0.4082
Epoch 2677/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.044
Epoch 2678/10000; Iter 1/80; Loss: 0.4296
Epoch 2678/10000; Iter 51/80; Loss: 0.3995
Epoch 2678/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.048
Epoch 2679/10000; Iter 1/80; Loss: 0.4455
Epoch 2679/10000; Iter 51/80; Loss: 0.4667
Epoch 2679/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.049
Epoch 2680/10000; Iter 1/80; Loss: 0.4891
Epoch 2680/10000; Iter 51/80; Loss: 0.3792
Epoch 2680/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.051
Epoch 2681/10000; Iter 1/80; Loss: 0.4331
Epoch 2681/10000; Iter 51/80; Loss: 0.3547
Epoch 2681/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.048
Epoch 2682/10000; Iter 1/80; Loss: 0.4192
Epoch 2682/10000; Iter 51/80; Loss: 0.4309
Epoch 2682/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.047
Epoch 2683/10000; Iter 1/80; Loss: 0.4046
Epoch 2683/10000; Iter 51/80; Loss: 0.4108
Epoch 2683/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.046
Epoch 2684/10000; Iter 1/80; Loss: 0.3952
Epoch 2684/10000; Iter 51/80; Loss: 0.4215
Epoch 2684/10000; Iter 80/80; Training Loss: 0.4360, Test Loss: 0.043
Epoch 2685/10000; Iter 1/80; Loss: 0.4065
Epoch 2685/10000; Iter 51/80; Loss: 0.4005
Epoch 2685/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.051
Epoch 2686/10000; Iter 1/80; Loss: 0.3877
Epoch 2686/10000; Iter 51/80; Loss: 0.4027
Epoch 2686/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.051
Epoch 2687/10000; Iter 1/80; Loss: 0.4116
Epoch 2687/10000; Iter 51/80; Loss: 0.4651
Epoch 2687/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.043
Epoch 2688/10000; Iter 1/80; Loss: 0.4304
Epoch 2688/10000; Iter 51/80; Loss: 0.4104
Epoch 2688/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.052
Epoch 2689/10000; Iter 1/80; Loss: 0.4645
Epoch 2689/10000; Iter 51/80; Loss: 0.3962
Epoch 2689/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.051
Epoch 2690/10000; Iter 1/80; Loss: 0.4343
Epoch 2690/10000; Iter 51/80; Loss: 0.4513
Epoch 2690/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.05
Epoch 2691/10000; Iter 1/80; Loss: 0.4324
Epoch 2691/10000; Iter 51/80; Loss: 0.4730
Epoch 2691/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.052
Epoch 2692/10000; Iter 1/80; Loss: 0.4356
Epoch 2692/10000; Iter 51/80; Loss: 0.4676
Epoch 2692/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.046
Epoch 2693/10000; Iter 1/80; Loss: 0.3586
Epoch 2693/10000; Iter 51/80; Loss: 0.4678
Epoch 2693/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.047
Epoch 2694/10000; Iter 1/80; Loss: 0.3585
Epoch 2694/10000; Iter 51/80; Loss: 0.4847
Epoch 2694/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.047
Epoch 2695/10000; Iter 1/80; Loss: 0.3863
Epoch 2695/10000; Iter 51/80; Loss: 0.4226
Epoch 2695/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.048
Epoch 2696/10000; Iter 1/80; Loss: 0.4557
Epoch 2696/10000; Iter 51/80; Loss: 0.3656
Epoch 2696/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.046
Epoch 2697/10000; Iter 1/80; Loss: 0.4631
Epoch 2697/10000; Iter 51/80; Loss: 0.4245
Epoch 2697/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.047
Epoch 2698/10000; Iter 1/80; Loss: 0.3743
Epoch 2698/10000; Iter 51/80; Loss: 0.3674
Epoch 2698/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.052
Epoch 2699/10000; Iter 1/80; Loss: 0.4493
Epoch 2699/10000; Iter 51/80; Loss: 0.3826
Epoch 2699/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.05
Epoch 2700/10000; Iter 1/80; Loss: 0.4691
Epoch 2700/10000; Iter 51/80; Loss: 0.4572
Epoch 2700/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.04
Epoch 2701/10000; Iter 1/80; Loss: 0.4363
Epoch 2701/10000; Iter 51/80; Loss: 0.4137
Epoch 2701/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.045
Model saved
Epoch 2702/10000; Iter 1/80; Loss: 0.3724
Epoch 2702/10000; Iter 51/80; Loss: 0.4431
Epoch 2702/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.054
Epoch 2703/10000; Iter 1/80; Loss: 0.5064
Epoch 2703/10000; Iter 51/80; Loss: 0.4426
Epoch 2703/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.049
Epoch 2704/10000; Iter 1/80; Loss: 0.4201
Epoch 2704/10000; Iter 51/80; Loss: 0.4078
Epoch 2704/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.043
Epoch 2705/10000; Iter 1/80; Loss: 0.4380
Epoch 2705/10000; Iter 51/80; Loss: 0.4495
Epoch 2705/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.047
Epoch 2706/10000; Iter 1/80; Loss: 0.4656
Epoch 2706/10000; Iter 51/80; Loss: 0.4338
Epoch 2706/10000; Iter 80/80; Training Loss: 0.4410, Test Loss: 0.054
Epoch 2707/10000; Iter 1/80; Loss: 0.4816
Epoch 2707/10000; Iter 51/80; Loss: 0.4648
Epoch 2707/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.046
Epoch 2708/10000; Iter 1/80; Loss: 0.3991
Epoch 2708/10000; Iter 51/80; Loss: 0.4111
Epoch 2708/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.045
Epoch 2709/10000; Iter 1/80; Loss: 0.4384
Epoch 2709/10000; Iter 51/80; Loss: 0.4483
Epoch 2709/10000; Iter 80/80; Training Loss: 0.4370, Test Loss: 0.048
Epoch 2710/10000; Iter 1/80; Loss: 0.4048
Epoch 2710/10000; Iter 51/80; Loss: 0.4291
Epoch 2710/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.05
Epoch 2711/10000; Iter 1/80; Loss: 0.4607
Epoch 2711/10000; Iter 51/80; Loss: 0.4071
Epoch 2711/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.045
Epoch 2712/10000; Iter 1/80; Loss: 0.4499
Epoch 2712/10000; Iter 51/80; Loss: 0.4331
Epoch 2712/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.041
Epoch 2713/10000; Iter 1/80; Loss: 0.3764
Epoch 2713/10000; Iter 51/80; Loss: 0.3945
Epoch 2713/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.049
Epoch 2714/10000; Iter 1/80; Loss: 0.4886
Epoch 2714/10000; Iter 51/80; Loss: 0.4537
Epoch 2714/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.041
Epoch 2715/10000; Iter 1/80; Loss: 0.4170
Epoch 2715/10000; Iter 51/80; Loss: 0.4159
Epoch 2715/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.043
Epoch 2716/10000; Iter 1/80; Loss: 0.3740
Epoch 2716/10000; Iter 51/80; Loss: 0.4508
Epoch 2716/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.054
Epoch 2717/10000; Iter 1/80; Loss: 0.4437
Epoch 2717/10000; Iter 51/80; Loss: 0.4261
Epoch 2717/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.045
Epoch 2718/10000; Iter 1/80; Loss: 0.4674
Epoch 2718/10000; Iter 51/80; Loss: 0.4010
Epoch 2718/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.052
Epoch 2719/10000; Iter 1/80; Loss: 0.4020
Epoch 2719/10000; Iter 51/80; Loss: 0.4093
Epoch 2719/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.047
Epoch 2720/10000; Iter 1/80; Loss: 0.4178
Epoch 2720/10000; Iter 51/80; Loss: 0.4374
Epoch 2720/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.046
Epoch 2721/10000; Iter 1/80; Loss: 0.4195
Epoch 2721/10000; Iter 51/80; Loss: 0.4133
Epoch 2721/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.051
Epoch 2722/10000; Iter 1/80; Loss: 0.4707
Epoch 2722/10000; Iter 51/80; Loss: 0.4068
Epoch 2722/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.042
Epoch 2723/10000; Iter 1/80; Loss: 0.3817
Epoch 2723/10000; Iter 51/80; Loss: 0.5086
Epoch 2723/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.047
Epoch 2724/10000; Iter 1/80; Loss: 0.4052
Epoch 2724/10000; Iter 51/80; Loss: 0.4304
Epoch 2724/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.044
Epoch 2725/10000; Iter 1/80; Loss: 0.4571
Epoch 2725/10000; Iter 51/80; Loss: 0.3433
Epoch 2725/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.048
Epoch 2726/10000; Iter 1/80; Loss: 0.4403
Epoch 2726/10000; Iter 51/80; Loss: 0.4431
Epoch 2726/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.052
Epoch 2727/10000; Iter 1/80; Loss: 0.4262
Epoch 2727/10000; Iter 51/80; Loss: 0.4385
Epoch 2727/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.042
Epoch 2728/10000; Iter 1/80; Loss: 0.4006
Epoch 2728/10000; Iter 51/80; Loss: 0.4070
Epoch 2728/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.051
Epoch 2729/10000; Iter 1/80; Loss: 0.3900
Epoch 2729/10000; Iter 51/80; Loss: 0.3972
Epoch 2729/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.04
Epoch 2730/10000; Iter 1/80; Loss: 0.4241
Epoch 2730/10000; Iter 51/80; Loss: 0.4823
Epoch 2730/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.046
Epoch 2731/10000; Iter 1/80; Loss: 0.4668
Epoch 2731/10000; Iter 51/80; Loss: 0.4576
Epoch 2731/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.04
Epoch 2732/10000; Iter 1/80; Loss: 0.4005
Epoch 2732/10000; Iter 51/80; Loss: 0.4721
Epoch 2732/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.044
Epoch 2733/10000; Iter 1/80; Loss: 0.4465
Epoch 2733/10000; Iter 51/80; Loss: 0.4417
Epoch 2733/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.038
Epoch 2734/10000; Iter 1/80; Loss: 0.4459
Epoch 2734/10000; Iter 51/80; Loss: 0.4461
Epoch 2734/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.05
Epoch 2735/10000; Iter 1/80; Loss: 0.3808
Epoch 2735/10000; Iter 51/80; Loss: 0.4233
Epoch 2735/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.047
Epoch 2736/10000; Iter 1/80; Loss: 0.4098
Epoch 2736/10000; Iter 51/80; Loss: 0.3701
Epoch 2736/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.046
Epoch 2737/10000; Iter 1/80; Loss: 0.5304
Epoch 2737/10000; Iter 51/80; Loss: 0.3609
Epoch 2737/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.055
Epoch 2738/10000; Iter 1/80; Loss: 0.4470
Epoch 2738/10000; Iter 51/80; Loss: 0.4534
Epoch 2738/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.044
Epoch 2739/10000; Iter 1/80; Loss: 0.3753
Epoch 2739/10000; Iter 51/80; Loss: 0.4367
Epoch 2739/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.047
Epoch 2740/10000; Iter 1/80; Loss: 0.4417
Epoch 2740/10000; Iter 51/80; Loss: 0.5381
Epoch 2740/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.048
Epoch 2741/10000; Iter 1/80; Loss: 0.3628
Epoch 2741/10000; Iter 51/80; Loss: 0.3874
Epoch 2741/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.047
Epoch 2742/10000; Iter 1/80; Loss: 0.3949
Epoch 2742/10000; Iter 51/80; Loss: 0.4008
Epoch 2742/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.049
Epoch 2743/10000; Iter 1/80; Loss: 0.4258
Epoch 2743/10000; Iter 51/80; Loss: 0.5005
Epoch 2743/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.053
Epoch 2744/10000; Iter 1/80; Loss: 0.4153
Epoch 2744/10000; Iter 51/80; Loss: 0.4796
Epoch 2744/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.044
Epoch 2745/10000; Iter 1/80; Loss: 0.4083
Epoch 2745/10000; Iter 51/80; Loss: 0.4530
Epoch 2745/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.053
Epoch 2746/10000; Iter 1/80; Loss: 0.3997
Epoch 2746/10000; Iter 51/80; Loss: 0.3995
Epoch 2746/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.046
Epoch 2747/10000; Iter 1/80; Loss: 0.3474
Epoch 2747/10000; Iter 51/80; Loss: 0.4653
Epoch 2747/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.052
Epoch 2748/10000; Iter 1/80; Loss: 0.5369
Epoch 2748/10000; Iter 51/80; Loss: 0.4555
Epoch 2748/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.045
Epoch 2749/10000; Iter 1/80; Loss: 0.3982
Epoch 2749/10000; Iter 51/80; Loss: 0.5038
Epoch 2749/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.05
Epoch 2750/10000; Iter 1/80; Loss: 0.4074
Epoch 2750/10000; Iter 51/80; Loss: 0.4255
Epoch 2750/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.042
Epoch 2751/10000; Iter 1/80; Loss: 0.4135
Epoch 2751/10000; Iter 51/80; Loss: 0.4734
Epoch 2751/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.051
Epoch 2752/10000; Iter 1/80; Loss: 0.3960
Epoch 2752/10000; Iter 51/80; Loss: 0.4202
Epoch 2752/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.041
Epoch 2753/10000; Iter 1/80; Loss: 0.4270
Epoch 2753/10000; Iter 51/80; Loss: 0.4360
Epoch 2753/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.042
Epoch 2754/10000; Iter 1/80; Loss: 0.4327
Epoch 2754/10000; Iter 51/80; Loss: 0.3764
Epoch 2754/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.05
Epoch 2755/10000; Iter 1/80; Loss: 0.4268
Epoch 2755/10000; Iter 51/80; Loss: 0.4555
Epoch 2755/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.043
Epoch 2756/10000; Iter 1/80; Loss: 0.4071
Epoch 2756/10000; Iter 51/80; Loss: 0.4395
Epoch 2756/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.048
Epoch 2757/10000; Iter 1/80; Loss: 0.4554
Epoch 2757/10000; Iter 51/80; Loss: 0.4325
Epoch 2757/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.052
Epoch 2758/10000; Iter 1/80; Loss: 0.4824
Epoch 2758/10000; Iter 51/80; Loss: 0.4789
Epoch 2758/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.048
Epoch 2759/10000; Iter 1/80; Loss: 0.4330
Epoch 2759/10000; Iter 51/80; Loss: 0.4445
Epoch 2759/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.054
Epoch 2760/10000; Iter 1/80; Loss: 0.5435
Epoch 2760/10000; Iter 51/80; Loss: 0.4088
Epoch 2760/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.047
Epoch 2761/10000; Iter 1/80; Loss: 0.4300
Epoch 2761/10000; Iter 51/80; Loss: 0.4235
Epoch 2761/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.043
Epoch 2762/10000; Iter 1/80; Loss: 0.4620
Epoch 2762/10000; Iter 51/80; Loss: 0.4898
Epoch 2762/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.045
Epoch 2763/10000; Iter 1/80; Loss: 0.3664
Epoch 2763/10000; Iter 51/80; Loss: 0.3653
Epoch 2763/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.043
Epoch 2764/10000; Iter 1/80; Loss: 0.5367
Epoch 2764/10000; Iter 51/80; Loss: 0.4243
Epoch 2764/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.056
Epoch 2765/10000; Iter 1/80; Loss: 0.4201
Epoch 2765/10000; Iter 51/80; Loss: 0.4707
Epoch 2765/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.053
Epoch 2766/10000; Iter 1/80; Loss: 0.4435
Epoch 2766/10000; Iter 51/80; Loss: 0.4037
Epoch 2766/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.048
Epoch 2767/10000; Iter 1/80; Loss: 0.4632
Epoch 2767/10000; Iter 51/80; Loss: 0.4204
Epoch 2767/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.045
Epoch 2768/10000; Iter 1/80; Loss: 0.4131
Epoch 2768/10000; Iter 51/80; Loss: 0.4573
Epoch 2768/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.05
Epoch 2769/10000; Iter 1/80; Loss: 0.4332
Epoch 2769/10000; Iter 51/80; Loss: 0.4639
Epoch 2769/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.044
Epoch 2770/10000; Iter 1/80; Loss: 0.3983
Epoch 2770/10000; Iter 51/80; Loss: 0.4749
Epoch 2770/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.054
Epoch 2771/10000; Iter 1/80; Loss: 0.4646
Epoch 2771/10000; Iter 51/80; Loss: 0.4308
Epoch 2771/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.047
Epoch 2772/10000; Iter 1/80; Loss: 0.4612
Epoch 2772/10000; Iter 51/80; Loss: 0.4437
Epoch 2772/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.045
Epoch 2773/10000; Iter 1/80; Loss: 0.4168
Epoch 2773/10000; Iter 51/80; Loss: 0.3963
Epoch 2773/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.048
Epoch 2774/10000; Iter 1/80; Loss: 0.4375
Epoch 2774/10000; Iter 51/80; Loss: 0.3906
Epoch 2774/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.043
Epoch 2775/10000; Iter 1/80; Loss: 0.3926
Epoch 2775/10000; Iter 51/80; Loss: 0.4447
Epoch 2775/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.057
Epoch 2776/10000; Iter 1/80; Loss: 0.4743
Epoch 2776/10000; Iter 51/80; Loss: 0.4489
Epoch 2776/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.046
Epoch 2777/10000; Iter 1/80; Loss: 0.4021
Epoch 2777/10000; Iter 51/80; Loss: 0.4009
Epoch 2777/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.048
Epoch 2778/10000; Iter 1/80; Loss: 0.4679
Epoch 2778/10000; Iter 51/80; Loss: 0.4398
Epoch 2778/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.047
Epoch 2779/10000; Iter 1/80; Loss: 0.4214
Epoch 2779/10000; Iter 51/80; Loss: 0.4462
Epoch 2779/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.046
Epoch 2780/10000; Iter 1/80; Loss: 0.4192
Epoch 2780/10000; Iter 51/80; Loss: 0.4309
Epoch 2780/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.05
Epoch 2781/10000; Iter 1/80; Loss: 0.4244
Epoch 2781/10000; Iter 51/80; Loss: 0.4646
Epoch 2781/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.052
Epoch 2782/10000; Iter 1/80; Loss: 0.4155
Epoch 2782/10000; Iter 51/80; Loss: 0.4256
Epoch 2782/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.051
Epoch 2783/10000; Iter 1/80; Loss: 0.4638
Epoch 2783/10000; Iter 51/80; Loss: 0.4553
Epoch 2783/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.047
Epoch 2784/10000; Iter 1/80; Loss: 0.4656
Epoch 2784/10000; Iter 51/80; Loss: 0.3443
Epoch 2784/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.049
Epoch 2785/10000; Iter 1/80; Loss: 0.3957
Epoch 2785/10000; Iter 51/80; Loss: 0.3812
Epoch 2785/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.046
Epoch 2786/10000; Iter 1/80; Loss: 0.4074
Epoch 2786/10000; Iter 51/80; Loss: 0.4342
Epoch 2786/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.046
Epoch 2787/10000; Iter 1/80; Loss: 0.4179
Epoch 2787/10000; Iter 51/80; Loss: 0.4111
Epoch 2787/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.046
Epoch 2788/10000; Iter 1/80; Loss: 0.4230
Epoch 2788/10000; Iter 51/80; Loss: 0.4936
Epoch 2788/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.047
Epoch 2789/10000; Iter 1/80; Loss: 0.4169
Epoch 2789/10000; Iter 51/80; Loss: 0.4366
Epoch 2789/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.051
Epoch 2790/10000; Iter 1/80; Loss: 0.4275
Epoch 2790/10000; Iter 51/80; Loss: 0.3910
Epoch 2790/10000; Iter 80/80; Training Loss: 0.4340, Test Loss: 0.042
Epoch 2791/10000; Iter 1/80; Loss: 0.4167
Epoch 2791/10000; Iter 51/80; Loss: 0.4374
Epoch 2791/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.05
Epoch 2792/10000; Iter 1/80; Loss: 0.4081
Epoch 2792/10000; Iter 51/80; Loss: 0.4754
Epoch 2792/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.048
Epoch 2793/10000; Iter 1/80; Loss: 0.4210
Epoch 2793/10000; Iter 51/80; Loss: 0.3798
Epoch 2793/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.053
Epoch 2794/10000; Iter 1/80; Loss: 0.4879
Epoch 2794/10000; Iter 51/80; Loss: 0.4722
Epoch 2794/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.045
Epoch 2795/10000; Iter 1/80; Loss: 0.4039
Epoch 2795/10000; Iter 51/80; Loss: 0.4964
Epoch 2795/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.049
Epoch 2796/10000; Iter 1/80; Loss: 0.4149
Epoch 2796/10000; Iter 51/80; Loss: 0.4414
Epoch 2796/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.044
Epoch 2797/10000; Iter 1/80; Loss: 0.3687
Epoch 2797/10000; Iter 51/80; Loss: 0.3553
Epoch 2797/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.046
Epoch 2798/10000; Iter 1/80; Loss: 0.4069
Epoch 2798/10000; Iter 51/80; Loss: 0.4172
Epoch 2798/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.048
Epoch 2799/10000; Iter 1/80; Loss: 0.4868
Epoch 2799/10000; Iter 51/80; Loss: 0.4331
Epoch 2799/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.048
Epoch 2800/10000; Iter 1/80; Loss: 0.4516
Epoch 2800/10000; Iter 51/80; Loss: 0.4872
Epoch 2800/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.043
Epoch 2801/10000; Iter 1/80; Loss: 0.4482
Epoch 2801/10000; Iter 51/80; Loss: 0.4100
Epoch 2801/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.044
Model saved
Epoch 2802/10000; Iter 1/80; Loss: 0.4521
Epoch 2802/10000; Iter 51/80; Loss: 0.4348
Epoch 2802/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.043
Epoch 2803/10000; Iter 1/80; Loss: 0.4270
Epoch 2803/10000; Iter 51/80; Loss: 0.4527
Epoch 2803/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.049
Epoch 2804/10000; Iter 1/80; Loss: 0.3615
Epoch 2804/10000; Iter 51/80; Loss: 0.3843
Epoch 2804/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.049
Epoch 2805/10000; Iter 1/80; Loss: 0.4142
Epoch 2805/10000; Iter 51/80; Loss: 0.3904
Epoch 2805/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.044
Epoch 2806/10000; Iter 1/80; Loss: 0.4035
Epoch 2806/10000; Iter 51/80; Loss: 0.4524
Epoch 2806/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.042
Epoch 2807/10000; Iter 1/80; Loss: 0.4159
Epoch 2807/10000; Iter 51/80; Loss: 0.3959
Epoch 2807/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.05
Epoch 2808/10000; Iter 1/80; Loss: 0.4989
Epoch 2808/10000; Iter 51/80; Loss: 0.4099
Epoch 2808/10000; Iter 80/80; Training Loss: 0.4330, Test Loss: 0.049
Epoch 2809/10000; Iter 1/80; Loss: 0.3736
Epoch 2809/10000; Iter 51/80; Loss: 0.4955
Epoch 2809/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.048
Epoch 2810/10000; Iter 1/80; Loss: 0.3868
Epoch 2810/10000; Iter 51/80; Loss: 0.4400
Epoch 2810/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.055
Epoch 2811/10000; Iter 1/80; Loss: 0.4116
Epoch 2811/10000; Iter 51/80; Loss: 0.4489
Epoch 2811/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.04
Epoch 2812/10000; Iter 1/80; Loss: 0.5106
Epoch 2812/10000; Iter 51/80; Loss: 0.3455
Epoch 2812/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.048
Epoch 2813/10000; Iter 1/80; Loss: 0.3652
Epoch 2813/10000; Iter 51/80; Loss: 0.4494
Epoch 2813/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.052
Epoch 2814/10000; Iter 1/80; Loss: 0.4473
Epoch 2814/10000; Iter 51/80; Loss: 0.3911
Epoch 2814/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.049
Epoch 2815/10000; Iter 1/80; Loss: 0.4412
Epoch 2815/10000; Iter 51/80; Loss: 0.4163
Epoch 2815/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.048
Epoch 2816/10000; Iter 1/80; Loss: 0.4175
Epoch 2816/10000; Iter 51/80; Loss: 0.5073
Epoch 2816/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.048
Epoch 2817/10000; Iter 1/80; Loss: 0.4751
Epoch 2817/10000; Iter 51/80; Loss: 0.4476
Epoch 2817/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.047
Epoch 2818/10000; Iter 1/80; Loss: 0.4575
Epoch 2818/10000; Iter 51/80; Loss: 0.4682
Epoch 2818/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.051
Epoch 2819/10000; Iter 1/80; Loss: 0.4959
Epoch 2819/10000; Iter 51/80; Loss: 0.4076
Epoch 2819/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.048
Epoch 2820/10000; Iter 1/80; Loss: 0.3751
Epoch 2820/10000; Iter 51/80; Loss: 0.3861
Epoch 2820/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.05
Epoch 2821/10000; Iter 1/80; Loss: 0.5041
Epoch 2821/10000; Iter 51/80; Loss: 0.4201
Epoch 2821/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.046
Epoch 2822/10000; Iter 1/80; Loss: 0.4361
Epoch 2822/10000; Iter 51/80; Loss: 0.4303
Epoch 2822/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.041
Epoch 2823/10000; Iter 1/80; Loss: 0.4280
Epoch 2823/10000; Iter 51/80; Loss: 0.4222
Epoch 2823/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.043
Epoch 2824/10000; Iter 1/80; Loss: 0.4224
Epoch 2824/10000; Iter 51/80; Loss: 0.4170
Epoch 2824/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.047
Epoch 2825/10000; Iter 1/80; Loss: 0.4212
Epoch 2825/10000; Iter 51/80; Loss: 0.4053
Epoch 2825/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.048
Epoch 2826/10000; Iter 1/80; Loss: 0.3951
Epoch 2826/10000; Iter 51/80; Loss: 0.3712
Epoch 2826/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.046
Epoch 2827/10000; Iter 1/80; Loss: 0.3908
Epoch 2827/10000; Iter 51/80; Loss: 0.4569
Epoch 2827/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.049
Epoch 2828/10000; Iter 1/80; Loss: 0.4466
Epoch 2828/10000; Iter 51/80; Loss: 0.4071
Epoch 2828/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.047
Epoch 2829/10000; Iter 1/80; Loss: 0.3953
Epoch 2829/10000; Iter 51/80; Loss: 0.4914
Epoch 2829/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.049
Epoch 2830/10000; Iter 1/80; Loss: 0.4169
Epoch 2830/10000; Iter 51/80; Loss: 0.4675
Epoch 2830/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.045
Epoch 2831/10000; Iter 1/80; Loss: 0.4094
Epoch 2831/10000; Iter 51/80; Loss: 0.4571
Epoch 2831/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.051
Epoch 2832/10000; Iter 1/80; Loss: 0.4226
Epoch 2832/10000; Iter 51/80; Loss: 0.3914
Epoch 2832/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.05
Epoch 2833/10000; Iter 1/80; Loss: 0.4359
Epoch 2833/10000; Iter 51/80; Loss: 0.4686
Epoch 2833/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.047
Epoch 2834/10000; Iter 1/80; Loss: 0.4768
Epoch 2834/10000; Iter 51/80; Loss: 0.4030
Epoch 2834/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.05
Epoch 2835/10000; Iter 1/80; Loss: 0.3794
Epoch 2835/10000; Iter 51/80; Loss: 0.4663
Epoch 2835/10000; Iter 80/80; Training Loss: 0.4300, Test Loss: 0.046
Epoch 2836/10000; Iter 1/80; Loss: 0.4181
Epoch 2836/10000; Iter 51/80; Loss: 0.4404
Epoch 2836/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.053
Epoch 2837/10000; Iter 1/80; Loss: 0.3823
Epoch 2837/10000; Iter 51/80; Loss: 0.4080
Epoch 2837/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.043
Epoch 2838/10000; Iter 1/80; Loss: 0.4297
Epoch 2838/10000; Iter 51/80; Loss: 0.4014
Epoch 2838/10000; Iter 80/80; Training Loss: 0.4320, Test Loss: 0.051
Epoch 2839/10000; Iter 1/80; Loss: 0.3988
Epoch 2839/10000; Iter 51/80; Loss: 0.3957
Epoch 2839/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.051
Epoch 2840/10000; Iter 1/80; Loss: 0.3761
Epoch 2840/10000; Iter 51/80; Loss: 0.4409
Epoch 2840/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.046
Epoch 2841/10000; Iter 1/80; Loss: 0.4052
Epoch 2841/10000; Iter 51/80; Loss: 0.4229
Epoch 2841/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.044
Epoch 2842/10000; Iter 1/80; Loss: 0.4122
Epoch 2842/10000; Iter 51/80; Loss: 0.3961
Epoch 2842/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.048
Epoch 2843/10000; Iter 1/80; Loss: 0.4827
Epoch 2843/10000; Iter 51/80; Loss: 0.4288
Epoch 2843/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.044
Epoch 2844/10000; Iter 1/80; Loss: 0.4189
Epoch 2844/10000; Iter 51/80; Loss: 0.4273
Epoch 2844/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.043
Epoch 2845/10000; Iter 1/80; Loss: 0.3785
Epoch 2845/10000; Iter 51/80; Loss: 0.5043
Epoch 2845/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.049
Epoch 2846/10000; Iter 1/80; Loss: 0.4369
Epoch 2846/10000; Iter 51/80; Loss: 0.3851
Epoch 2846/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.043
Epoch 2847/10000; Iter 1/80; Loss: 0.4315
Epoch 2847/10000; Iter 51/80; Loss: 0.3997
Epoch 2847/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.048
Epoch 2848/10000; Iter 1/80; Loss: 0.4242
Epoch 2848/10000; Iter 51/80; Loss: 0.4237
Epoch 2848/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.052
Epoch 2849/10000; Iter 1/80; Loss: 0.5417
Epoch 2849/10000; Iter 51/80; Loss: 0.4612
Epoch 2849/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.048
Epoch 2850/10000; Iter 1/80; Loss: 0.3707
Epoch 2850/10000; Iter 51/80; Loss: 0.4127
Epoch 2850/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.041
Epoch 2851/10000; Iter 1/80; Loss: 0.3891
Epoch 2851/10000; Iter 51/80; Loss: 0.4219
Epoch 2851/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.051
Epoch 2852/10000; Iter 1/80; Loss: 0.4102
Epoch 2852/10000; Iter 51/80; Loss: 0.3581
Epoch 2852/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.049
Epoch 2853/10000; Iter 1/80; Loss: 0.4216
Epoch 2853/10000; Iter 51/80; Loss: 0.3849
Epoch 2853/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.051
Epoch 2854/10000; Iter 1/80; Loss: 0.4416
Epoch 2854/10000; Iter 51/80; Loss: 0.3943
Epoch 2854/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.047
Epoch 2855/10000; Iter 1/80; Loss: 0.4249
Epoch 2855/10000; Iter 51/80; Loss: 0.4689
Epoch 2855/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.052
Epoch 2856/10000; Iter 1/80; Loss: 0.4005
Epoch 2856/10000; Iter 51/80; Loss: 0.4230
Epoch 2856/10000; Iter 80/80; Training Loss: 0.4350, Test Loss: 0.052
Epoch 2857/10000; Iter 1/80; Loss: 0.3452
Epoch 2857/10000; Iter 51/80; Loss: 0.4554
Epoch 2857/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.044
Epoch 2858/10000; Iter 1/80; Loss: 0.3827
Epoch 2858/10000; Iter 51/80; Loss: 0.4555
Epoch 2858/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.044
Epoch 2859/10000; Iter 1/80; Loss: 0.4448
Epoch 2859/10000; Iter 51/80; Loss: 0.4084
Epoch 2859/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.04
Epoch 2860/10000; Iter 1/80; Loss: 0.3865
Epoch 2860/10000; Iter 51/80; Loss: 0.3694
Epoch 2860/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.043
Epoch 2861/10000; Iter 1/80; Loss: 0.4035
Epoch 2861/10000; Iter 51/80; Loss: 0.4483
Epoch 2861/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.047
Epoch 2862/10000; Iter 1/80; Loss: 0.4103
Epoch 2862/10000; Iter 51/80; Loss: 0.4552
Epoch 2862/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.048
Epoch 2863/10000; Iter 1/80; Loss: 0.4655
Epoch 2863/10000; Iter 51/80; Loss: 0.4262
Epoch 2863/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.049
Epoch 2864/10000; Iter 1/80; Loss: 0.4691
Epoch 2864/10000; Iter 51/80; Loss: 0.4387
Epoch 2864/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.045
Epoch 2865/10000; Iter 1/80; Loss: 0.4022
Epoch 2865/10000; Iter 51/80; Loss: 0.4580
Epoch 2865/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.048
Epoch 2866/10000; Iter 1/80; Loss: 0.4772
Epoch 2866/10000; Iter 51/80; Loss: 0.4602
Epoch 2866/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.047
Epoch 2867/10000; Iter 1/80; Loss: 0.3816
Epoch 2867/10000; Iter 51/80; Loss: 0.4766
Epoch 2867/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.044
Epoch 2868/10000; Iter 1/80; Loss: 0.3791
Epoch 2868/10000; Iter 51/80; Loss: 0.4252
Epoch 2868/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.045
Epoch 2869/10000; Iter 1/80; Loss: 0.4442
Epoch 2869/10000; Iter 51/80; Loss: 0.3984
Epoch 2869/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.048
Epoch 2870/10000; Iter 1/80; Loss: 0.3896
Epoch 2870/10000; Iter 51/80; Loss: 0.4326
Epoch 2870/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.045
Epoch 2871/10000; Iter 1/80; Loss: 0.3886
Epoch 2871/10000; Iter 51/80; Loss: 0.4641
Epoch 2871/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.048
Epoch 2872/10000; Iter 1/80; Loss: 0.3985
Epoch 2872/10000; Iter 51/80; Loss: 0.4511
Epoch 2872/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.051
Epoch 2873/10000; Iter 1/80; Loss: 0.4194
Epoch 2873/10000; Iter 51/80; Loss: 0.4047
Epoch 2873/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.046
Epoch 2874/10000; Iter 1/80; Loss: 0.3973
Epoch 2874/10000; Iter 51/80; Loss: 0.3926
Epoch 2874/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.05
Epoch 2875/10000; Iter 1/80; Loss: 0.4205
Epoch 2875/10000; Iter 51/80; Loss: 0.4341
Epoch 2875/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.046
Epoch 2876/10000; Iter 1/80; Loss: 0.4125
Epoch 2876/10000; Iter 51/80; Loss: 0.4466
Epoch 2876/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.051
Epoch 2877/10000; Iter 1/80; Loss: 0.4409
Epoch 2877/10000; Iter 51/80; Loss: 0.3928
Epoch 2877/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.04
Epoch 2878/10000; Iter 1/80; Loss: 0.4059
Epoch 2878/10000; Iter 51/80; Loss: 0.3964
Epoch 2878/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.049
Epoch 2879/10000; Iter 1/80; Loss: 0.4316
Epoch 2879/10000; Iter 51/80; Loss: 0.4576
Epoch 2879/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.042
Epoch 2880/10000; Iter 1/80; Loss: 0.4133
Epoch 2880/10000; Iter 51/80; Loss: 0.4402
Epoch 2880/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.05
Epoch 2881/10000; Iter 1/80; Loss: 0.4037
Epoch 2881/10000; Iter 51/80; Loss: 0.4178
Epoch 2881/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.048
Epoch 2882/10000; Iter 1/80; Loss: 0.4143
Epoch 2882/10000; Iter 51/80; Loss: 0.4038
Epoch 2882/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.044
Epoch 2883/10000; Iter 1/80; Loss: 0.4732
Epoch 2883/10000; Iter 51/80; Loss: 0.4220
Epoch 2883/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.048
Epoch 2884/10000; Iter 1/80; Loss: 0.4198
Epoch 2884/10000; Iter 51/80; Loss: 0.3860
Epoch 2884/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.04
Epoch 2885/10000; Iter 1/80; Loss: 0.4175
Epoch 2885/10000; Iter 51/80; Loss: 0.4033
Epoch 2885/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.046
Epoch 2886/10000; Iter 1/80; Loss: 0.3964
Epoch 2886/10000; Iter 51/80; Loss: 0.3904
Epoch 2886/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.045
Epoch 2887/10000; Iter 1/80; Loss: 0.4260
Epoch 2887/10000; Iter 51/80; Loss: 0.4514
Epoch 2887/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.05
Epoch 2888/10000; Iter 1/80; Loss: 0.4952
Epoch 2888/10000; Iter 51/80; Loss: 0.4858
Epoch 2888/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.044
Epoch 2889/10000; Iter 1/80; Loss: 0.4206
Epoch 2889/10000; Iter 51/80; Loss: 0.4220
Epoch 2889/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.049
Epoch 2890/10000; Iter 1/80; Loss: 0.4062
Epoch 2890/10000; Iter 51/80; Loss: 0.3809
Epoch 2890/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.049
Epoch 2891/10000; Iter 1/80; Loss: 0.4544
Epoch 2891/10000; Iter 51/80; Loss: 0.4653
Epoch 2891/10000; Iter 80/80; Training Loss: 0.4310, Test Loss: 0.046
Epoch 2892/10000; Iter 1/80; Loss: 0.3739
Epoch 2892/10000; Iter 51/80; Loss: 0.4538
Epoch 2892/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.041
Epoch 2893/10000; Iter 1/80; Loss: 0.4110
Epoch 2893/10000; Iter 51/80; Loss: 0.4021
Epoch 2893/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.039
Epoch 2894/10000; Iter 1/80; Loss: 0.3821
Epoch 2894/10000; Iter 51/80; Loss: 0.4066
Epoch 2894/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.046
Epoch 2895/10000; Iter 1/80; Loss: 0.4415
Epoch 2895/10000; Iter 51/80; Loss: 0.5404
Epoch 2895/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.044
Epoch 2896/10000; Iter 1/80; Loss: 0.4075
Epoch 2896/10000; Iter 51/80; Loss: 0.4788
Epoch 2896/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.044
Epoch 2897/10000; Iter 1/80; Loss: 0.4331
Epoch 2897/10000; Iter 51/80; Loss: 0.4255
Epoch 2897/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.052
Epoch 2898/10000; Iter 1/80; Loss: 0.4348
Epoch 2898/10000; Iter 51/80; Loss: 0.4079
Epoch 2898/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.049
Epoch 2899/10000; Iter 1/80; Loss: 0.3692
Epoch 2899/10000; Iter 51/80; Loss: 0.4579
Epoch 2899/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.045
Epoch 2900/10000; Iter 1/80; Loss: 0.4264
Epoch 2900/10000; Iter 51/80; Loss: 0.3845
Epoch 2900/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.048
Epoch 2901/10000; Iter 1/80; Loss: 0.4076
Epoch 2901/10000; Iter 51/80; Loss: 0.4012
Epoch 2901/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.041
Model saved
Epoch 2902/10000; Iter 1/80; Loss: 0.4061
Epoch 2902/10000; Iter 51/80; Loss: 0.4439
Epoch 2902/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.047
Epoch 2903/10000; Iter 1/80; Loss: 0.4074
Epoch 2903/10000; Iter 51/80; Loss: 0.4122
Epoch 2903/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.048
Epoch 2904/10000; Iter 1/80; Loss: 0.4195
Epoch 2904/10000; Iter 51/80; Loss: 0.3734
Epoch 2904/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.053
Epoch 2905/10000; Iter 1/80; Loss: 0.4486
Epoch 2905/10000; Iter 51/80; Loss: 0.3487
Epoch 2905/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.046
Epoch 2906/10000; Iter 1/80; Loss: 0.3727
Epoch 2906/10000; Iter 51/80; Loss: 0.3600
Epoch 2906/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.046
Epoch 2907/10000; Iter 1/80; Loss: 0.4472
Epoch 2907/10000; Iter 51/80; Loss: 0.3927
Epoch 2907/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.054
Epoch 2908/10000; Iter 1/80; Loss: 0.3974
Epoch 2908/10000; Iter 51/80; Loss: 0.4418
Epoch 2908/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.048
Epoch 2909/10000; Iter 1/80; Loss: 0.4272
Epoch 2909/10000; Iter 51/80; Loss: 0.4205
Epoch 2909/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.05
Epoch 2910/10000; Iter 1/80; Loss: 0.4825
Epoch 2910/10000; Iter 51/80; Loss: 0.3816
Epoch 2910/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.049
Epoch 2911/10000; Iter 1/80; Loss: 0.3755
Epoch 2911/10000; Iter 51/80; Loss: 0.3804
Epoch 2911/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.048
Epoch 2912/10000; Iter 1/80; Loss: 0.4631
Epoch 2912/10000; Iter 51/80; Loss: 0.4504
Epoch 2912/10000; Iter 80/80; Training Loss: 0.4290, Test Loss: 0.048
Epoch 2913/10000; Iter 1/80; Loss: 0.4090
Epoch 2913/10000; Iter 51/80; Loss: 0.3828
Epoch 2913/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.042
Epoch 2914/10000; Iter 1/80; Loss: 0.3941
Epoch 2914/10000; Iter 51/80; Loss: 0.4136
Epoch 2914/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.045
Epoch 2915/10000; Iter 1/80; Loss: 0.3518
Epoch 2915/10000; Iter 51/80; Loss: 0.3939
Epoch 2915/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.046
Epoch 2916/10000; Iter 1/80; Loss: 0.4149
Epoch 2916/10000; Iter 51/80; Loss: 0.4032
Epoch 2916/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.041
Epoch 2917/10000; Iter 1/80; Loss: 0.3691
Epoch 2917/10000; Iter 51/80; Loss: 0.4071
Epoch 2917/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.041
Epoch 2918/10000; Iter 1/80; Loss: 0.4275
Epoch 2918/10000; Iter 51/80; Loss: 0.3788
Epoch 2918/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.046
Epoch 2919/10000; Iter 1/80; Loss: 0.4719
Epoch 2919/10000; Iter 51/80; Loss: 0.4502
Epoch 2919/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.045
Epoch 2920/10000; Iter 1/80; Loss: 0.3978
Epoch 2920/10000; Iter 51/80; Loss: 0.4323
Epoch 2920/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.046
Epoch 2921/10000; Iter 1/80; Loss: 0.4560
Epoch 2921/10000; Iter 51/80; Loss: 0.3663
Epoch 2921/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.051
Epoch 2922/10000; Iter 1/80; Loss: 0.4249
Epoch 2922/10000; Iter 51/80; Loss: 0.4966
Epoch 2922/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.048
Epoch 2923/10000; Iter 1/80; Loss: 0.4054
Epoch 2923/10000; Iter 51/80; Loss: 0.4955
Epoch 2923/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.048
Epoch 2924/10000; Iter 1/80; Loss: 0.4548
Epoch 2924/10000; Iter 51/80; Loss: 0.4497
Epoch 2924/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.046
Epoch 2925/10000; Iter 1/80; Loss: 0.4593
Epoch 2925/10000; Iter 51/80; Loss: 0.3700
Epoch 2925/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.046
Epoch 2926/10000; Iter 1/80; Loss: 0.4468
Epoch 2926/10000; Iter 51/80; Loss: 0.4107
Epoch 2926/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.049
Epoch 2927/10000; Iter 1/80; Loss: 0.3626
Epoch 2927/10000; Iter 51/80; Loss: 0.3931
Epoch 2927/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.044
Epoch 2928/10000; Iter 1/80; Loss: 0.3777
Epoch 2928/10000; Iter 51/80; Loss: 0.3959
Epoch 2928/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.049
Epoch 2929/10000; Iter 1/80; Loss: 0.4444
Epoch 2929/10000; Iter 51/80; Loss: 0.4173
Epoch 2929/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.052
Epoch 2930/10000; Iter 1/80; Loss: 0.4483
Epoch 2930/10000; Iter 51/80; Loss: 0.4513
Epoch 2930/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.046
Epoch 2931/10000; Iter 1/80; Loss: 0.4168
Epoch 2931/10000; Iter 51/80; Loss: 0.4065
Epoch 2931/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.051
Epoch 2932/10000; Iter 1/80; Loss: 0.4060
Epoch 2932/10000; Iter 51/80; Loss: 0.4625
Epoch 2932/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.041
Epoch 2933/10000; Iter 1/80; Loss: 0.5111
Epoch 2933/10000; Iter 51/80; Loss: 0.4351
Epoch 2933/10000; Iter 80/80; Training Loss: 0.4280, Test Loss: 0.04
Epoch 2934/10000; Iter 1/80; Loss: 0.4342
Epoch 2934/10000; Iter 51/80; Loss: 0.3994
Epoch 2934/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.046
Epoch 2935/10000; Iter 1/80; Loss: 0.3843
Epoch 2935/10000; Iter 51/80; Loss: 0.4688
Epoch 2935/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.044
Epoch 2936/10000; Iter 1/80; Loss: 0.4154
Epoch 2936/10000; Iter 51/80; Loss: 0.4843
Epoch 2936/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.046
Epoch 2937/10000; Iter 1/80; Loss: 0.4444
Epoch 2937/10000; Iter 51/80; Loss: 0.4188
Epoch 2937/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.047
Epoch 2938/10000; Iter 1/80; Loss: 0.4249
Epoch 2938/10000; Iter 51/80; Loss: 0.4311
Epoch 2938/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.041
Epoch 2939/10000; Iter 1/80; Loss: 0.4451
Epoch 2939/10000; Iter 51/80; Loss: 0.3635
Epoch 2939/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.048
Epoch 2940/10000; Iter 1/80; Loss: 0.4403
Epoch 2940/10000; Iter 51/80; Loss: 0.3824
Epoch 2940/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.048
Epoch 2941/10000; Iter 1/80; Loss: 0.3821
Epoch 2941/10000; Iter 51/80; Loss: 0.3991
Epoch 2941/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.042
Epoch 2942/10000; Iter 1/80; Loss: 0.4319
Epoch 2942/10000; Iter 51/80; Loss: 0.3594
Epoch 2942/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.05
Epoch 2943/10000; Iter 1/80; Loss: 0.4114
Epoch 2943/10000; Iter 51/80; Loss: 0.4392
Epoch 2943/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.048
Epoch 2944/10000; Iter 1/80; Loss: 0.4927
Epoch 2944/10000; Iter 51/80; Loss: 0.4092
Epoch 2944/10000; Iter 80/80; Training Loss: 0.4270, Test Loss: 0.047
Epoch 2945/10000; Iter 1/80; Loss: 0.4097
Epoch 2945/10000; Iter 51/80; Loss: 0.4246
Epoch 2945/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.051
Epoch 2946/10000; Iter 1/80; Loss: 0.4634
Epoch 2946/10000; Iter 51/80; Loss: 0.4380
Epoch 2946/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.04
Epoch 2947/10000; Iter 1/80; Loss: 0.4363
Epoch 2947/10000; Iter 51/80; Loss: 0.4196
Epoch 2947/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.039
Epoch 2948/10000; Iter 1/80; Loss: 0.3511
Epoch 2948/10000; Iter 51/80; Loss: 0.4897
Epoch 2948/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.05
Epoch 2949/10000; Iter 1/80; Loss: 0.4538
Epoch 2949/10000; Iter 51/80; Loss: 0.4338
Epoch 2949/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.042
Epoch 2950/10000; Iter 1/80; Loss: 0.4006
Epoch 2950/10000; Iter 51/80; Loss: 0.4915
Epoch 2950/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.045
Epoch 2951/10000; Iter 1/80; Loss: 0.4292
Epoch 2951/10000; Iter 51/80; Loss: 0.4062
Epoch 2951/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.044
Epoch 2952/10000; Iter 1/80; Loss: 0.4787
Epoch 2952/10000; Iter 51/80; Loss: 0.3861
Epoch 2952/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.047
Epoch 2953/10000; Iter 1/80; Loss: 0.4176
Epoch 2953/10000; Iter 51/80; Loss: 0.3817
Epoch 2953/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.047
Epoch 2954/10000; Iter 1/80; Loss: 0.4492
Epoch 2954/10000; Iter 51/80; Loss: 0.3878
Epoch 2954/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.045
Epoch 2955/10000; Iter 1/80; Loss: 0.4143
Epoch 2955/10000; Iter 51/80; Loss: 0.3814
Epoch 2955/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.042
Epoch 2956/10000; Iter 1/80; Loss: 0.4518
Epoch 2956/10000; Iter 51/80; Loss: 0.4565
Epoch 2956/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.04
Epoch 2957/10000; Iter 1/80; Loss: 0.4507
Epoch 2957/10000; Iter 51/80; Loss: 0.3810
Epoch 2957/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.042
Epoch 2958/10000; Iter 1/80; Loss: 0.4556
Epoch 2958/10000; Iter 51/80; Loss: 0.4080
Epoch 2958/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.045
Epoch 2959/10000; Iter 1/80; Loss: 0.4605
Epoch 2959/10000; Iter 51/80; Loss: 0.4020
Epoch 2959/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.052
Epoch 2960/10000; Iter 1/80; Loss: 0.4659
Epoch 2960/10000; Iter 51/80; Loss: 0.5002
Epoch 2960/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.048
Epoch 2961/10000; Iter 1/80; Loss: 0.4062
Epoch 2961/10000; Iter 51/80; Loss: 0.4537
Epoch 2961/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.037
Epoch 2962/10000; Iter 1/80; Loss: 0.4240
Epoch 2962/10000; Iter 51/80; Loss: 0.3672
Epoch 2962/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.045
Epoch 2963/10000; Iter 1/80; Loss: 0.4499
Epoch 2963/10000; Iter 51/80; Loss: 0.4234
Epoch 2963/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.047
Epoch 2964/10000; Iter 1/80; Loss: 0.4340
Epoch 2964/10000; Iter 51/80; Loss: 0.3676
Epoch 2964/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.047
Epoch 2965/10000; Iter 1/80; Loss: 0.4096
Epoch 2965/10000; Iter 51/80; Loss: 0.4373
Epoch 2965/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.045
Epoch 2966/10000; Iter 1/80; Loss: 0.4141
Epoch 2966/10000; Iter 51/80; Loss: 0.4321
Epoch 2966/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.044
Epoch 2967/10000; Iter 1/80; Loss: 0.3902
Epoch 2967/10000; Iter 51/80; Loss: 0.4418
Epoch 2967/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.049
Epoch 2968/10000; Iter 1/80; Loss: 0.4762
Epoch 2968/10000; Iter 51/80; Loss: 0.4287
Epoch 2968/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.05
Epoch 2969/10000; Iter 1/80; Loss: 0.4108
Epoch 2969/10000; Iter 51/80; Loss: 0.4229
Epoch 2969/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.04
Epoch 2970/10000; Iter 1/80; Loss: 0.3752
Epoch 2970/10000; Iter 51/80; Loss: 0.3678
Epoch 2970/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.042
Epoch 2971/10000; Iter 1/80; Loss: 0.4489
Epoch 2971/10000; Iter 51/80; Loss: 0.3818
Epoch 2971/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.043
Epoch 2972/10000; Iter 1/80; Loss: 0.4333
Epoch 2972/10000; Iter 51/80; Loss: 0.3952
Epoch 2972/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.047
Epoch 2973/10000; Iter 1/80; Loss: 0.4291
Epoch 2973/10000; Iter 51/80; Loss: 0.4324
Epoch 2973/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.048
Epoch 2974/10000; Iter 1/80; Loss: 0.4290
Epoch 2974/10000; Iter 51/80; Loss: 0.4064
Epoch 2974/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.051
Epoch 2975/10000; Iter 1/80; Loss: 0.4189
Epoch 2975/10000; Iter 51/80; Loss: 0.3603
Epoch 2975/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.047
Epoch 2976/10000; Iter 1/80; Loss: 0.3696
Epoch 2976/10000; Iter 51/80; Loss: 0.4092
Epoch 2976/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.054
Epoch 2977/10000; Iter 1/80; Loss: 0.4506
Epoch 2977/10000; Iter 51/80; Loss: 0.3312
Epoch 2977/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.042
Epoch 2978/10000; Iter 1/80; Loss: 0.3844
Epoch 2978/10000; Iter 51/80; Loss: 0.3880
Epoch 2978/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.045
Epoch 2979/10000; Iter 1/80; Loss: 0.4522
Epoch 2979/10000; Iter 51/80; Loss: 0.4125
Epoch 2979/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.053
Epoch 2980/10000; Iter 1/80; Loss: 0.4300
Epoch 2980/10000; Iter 51/80; Loss: 0.3969
Epoch 2980/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.048
Epoch 2981/10000; Iter 1/80; Loss: 0.4940
Epoch 2981/10000; Iter 51/80; Loss: 0.3753
Epoch 2981/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.052
Epoch 2982/10000; Iter 1/80; Loss: 0.3881
Epoch 2982/10000; Iter 51/80; Loss: 0.3825
Epoch 2982/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.043
Epoch 2983/10000; Iter 1/80; Loss: 0.3824
Epoch 2983/10000; Iter 51/80; Loss: 0.3913
Epoch 2983/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.048
Epoch 2984/10000; Iter 1/80; Loss: 0.4444
Epoch 2984/10000; Iter 51/80; Loss: 0.4298
Epoch 2984/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.047
Epoch 2985/10000; Iter 1/80; Loss: 0.4190
Epoch 2985/10000; Iter 51/80; Loss: 0.4850
Epoch 2985/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.041
Epoch 2986/10000; Iter 1/80; Loss: 0.4956
Epoch 2986/10000; Iter 51/80; Loss: 0.3843
Epoch 2986/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.045
Epoch 2987/10000; Iter 1/80; Loss: 0.3487
Epoch 2987/10000; Iter 51/80; Loss: 0.4562
Epoch 2987/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.049
Epoch 2988/10000; Iter 1/80; Loss: 0.4436
Epoch 2988/10000; Iter 51/80; Loss: 0.4429
Epoch 2988/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.049
Epoch 2989/10000; Iter 1/80; Loss: 0.4252
Epoch 2989/10000; Iter 51/80; Loss: 0.3796
Epoch 2989/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.047
Epoch 2990/10000; Iter 1/80; Loss: 0.3899
Epoch 2990/10000; Iter 51/80; Loss: 0.3970
Epoch 2990/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.038
Epoch 2991/10000; Iter 1/80; Loss: 0.4104
Epoch 2991/10000; Iter 51/80; Loss: 0.4540
Epoch 2991/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.042
Epoch 2992/10000; Iter 1/80; Loss: 0.4420
Epoch 2992/10000; Iter 51/80; Loss: 0.4227
Epoch 2992/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.052
Epoch 2993/10000; Iter 1/80; Loss: 0.4131
Epoch 2993/10000; Iter 51/80; Loss: 0.4181
Epoch 2993/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.043
Epoch 2994/10000; Iter 1/80; Loss: 0.4378
Epoch 2994/10000; Iter 51/80; Loss: 0.4721
Epoch 2994/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.047
Epoch 2995/10000; Iter 1/80; Loss: 0.4490
Epoch 2995/10000; Iter 51/80; Loss: 0.3962
Epoch 2995/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.043
Epoch 2996/10000; Iter 1/80; Loss: 0.4384
Epoch 2996/10000; Iter 51/80; Loss: 0.4015
Epoch 2996/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.043
Epoch 2997/10000; Iter 1/80; Loss: 0.3986
Epoch 2997/10000; Iter 51/80; Loss: 0.3923
Epoch 2997/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.05
Epoch 2998/10000; Iter 1/80; Loss: 0.4102
Epoch 2998/10000; Iter 51/80; Loss: 0.4110
Epoch 2998/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.046
Epoch 2999/10000; Iter 1/80; Loss: 0.4820
Epoch 2999/10000; Iter 51/80; Loss: 0.4369
Epoch 2999/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.047
Epoch 3000/10000; Iter 1/80; Loss: 0.4119
Epoch 3000/10000; Iter 51/80; Loss: 0.3851
Epoch 3000/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.051
Epoch 3001/10000; Iter 1/80; Loss: 0.4321
Epoch 3001/10000; Iter 51/80; Loss: 0.4262
Epoch 3001/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.052
Model saved
Epoch 3002/10000; Iter 1/80; Loss: 0.4566
Epoch 3002/10000; Iter 51/80; Loss: 0.4282
Epoch 3002/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.054
Epoch 3003/10000; Iter 1/80; Loss: 0.4089
Epoch 3003/10000; Iter 51/80; Loss: 0.4042
Epoch 3003/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.039
Epoch 3004/10000; Iter 1/80; Loss: 0.4120
Epoch 3004/10000; Iter 51/80; Loss: 0.4074
Epoch 3004/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.045
Epoch 3005/10000; Iter 1/80; Loss: 0.4062
Epoch 3005/10000; Iter 51/80; Loss: 0.3932
Epoch 3005/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.043
Epoch 3006/10000; Iter 1/80; Loss: 0.3730
Epoch 3006/10000; Iter 51/80; Loss: 0.4198
Epoch 3006/10000; Iter 80/80; Training Loss: 0.4260, Test Loss: 0.044
Epoch 3007/10000; Iter 1/80; Loss: 0.3679
Epoch 3007/10000; Iter 51/80; Loss: 0.3928
Epoch 3007/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.042
Epoch 3008/10000; Iter 1/80; Loss: 0.4087
Epoch 3008/10000; Iter 51/80; Loss: 0.4295
Epoch 3008/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.044
Epoch 3009/10000; Iter 1/80; Loss: 0.3863
Epoch 3009/10000; Iter 51/80; Loss: 0.3892
Epoch 3009/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.043
Epoch 3010/10000; Iter 1/80; Loss: 0.4672
Epoch 3010/10000; Iter 51/80; Loss: 0.3662
Epoch 3010/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.053
Epoch 3011/10000; Iter 1/80; Loss: 0.4157
Epoch 3011/10000; Iter 51/80; Loss: 0.3851
Epoch 3011/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.041
Epoch 3012/10000; Iter 1/80; Loss: 0.4112
Epoch 3012/10000; Iter 51/80; Loss: 0.4347
Epoch 3012/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.044
Epoch 3013/10000; Iter 1/80; Loss: 0.4541
Epoch 3013/10000; Iter 51/80; Loss: 0.4591
Epoch 3013/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.051
Epoch 3014/10000; Iter 1/80; Loss: 0.4621
Epoch 3014/10000; Iter 51/80; Loss: 0.3793
Epoch 3014/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.056
Epoch 3015/10000; Iter 1/80; Loss: 0.3573
Epoch 3015/10000; Iter 51/80; Loss: 0.3599
Epoch 3015/10000; Iter 80/80; Training Loss: 0.4240, Test Loss: 0.047
Epoch 3016/10000; Iter 1/80; Loss: 0.3922
Epoch 3016/10000; Iter 51/80; Loss: 0.4852
Epoch 3016/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.038
Epoch 3017/10000; Iter 1/80; Loss: 0.4094
Epoch 3017/10000; Iter 51/80; Loss: 0.3937
Epoch 3017/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.043
Epoch 3018/10000; Iter 1/80; Loss: 0.4377
Epoch 3018/10000; Iter 51/80; Loss: 0.4337
Epoch 3018/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.043
Epoch 3019/10000; Iter 1/80; Loss: 0.4499
Epoch 3019/10000; Iter 51/80; Loss: 0.5034
Epoch 3019/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.044
Epoch 3020/10000; Iter 1/80; Loss: 0.4302
Epoch 3020/10000; Iter 51/80; Loss: 0.3927
Epoch 3020/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.051
Epoch 3021/10000; Iter 1/80; Loss: 0.4390
Epoch 3021/10000; Iter 51/80; Loss: 0.3463
Epoch 3021/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.047
Epoch 3022/10000; Iter 1/80; Loss: 0.4266
Epoch 3022/10000; Iter 51/80; Loss: 0.3913
Epoch 3022/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.043
Epoch 3023/10000; Iter 1/80; Loss: 0.4232
Epoch 3023/10000; Iter 51/80; Loss: 0.4415
Epoch 3023/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3024/10000; Iter 1/80; Loss: 0.4315
Epoch 3024/10000; Iter 51/80; Loss: 0.4501
Epoch 3024/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.055
Epoch 3025/10000; Iter 1/80; Loss: 0.3798
Epoch 3025/10000; Iter 51/80; Loss: 0.5144
Epoch 3025/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.049
Epoch 3026/10000; Iter 1/80; Loss: 0.4246
Epoch 3026/10000; Iter 51/80; Loss: 0.4670
Epoch 3026/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.047
Epoch 3027/10000; Iter 1/80; Loss: 0.3978
Epoch 3027/10000; Iter 51/80; Loss: 0.4434
Epoch 3027/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.044
Epoch 3028/10000; Iter 1/80; Loss: 0.4131
Epoch 3028/10000; Iter 51/80; Loss: 0.4250
Epoch 3028/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.044
Epoch 3029/10000; Iter 1/80; Loss: 0.4217
Epoch 3029/10000; Iter 51/80; Loss: 0.3916
Epoch 3029/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.041
Epoch 3030/10000; Iter 1/80; Loss: 0.4479
Epoch 3030/10000; Iter 51/80; Loss: 0.4420
Epoch 3030/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.051
Epoch 3031/10000; Iter 1/80; Loss: 0.4273
Epoch 3031/10000; Iter 51/80; Loss: 0.4909
Epoch 3031/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.044
Epoch 3032/10000; Iter 1/80; Loss: 0.4374
Epoch 3032/10000; Iter 51/80; Loss: 0.4818
Epoch 3032/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.043
Epoch 3033/10000; Iter 1/80; Loss: 0.3563
Epoch 3033/10000; Iter 51/80; Loss: 0.4592
Epoch 3033/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.044
Epoch 3034/10000; Iter 1/80; Loss: 0.3870
Epoch 3034/10000; Iter 51/80; Loss: 0.3725
Epoch 3034/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.043
Epoch 3035/10000; Iter 1/80; Loss: 0.3881
Epoch 3035/10000; Iter 51/80; Loss: 0.4678
Epoch 3035/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.045
Epoch 3036/10000; Iter 1/80; Loss: 0.4346
Epoch 3036/10000; Iter 51/80; Loss: 0.3969
Epoch 3036/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.042
Epoch 3037/10000; Iter 1/80; Loss: 0.4263
Epoch 3037/10000; Iter 51/80; Loss: 0.3619
Epoch 3037/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.041
Epoch 3038/10000; Iter 1/80; Loss: 0.4270
Epoch 3038/10000; Iter 51/80; Loss: 0.4416
Epoch 3038/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.052
Epoch 3039/10000; Iter 1/80; Loss: 0.3711
Epoch 3039/10000; Iter 51/80; Loss: 0.3982
Epoch 3039/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.047
Epoch 3040/10000; Iter 1/80; Loss: 0.3925
Epoch 3040/10000; Iter 51/80; Loss: 0.5317
Epoch 3040/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.04
Epoch 3041/10000; Iter 1/80; Loss: 0.4641
Epoch 3041/10000; Iter 51/80; Loss: 0.4501
Epoch 3041/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.038
Epoch 3042/10000; Iter 1/80; Loss: 0.4805
Epoch 3042/10000; Iter 51/80; Loss: 0.4590
Epoch 3042/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.05
Epoch 3043/10000; Iter 1/80; Loss: 0.4225
Epoch 3043/10000; Iter 51/80; Loss: 0.4619
Epoch 3043/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.047
Epoch 3044/10000; Iter 1/80; Loss: 0.4154
Epoch 3044/10000; Iter 51/80; Loss: 0.4194
Epoch 3044/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.047
Epoch 3045/10000; Iter 1/80; Loss: 0.4352
Epoch 3045/10000; Iter 51/80; Loss: 0.4042
Epoch 3045/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.046
Epoch 3046/10000; Iter 1/80; Loss: 0.4293
Epoch 3046/10000; Iter 51/80; Loss: 0.3779
Epoch 3046/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.049
Epoch 3047/10000; Iter 1/80; Loss: 0.4540
Epoch 3047/10000; Iter 51/80; Loss: 0.4318
Epoch 3047/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.043
Epoch 3048/10000; Iter 1/80; Loss: 0.4131
Epoch 3048/10000; Iter 51/80; Loss: 0.4272
Epoch 3048/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.043
Epoch 3049/10000; Iter 1/80; Loss: 0.4232
Epoch 3049/10000; Iter 51/80; Loss: 0.4298
Epoch 3049/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.04
Epoch 3050/10000; Iter 1/80; Loss: 0.3888
Epoch 3050/10000; Iter 51/80; Loss: 0.4060
Epoch 3050/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.048
Epoch 3051/10000; Iter 1/80; Loss: 0.4236
Epoch 3051/10000; Iter 51/80; Loss: 0.4066
Epoch 3051/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.043
Epoch 3052/10000; Iter 1/80; Loss: 0.3416
Epoch 3052/10000; Iter 51/80; Loss: 0.4074
Epoch 3052/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.044
Epoch 3053/10000; Iter 1/80; Loss: 0.4076
Epoch 3053/10000; Iter 51/80; Loss: 0.4501
Epoch 3053/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.045
Epoch 3054/10000; Iter 1/80; Loss: 0.3973
Epoch 3054/10000; Iter 51/80; Loss: 0.4805
Epoch 3054/10000; Iter 80/80; Training Loss: 0.4200, Test Loss: 0.043
Epoch 3055/10000; Iter 1/80; Loss: 0.4316
Epoch 3055/10000; Iter 51/80; Loss: 0.4215
Epoch 3055/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.041
Epoch 3056/10000; Iter 1/80; Loss: 0.3789
Epoch 3056/10000; Iter 51/80; Loss: 0.3761
Epoch 3056/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.049
Epoch 3057/10000; Iter 1/80; Loss: 0.3788
Epoch 3057/10000; Iter 51/80; Loss: 0.4180
Epoch 3057/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.051
Epoch 3058/10000; Iter 1/80; Loss: 0.3862
Epoch 3058/10000; Iter 51/80; Loss: 0.4148
Epoch 3058/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.045
Epoch 3059/10000; Iter 1/80; Loss: 0.4327
Epoch 3059/10000; Iter 51/80; Loss: 0.4576
Epoch 3059/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.047
Epoch 3060/10000; Iter 1/80; Loss: 0.3878
Epoch 3060/10000; Iter 51/80; Loss: 0.4366
Epoch 3060/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.053
Epoch 3061/10000; Iter 1/80; Loss: 0.4314
Epoch 3061/10000; Iter 51/80; Loss: 0.4005
Epoch 3061/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.046
Epoch 3062/10000; Iter 1/80; Loss: 0.4101
Epoch 3062/10000; Iter 51/80; Loss: 0.3440
Epoch 3062/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.043
Epoch 3063/10000; Iter 1/80; Loss: 0.4003
Epoch 3063/10000; Iter 51/80; Loss: 0.3996
Epoch 3063/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.049
Epoch 3064/10000; Iter 1/80; Loss: 0.4320
Epoch 3064/10000; Iter 51/80; Loss: 0.4404
Epoch 3064/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.043
Epoch 3065/10000; Iter 1/80; Loss: 0.4395
Epoch 3065/10000; Iter 51/80; Loss: 0.4000
Epoch 3065/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.048
Epoch 3066/10000; Iter 1/80; Loss: 0.3630
Epoch 3066/10000; Iter 51/80; Loss: 0.3926
Epoch 3066/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.044
Epoch 3067/10000; Iter 1/80; Loss: 0.4370
Epoch 3067/10000; Iter 51/80; Loss: 0.3882
Epoch 3067/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.044
Epoch 3068/10000; Iter 1/80; Loss: 0.4068
Epoch 3068/10000; Iter 51/80; Loss: 0.4577
Epoch 3068/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.048
Epoch 3069/10000; Iter 1/80; Loss: 0.3862
Epoch 3069/10000; Iter 51/80; Loss: 0.3763
Epoch 3069/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.048
Epoch 3070/10000; Iter 1/80; Loss: 0.4295
Epoch 3070/10000; Iter 51/80; Loss: 0.4690
Epoch 3070/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.043
Epoch 3071/10000; Iter 1/80; Loss: 0.3889
Epoch 3071/10000; Iter 51/80; Loss: 0.4573
Epoch 3071/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.042
Epoch 3072/10000; Iter 1/80; Loss: 0.3874
Epoch 3072/10000; Iter 51/80; Loss: 0.4315
Epoch 3072/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.039
Epoch 3073/10000; Iter 1/80; Loss: 0.3513
Epoch 3073/10000; Iter 51/80; Loss: 0.3785
Epoch 3073/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.046
Epoch 3074/10000; Iter 1/80; Loss: 0.4041
Epoch 3074/10000; Iter 51/80; Loss: 0.3558
Epoch 3074/10000; Iter 80/80; Training Loss: 0.4230, Test Loss: 0.045
Epoch 3075/10000; Iter 1/80; Loss: 0.4648
Epoch 3075/10000; Iter 51/80; Loss: 0.3718
Epoch 3075/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.046
Epoch 3076/10000; Iter 1/80; Loss: 0.4699
Epoch 3076/10000; Iter 51/80; Loss: 0.4214
Epoch 3076/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.047
Epoch 3077/10000; Iter 1/80; Loss: 0.4488
Epoch 3077/10000; Iter 51/80; Loss: 0.3786
Epoch 3077/10000; Iter 80/80; Training Loss: 0.4250, Test Loss: 0.045
Epoch 3078/10000; Iter 1/80; Loss: 0.4445
Epoch 3078/10000; Iter 51/80; Loss: 0.4066
Epoch 3078/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.049
Epoch 3079/10000; Iter 1/80; Loss: 0.4924
Epoch 3079/10000; Iter 51/80; Loss: 0.4038
Epoch 3079/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.04
Epoch 3080/10000; Iter 1/80; Loss: 0.4054
Epoch 3080/10000; Iter 51/80; Loss: 0.4723
Epoch 3080/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.044
Epoch 3081/10000; Iter 1/80; Loss: 0.4721
Epoch 3081/10000; Iter 51/80; Loss: 0.4362
Epoch 3081/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.048
Epoch 3082/10000; Iter 1/80; Loss: 0.5116
Epoch 3082/10000; Iter 51/80; Loss: 0.4127
Epoch 3082/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.044
Epoch 3083/10000; Iter 1/80; Loss: 0.4707
Epoch 3083/10000; Iter 51/80; Loss: 0.3842
Epoch 3083/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.049
Epoch 3084/10000; Iter 1/80; Loss: 0.4368
Epoch 3084/10000; Iter 51/80; Loss: 0.4141
Epoch 3084/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.044
Epoch 3085/10000; Iter 1/80; Loss: 0.4217
Epoch 3085/10000; Iter 51/80; Loss: 0.3985
Epoch 3085/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.053
Epoch 3086/10000; Iter 1/80; Loss: 0.3880
Epoch 3086/10000; Iter 51/80; Loss: 0.3841
Epoch 3086/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.046
Epoch 3087/10000; Iter 1/80; Loss: 0.4400
Epoch 3087/10000; Iter 51/80; Loss: 0.3804
Epoch 3087/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.049
Epoch 3088/10000; Iter 1/80; Loss: 0.4191
Epoch 3088/10000; Iter 51/80; Loss: 0.4128
Epoch 3088/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.049
Epoch 3089/10000; Iter 1/80; Loss: 0.4204
Epoch 3089/10000; Iter 51/80; Loss: 0.3914
Epoch 3089/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.044
Epoch 3090/10000; Iter 1/80; Loss: 0.4833
Epoch 3090/10000; Iter 51/80; Loss: 0.4404
Epoch 3090/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.041
Epoch 3091/10000; Iter 1/80; Loss: 0.4472
Epoch 3091/10000; Iter 51/80; Loss: 0.3857
Epoch 3091/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3092/10000; Iter 1/80; Loss: 0.4280
Epoch 3092/10000; Iter 51/80; Loss: 0.3987
Epoch 3092/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.041
Epoch 3093/10000; Iter 1/80; Loss: 0.3899
Epoch 3093/10000; Iter 51/80; Loss: 0.3766
Epoch 3093/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.056
Epoch 3094/10000; Iter 1/80; Loss: 0.4628
Epoch 3094/10000; Iter 51/80; Loss: 0.4875
Epoch 3094/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.048
Epoch 3095/10000; Iter 1/80; Loss: 0.4304
Epoch 3095/10000; Iter 51/80; Loss: 0.4083
Epoch 3095/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.043
Epoch 3096/10000; Iter 1/80; Loss: 0.4369
Epoch 3096/10000; Iter 51/80; Loss: 0.4968
Epoch 3096/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.045
Epoch 3097/10000; Iter 1/80; Loss: 0.4381
Epoch 3097/10000; Iter 51/80; Loss: 0.4124
Epoch 3097/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.051
Epoch 3098/10000; Iter 1/80; Loss: 0.3348
Epoch 3098/10000; Iter 51/80; Loss: 0.4783
Epoch 3098/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.044
Epoch 3099/10000; Iter 1/80; Loss: 0.4184
Epoch 3099/10000; Iter 51/80; Loss: 0.3946
Epoch 3099/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.042
Epoch 3100/10000; Iter 1/80; Loss: 0.3877
Epoch 3100/10000; Iter 51/80; Loss: 0.4065
Epoch 3100/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.04
Epoch 3101/10000; Iter 1/80; Loss: 0.3805
Epoch 3101/10000; Iter 51/80; Loss: 0.5382
Epoch 3101/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.043
Model saved
Epoch 3102/10000; Iter 1/80; Loss: 0.3897
Epoch 3102/10000; Iter 51/80; Loss: 0.4161
Epoch 3102/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.051
Epoch 3103/10000; Iter 1/80; Loss: 0.3907
Epoch 3103/10000; Iter 51/80; Loss: 0.4146
Epoch 3103/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.047
Epoch 3104/10000; Iter 1/80; Loss: 0.4002
Epoch 3104/10000; Iter 51/80; Loss: 0.3850
Epoch 3104/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.055
Epoch 3105/10000; Iter 1/80; Loss: 0.5153
Epoch 3105/10000; Iter 51/80; Loss: 0.3938
Epoch 3105/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.044
Epoch 3106/10000; Iter 1/80; Loss: 0.4531
Epoch 3106/10000; Iter 51/80; Loss: 0.3933
Epoch 3106/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.044
Epoch 3107/10000; Iter 1/80; Loss: 0.3963
Epoch 3107/10000; Iter 51/80; Loss: 0.3605
Epoch 3107/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.048
Epoch 3108/10000; Iter 1/80; Loss: 0.3641
Epoch 3108/10000; Iter 51/80; Loss: 0.4465
Epoch 3108/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.05
Epoch 3109/10000; Iter 1/80; Loss: 0.4509
Epoch 3109/10000; Iter 51/80; Loss: 0.4361
Epoch 3109/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.041
Epoch 3110/10000; Iter 1/80; Loss: 0.4003
Epoch 3110/10000; Iter 51/80; Loss: 0.4335
Epoch 3110/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.042
Epoch 3111/10000; Iter 1/80; Loss: 0.4178
Epoch 3111/10000; Iter 51/80; Loss: 0.4163
Epoch 3111/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.05
Epoch 3112/10000; Iter 1/80; Loss: 0.3955
Epoch 3112/10000; Iter 51/80; Loss: 0.4805
Epoch 3112/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.044
Epoch 3113/10000; Iter 1/80; Loss: 0.3894
Epoch 3113/10000; Iter 51/80; Loss: 0.3968
Epoch 3113/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.049
Epoch 3114/10000; Iter 1/80; Loss: 0.4131
Epoch 3114/10000; Iter 51/80; Loss: 0.4063
Epoch 3114/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.048
Epoch 3115/10000; Iter 1/80; Loss: 0.4275
Epoch 3115/10000; Iter 51/80; Loss: 0.4235
Epoch 3115/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.041
Epoch 3116/10000; Iter 1/80; Loss: 0.3879
Epoch 3116/10000; Iter 51/80; Loss: 0.4359
Epoch 3116/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.053
Epoch 3117/10000; Iter 1/80; Loss: 0.4509
Epoch 3117/10000; Iter 51/80; Loss: 0.4052
Epoch 3117/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.046
Epoch 3118/10000; Iter 1/80; Loss: 0.4126
Epoch 3118/10000; Iter 51/80; Loss: 0.4053
Epoch 3118/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.044
Epoch 3119/10000; Iter 1/80; Loss: 0.4368
Epoch 3119/10000; Iter 51/80; Loss: 0.3961
Epoch 3119/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.046
Epoch 3120/10000; Iter 1/80; Loss: 0.4486
Epoch 3120/10000; Iter 51/80; Loss: 0.4765
Epoch 3120/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.047
Epoch 3121/10000; Iter 1/80; Loss: 0.3475
Epoch 3121/10000; Iter 51/80; Loss: 0.3677
Epoch 3121/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.044
Epoch 3122/10000; Iter 1/80; Loss: 0.3559
Epoch 3122/10000; Iter 51/80; Loss: 0.3971
Epoch 3122/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.044
Epoch 3123/10000; Iter 1/80; Loss: 0.4928
Epoch 3123/10000; Iter 51/80; Loss: 0.3606
Epoch 3123/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.044
Epoch 3124/10000; Iter 1/80; Loss: 0.3642
Epoch 3124/10000; Iter 51/80; Loss: 0.4347
Epoch 3124/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.044
Epoch 3125/10000; Iter 1/80; Loss: 0.3893
Epoch 3125/10000; Iter 51/80; Loss: 0.4050
Epoch 3125/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.048
Epoch 3126/10000; Iter 1/80; Loss: 0.3640
Epoch 3126/10000; Iter 51/80; Loss: 0.4166
Epoch 3126/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.042
Epoch 3127/10000; Iter 1/80; Loss: 0.3954
Epoch 3127/10000; Iter 51/80; Loss: 0.4637
Epoch 3127/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.047
Epoch 3128/10000; Iter 1/80; Loss: 0.3892
Epoch 3128/10000; Iter 51/80; Loss: 0.3648
Epoch 3128/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.053
Epoch 3129/10000; Iter 1/80; Loss: 0.4380
Epoch 3129/10000; Iter 51/80; Loss: 0.4680
Epoch 3129/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.05
Epoch 3130/10000; Iter 1/80; Loss: 0.4237
Epoch 3130/10000; Iter 51/80; Loss: 0.4412
Epoch 3130/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.048
Epoch 3131/10000; Iter 1/80; Loss: 0.3672
Epoch 3131/10000; Iter 51/80; Loss: 0.3805
Epoch 3131/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.048
Epoch 3132/10000; Iter 1/80; Loss: 0.4386
Epoch 3132/10000; Iter 51/80; Loss: 0.4000
Epoch 3132/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.051
Epoch 3133/10000; Iter 1/80; Loss: 0.3863
Epoch 3133/10000; Iter 51/80; Loss: 0.4169
Epoch 3133/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.048
Epoch 3134/10000; Iter 1/80; Loss: 0.4313
Epoch 3134/10000; Iter 51/80; Loss: 0.4492
Epoch 3134/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.045
Epoch 3135/10000; Iter 1/80; Loss: 0.4594
Epoch 3135/10000; Iter 51/80; Loss: 0.4402
Epoch 3135/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.041
Epoch 3136/10000; Iter 1/80; Loss: 0.3830
Epoch 3136/10000; Iter 51/80; Loss: 0.3687
Epoch 3136/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.046
Epoch 3137/10000; Iter 1/80; Loss: 0.3736
Epoch 3137/10000; Iter 51/80; Loss: 0.3974
Epoch 3137/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.048
Epoch 3138/10000; Iter 1/80; Loss: 0.4000
Epoch 3138/10000; Iter 51/80; Loss: 0.4006
Epoch 3138/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.046
Epoch 3139/10000; Iter 1/80; Loss: 0.3999
Epoch 3139/10000; Iter 51/80; Loss: 0.4347
Epoch 3139/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.054
Epoch 3140/10000; Iter 1/80; Loss: 0.4239
Epoch 3140/10000; Iter 51/80; Loss: 0.4373
Epoch 3140/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.045
Epoch 3141/10000; Iter 1/80; Loss: 0.3974
Epoch 3141/10000; Iter 51/80; Loss: 0.4242
Epoch 3141/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.047
Epoch 3142/10000; Iter 1/80; Loss: 0.4671
Epoch 3142/10000; Iter 51/80; Loss: 0.3792
Epoch 3142/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.047
Epoch 3143/10000; Iter 1/80; Loss: 0.3672
Epoch 3143/10000; Iter 51/80; Loss: 0.4097
Epoch 3143/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.047
Epoch 3144/10000; Iter 1/80; Loss: 0.4026
Epoch 3144/10000; Iter 51/80; Loss: 0.3755
Epoch 3144/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.047
Epoch 3145/10000; Iter 1/80; Loss: 0.3992
Epoch 3145/10000; Iter 51/80; Loss: 0.3713
Epoch 3145/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.045
Epoch 3146/10000; Iter 1/80; Loss: 0.4469
Epoch 3146/10000; Iter 51/80; Loss: 0.4343
Epoch 3146/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.053
Epoch 3147/10000; Iter 1/80; Loss: 0.4304
Epoch 3147/10000; Iter 51/80; Loss: 0.4907
Epoch 3147/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.043
Epoch 3148/10000; Iter 1/80; Loss: 0.4471
Epoch 3148/10000; Iter 51/80; Loss: 0.3873
Epoch 3148/10000; Iter 80/80; Training Loss: 0.4220, Test Loss: 0.048
Epoch 3149/10000; Iter 1/80; Loss: 0.3658
Epoch 3149/10000; Iter 51/80; Loss: 0.4582
Epoch 3149/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.04
Epoch 3150/10000; Iter 1/80; Loss: 0.3745
Epoch 3150/10000; Iter 51/80; Loss: 0.3885
Epoch 3150/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3151/10000; Iter 1/80; Loss: 0.5300
Epoch 3151/10000; Iter 51/80; Loss: 0.3976
Epoch 3151/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.043
Epoch 3152/10000; Iter 1/80; Loss: 0.4375
Epoch 3152/10000; Iter 51/80; Loss: 0.4599
Epoch 3152/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.042
Epoch 3153/10000; Iter 1/80; Loss: 0.4525
Epoch 3153/10000; Iter 51/80; Loss: 0.4012
Epoch 3153/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.043
Epoch 3154/10000; Iter 1/80; Loss: 0.3851
Epoch 3154/10000; Iter 51/80; Loss: 0.4295
Epoch 3154/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.039
Epoch 3155/10000; Iter 1/80; Loss: 0.3404
Epoch 3155/10000; Iter 51/80; Loss: 0.3940
Epoch 3155/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.046
Epoch 3156/10000; Iter 1/80; Loss: 0.4077
Epoch 3156/10000; Iter 51/80; Loss: 0.3642
Epoch 3156/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3157/10000; Iter 1/80; Loss: 0.3867
Epoch 3157/10000; Iter 51/80; Loss: 0.4090
Epoch 3157/10000; Iter 80/80; Training Loss: 0.4190, Test Loss: 0.054
Epoch 3158/10000; Iter 1/80; Loss: 0.3719
Epoch 3158/10000; Iter 51/80; Loss: 0.4641
Epoch 3158/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.036
Epoch 3159/10000; Iter 1/80; Loss: 0.4403
Epoch 3159/10000; Iter 51/80; Loss: 0.4329
Epoch 3159/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.045
Epoch 3160/10000; Iter 1/80; Loss: 0.3997
Epoch 3160/10000; Iter 51/80; Loss: 0.4648
Epoch 3160/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.039
Epoch 3161/10000; Iter 1/80; Loss: 0.4144
Epoch 3161/10000; Iter 51/80; Loss: 0.4270
Epoch 3161/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.047
Epoch 3162/10000; Iter 1/80; Loss: 0.3824
Epoch 3162/10000; Iter 51/80; Loss: 0.4994
Epoch 3162/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.046
Epoch 3163/10000; Iter 1/80; Loss: 0.4266
Epoch 3163/10000; Iter 51/80; Loss: 0.5138
Epoch 3163/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.042
Epoch 3164/10000; Iter 1/80; Loss: 0.4430
Epoch 3164/10000; Iter 51/80; Loss: 0.3710
Epoch 3164/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3165/10000; Iter 1/80; Loss: 0.4045
Epoch 3165/10000; Iter 51/80; Loss: 0.3734
Epoch 3165/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.048
Epoch 3166/10000; Iter 1/80; Loss: 0.4141
Epoch 3166/10000; Iter 51/80; Loss: 0.4204
Epoch 3166/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.045
Epoch 3167/10000; Iter 1/80; Loss: 0.3839
Epoch 3167/10000; Iter 51/80; Loss: 0.4825
Epoch 3167/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.045
Epoch 3168/10000; Iter 1/80; Loss: 0.4535
Epoch 3168/10000; Iter 51/80; Loss: 0.4692
Epoch 3168/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.049
Epoch 3169/10000; Iter 1/80; Loss: 0.3588
Epoch 3169/10000; Iter 51/80; Loss: 0.3813
Epoch 3169/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.044
Epoch 3170/10000; Iter 1/80; Loss: 0.4028
Epoch 3170/10000; Iter 51/80; Loss: 0.3311
Epoch 3170/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.047
Epoch 3171/10000; Iter 1/80; Loss: 0.3565
Epoch 3171/10000; Iter 51/80; Loss: 0.4080
Epoch 3171/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.045
Epoch 3172/10000; Iter 1/80; Loss: 0.4265
Epoch 3172/10000; Iter 51/80; Loss: 0.3498
Epoch 3172/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.043
Epoch 3173/10000; Iter 1/80; Loss: 0.4244
Epoch 3173/10000; Iter 51/80; Loss: 0.4013
Epoch 3173/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.047
Epoch 3174/10000; Iter 1/80; Loss: 0.4073
Epoch 3174/10000; Iter 51/80; Loss: 0.3401
Epoch 3174/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.049
Epoch 3175/10000; Iter 1/80; Loss: 0.4001
Epoch 3175/10000; Iter 51/80; Loss: 0.3377
Epoch 3175/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.051
Epoch 3176/10000; Iter 1/80; Loss: 0.4401
Epoch 3176/10000; Iter 51/80; Loss: 0.4905
Epoch 3176/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.047
Epoch 3177/10000; Iter 1/80; Loss: 0.4219
Epoch 3177/10000; Iter 51/80; Loss: 0.3953
Epoch 3177/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.048
Epoch 3178/10000; Iter 1/80; Loss: 0.4181
Epoch 3178/10000; Iter 51/80; Loss: 0.4142
Epoch 3178/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.043
Epoch 3179/10000; Iter 1/80; Loss: 0.4037
Epoch 3179/10000; Iter 51/80; Loss: 0.4154
Epoch 3179/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.048
Epoch 3180/10000; Iter 1/80; Loss: 0.4336
Epoch 3180/10000; Iter 51/80; Loss: 0.4212
Epoch 3180/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.051
Epoch 3181/10000; Iter 1/80; Loss: 0.3909
Epoch 3181/10000; Iter 51/80; Loss: 0.4220
Epoch 3181/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.047
Epoch 3182/10000; Iter 1/80; Loss: 0.4812
Epoch 3182/10000; Iter 51/80; Loss: 0.4482
Epoch 3182/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.042
Epoch 3183/10000; Iter 1/80; Loss: 0.4555
Epoch 3183/10000; Iter 51/80; Loss: 0.4281
Epoch 3183/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.047
Epoch 3184/10000; Iter 1/80; Loss: 0.4374
Epoch 3184/10000; Iter 51/80; Loss: 0.4699
Epoch 3184/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3185/10000; Iter 1/80; Loss: 0.4019
Epoch 3185/10000; Iter 51/80; Loss: 0.4241
Epoch 3185/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.048
Epoch 3186/10000; Iter 1/80; Loss: 0.4501
Epoch 3186/10000; Iter 51/80; Loss: 0.4699
Epoch 3186/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3187/10000; Iter 1/80; Loss: 0.4345
Epoch 3187/10000; Iter 51/80; Loss: 0.3874
Epoch 3187/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.049
Epoch 3188/10000; Iter 1/80; Loss: 0.4109
Epoch 3188/10000; Iter 51/80; Loss: 0.4066
Epoch 3188/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.045
Epoch 3189/10000; Iter 1/80; Loss: 0.4058
Epoch 3189/10000; Iter 51/80; Loss: 0.3908
Epoch 3189/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.041
Epoch 3190/10000; Iter 1/80; Loss: 0.3713
Epoch 3190/10000; Iter 51/80; Loss: 0.4618
Epoch 3190/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.041
Epoch 3191/10000; Iter 1/80; Loss: 0.3927
Epoch 3191/10000; Iter 51/80; Loss: 0.3833
Epoch 3191/10000; Iter 80/80; Training Loss: 0.4210, Test Loss: 0.041
Epoch 3192/10000; Iter 1/80; Loss: 0.3990
Epoch 3192/10000; Iter 51/80; Loss: 0.4003
Epoch 3192/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.047
Epoch 3193/10000; Iter 1/80; Loss: 0.3923
Epoch 3193/10000; Iter 51/80; Loss: 0.3959
Epoch 3193/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.051
Epoch 3194/10000; Iter 1/80; Loss: 0.4548
Epoch 3194/10000; Iter 51/80; Loss: 0.3879
Epoch 3194/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.044
Epoch 3195/10000; Iter 1/80; Loss: 0.3933
Epoch 3195/10000; Iter 51/80; Loss: 0.3968
Epoch 3195/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.047
Epoch 3196/10000; Iter 1/80; Loss: 0.3712
Epoch 3196/10000; Iter 51/80; Loss: 0.4315
Epoch 3196/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.04
Epoch 3197/10000; Iter 1/80; Loss: 0.4567
Epoch 3197/10000; Iter 51/80; Loss: 0.4123
Epoch 3197/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.05
Epoch 3198/10000; Iter 1/80; Loss: 0.3651
Epoch 3198/10000; Iter 51/80; Loss: 0.3691
Epoch 3198/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.048
Epoch 3199/10000; Iter 1/80; Loss: 0.4400
Epoch 3199/10000; Iter 51/80; Loss: 0.4111
Epoch 3199/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.048
Epoch 3200/10000; Iter 1/80; Loss: 0.4017
Epoch 3200/10000; Iter 51/80; Loss: 0.3965
Epoch 3200/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.046
Epoch 3201/10000; Iter 1/80; Loss: 0.3946
Epoch 3201/10000; Iter 51/80; Loss: 0.3744
Epoch 3201/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.041
Model saved
Epoch 3202/10000; Iter 1/80; Loss: 0.4685
Epoch 3202/10000; Iter 51/80; Loss: 0.3878
Epoch 3202/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.041
Epoch 3203/10000; Iter 1/80; Loss: 0.4363
Epoch 3203/10000; Iter 51/80; Loss: 0.4106
Epoch 3203/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.037
Epoch 3204/10000; Iter 1/80; Loss: 0.4014
Epoch 3204/10000; Iter 51/80; Loss: 0.3931
Epoch 3204/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.038
Epoch 3205/10000; Iter 1/80; Loss: 0.3831
Epoch 3205/10000; Iter 51/80; Loss: 0.4689
Epoch 3205/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.044
Epoch 3206/10000; Iter 1/80; Loss: 0.3314
Epoch 3206/10000; Iter 51/80; Loss: 0.3816
Epoch 3206/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.044
Epoch 3207/10000; Iter 1/80; Loss: 0.4101
Epoch 3207/10000; Iter 51/80; Loss: 0.3888
Epoch 3207/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.046
Epoch 3208/10000; Iter 1/80; Loss: 0.3488
Epoch 3208/10000; Iter 51/80; Loss: 0.3684
Epoch 3208/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.048
Epoch 3209/10000; Iter 1/80; Loss: 0.3582
Epoch 3209/10000; Iter 51/80; Loss: 0.3982
Epoch 3209/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.048
Epoch 3210/10000; Iter 1/80; Loss: 0.3738
Epoch 3210/10000; Iter 51/80; Loss: 0.4249
Epoch 3210/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.042
Epoch 3211/10000; Iter 1/80; Loss: 0.3842
Epoch 3211/10000; Iter 51/80; Loss: 0.4172
Epoch 3211/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.043
Epoch 3212/10000; Iter 1/80; Loss: 0.4931
Epoch 3212/10000; Iter 51/80; Loss: 0.4046
Epoch 3212/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.048
Epoch 3213/10000; Iter 1/80; Loss: 0.3773
Epoch 3213/10000; Iter 51/80; Loss: 0.4334
Epoch 3213/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.042
Epoch 3214/10000; Iter 1/80; Loss: 0.4734
Epoch 3214/10000; Iter 51/80; Loss: 0.4673
Epoch 3214/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.037
Epoch 3215/10000; Iter 1/80; Loss: 0.3885
Epoch 3215/10000; Iter 51/80; Loss: 0.3973
Epoch 3215/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.047
Epoch 3216/10000; Iter 1/80; Loss: 0.3992
Epoch 3216/10000; Iter 51/80; Loss: 0.4067
Epoch 3216/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.04
Epoch 3217/10000; Iter 1/80; Loss: 0.4054
Epoch 3217/10000; Iter 51/80; Loss: 0.3818
Epoch 3217/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.044
Epoch 3218/10000; Iter 1/80; Loss: 0.3680
Epoch 3218/10000; Iter 51/80; Loss: 0.4089
Epoch 3218/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.04
Epoch 3219/10000; Iter 1/80; Loss: 0.4244
Epoch 3219/10000; Iter 51/80; Loss: 0.3527
Epoch 3219/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.043
Epoch 3220/10000; Iter 1/80; Loss: 0.3867
Epoch 3220/10000; Iter 51/80; Loss: 0.3965
Epoch 3220/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.054
Epoch 3221/10000; Iter 1/80; Loss: 0.3497
Epoch 3221/10000; Iter 51/80; Loss: 0.3476
Epoch 3221/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.055
Epoch 3222/10000; Iter 1/80; Loss: 0.4241
Epoch 3222/10000; Iter 51/80; Loss: 0.4087
Epoch 3222/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3223/10000; Iter 1/80; Loss: 0.4185
Epoch 3223/10000; Iter 51/80; Loss: 0.4009
Epoch 3223/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.044
Epoch 3224/10000; Iter 1/80; Loss: 0.3368
Epoch 3224/10000; Iter 51/80; Loss: 0.4514
Epoch 3224/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3225/10000; Iter 1/80; Loss: 0.4608
Epoch 3225/10000; Iter 51/80; Loss: 0.4294
Epoch 3225/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.044
Epoch 3226/10000; Iter 1/80; Loss: 0.4067
Epoch 3226/10000; Iter 51/80; Loss: 0.4375
Epoch 3226/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.045
Epoch 3227/10000; Iter 1/80; Loss: 0.3979
Epoch 3227/10000; Iter 51/80; Loss: 0.4048
Epoch 3227/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3228/10000; Iter 1/80; Loss: 0.3714
Epoch 3228/10000; Iter 51/80; Loss: 0.3532
Epoch 3228/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.044
Epoch 3229/10000; Iter 1/80; Loss: 0.3874
Epoch 3229/10000; Iter 51/80; Loss: 0.4176
Epoch 3229/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.038
Epoch 3230/10000; Iter 1/80; Loss: 0.4087
Epoch 3230/10000; Iter 51/80; Loss: 0.4447
Epoch 3230/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.049
Epoch 3231/10000; Iter 1/80; Loss: 0.4372
Epoch 3231/10000; Iter 51/80; Loss: 0.4687
Epoch 3231/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.041
Epoch 3232/10000; Iter 1/80; Loss: 0.4324
Epoch 3232/10000; Iter 51/80; Loss: 0.4621
Epoch 3232/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.045
Epoch 3233/10000; Iter 1/80; Loss: 0.4241
Epoch 3233/10000; Iter 51/80; Loss: 0.3751
Epoch 3233/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.044
Epoch 3234/10000; Iter 1/80; Loss: 0.4058
Epoch 3234/10000; Iter 51/80; Loss: 0.4102
Epoch 3234/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.04
Epoch 3235/10000; Iter 1/80; Loss: 0.4610
Epoch 3235/10000; Iter 51/80; Loss: 0.4264
Epoch 3235/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.047
Epoch 3236/10000; Iter 1/80; Loss: 0.3879
Epoch 3236/10000; Iter 51/80; Loss: 0.4251
Epoch 3236/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.041
Epoch 3237/10000; Iter 1/80; Loss: 0.3877
Epoch 3237/10000; Iter 51/80; Loss: 0.3502
Epoch 3237/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.045
Epoch 3238/10000; Iter 1/80; Loss: 0.3491
Epoch 3238/10000; Iter 51/80; Loss: 0.3748
Epoch 3238/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.04
Epoch 3239/10000; Iter 1/80; Loss: 0.3947
Epoch 3239/10000; Iter 51/80; Loss: 0.3896
Epoch 3239/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.044
Epoch 3240/10000; Iter 1/80; Loss: 0.4606
Epoch 3240/10000; Iter 51/80; Loss: 0.4638
Epoch 3240/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.041
Epoch 3241/10000; Iter 1/80; Loss: 0.3924
Epoch 3241/10000; Iter 51/80; Loss: 0.4097
Epoch 3241/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.05
Epoch 3242/10000; Iter 1/80; Loss: 0.4310
Epoch 3242/10000; Iter 51/80; Loss: 0.4825
Epoch 3242/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.047
Epoch 3243/10000; Iter 1/80; Loss: 0.4300
Epoch 3243/10000; Iter 51/80; Loss: 0.3734
Epoch 3243/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.053
Epoch 3244/10000; Iter 1/80; Loss: 0.3636
Epoch 3244/10000; Iter 51/80; Loss: 0.3954
Epoch 3244/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.05
Epoch 3245/10000; Iter 1/80; Loss: 0.4530
Epoch 3245/10000; Iter 51/80; Loss: 0.4019
Epoch 3245/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.042
Epoch 3246/10000; Iter 1/80; Loss: 0.4001
Epoch 3246/10000; Iter 51/80; Loss: 0.3776
Epoch 3246/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.045
Epoch 3247/10000; Iter 1/80; Loss: 0.3976
Epoch 3247/10000; Iter 51/80; Loss: 0.3949
Epoch 3247/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.045
Epoch 3248/10000; Iter 1/80; Loss: 0.3709
Epoch 3248/10000; Iter 51/80; Loss: 0.4274
Epoch 3248/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.052
Epoch 3249/10000; Iter 1/80; Loss: 0.4062
Epoch 3249/10000; Iter 51/80; Loss: 0.4393
Epoch 3249/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.042
Epoch 3250/10000; Iter 1/80; Loss: 0.4622
Epoch 3250/10000; Iter 51/80; Loss: 0.3677
Epoch 3250/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.042
Epoch 3251/10000; Iter 1/80; Loss: 0.4167
Epoch 3251/10000; Iter 51/80; Loss: 0.4197
Epoch 3251/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3252/10000; Iter 1/80; Loss: 0.4071
Epoch 3252/10000; Iter 51/80; Loss: 0.4139
Epoch 3252/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3253/10000; Iter 1/80; Loss: 0.4334
Epoch 3253/10000; Iter 51/80; Loss: 0.4470
Epoch 3253/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.054
Epoch 3254/10000; Iter 1/80; Loss: 0.4488
Epoch 3254/10000; Iter 51/80; Loss: 0.3715
Epoch 3254/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.04
Epoch 3255/10000; Iter 1/80; Loss: 0.4136
Epoch 3255/10000; Iter 51/80; Loss: 0.3960
Epoch 3255/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.046
Epoch 3256/10000; Iter 1/80; Loss: 0.3871
Epoch 3256/10000; Iter 51/80; Loss: 0.4066
Epoch 3256/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.049
Epoch 3257/10000; Iter 1/80; Loss: 0.4130
Epoch 3257/10000; Iter 51/80; Loss: 0.3408
Epoch 3257/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.044
Epoch 3258/10000; Iter 1/80; Loss: 0.3620
Epoch 3258/10000; Iter 51/80; Loss: 0.4905
Epoch 3258/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.051
Epoch 3259/10000; Iter 1/80; Loss: 0.4149
Epoch 3259/10000; Iter 51/80; Loss: 0.4198
Epoch 3259/10000; Iter 80/80; Training Loss: 0.4170, Test Loss: 0.047
Epoch 3260/10000; Iter 1/80; Loss: 0.3970
Epoch 3260/10000; Iter 51/80; Loss: 0.4489
Epoch 3260/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.048
Epoch 3261/10000; Iter 1/80; Loss: 0.4429
Epoch 3261/10000; Iter 51/80; Loss: 0.4003
Epoch 3261/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3262/10000; Iter 1/80; Loss: 0.5483
Epoch 3262/10000; Iter 51/80; Loss: 0.4055
Epoch 3262/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.044
Epoch 3263/10000; Iter 1/80; Loss: 0.3786
Epoch 3263/10000; Iter 51/80; Loss: 0.3923
Epoch 3263/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.046
Epoch 3264/10000; Iter 1/80; Loss: 0.4471
Epoch 3264/10000; Iter 51/80; Loss: 0.3289
Epoch 3264/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.045
Epoch 3265/10000; Iter 1/80; Loss: 0.3860
Epoch 3265/10000; Iter 51/80; Loss: 0.3618
Epoch 3265/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.042
Epoch 3266/10000; Iter 1/80; Loss: 0.4267
Epoch 3266/10000; Iter 51/80; Loss: 0.3638
Epoch 3266/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 3267/10000; Iter 1/80; Loss: 0.4364
Epoch 3267/10000; Iter 51/80; Loss: 0.3710
Epoch 3267/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.047
Epoch 3268/10000; Iter 1/80; Loss: 0.4439
Epoch 3268/10000; Iter 51/80; Loss: 0.4200
Epoch 3268/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.045
Epoch 3269/10000; Iter 1/80; Loss: 0.4041
Epoch 3269/10000; Iter 51/80; Loss: 0.3946
Epoch 3269/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.047
Epoch 3270/10000; Iter 1/80; Loss: 0.3773
Epoch 3270/10000; Iter 51/80; Loss: 0.3791
Epoch 3270/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.052
Epoch 3271/10000; Iter 1/80; Loss: 0.3627
Epoch 3271/10000; Iter 51/80; Loss: 0.3587
Epoch 3271/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.037
Epoch 3272/10000; Iter 1/80; Loss: 0.4365
Epoch 3272/10000; Iter 51/80; Loss: 0.3879
Epoch 3272/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.054
Epoch 3273/10000; Iter 1/80; Loss: 0.4191
Epoch 3273/10000; Iter 51/80; Loss: 0.4127
Epoch 3273/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.044
Epoch 3274/10000; Iter 1/80; Loss: 0.4086
Epoch 3274/10000; Iter 51/80; Loss: 0.3941
Epoch 3274/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.045
Epoch 3275/10000; Iter 1/80; Loss: 0.3558
Epoch 3275/10000; Iter 51/80; Loss: 0.3852
Epoch 3275/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.047
Epoch 3276/10000; Iter 1/80; Loss: 0.4321
Epoch 3276/10000; Iter 51/80; Loss: 0.4769
Epoch 3276/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.042
Epoch 3277/10000; Iter 1/80; Loss: 0.3852
Epoch 3277/10000; Iter 51/80; Loss: 0.3695
Epoch 3277/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.043
Epoch 3278/10000; Iter 1/80; Loss: 0.3829
Epoch 3278/10000; Iter 51/80; Loss: 0.4587
Epoch 3278/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.042
Epoch 3279/10000; Iter 1/80; Loss: 0.4517
Epoch 3279/10000; Iter 51/80; Loss: 0.3914
Epoch 3279/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.05
Epoch 3280/10000; Iter 1/80; Loss: 0.4048
Epoch 3280/10000; Iter 51/80; Loss: 0.3941
Epoch 3280/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.049
Epoch 3281/10000; Iter 1/80; Loss: 0.3928
Epoch 3281/10000; Iter 51/80; Loss: 0.4492
Epoch 3281/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.045
Epoch 3282/10000; Iter 1/80; Loss: 0.4507
Epoch 3282/10000; Iter 51/80; Loss: 0.4205
Epoch 3282/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.043
Epoch 3283/10000; Iter 1/80; Loss: 0.4692
Epoch 3283/10000; Iter 51/80; Loss: 0.4079
Epoch 3283/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3284/10000; Iter 1/80; Loss: 0.3392
Epoch 3284/10000; Iter 51/80; Loss: 0.4506
Epoch 3284/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.049
Epoch 3285/10000; Iter 1/80; Loss: 0.3895
Epoch 3285/10000; Iter 51/80; Loss: 0.4351
Epoch 3285/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.042
Epoch 3286/10000; Iter 1/80; Loss: 0.4264
Epoch 3286/10000; Iter 51/80; Loss: 0.3972
Epoch 3286/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.05
Epoch 3287/10000; Iter 1/80; Loss: 0.4631
Epoch 3287/10000; Iter 51/80; Loss: 0.3818
Epoch 3287/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.047
Epoch 3288/10000; Iter 1/80; Loss: 0.3824
Epoch 3288/10000; Iter 51/80; Loss: 0.3475
Epoch 3288/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.049
Epoch 3289/10000; Iter 1/80; Loss: 0.4367
Epoch 3289/10000; Iter 51/80; Loss: 0.3428
Epoch 3289/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3290/10000; Iter 1/80; Loss: 0.4417
Epoch 3290/10000; Iter 51/80; Loss: 0.4611
Epoch 3290/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.045
Epoch 3291/10000; Iter 1/80; Loss: 0.3980
Epoch 3291/10000; Iter 51/80; Loss: 0.4739
Epoch 3291/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.044
Epoch 3292/10000; Iter 1/80; Loss: 0.4163
Epoch 3292/10000; Iter 51/80; Loss: 0.3771
Epoch 3292/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.042
Epoch 3293/10000; Iter 1/80; Loss: 0.4611
Epoch 3293/10000; Iter 51/80; Loss: 0.3904
Epoch 3293/10000; Iter 80/80; Training Loss: 0.4150, Test Loss: 0.047
Epoch 3294/10000; Iter 1/80; Loss: 0.3574
Epoch 3294/10000; Iter 51/80; Loss: 0.3721
Epoch 3294/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.039
Epoch 3295/10000; Iter 1/80; Loss: 0.3812
Epoch 3295/10000; Iter 51/80; Loss: 0.4367
Epoch 3295/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.048
Epoch 3296/10000; Iter 1/80; Loss: 0.3902
Epoch 3296/10000; Iter 51/80; Loss: 0.3968
Epoch 3296/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.046
Epoch 3297/10000; Iter 1/80; Loss: 0.3323
Epoch 3297/10000; Iter 51/80; Loss: 0.3741
Epoch 3297/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.048
Epoch 3298/10000; Iter 1/80; Loss: 0.4136
Epoch 3298/10000; Iter 51/80; Loss: 0.4087
Epoch 3298/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.046
Epoch 3299/10000; Iter 1/80; Loss: 0.3790
Epoch 3299/10000; Iter 51/80; Loss: 0.3757
Epoch 3299/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3300/10000; Iter 1/80; Loss: 0.3723
Epoch 3300/10000; Iter 51/80; Loss: 0.3812
Epoch 3300/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.038
Epoch 3301/10000; Iter 1/80; Loss: 0.3831
Epoch 3301/10000; Iter 51/80; Loss: 0.3942
Epoch 3301/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.046
Model saved
Epoch 3302/10000; Iter 1/80; Loss: 0.4471
Epoch 3302/10000; Iter 51/80; Loss: 0.4099
Epoch 3302/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3303/10000; Iter 1/80; Loss: 0.3995
Epoch 3303/10000; Iter 51/80; Loss: 0.4172
Epoch 3303/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3304/10000; Iter 1/80; Loss: 0.3822
Epoch 3304/10000; Iter 51/80; Loss: 0.4611
Epoch 3304/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.049
Epoch 3305/10000; Iter 1/80; Loss: 0.4038
Epoch 3305/10000; Iter 51/80; Loss: 0.3723
Epoch 3305/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3306/10000; Iter 1/80; Loss: 0.4002
Epoch 3306/10000; Iter 51/80; Loss: 0.4076
Epoch 3306/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.048
Epoch 3307/10000; Iter 1/80; Loss: 0.4505
Epoch 3307/10000; Iter 51/80; Loss: 0.3578
Epoch 3307/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.053
Epoch 3308/10000; Iter 1/80; Loss: 0.4014
Epoch 3308/10000; Iter 51/80; Loss: 0.4518
Epoch 3308/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.048
Epoch 3309/10000; Iter 1/80; Loss: 0.3583
Epoch 3309/10000; Iter 51/80; Loss: 0.4387
Epoch 3309/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.042
Epoch 3310/10000; Iter 1/80; Loss: 0.4013
Epoch 3310/10000; Iter 51/80; Loss: 0.4111
Epoch 3310/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.045
Epoch 3311/10000; Iter 1/80; Loss: 0.3857
Epoch 3311/10000; Iter 51/80; Loss: 0.3964
Epoch 3311/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.048
Epoch 3312/10000; Iter 1/80; Loss: 0.4039
Epoch 3312/10000; Iter 51/80; Loss: 0.3904
Epoch 3312/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3313/10000; Iter 1/80; Loss: 0.4339
Epoch 3313/10000; Iter 51/80; Loss: 0.4561
Epoch 3313/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3314/10000; Iter 1/80; Loss: 0.3967
Epoch 3314/10000; Iter 51/80; Loss: 0.4294
Epoch 3314/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3315/10000; Iter 1/80; Loss: 0.4286
Epoch 3315/10000; Iter 51/80; Loss: 0.3820
Epoch 3315/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3316/10000; Iter 1/80; Loss: 0.3916
Epoch 3316/10000; Iter 51/80; Loss: 0.3744
Epoch 3316/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.05
Epoch 3317/10000; Iter 1/80; Loss: 0.3907
Epoch 3317/10000; Iter 51/80; Loss: 0.3843
Epoch 3317/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.044
Epoch 3318/10000; Iter 1/80; Loss: 0.3627
Epoch 3318/10000; Iter 51/80; Loss: 0.3781
Epoch 3318/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.044
Epoch 3319/10000; Iter 1/80; Loss: 0.4334
Epoch 3319/10000; Iter 51/80; Loss: 0.4062
Epoch 3319/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.05
Epoch 3320/10000; Iter 1/80; Loss: 0.4146
Epoch 3320/10000; Iter 51/80; Loss: 0.3950
Epoch 3320/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.049
Epoch 3321/10000; Iter 1/80; Loss: 0.4673
Epoch 3321/10000; Iter 51/80; Loss: 0.4125
Epoch 3321/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.041
Epoch 3322/10000; Iter 1/80; Loss: 0.4113
Epoch 3322/10000; Iter 51/80; Loss: 0.4650
Epoch 3322/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.047
Epoch 3323/10000; Iter 1/80; Loss: 0.4362
Epoch 3323/10000; Iter 51/80; Loss: 0.4276
Epoch 3323/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3324/10000; Iter 1/80; Loss: 0.4201
Epoch 3324/10000; Iter 51/80; Loss: 0.4467
Epoch 3324/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.036
Epoch 3325/10000; Iter 1/80; Loss: 0.4351
Epoch 3325/10000; Iter 51/80; Loss: 0.3954
Epoch 3325/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.041
Epoch 3326/10000; Iter 1/80; Loss: 0.4689
Epoch 3326/10000; Iter 51/80; Loss: 0.3974
Epoch 3326/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.043
Epoch 3327/10000; Iter 1/80; Loss: 0.3796
Epoch 3327/10000; Iter 51/80; Loss: 0.3557
Epoch 3327/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.045
Epoch 3328/10000; Iter 1/80; Loss: 0.3988
Epoch 3328/10000; Iter 51/80; Loss: 0.4774
Epoch 3328/10000; Iter 80/80; Training Loss: 0.4130, Test Loss: 0.051
Epoch 3329/10000; Iter 1/80; Loss: 0.3739
Epoch 3329/10000; Iter 51/80; Loss: 0.4027
Epoch 3329/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.043
Epoch 3330/10000; Iter 1/80; Loss: 0.3795
Epoch 3330/10000; Iter 51/80; Loss: 0.3241
Epoch 3330/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.052
Epoch 3331/10000; Iter 1/80; Loss: 0.4736
Epoch 3331/10000; Iter 51/80; Loss: 0.4217
Epoch 3331/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.052
Epoch 3332/10000; Iter 1/80; Loss: 0.4333
Epoch 3332/10000; Iter 51/80; Loss: 0.4294
Epoch 3332/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.043
Epoch 3333/10000; Iter 1/80; Loss: 0.3960
Epoch 3333/10000; Iter 51/80; Loss: 0.3944
Epoch 3333/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.044
Epoch 3334/10000; Iter 1/80; Loss: 0.4019
Epoch 3334/10000; Iter 51/80; Loss: 0.3741
Epoch 3334/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.041
Epoch 3335/10000; Iter 1/80; Loss: 0.3898
Epoch 3335/10000; Iter 51/80; Loss: 0.3877
Epoch 3335/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.042
Epoch 3336/10000; Iter 1/80; Loss: 0.4544
Epoch 3336/10000; Iter 51/80; Loss: 0.3995
Epoch 3336/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.038
Epoch 3337/10000; Iter 1/80; Loss: 0.4223
Epoch 3337/10000; Iter 51/80; Loss: 0.3706
Epoch 3337/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.046
Epoch 3338/10000; Iter 1/80; Loss: 0.3635
Epoch 3338/10000; Iter 51/80; Loss: 0.4213
Epoch 3338/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.05
Epoch 3339/10000; Iter 1/80; Loss: 0.4837
Epoch 3339/10000; Iter 51/80; Loss: 0.3694
Epoch 3339/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.046
Epoch 3340/10000; Iter 1/80; Loss: 0.4902
Epoch 3340/10000; Iter 51/80; Loss: 0.4418
Epoch 3340/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3341/10000; Iter 1/80; Loss: 0.3547
Epoch 3341/10000; Iter 51/80; Loss: 0.3667
Epoch 3341/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3342/10000; Iter 1/80; Loss: 0.3657
Epoch 3342/10000; Iter 51/80; Loss: 0.3985
Epoch 3342/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3343/10000; Iter 1/80; Loss: 0.4191
Epoch 3343/10000; Iter 51/80; Loss: 0.4011
Epoch 3343/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.037
Epoch 3344/10000; Iter 1/80; Loss: 0.4675
Epoch 3344/10000; Iter 51/80; Loss: 0.3803
Epoch 3344/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.052
Epoch 3345/10000; Iter 1/80; Loss: 0.4398
Epoch 3345/10000; Iter 51/80; Loss: 0.3684
Epoch 3345/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.048
Epoch 3346/10000; Iter 1/80; Loss: 0.4289
Epoch 3346/10000; Iter 51/80; Loss: 0.3794
Epoch 3346/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.044
Epoch 3347/10000; Iter 1/80; Loss: 0.4190
Epoch 3347/10000; Iter 51/80; Loss: 0.3609
Epoch 3347/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.048
Epoch 3348/10000; Iter 1/80; Loss: 0.3976
Epoch 3348/10000; Iter 51/80; Loss: 0.4983
Epoch 3348/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.046
Epoch 3349/10000; Iter 1/80; Loss: 0.4494
Epoch 3349/10000; Iter 51/80; Loss: 0.4251
Epoch 3349/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.048
Epoch 3350/10000; Iter 1/80; Loss: 0.3975
Epoch 3350/10000; Iter 51/80; Loss: 0.4065
Epoch 3350/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.048
Epoch 3351/10000; Iter 1/80; Loss: 0.3829
Epoch 3351/10000; Iter 51/80; Loss: 0.3936
Epoch 3351/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.043
Epoch 3352/10000; Iter 1/80; Loss: 0.4302
Epoch 3352/10000; Iter 51/80; Loss: 0.3521
Epoch 3352/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.04
Epoch 3353/10000; Iter 1/80; Loss: 0.3549
Epoch 3353/10000; Iter 51/80; Loss: 0.4344
Epoch 3353/10000; Iter 80/80; Training Loss: 0.4140, Test Loss: 0.047
Epoch 3354/10000; Iter 1/80; Loss: 0.3700
Epoch 3354/10000; Iter 51/80; Loss: 0.4024
Epoch 3354/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.047
Epoch 3355/10000; Iter 1/80; Loss: 0.3537
Epoch 3355/10000; Iter 51/80; Loss: 0.4526
Epoch 3355/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.049
Epoch 3356/10000; Iter 1/80; Loss: 0.4155
Epoch 3356/10000; Iter 51/80; Loss: 0.4358
Epoch 3356/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.051
Epoch 3357/10000; Iter 1/80; Loss: 0.4503
Epoch 3357/10000; Iter 51/80; Loss: 0.3902
Epoch 3357/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.048
Epoch 3358/10000; Iter 1/80; Loss: 0.4685
Epoch 3358/10000; Iter 51/80; Loss: 0.3990
Epoch 3358/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.047
Epoch 3359/10000; Iter 1/80; Loss: 0.4206
Epoch 3359/10000; Iter 51/80; Loss: 0.4578
Epoch 3359/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.04
Epoch 3360/10000; Iter 1/80; Loss: 0.3988
Epoch 3360/10000; Iter 51/80; Loss: 0.3799
Epoch 3360/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.043
Epoch 3361/10000; Iter 1/80; Loss: 0.4039
Epoch 3361/10000; Iter 51/80; Loss: 0.3811
Epoch 3361/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.043
Epoch 3362/10000; Iter 1/80; Loss: 0.3777
Epoch 3362/10000; Iter 51/80; Loss: 0.4179
Epoch 3362/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.048
Epoch 3363/10000; Iter 1/80; Loss: 0.3775
Epoch 3363/10000; Iter 51/80; Loss: 0.4358
Epoch 3363/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.041
Epoch 3364/10000; Iter 1/80; Loss: 0.3825
Epoch 3364/10000; Iter 51/80; Loss: 0.4366
Epoch 3364/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.045
Epoch 3365/10000; Iter 1/80; Loss: 0.3377
Epoch 3365/10000; Iter 51/80; Loss: 0.4015
Epoch 3365/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.047
Epoch 3366/10000; Iter 1/80; Loss: 0.4044
Epoch 3366/10000; Iter 51/80; Loss: 0.3967
Epoch 3366/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3367/10000; Iter 1/80; Loss: 0.4311
Epoch 3367/10000; Iter 51/80; Loss: 0.3950
Epoch 3367/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.051
Epoch 3368/10000; Iter 1/80; Loss: 0.3871
Epoch 3368/10000; Iter 51/80; Loss: 0.3859
Epoch 3368/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.045
Epoch 3369/10000; Iter 1/80; Loss: 0.4104
Epoch 3369/10000; Iter 51/80; Loss: 0.4286
Epoch 3369/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.044
Epoch 3370/10000; Iter 1/80; Loss: 0.3914
Epoch 3370/10000; Iter 51/80; Loss: 0.4364
Epoch 3370/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.042
Epoch 3371/10000; Iter 1/80; Loss: 0.4082
Epoch 3371/10000; Iter 51/80; Loss: 0.4228
Epoch 3371/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.044
Epoch 3372/10000; Iter 1/80; Loss: 0.4415
Epoch 3372/10000; Iter 51/80; Loss: 0.3936
Epoch 3372/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.045
Epoch 3373/10000; Iter 1/80; Loss: 0.3779
Epoch 3373/10000; Iter 51/80; Loss: 0.4025
Epoch 3373/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.05
Epoch 3374/10000; Iter 1/80; Loss: 0.4009
Epoch 3374/10000; Iter 51/80; Loss: 0.4369
Epoch 3374/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.045
Epoch 3375/10000; Iter 1/80; Loss: 0.3990
Epoch 3375/10000; Iter 51/80; Loss: 0.3613
Epoch 3375/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.04
Epoch 3376/10000; Iter 1/80; Loss: 0.4296
Epoch 3376/10000; Iter 51/80; Loss: 0.3960
Epoch 3376/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3377/10000; Iter 1/80; Loss: 0.4322
Epoch 3377/10000; Iter 51/80; Loss: 0.4152
Epoch 3377/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.046
Epoch 3378/10000; Iter 1/80; Loss: 0.4409
Epoch 3378/10000; Iter 51/80; Loss: 0.4394
Epoch 3378/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.043
Epoch 3379/10000; Iter 1/80; Loss: 0.4220
Epoch 3379/10000; Iter 51/80; Loss: 0.3576
Epoch 3379/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.038
Epoch 3380/10000; Iter 1/80; Loss: 0.3970
Epoch 3380/10000; Iter 51/80; Loss: 0.3765
Epoch 3380/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.046
Epoch 3381/10000; Iter 1/80; Loss: 0.3995
Epoch 3381/10000; Iter 51/80; Loss: 0.4187
Epoch 3381/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3382/10000; Iter 1/80; Loss: 0.4665
Epoch 3382/10000; Iter 51/80; Loss: 0.4375
Epoch 3382/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.046
Epoch 3383/10000; Iter 1/80; Loss: 0.4269
Epoch 3383/10000; Iter 51/80; Loss: 0.3796
Epoch 3383/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.047
Epoch 3384/10000; Iter 1/80; Loss: 0.4233
Epoch 3384/10000; Iter 51/80; Loss: 0.3394
Epoch 3384/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.043
Epoch 3385/10000; Iter 1/80; Loss: 0.4296
Epoch 3385/10000; Iter 51/80; Loss: 0.3940
Epoch 3385/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.04
Epoch 3386/10000; Iter 1/80; Loss: 0.3807
Epoch 3386/10000; Iter 51/80; Loss: 0.4338
Epoch 3386/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.04
Epoch 3387/10000; Iter 1/80; Loss: 0.3748
Epoch 3387/10000; Iter 51/80; Loss: 0.4192
Epoch 3387/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3388/10000; Iter 1/80; Loss: 0.3817
Epoch 3388/10000; Iter 51/80; Loss: 0.4437
Epoch 3388/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.048
Epoch 3389/10000; Iter 1/80; Loss: 0.4404
Epoch 3389/10000; Iter 51/80; Loss: 0.4241
Epoch 3389/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3390/10000; Iter 1/80; Loss: 0.3586
Epoch 3390/10000; Iter 51/80; Loss: 0.3887
Epoch 3390/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.049
Epoch 3391/10000; Iter 1/80; Loss: 0.3932
Epoch 3391/10000; Iter 51/80; Loss: 0.4018
Epoch 3391/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.047
Epoch 3392/10000; Iter 1/80; Loss: 0.4201
Epoch 3392/10000; Iter 51/80; Loss: 0.4235
Epoch 3392/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.044
Epoch 3393/10000; Iter 1/80; Loss: 0.4124
Epoch 3393/10000; Iter 51/80; Loss: 0.4432
Epoch 3393/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.048
Epoch 3394/10000; Iter 1/80; Loss: 0.3892
Epoch 3394/10000; Iter 51/80; Loss: 0.3719
Epoch 3394/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 3395/10000; Iter 1/80; Loss: 0.4082
Epoch 3395/10000; Iter 51/80; Loss: 0.4293
Epoch 3395/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.042
Epoch 3396/10000; Iter 1/80; Loss: 0.3785
Epoch 3396/10000; Iter 51/80; Loss: 0.4647
Epoch 3396/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3397/10000; Iter 1/80; Loss: 0.3535
Epoch 3397/10000; Iter 51/80; Loss: 0.3811
Epoch 3397/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.04
Epoch 3398/10000; Iter 1/80; Loss: 0.4377
Epoch 3398/10000; Iter 51/80; Loss: 0.4699
Epoch 3398/10000; Iter 80/80; Training Loss: 0.4160, Test Loss: 0.041
Epoch 3399/10000; Iter 1/80; Loss: 0.3638
Epoch 3399/10000; Iter 51/80; Loss: 0.3667
Epoch 3399/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3400/10000; Iter 1/80; Loss: 0.4174
Epoch 3400/10000; Iter 51/80; Loss: 0.4728
Epoch 3400/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3401/10000; Iter 1/80; Loss: 0.3937
Epoch 3401/10000; Iter 51/80; Loss: 0.4230
Epoch 3401/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.045
Model saved
Epoch 3402/10000; Iter 1/80; Loss: 0.4321
Epoch 3402/10000; Iter 51/80; Loss: 0.3590
Epoch 3402/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.041
Epoch 3403/10000; Iter 1/80; Loss: 0.3700
Epoch 3403/10000; Iter 51/80; Loss: 0.3865
Epoch 3403/10000; Iter 80/80; Training Loss: 0.4180, Test Loss: 0.041
Epoch 3404/10000; Iter 1/80; Loss: 0.4134
Epoch 3404/10000; Iter 51/80; Loss: 0.4391
Epoch 3404/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.042
Epoch 3405/10000; Iter 1/80; Loss: 0.3666
Epoch 3405/10000; Iter 51/80; Loss: 0.3967
Epoch 3405/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.051
Epoch 3406/10000; Iter 1/80; Loss: 0.4324
Epoch 3406/10000; Iter 51/80; Loss: 0.4054
Epoch 3406/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3407/10000; Iter 1/80; Loss: 0.3881
Epoch 3407/10000; Iter 51/80; Loss: 0.4001
Epoch 3407/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.054
Epoch 3408/10000; Iter 1/80; Loss: 0.4425
Epoch 3408/10000; Iter 51/80; Loss: 0.3492
Epoch 3408/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.05
Epoch 3409/10000; Iter 1/80; Loss: 0.3992
Epoch 3409/10000; Iter 51/80; Loss: 0.4053
Epoch 3409/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.045
Epoch 3410/10000; Iter 1/80; Loss: 0.3877
Epoch 3410/10000; Iter 51/80; Loss: 0.3844
Epoch 3410/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.046
Epoch 3411/10000; Iter 1/80; Loss: 0.4340
Epoch 3411/10000; Iter 51/80; Loss: 0.4317
Epoch 3411/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 3412/10000; Iter 1/80; Loss: 0.4442
Epoch 3412/10000; Iter 51/80; Loss: 0.3826
Epoch 3412/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.041
Epoch 3413/10000; Iter 1/80; Loss: 0.4343
Epoch 3413/10000; Iter 51/80; Loss: 0.3646
Epoch 3413/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.041
Epoch 3414/10000; Iter 1/80; Loss: 0.3623
Epoch 3414/10000; Iter 51/80; Loss: 0.4350
Epoch 3414/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.049
Epoch 3415/10000; Iter 1/80; Loss: 0.3452
Epoch 3415/10000; Iter 51/80; Loss: 0.4199
Epoch 3415/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.045
Epoch 3416/10000; Iter 1/80; Loss: 0.4215
Epoch 3416/10000; Iter 51/80; Loss: 0.4474
Epoch 3416/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.047
Epoch 3417/10000; Iter 1/80; Loss: 0.4419
Epoch 3417/10000; Iter 51/80; Loss: 0.4249
Epoch 3417/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.047
Epoch 3418/10000; Iter 1/80; Loss: 0.4840
Epoch 3418/10000; Iter 51/80; Loss: 0.4319
Epoch 3418/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.045
Epoch 3419/10000; Iter 1/80; Loss: 0.3819
Epoch 3419/10000; Iter 51/80; Loss: 0.4063
Epoch 3419/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3420/10000; Iter 1/80; Loss: 0.4056
Epoch 3420/10000; Iter 51/80; Loss: 0.3622
Epoch 3420/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.035
Epoch 3421/10000; Iter 1/80; Loss: 0.3764
Epoch 3421/10000; Iter 51/80; Loss: 0.4614
Epoch 3421/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 3422/10000; Iter 1/80; Loss: 0.3919
Epoch 3422/10000; Iter 51/80; Loss: 0.4479
Epoch 3422/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.043
Epoch 3423/10000; Iter 1/80; Loss: 0.4016
Epoch 3423/10000; Iter 51/80; Loss: 0.4185
Epoch 3423/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3424/10000; Iter 1/80; Loss: 0.3711
Epoch 3424/10000; Iter 51/80; Loss: 0.4436
Epoch 3424/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3425/10000; Iter 1/80; Loss: 0.3539
Epoch 3425/10000; Iter 51/80; Loss: 0.3755
Epoch 3425/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3426/10000; Iter 1/80; Loss: 0.4495
Epoch 3426/10000; Iter 51/80; Loss: 0.3883
Epoch 3426/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.043
Epoch 3427/10000; Iter 1/80; Loss: 0.3995
Epoch 3427/10000; Iter 51/80; Loss: 0.3962
Epoch 3427/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.046
Epoch 3428/10000; Iter 1/80; Loss: 0.3952
Epoch 3428/10000; Iter 51/80; Loss: 0.4608
Epoch 3428/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.039
Epoch 3429/10000; Iter 1/80; Loss: 0.4371
Epoch 3429/10000; Iter 51/80; Loss: 0.4624
Epoch 3429/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.045
Epoch 3430/10000; Iter 1/80; Loss: 0.3729
Epoch 3430/10000; Iter 51/80; Loss: 0.3727
Epoch 3430/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.051
Epoch 3431/10000; Iter 1/80; Loss: 0.3706
Epoch 3431/10000; Iter 51/80; Loss: 0.3939
Epoch 3431/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.048
Epoch 3432/10000; Iter 1/80; Loss: 0.4471
Epoch 3432/10000; Iter 51/80; Loss: 0.4183
Epoch 3432/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.041
Epoch 3433/10000; Iter 1/80; Loss: 0.4272
Epoch 3433/10000; Iter 51/80; Loss: 0.3521
Epoch 3433/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.048
Epoch 3434/10000; Iter 1/80; Loss: 0.4167
Epoch 3434/10000; Iter 51/80; Loss: 0.3930
Epoch 3434/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.05
Epoch 3435/10000; Iter 1/80; Loss: 0.4123
Epoch 3435/10000; Iter 51/80; Loss: 0.3939
Epoch 3435/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.045
Epoch 3436/10000; Iter 1/80; Loss: 0.3839
Epoch 3436/10000; Iter 51/80; Loss: 0.4551
Epoch 3436/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.046
Epoch 3437/10000; Iter 1/80; Loss: 0.3716
Epoch 3437/10000; Iter 51/80; Loss: 0.3855
Epoch 3437/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.046
Epoch 3438/10000; Iter 1/80; Loss: 0.3985
Epoch 3438/10000; Iter 51/80; Loss: 0.4461
Epoch 3438/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.048
Epoch 3439/10000; Iter 1/80; Loss: 0.4118
Epoch 3439/10000; Iter 51/80; Loss: 0.3903
Epoch 3439/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.048
Epoch 3440/10000; Iter 1/80; Loss: 0.3710
Epoch 3440/10000; Iter 51/80; Loss: 0.4374
Epoch 3440/10000; Iter 80/80; Training Loss: 0.4110, Test Loss: 0.049
Epoch 3441/10000; Iter 1/80; Loss: 0.3852
Epoch 3441/10000; Iter 51/80; Loss: 0.4154
Epoch 3441/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.047
Epoch 3442/10000; Iter 1/80; Loss: 0.3986
Epoch 3442/10000; Iter 51/80; Loss: 0.4264
Epoch 3442/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.049
Epoch 3443/10000; Iter 1/80; Loss: 0.3637
Epoch 3443/10000; Iter 51/80; Loss: 0.4173
Epoch 3443/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.045
Epoch 3444/10000; Iter 1/80; Loss: 0.4361
Epoch 3444/10000; Iter 51/80; Loss: 0.3710
Epoch 3444/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.04
Epoch 3445/10000; Iter 1/80; Loss: 0.3416
Epoch 3445/10000; Iter 51/80; Loss: 0.4053
Epoch 3445/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.05
Epoch 3446/10000; Iter 1/80; Loss: 0.3964
Epoch 3446/10000; Iter 51/80; Loss: 0.4081
Epoch 3446/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.043
Epoch 3447/10000; Iter 1/80; Loss: 0.4597
Epoch 3447/10000; Iter 51/80; Loss: 0.4169
Epoch 3447/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3448/10000; Iter 1/80; Loss: 0.3448
Epoch 3448/10000; Iter 51/80; Loss: 0.3606
Epoch 3448/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.047
Epoch 3449/10000; Iter 1/80; Loss: 0.3130
Epoch 3449/10000; Iter 51/80; Loss: 0.4400
Epoch 3449/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.052
Epoch 3450/10000; Iter 1/80; Loss: 0.3759
Epoch 3450/10000; Iter 51/80; Loss: 0.4113
Epoch 3450/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3451/10000; Iter 1/80; Loss: 0.3750
Epoch 3451/10000; Iter 51/80; Loss: 0.3638
Epoch 3451/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3452/10000; Iter 1/80; Loss: 0.3934
Epoch 3452/10000; Iter 51/80; Loss: 0.4311
Epoch 3452/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.047
Epoch 3453/10000; Iter 1/80; Loss: 0.3529
Epoch 3453/10000; Iter 51/80; Loss: 0.4089
Epoch 3453/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.045
Epoch 3454/10000; Iter 1/80; Loss: 0.4539
Epoch 3454/10000; Iter 51/80; Loss: 0.3632
Epoch 3454/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.041
Epoch 3455/10000; Iter 1/80; Loss: 0.4492
Epoch 3455/10000; Iter 51/80; Loss: 0.4153
Epoch 3455/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.042
Epoch 3456/10000; Iter 1/80; Loss: 0.4106
Epoch 3456/10000; Iter 51/80; Loss: 0.4216
Epoch 3456/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3457/10000; Iter 1/80; Loss: 0.3222
Epoch 3457/10000; Iter 51/80; Loss: 0.3328
Epoch 3457/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.036
Epoch 3458/10000; Iter 1/80; Loss: 0.3597
Epoch 3458/10000; Iter 51/80; Loss: 0.4067
Epoch 3458/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 3459/10000; Iter 1/80; Loss: 0.4147
Epoch 3459/10000; Iter 51/80; Loss: 0.4139
Epoch 3459/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3460/10000; Iter 1/80; Loss: 0.3760
Epoch 3460/10000; Iter 51/80; Loss: 0.4133
Epoch 3460/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.043
Epoch 3461/10000; Iter 1/80; Loss: 0.4166
Epoch 3461/10000; Iter 51/80; Loss: 0.3720
Epoch 3461/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.04
Epoch 3462/10000; Iter 1/80; Loss: 0.3578
Epoch 3462/10000; Iter 51/80; Loss: 0.3895
Epoch 3462/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.048
Epoch 3463/10000; Iter 1/80; Loss: 0.3895
Epoch 3463/10000; Iter 51/80; Loss: 0.4054
Epoch 3463/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.044
Epoch 3464/10000; Iter 1/80; Loss: 0.4576
Epoch 3464/10000; Iter 51/80; Loss: 0.3758
Epoch 3464/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.043
Epoch 3465/10000; Iter 1/80; Loss: 0.4390
Epoch 3465/10000; Iter 51/80; Loss: 0.3919
Epoch 3465/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3466/10000; Iter 1/80; Loss: 0.5399
Epoch 3466/10000; Iter 51/80; Loss: 0.3967
Epoch 3466/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.048
Epoch 3467/10000; Iter 1/80; Loss: 0.4475
Epoch 3467/10000; Iter 51/80; Loss: 0.3323
Epoch 3467/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.04
Epoch 3468/10000; Iter 1/80; Loss: 0.3709
Epoch 3468/10000; Iter 51/80; Loss: 0.3251
Epoch 3468/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.049
Epoch 3469/10000; Iter 1/80; Loss: 0.4210
Epoch 3469/10000; Iter 51/80; Loss: 0.4111
Epoch 3469/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.041
Epoch 3470/10000; Iter 1/80; Loss: 0.4523
Epoch 3470/10000; Iter 51/80; Loss: 0.3785
Epoch 3470/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.042
Epoch 3471/10000; Iter 1/80; Loss: 0.4651
Epoch 3471/10000; Iter 51/80; Loss: 0.3995
Epoch 3471/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.04
Epoch 3472/10000; Iter 1/80; Loss: 0.3657
Epoch 3472/10000; Iter 51/80; Loss: 0.3993
Epoch 3472/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.04
Epoch 3473/10000; Iter 1/80; Loss: 0.4621
Epoch 3473/10000; Iter 51/80; Loss: 0.3762
Epoch 3473/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.038
Epoch 3474/10000; Iter 1/80; Loss: 0.3869
Epoch 3474/10000; Iter 51/80; Loss: 0.4221
Epoch 3474/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.042
Epoch 3475/10000; Iter 1/80; Loss: 0.3139
Epoch 3475/10000; Iter 51/80; Loss: 0.3761
Epoch 3475/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.042
Epoch 3476/10000; Iter 1/80; Loss: 0.4497
Epoch 3476/10000; Iter 51/80; Loss: 0.4249
Epoch 3476/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.039
Epoch 3477/10000; Iter 1/80; Loss: 0.3688
Epoch 3477/10000; Iter 51/80; Loss: 0.4829
Epoch 3477/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.048
Epoch 3478/10000; Iter 1/80; Loss: 0.3845
Epoch 3478/10000; Iter 51/80; Loss: 0.3680
Epoch 3478/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.038
Epoch 3479/10000; Iter 1/80; Loss: 0.4190
Epoch 3479/10000; Iter 51/80; Loss: 0.4310
Epoch 3479/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.042
Epoch 3480/10000; Iter 1/80; Loss: 0.3924
Epoch 3480/10000; Iter 51/80; Loss: 0.3935
Epoch 3480/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3481/10000; Iter 1/80; Loss: 0.4255
Epoch 3481/10000; Iter 51/80; Loss: 0.3663
Epoch 3481/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.043
Epoch 3482/10000; Iter 1/80; Loss: 0.4114
Epoch 3482/10000; Iter 51/80; Loss: 0.4536
Epoch 3482/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.043
Epoch 3483/10000; Iter 1/80; Loss: 0.3801
Epoch 3483/10000; Iter 51/80; Loss: 0.4066
Epoch 3483/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.045
Epoch 3484/10000; Iter 1/80; Loss: 0.4199
Epoch 3484/10000; Iter 51/80; Loss: 0.3948
Epoch 3484/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.039
Epoch 3485/10000; Iter 1/80; Loss: 0.3690
Epoch 3485/10000; Iter 51/80; Loss: 0.4132
Epoch 3485/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.048
Epoch 3486/10000; Iter 1/80; Loss: 0.4053
Epoch 3486/10000; Iter 51/80; Loss: 0.3792
Epoch 3486/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.043
Epoch 3487/10000; Iter 1/80; Loss: 0.4171
Epoch 3487/10000; Iter 51/80; Loss: 0.4145
Epoch 3487/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.039
Epoch 3488/10000; Iter 1/80; Loss: 0.4225
Epoch 3488/10000; Iter 51/80; Loss: 0.3945
Epoch 3488/10000; Iter 80/80; Training Loss: 0.4100, Test Loss: 0.043
Epoch 3489/10000; Iter 1/80; Loss: 0.3935
Epoch 3489/10000; Iter 51/80; Loss: 0.4086
Epoch 3489/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3490/10000; Iter 1/80; Loss: 0.4822
Epoch 3490/10000; Iter 51/80; Loss: 0.3944
Epoch 3490/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.043
Epoch 3491/10000; Iter 1/80; Loss: 0.3841
Epoch 3491/10000; Iter 51/80; Loss: 0.3911
Epoch 3491/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3492/10000; Iter 1/80; Loss: 0.3885
Epoch 3492/10000; Iter 51/80; Loss: 0.3602
Epoch 3492/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.045
Epoch 3493/10000; Iter 1/80; Loss: 0.4259
Epoch 3493/10000; Iter 51/80; Loss: 0.3736
Epoch 3493/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.042
Epoch 3494/10000; Iter 1/80; Loss: 0.3639
Epoch 3494/10000; Iter 51/80; Loss: 0.4075
Epoch 3494/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.043
Epoch 3495/10000; Iter 1/80; Loss: 0.3698
Epoch 3495/10000; Iter 51/80; Loss: 0.3971
Epoch 3495/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.04
Epoch 3496/10000; Iter 1/80; Loss: 0.4330
Epoch 3496/10000; Iter 51/80; Loss: 0.3823
Epoch 3496/10000; Iter 80/80; Training Loss: 0.4120, Test Loss: 0.042
Epoch 3497/10000; Iter 1/80; Loss: 0.4618
Epoch 3497/10000; Iter 51/80; Loss: 0.4733
Epoch 3497/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3498/10000; Iter 1/80; Loss: 0.4670
Epoch 3498/10000; Iter 51/80; Loss: 0.4275
Epoch 3498/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3499/10000; Iter 1/80; Loss: 0.3365
Epoch 3499/10000; Iter 51/80; Loss: 0.3655
Epoch 3499/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3500/10000; Iter 1/80; Loss: 0.4503
Epoch 3500/10000; Iter 51/80; Loss: 0.4361
Epoch 3500/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 3501/10000; Iter 1/80; Loss: 0.3875
Epoch 3501/10000; Iter 51/80; Loss: 0.3987
Epoch 3501/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Model saved
Epoch 3502/10000; Iter 1/80; Loss: 0.4197
Epoch 3502/10000; Iter 51/80; Loss: 0.3787
Epoch 3502/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.041
Epoch 3503/10000; Iter 1/80; Loss: 0.4417
Epoch 3503/10000; Iter 51/80; Loss: 0.3937
Epoch 3503/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.046
Epoch 3504/10000; Iter 1/80; Loss: 0.3626
Epoch 3504/10000; Iter 51/80; Loss: 0.3889
Epoch 3504/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.044
Epoch 3505/10000; Iter 1/80; Loss: 0.4707
Epoch 3505/10000; Iter 51/80; Loss: 0.4090
Epoch 3505/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.045
Epoch 3506/10000; Iter 1/80; Loss: 0.3911
Epoch 3506/10000; Iter 51/80; Loss: 0.3843
Epoch 3506/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.046
Epoch 3507/10000; Iter 1/80; Loss: 0.4447
Epoch 3507/10000; Iter 51/80; Loss: 0.3599
Epoch 3507/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 3508/10000; Iter 1/80; Loss: 0.3771
Epoch 3508/10000; Iter 51/80; Loss: 0.3679
Epoch 3508/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.05
Epoch 3509/10000; Iter 1/80; Loss: 0.4419
Epoch 3509/10000; Iter 51/80; Loss: 0.4113
Epoch 3509/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.04
Epoch 3510/10000; Iter 1/80; Loss: 0.4526
Epoch 3510/10000; Iter 51/80; Loss: 0.4011
Epoch 3510/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.04
Epoch 3511/10000; Iter 1/80; Loss: 0.4046
Epoch 3511/10000; Iter 51/80; Loss: 0.4451
Epoch 3511/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.046
Epoch 3512/10000; Iter 1/80; Loss: 0.4558
Epoch 3512/10000; Iter 51/80; Loss: 0.4206
Epoch 3512/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.045
Epoch 3513/10000; Iter 1/80; Loss: 0.3883
Epoch 3513/10000; Iter 51/80; Loss: 0.4439
Epoch 3513/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.046
Epoch 3514/10000; Iter 1/80; Loss: 0.3667
Epoch 3514/10000; Iter 51/80; Loss: 0.3513
Epoch 3514/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.046
Epoch 3515/10000; Iter 1/80; Loss: 0.3410
Epoch 3515/10000; Iter 51/80; Loss: 0.4643
Epoch 3515/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3516/10000; Iter 1/80; Loss: 0.3842
Epoch 3516/10000; Iter 51/80; Loss: 0.4198
Epoch 3516/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.048
Epoch 3517/10000; Iter 1/80; Loss: 0.4087
Epoch 3517/10000; Iter 51/80; Loss: 0.4108
Epoch 3517/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3518/10000; Iter 1/80; Loss: 0.3370
Epoch 3518/10000; Iter 51/80; Loss: 0.3928
Epoch 3518/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3519/10000; Iter 1/80; Loss: 0.4069
Epoch 3519/10000; Iter 51/80; Loss: 0.3640
Epoch 3519/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.048
Epoch 3520/10000; Iter 1/80; Loss: 0.3975
Epoch 3520/10000; Iter 51/80; Loss: 0.4441
Epoch 3520/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.042
Epoch 3521/10000; Iter 1/80; Loss: 0.3442
Epoch 3521/10000; Iter 51/80; Loss: 0.3462
Epoch 3521/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3522/10000; Iter 1/80; Loss: 0.3774
Epoch 3522/10000; Iter 51/80; Loss: 0.3935
Epoch 3522/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3523/10000; Iter 1/80; Loss: 0.3252
Epoch 3523/10000; Iter 51/80; Loss: 0.4243
Epoch 3523/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3524/10000; Iter 1/80; Loss: 0.4042
Epoch 3524/10000; Iter 51/80; Loss: 0.4543
Epoch 3524/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.049
Epoch 3525/10000; Iter 1/80; Loss: 0.3824
Epoch 3525/10000; Iter 51/80; Loss: 0.3424
Epoch 3525/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.049
Epoch 3526/10000; Iter 1/80; Loss: 0.3260
Epoch 3526/10000; Iter 51/80; Loss: 0.3604
Epoch 3526/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.04
Epoch 3527/10000; Iter 1/80; Loss: 0.3895
Epoch 3527/10000; Iter 51/80; Loss: 0.3869
Epoch 3527/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.037
Epoch 3528/10000; Iter 1/80; Loss: 0.3770
Epoch 3528/10000; Iter 51/80; Loss: 0.3663
Epoch 3528/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.047
Epoch 3529/10000; Iter 1/80; Loss: 0.3654
Epoch 3529/10000; Iter 51/80; Loss: 0.4349
Epoch 3529/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.044
Epoch 3530/10000; Iter 1/80; Loss: 0.4217
Epoch 3530/10000; Iter 51/80; Loss: 0.3979
Epoch 3530/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 3531/10000; Iter 1/80; Loss: 0.3511
Epoch 3531/10000; Iter 51/80; Loss: 0.4468
Epoch 3531/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.043
Epoch 3532/10000; Iter 1/80; Loss: 0.4002
Epoch 3532/10000; Iter 51/80; Loss: 0.3818
Epoch 3532/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.039
Epoch 3533/10000; Iter 1/80; Loss: 0.3882
Epoch 3533/10000; Iter 51/80; Loss: 0.3861
Epoch 3533/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3534/10000; Iter 1/80; Loss: 0.3934
Epoch 3534/10000; Iter 51/80; Loss: 0.3830
Epoch 3534/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.041
Epoch 3535/10000; Iter 1/80; Loss: 0.4379
Epoch 3535/10000; Iter 51/80; Loss: 0.4393
Epoch 3535/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.041
Epoch 3536/10000; Iter 1/80; Loss: 0.4237
Epoch 3536/10000; Iter 51/80; Loss: 0.4116
Epoch 3536/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.043
Epoch 3537/10000; Iter 1/80; Loss: 0.4739
Epoch 3537/10000; Iter 51/80; Loss: 0.3563
Epoch 3537/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3538/10000; Iter 1/80; Loss: 0.3488
Epoch 3538/10000; Iter 51/80; Loss: 0.4487
Epoch 3538/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.042
Epoch 3539/10000; Iter 1/80; Loss: 0.3794
Epoch 3539/10000; Iter 51/80; Loss: 0.3904
Epoch 3539/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.053
Epoch 3540/10000; Iter 1/80; Loss: 0.4018
Epoch 3540/10000; Iter 51/80; Loss: 0.3697
Epoch 3540/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.05
Epoch 3541/10000; Iter 1/80; Loss: 0.4092
Epoch 3541/10000; Iter 51/80; Loss: 0.3820
Epoch 3541/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.044
Epoch 3542/10000; Iter 1/80; Loss: 0.3913
Epoch 3542/10000; Iter 51/80; Loss: 0.3613
Epoch 3542/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.046
Epoch 3543/10000; Iter 1/80; Loss: 0.4459
Epoch 3543/10000; Iter 51/80; Loss: 0.3904
Epoch 3543/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.042
Epoch 3544/10000; Iter 1/80; Loss: 0.3667
Epoch 3544/10000; Iter 51/80; Loss: 0.4304
Epoch 3544/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.047
Epoch 3545/10000; Iter 1/80; Loss: 0.4031
Epoch 3545/10000; Iter 51/80; Loss: 0.4152
Epoch 3545/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.042
Epoch 3546/10000; Iter 1/80; Loss: 0.3859
Epoch 3546/10000; Iter 51/80; Loss: 0.4072
Epoch 3546/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.044
Epoch 3547/10000; Iter 1/80; Loss: 0.3748
Epoch 3547/10000; Iter 51/80; Loss: 0.4535
Epoch 3547/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.049
Epoch 3548/10000; Iter 1/80; Loss: 0.3830
Epoch 3548/10000; Iter 51/80; Loss: 0.4106
Epoch 3548/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.05
Epoch 3549/10000; Iter 1/80; Loss: 0.3610
Epoch 3549/10000; Iter 51/80; Loss: 0.4474
Epoch 3549/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3550/10000; Iter 1/80; Loss: 0.3716
Epoch 3550/10000; Iter 51/80; Loss: 0.4727
Epoch 3550/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3551/10000; Iter 1/80; Loss: 0.4593
Epoch 3551/10000; Iter 51/80; Loss: 0.3288
Epoch 3551/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.048
Epoch 3552/10000; Iter 1/80; Loss: 0.3808
Epoch 3552/10000; Iter 51/80; Loss: 0.4471
Epoch 3552/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.043
Epoch 3553/10000; Iter 1/80; Loss: 0.3485
Epoch 3553/10000; Iter 51/80; Loss: 0.4125
Epoch 3553/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.039
Epoch 3554/10000; Iter 1/80; Loss: 0.3984
Epoch 3554/10000; Iter 51/80; Loss: 0.3908
Epoch 3554/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.037
Epoch 3555/10000; Iter 1/80; Loss: 0.4507
Epoch 3555/10000; Iter 51/80; Loss: 0.4100
Epoch 3555/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3556/10000; Iter 1/80; Loss: 0.4678
Epoch 3556/10000; Iter 51/80; Loss: 0.4580
Epoch 3556/10000; Iter 80/80; Training Loss: 0.4080, Test Loss: 0.051
Epoch 3557/10000; Iter 1/80; Loss: 0.3870
Epoch 3557/10000; Iter 51/80; Loss: 0.3587
Epoch 3557/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3558/10000; Iter 1/80; Loss: 0.4044
Epoch 3558/10000; Iter 51/80; Loss: 0.3575
Epoch 3558/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.05
Epoch 3559/10000; Iter 1/80; Loss: 0.3586
Epoch 3559/10000; Iter 51/80; Loss: 0.3935
Epoch 3559/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.041
Epoch 3560/10000; Iter 1/80; Loss: 0.4020
Epoch 3560/10000; Iter 51/80; Loss: 0.3505
Epoch 3560/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3561/10000; Iter 1/80; Loss: 0.3947
Epoch 3561/10000; Iter 51/80; Loss: 0.4610
Epoch 3561/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.045
Epoch 3562/10000; Iter 1/80; Loss: 0.3652
Epoch 3562/10000; Iter 51/80; Loss: 0.4072
Epoch 3562/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.041
Epoch 3563/10000; Iter 1/80; Loss: 0.3570
Epoch 3563/10000; Iter 51/80; Loss: 0.3948
Epoch 3563/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.042
Epoch 3564/10000; Iter 1/80; Loss: 0.3674
Epoch 3564/10000; Iter 51/80; Loss: 0.4413
Epoch 3564/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.047
Epoch 3565/10000; Iter 1/80; Loss: 0.4585
Epoch 3565/10000; Iter 51/80; Loss: 0.4264
Epoch 3565/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.047
Epoch 3566/10000; Iter 1/80; Loss: 0.3602
Epoch 3566/10000; Iter 51/80; Loss: 0.4274
Epoch 3566/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.044
Epoch 3567/10000; Iter 1/80; Loss: 0.3989
Epoch 3567/10000; Iter 51/80; Loss: 0.4242
Epoch 3567/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.044
Epoch 3568/10000; Iter 1/80; Loss: 0.3668
Epoch 3568/10000; Iter 51/80; Loss: 0.4390
Epoch 3568/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.048
Epoch 3569/10000; Iter 1/80; Loss: 0.4728
Epoch 3569/10000; Iter 51/80; Loss: 0.4195
Epoch 3569/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.042
Epoch 3570/10000; Iter 1/80; Loss: 0.4105
Epoch 3570/10000; Iter 51/80; Loss: 0.4455
Epoch 3570/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.047
Epoch 3571/10000; Iter 1/80; Loss: 0.4921
Epoch 3571/10000; Iter 51/80; Loss: 0.3621
Epoch 3571/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3572/10000; Iter 1/80; Loss: 0.4581
Epoch 3572/10000; Iter 51/80; Loss: 0.3966
Epoch 3572/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3573/10000; Iter 1/80; Loss: 0.3663
Epoch 3573/10000; Iter 51/80; Loss: 0.4037
Epoch 3573/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3574/10000; Iter 1/80; Loss: 0.4059
Epoch 3574/10000; Iter 51/80; Loss: 0.3881
Epoch 3574/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3575/10000; Iter 1/80; Loss: 0.3481
Epoch 3575/10000; Iter 51/80; Loss: 0.3665
Epoch 3575/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.045
Epoch 3576/10000; Iter 1/80; Loss: 0.4280
Epoch 3576/10000; Iter 51/80; Loss: 0.3504
Epoch 3576/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.043
Epoch 3577/10000; Iter 1/80; Loss: 0.3833
Epoch 3577/10000; Iter 51/80; Loss: 0.4388
Epoch 3577/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.049
Epoch 3578/10000; Iter 1/80; Loss: 0.3704
Epoch 3578/10000; Iter 51/80; Loss: 0.3335
Epoch 3578/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3579/10000; Iter 1/80; Loss: 0.4041
Epoch 3579/10000; Iter 51/80; Loss: 0.4367
Epoch 3579/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.053
Epoch 3580/10000; Iter 1/80; Loss: 0.4261
Epoch 3580/10000; Iter 51/80; Loss: 0.4053
Epoch 3580/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.05
Epoch 3581/10000; Iter 1/80; Loss: 0.3911
Epoch 3581/10000; Iter 51/80; Loss: 0.3636
Epoch 3581/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.043
Epoch 3582/10000; Iter 1/80; Loss: 0.4043
Epoch 3582/10000; Iter 51/80; Loss: 0.3785
Epoch 3582/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.047
Epoch 3583/10000; Iter 1/80; Loss: 0.3856
Epoch 3583/10000; Iter 51/80; Loss: 0.3787
Epoch 3583/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3584/10000; Iter 1/80; Loss: 0.3899
Epoch 3584/10000; Iter 51/80; Loss: 0.3888
Epoch 3584/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.04
Epoch 3585/10000; Iter 1/80; Loss: 0.3897
Epoch 3585/10000; Iter 51/80; Loss: 0.3866
Epoch 3585/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.048
Epoch 3586/10000; Iter 1/80; Loss: 0.4123
Epoch 3586/10000; Iter 51/80; Loss: 0.4479
Epoch 3586/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.046
Epoch 3587/10000; Iter 1/80; Loss: 0.4405
Epoch 3587/10000; Iter 51/80; Loss: 0.3779
Epoch 3587/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.045
Epoch 3588/10000; Iter 1/80; Loss: 0.4697
Epoch 3588/10000; Iter 51/80; Loss: 0.3962
Epoch 3588/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.041
Epoch 3589/10000; Iter 1/80; Loss: 0.3822
Epoch 3589/10000; Iter 51/80; Loss: 0.5550
Epoch 3589/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.041
Epoch 3590/10000; Iter 1/80; Loss: 0.4533
Epoch 3590/10000; Iter 51/80; Loss: 0.4034
Epoch 3590/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.046
Epoch 3591/10000; Iter 1/80; Loss: 0.3900
Epoch 3591/10000; Iter 51/80; Loss: 0.3288
Epoch 3591/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.045
Epoch 3592/10000; Iter 1/80; Loss: 0.4279
Epoch 3592/10000; Iter 51/80; Loss: 0.4938
Epoch 3592/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.046
Epoch 3593/10000; Iter 1/80; Loss: 0.4094
Epoch 3593/10000; Iter 51/80; Loss: 0.4393
Epoch 3593/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 3594/10000; Iter 1/80; Loss: 0.4186
Epoch 3594/10000; Iter 51/80; Loss: 0.3938
Epoch 3594/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.046
Epoch 3595/10000; Iter 1/80; Loss: 0.4158
Epoch 3595/10000; Iter 51/80; Loss: 0.4048
Epoch 3595/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3596/10000; Iter 1/80; Loss: 0.3977
Epoch 3596/10000; Iter 51/80; Loss: 0.4117
Epoch 3596/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.047
Epoch 3597/10000; Iter 1/80; Loss: 0.3533
Epoch 3597/10000; Iter 51/80; Loss: 0.4143
Epoch 3597/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.044
Epoch 3598/10000; Iter 1/80; Loss: 0.3621
Epoch 3598/10000; Iter 51/80; Loss: 0.3607
Epoch 3598/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.045
Epoch 3599/10000; Iter 1/80; Loss: 0.3777
Epoch 3599/10000; Iter 51/80; Loss: 0.3588
Epoch 3599/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.047
Epoch 3600/10000; Iter 1/80; Loss: 0.3368
Epoch 3600/10000; Iter 51/80; Loss: 0.3664
Epoch 3600/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.043
Epoch 3601/10000; Iter 1/80; Loss: 0.4135
Epoch 3601/10000; Iter 51/80; Loss: 0.3547
Epoch 3601/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Model saved
Epoch 3602/10000; Iter 1/80; Loss: 0.3674
Epoch 3602/10000; Iter 51/80; Loss: 0.4029
Epoch 3602/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.042
Epoch 3603/10000; Iter 1/80; Loss: 0.3717
Epoch 3603/10000; Iter 51/80; Loss: 0.3859
Epoch 3603/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.043
Epoch 3604/10000; Iter 1/80; Loss: 0.4203
Epoch 3604/10000; Iter 51/80; Loss: 0.3706
Epoch 3604/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3605/10000; Iter 1/80; Loss: 0.4073
Epoch 3605/10000; Iter 51/80; Loss: 0.3972
Epoch 3605/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.037
Epoch 3606/10000; Iter 1/80; Loss: 0.4504
Epoch 3606/10000; Iter 51/80; Loss: 0.3815
Epoch 3606/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.042
Epoch 3607/10000; Iter 1/80; Loss: 0.4367
Epoch 3607/10000; Iter 51/80; Loss: 0.4014
Epoch 3607/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.044
Epoch 3608/10000; Iter 1/80; Loss: 0.4008
Epoch 3608/10000; Iter 51/80; Loss: 0.4043
Epoch 3608/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.042
Epoch 3609/10000; Iter 1/80; Loss: 0.4178
Epoch 3609/10000; Iter 51/80; Loss: 0.3526
Epoch 3609/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.045
Epoch 3610/10000; Iter 1/80; Loss: 0.4251
Epoch 3610/10000; Iter 51/80; Loss: 0.4232
Epoch 3610/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.046
Epoch 3611/10000; Iter 1/80; Loss: 0.3791
Epoch 3611/10000; Iter 51/80; Loss: 0.3703
Epoch 3611/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.042
Epoch 3612/10000; Iter 1/80; Loss: 0.3500
Epoch 3612/10000; Iter 51/80; Loss: 0.3348
Epoch 3612/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.044
Epoch 3613/10000; Iter 1/80; Loss: 0.3939
Epoch 3613/10000; Iter 51/80; Loss: 0.3907
Epoch 3613/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.046
Epoch 3614/10000; Iter 1/80; Loss: 0.4395
Epoch 3614/10000; Iter 51/80; Loss: 0.4084
Epoch 3614/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.05
Epoch 3615/10000; Iter 1/80; Loss: 0.3916
Epoch 3615/10000; Iter 51/80; Loss: 0.3530
Epoch 3615/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.038
Epoch 3616/10000; Iter 1/80; Loss: 0.4179
Epoch 3616/10000; Iter 51/80; Loss: 0.4303
Epoch 3616/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3617/10000; Iter 1/80; Loss: 0.3476
Epoch 3617/10000; Iter 51/80; Loss: 0.4663
Epoch 3617/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3618/10000; Iter 1/80; Loss: 0.4366
Epoch 3618/10000; Iter 51/80; Loss: 0.3806
Epoch 3618/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.048
Epoch 3619/10000; Iter 1/80; Loss: 0.4069
Epoch 3619/10000; Iter 51/80; Loss: 0.4010
Epoch 3619/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.049
Epoch 3620/10000; Iter 1/80; Loss: 0.4501
Epoch 3620/10000; Iter 51/80; Loss: 0.3913
Epoch 3620/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.042
Epoch 3621/10000; Iter 1/80; Loss: 0.4119
Epoch 3621/10000; Iter 51/80; Loss: 0.4325
Epoch 3621/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.049
Epoch 3622/10000; Iter 1/80; Loss: 0.4061
Epoch 3622/10000; Iter 51/80; Loss: 0.3668
Epoch 3622/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 3623/10000; Iter 1/80; Loss: 0.3941
Epoch 3623/10000; Iter 51/80; Loss: 0.3704
Epoch 3623/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.039
Epoch 3624/10000; Iter 1/80; Loss: 0.3161
Epoch 3624/10000; Iter 51/80; Loss: 0.4008
Epoch 3624/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3625/10000; Iter 1/80; Loss: 0.3769
Epoch 3625/10000; Iter 51/80; Loss: 0.4226
Epoch 3625/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.047
Epoch 3626/10000; Iter 1/80; Loss: 0.4940
Epoch 3626/10000; Iter 51/80; Loss: 0.4344
Epoch 3626/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 3627/10000; Iter 1/80; Loss: 0.4252
Epoch 3627/10000; Iter 51/80; Loss: 0.3979
Epoch 3627/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.038
Epoch 3628/10000; Iter 1/80; Loss: 0.4233
Epoch 3628/10000; Iter 51/80; Loss: 0.3657
Epoch 3628/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.049
Epoch 3629/10000; Iter 1/80; Loss: 0.4005
Epoch 3629/10000; Iter 51/80; Loss: 0.4168
Epoch 3629/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.046
Epoch 3630/10000; Iter 1/80; Loss: 0.4185
Epoch 3630/10000; Iter 51/80; Loss: 0.4214
Epoch 3630/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.037
Epoch 3631/10000; Iter 1/80; Loss: 0.4095
Epoch 3631/10000; Iter 51/80; Loss: 0.4809
Epoch 3631/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.048
Epoch 3632/10000; Iter 1/80; Loss: 0.4562
Epoch 3632/10000; Iter 51/80; Loss: 0.3703
Epoch 3632/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.045
Epoch 3633/10000; Iter 1/80; Loss: 0.3875
Epoch 3633/10000; Iter 51/80; Loss: 0.4468
Epoch 3633/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.038
Epoch 3634/10000; Iter 1/80; Loss: 0.4126
Epoch 3634/10000; Iter 51/80; Loss: 0.4187
Epoch 3634/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.04
Epoch 3635/10000; Iter 1/80; Loss: 0.3738
Epoch 3635/10000; Iter 51/80; Loss: 0.3739
Epoch 3635/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.038
Epoch 3636/10000; Iter 1/80; Loss: 0.4298
Epoch 3636/10000; Iter 51/80; Loss: 0.3632
Epoch 3636/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.052
Epoch 3637/10000; Iter 1/80; Loss: 0.3966
Epoch 3637/10000; Iter 51/80; Loss: 0.5307
Epoch 3637/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.046
Epoch 3638/10000; Iter 1/80; Loss: 0.4040
Epoch 3638/10000; Iter 51/80; Loss: 0.3988
Epoch 3638/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3639/10000; Iter 1/80; Loss: 0.4388
Epoch 3639/10000; Iter 51/80; Loss: 0.3857
Epoch 3639/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.044
Epoch 3640/10000; Iter 1/80; Loss: 0.4608
Epoch 3640/10000; Iter 51/80; Loss: 0.3727
Epoch 3640/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.049
Epoch 3641/10000; Iter 1/80; Loss: 0.4280
Epoch 3641/10000; Iter 51/80; Loss: 0.4160
Epoch 3641/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.042
Epoch 3642/10000; Iter 1/80; Loss: 0.4542
Epoch 3642/10000; Iter 51/80; Loss: 0.4415
Epoch 3642/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.049
Epoch 3643/10000; Iter 1/80; Loss: 0.4506
Epoch 3643/10000; Iter 51/80; Loss: 0.3613
Epoch 3643/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.048
Epoch 3644/10000; Iter 1/80; Loss: 0.4358
Epoch 3644/10000; Iter 51/80; Loss: 0.3849
Epoch 3644/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.051
Epoch 3645/10000; Iter 1/80; Loss: 0.3689
Epoch 3645/10000; Iter 51/80; Loss: 0.4305
Epoch 3645/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.041
Epoch 3646/10000; Iter 1/80; Loss: 0.4227
Epoch 3646/10000; Iter 51/80; Loss: 0.3621
Epoch 3646/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.049
Epoch 3647/10000; Iter 1/80; Loss: 0.4820
Epoch 3647/10000; Iter 51/80; Loss: 0.3719
Epoch 3647/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 3648/10000; Iter 1/80; Loss: 0.3832
Epoch 3648/10000; Iter 51/80; Loss: 0.3744
Epoch 3648/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 3649/10000; Iter 1/80; Loss: 0.4424
Epoch 3649/10000; Iter 51/80; Loss: 0.4192
Epoch 3649/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.056
Epoch 3650/10000; Iter 1/80; Loss: 0.3938
Epoch 3650/10000; Iter 51/80; Loss: 0.3505
Epoch 3650/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.039
Epoch 3651/10000; Iter 1/80; Loss: 0.3870
Epoch 3651/10000; Iter 51/80; Loss: 0.3993
Epoch 3651/10000; Iter 80/80; Training Loss: 0.4090, Test Loss: 0.046
Epoch 3652/10000; Iter 1/80; Loss: 0.3809
Epoch 3652/10000; Iter 51/80; Loss: 0.3825
Epoch 3652/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3653/10000; Iter 1/80; Loss: 0.3266
Epoch 3653/10000; Iter 51/80; Loss: 0.4326
Epoch 3653/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3654/10000; Iter 1/80; Loss: 0.4513
Epoch 3654/10000; Iter 51/80; Loss: 0.4177
Epoch 3654/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3655/10000; Iter 1/80; Loss: 0.3993
Epoch 3655/10000; Iter 51/80; Loss: 0.4684
Epoch 3655/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3656/10000; Iter 1/80; Loss: 0.3989
Epoch 3656/10000; Iter 51/80; Loss: 0.4496
Epoch 3656/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 3657/10000; Iter 1/80; Loss: 0.4670
Epoch 3657/10000; Iter 51/80; Loss: 0.4192
Epoch 3657/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.046
Epoch 3658/10000; Iter 1/80; Loss: 0.3694
Epoch 3658/10000; Iter 51/80; Loss: 0.3838
Epoch 3658/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.046
Epoch 3659/10000; Iter 1/80; Loss: 0.4573
Epoch 3659/10000; Iter 51/80; Loss: 0.4836
Epoch 3659/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.038
Epoch 3660/10000; Iter 1/80; Loss: 0.3750
Epoch 3660/10000; Iter 51/80; Loss: 0.3524
Epoch 3660/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.041
Epoch 3661/10000; Iter 1/80; Loss: 0.4402
Epoch 3661/10000; Iter 51/80; Loss: 0.4075
Epoch 3661/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.037
Epoch 3662/10000; Iter 1/80; Loss: 0.4343
Epoch 3662/10000; Iter 51/80; Loss: 0.4876
Epoch 3662/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.046
Epoch 3663/10000; Iter 1/80; Loss: 0.4576
Epoch 3663/10000; Iter 51/80; Loss: 0.3651
Epoch 3663/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3664/10000; Iter 1/80; Loss: 0.4579
Epoch 3664/10000; Iter 51/80; Loss: 0.4268
Epoch 3664/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.048
Epoch 3665/10000; Iter 1/80; Loss: 0.3617
Epoch 3665/10000; Iter 51/80; Loss: 0.3884
Epoch 3665/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 3666/10000; Iter 1/80; Loss: 0.3924
Epoch 3666/10000; Iter 51/80; Loss: 0.4621
Epoch 3666/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3667/10000; Iter 1/80; Loss: 0.4127
Epoch 3667/10000; Iter 51/80; Loss: 0.4077
Epoch 3667/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 3668/10000; Iter 1/80; Loss: 0.4116
Epoch 3668/10000; Iter 51/80; Loss: 0.4286
Epoch 3668/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.048
Epoch 3669/10000; Iter 1/80; Loss: 0.3815
Epoch 3669/10000; Iter 51/80; Loss: 0.3615
Epoch 3669/10000; Iter 80/80; Training Loss: 0.4070, Test Loss: 0.05
Epoch 3670/10000; Iter 1/80; Loss: 0.4235
Epoch 3670/10000; Iter 51/80; Loss: 0.4614
Epoch 3670/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3671/10000; Iter 1/80; Loss: 0.4401
Epoch 3671/10000; Iter 51/80; Loss: 0.4226
Epoch 3671/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.047
Epoch 3672/10000; Iter 1/80; Loss: 0.3285
Epoch 3672/10000; Iter 51/80; Loss: 0.3966
Epoch 3672/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.046
Epoch 3673/10000; Iter 1/80; Loss: 0.4461
Epoch 3673/10000; Iter 51/80; Loss: 0.3825
Epoch 3673/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3674/10000; Iter 1/80; Loss: 0.3777
Epoch 3674/10000; Iter 51/80; Loss: 0.3935
Epoch 3674/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.047
Epoch 3675/10000; Iter 1/80; Loss: 0.3549
Epoch 3675/10000; Iter 51/80; Loss: 0.4372
Epoch 3675/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.041
Epoch 3676/10000; Iter 1/80; Loss: 0.3971
Epoch 3676/10000; Iter 51/80; Loss: 0.4149
Epoch 3676/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.041
Epoch 3677/10000; Iter 1/80; Loss: 0.4196
Epoch 3677/10000; Iter 51/80; Loss: 0.4183
Epoch 3677/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.051
Epoch 3678/10000; Iter 1/80; Loss: 0.3752
Epoch 3678/10000; Iter 51/80; Loss: 0.3529
Epoch 3678/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3679/10000; Iter 1/80; Loss: 0.4293
Epoch 3679/10000; Iter 51/80; Loss: 0.3765
Epoch 3679/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.038
Epoch 3680/10000; Iter 1/80; Loss: 0.4377
Epoch 3680/10000; Iter 51/80; Loss: 0.4068
Epoch 3680/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.044
Epoch 3681/10000; Iter 1/80; Loss: 0.4348
Epoch 3681/10000; Iter 51/80; Loss: 0.3947
Epoch 3681/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.038
Epoch 3682/10000; Iter 1/80; Loss: 0.4293
Epoch 3682/10000; Iter 51/80; Loss: 0.3444
Epoch 3682/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.043
Epoch 3683/10000; Iter 1/80; Loss: 0.3874
Epoch 3683/10000; Iter 51/80; Loss: 0.3589
Epoch 3683/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.041
Epoch 3684/10000; Iter 1/80; Loss: 0.3767
Epoch 3684/10000; Iter 51/80; Loss: 0.3998
Epoch 3684/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.047
Epoch 3685/10000; Iter 1/80; Loss: 0.4617
Epoch 3685/10000; Iter 51/80; Loss: 0.3789
Epoch 3685/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 3686/10000; Iter 1/80; Loss: 0.3611
Epoch 3686/10000; Iter 51/80; Loss: 0.3734
Epoch 3686/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.044
Epoch 3687/10000; Iter 1/80; Loss: 0.4039
Epoch 3687/10000; Iter 51/80; Loss: 0.3471
Epoch 3687/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 3688/10000; Iter 1/80; Loss: 0.3687
Epoch 3688/10000; Iter 51/80; Loss: 0.5076
Epoch 3688/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.05
Epoch 3689/10000; Iter 1/80; Loss: 0.4552
Epoch 3689/10000; Iter 51/80; Loss: 0.4098
Epoch 3689/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 3690/10000; Iter 1/80; Loss: 0.4223
Epoch 3690/10000; Iter 51/80; Loss: 0.4111
Epoch 3690/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3691/10000; Iter 1/80; Loss: 0.3871
Epoch 3691/10000; Iter 51/80; Loss: 0.3668
Epoch 3691/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.045
Epoch 3692/10000; Iter 1/80; Loss: 0.4021
Epoch 3692/10000; Iter 51/80; Loss: 0.4550
Epoch 3692/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.049
Epoch 3693/10000; Iter 1/80; Loss: 0.4413
Epoch 3693/10000; Iter 51/80; Loss: 0.3971
Epoch 3693/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3694/10000; Iter 1/80; Loss: 0.3991
Epoch 3694/10000; Iter 51/80; Loss: 0.3878
Epoch 3694/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3695/10000; Iter 1/80; Loss: 0.3929
Epoch 3695/10000; Iter 51/80; Loss: 0.3745
Epoch 3695/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.048
Epoch 3696/10000; Iter 1/80; Loss: 0.3688
Epoch 3696/10000; Iter 51/80; Loss: 0.3619
Epoch 3696/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 3697/10000; Iter 1/80; Loss: 0.3957
Epoch 3697/10000; Iter 51/80; Loss: 0.4021
Epoch 3697/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 3698/10000; Iter 1/80; Loss: 0.3724
Epoch 3698/10000; Iter 51/80; Loss: 0.3612
Epoch 3698/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.044
Epoch 3699/10000; Iter 1/80; Loss: 0.4290
Epoch 3699/10000; Iter 51/80; Loss: 0.3578
Epoch 3699/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 3700/10000; Iter 1/80; Loss: 0.3831
Epoch 3700/10000; Iter 51/80; Loss: 0.4042
Epoch 3700/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.047
Epoch 3701/10000; Iter 1/80; Loss: 0.4299
Epoch 3701/10000; Iter 51/80; Loss: 0.3736
Epoch 3701/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Model saved
Epoch 3702/10000; Iter 1/80; Loss: 0.4125
Epoch 3702/10000; Iter 51/80; Loss: 0.4858
Epoch 3702/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3703/10000; Iter 1/80; Loss: 0.3771
Epoch 3703/10000; Iter 51/80; Loss: 0.3897
Epoch 3703/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.05
Epoch 3704/10000; Iter 1/80; Loss: 0.3731
Epoch 3704/10000; Iter 51/80; Loss: 0.3940
Epoch 3704/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.04
Epoch 3705/10000; Iter 1/80; Loss: 0.3915
Epoch 3705/10000; Iter 51/80; Loss: 0.3308
Epoch 3705/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.038
Epoch 3706/10000; Iter 1/80; Loss: 0.4136
Epoch 3706/10000; Iter 51/80; Loss: 0.3674
Epoch 3706/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.044
Epoch 3707/10000; Iter 1/80; Loss: 0.4317
Epoch 3707/10000; Iter 51/80; Loss: 0.4036
Epoch 3707/10000; Iter 80/80; Training Loss: 0.4060, Test Loss: 0.042
Epoch 3708/10000; Iter 1/80; Loss: 0.3946
Epoch 3708/10000; Iter 51/80; Loss: 0.4059
Epoch 3708/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.043
Epoch 3709/10000; Iter 1/80; Loss: 0.4792
Epoch 3709/10000; Iter 51/80; Loss: 0.4172
Epoch 3709/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.051
Epoch 3710/10000; Iter 1/80; Loss: 0.4662
Epoch 3710/10000; Iter 51/80; Loss: 0.4183
Epoch 3710/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.044
Epoch 3711/10000; Iter 1/80; Loss: 0.4689
Epoch 3711/10000; Iter 51/80; Loss: 0.3820
Epoch 3711/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.046
Epoch 3712/10000; Iter 1/80; Loss: 0.4083
Epoch 3712/10000; Iter 51/80; Loss: 0.3676
Epoch 3712/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3713/10000; Iter 1/80; Loss: 0.4752
Epoch 3713/10000; Iter 51/80; Loss: 0.3691
Epoch 3713/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3714/10000; Iter 1/80; Loss: 0.4649
Epoch 3714/10000; Iter 51/80; Loss: 0.3669
Epoch 3714/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3715/10000; Iter 1/80; Loss: 0.3822
Epoch 3715/10000; Iter 51/80; Loss: 0.4283
Epoch 3715/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.041
Epoch 3716/10000; Iter 1/80; Loss: 0.4804
Epoch 3716/10000; Iter 51/80; Loss: 0.3706
Epoch 3716/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.048
Epoch 3717/10000; Iter 1/80; Loss: 0.3660
Epoch 3717/10000; Iter 51/80; Loss: 0.4148
Epoch 3717/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3718/10000; Iter 1/80; Loss: 0.3773
Epoch 3718/10000; Iter 51/80; Loss: 0.3826
Epoch 3718/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.043
Epoch 3719/10000; Iter 1/80; Loss: 0.3926
Epoch 3719/10000; Iter 51/80; Loss: 0.4061
Epoch 3719/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.05
Epoch 3720/10000; Iter 1/80; Loss: 0.3914
Epoch 3720/10000; Iter 51/80; Loss: 0.3127
Epoch 3720/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3721/10000; Iter 1/80; Loss: 0.3882
Epoch 3721/10000; Iter 51/80; Loss: 0.3938
Epoch 3721/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 3722/10000; Iter 1/80; Loss: 0.3843
Epoch 3722/10000; Iter 51/80; Loss: 0.3853
Epoch 3722/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.038
Epoch 3723/10000; Iter 1/80; Loss: 0.4121
Epoch 3723/10000; Iter 51/80; Loss: 0.3564
Epoch 3723/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 3724/10000; Iter 1/80; Loss: 0.4088
Epoch 3724/10000; Iter 51/80; Loss: 0.3929
Epoch 3724/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.049
Epoch 3725/10000; Iter 1/80; Loss: 0.3567
Epoch 3725/10000; Iter 51/80; Loss: 0.3808
Epoch 3725/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 3726/10000; Iter 1/80; Loss: 0.4057
Epoch 3726/10000; Iter 51/80; Loss: 0.4246
Epoch 3726/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.048
Epoch 3727/10000; Iter 1/80; Loss: 0.4359
Epoch 3727/10000; Iter 51/80; Loss: 0.3762
Epoch 3727/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3728/10000; Iter 1/80; Loss: 0.4067
Epoch 3728/10000; Iter 51/80; Loss: 0.3484
Epoch 3728/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3729/10000; Iter 1/80; Loss: 0.3642
Epoch 3729/10000; Iter 51/80; Loss: 0.3808
Epoch 3729/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.048
Epoch 3730/10000; Iter 1/80; Loss: 0.4472
Epoch 3730/10000; Iter 51/80; Loss: 0.4137
Epoch 3730/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.044
Epoch 3731/10000; Iter 1/80; Loss: 0.3889
Epoch 3731/10000; Iter 51/80; Loss: 0.3756
Epoch 3731/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.04
Epoch 3732/10000; Iter 1/80; Loss: 0.3868
Epoch 3732/10000; Iter 51/80; Loss: 0.4343
Epoch 3732/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3733/10000; Iter 1/80; Loss: 0.3595
Epoch 3733/10000; Iter 51/80; Loss: 0.4229
Epoch 3733/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.052
Epoch 3734/10000; Iter 1/80; Loss: 0.4585
Epoch 3734/10000; Iter 51/80; Loss: 0.3799
Epoch 3734/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3735/10000; Iter 1/80; Loss: 0.4083
Epoch 3735/10000; Iter 51/80; Loss: 0.4287
Epoch 3735/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.046
Epoch 3736/10000; Iter 1/80; Loss: 0.4260
Epoch 3736/10000; Iter 51/80; Loss: 0.4165
Epoch 3736/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.047
Epoch 3737/10000; Iter 1/80; Loss: 0.4121
Epoch 3737/10000; Iter 51/80; Loss: 0.4361
Epoch 3737/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 3738/10000; Iter 1/80; Loss: 0.3741
Epoch 3738/10000; Iter 51/80; Loss: 0.4168
Epoch 3738/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.04
Epoch 3739/10000; Iter 1/80; Loss: 0.3657
Epoch 3739/10000; Iter 51/80; Loss: 0.3730
Epoch 3739/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.042
Epoch 3740/10000; Iter 1/80; Loss: 0.4088
Epoch 3740/10000; Iter 51/80; Loss: 0.3773
Epoch 3740/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.037
Epoch 3741/10000; Iter 1/80; Loss: 0.3830
Epoch 3741/10000; Iter 51/80; Loss: 0.4100
Epoch 3741/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.051
Epoch 3742/10000; Iter 1/80; Loss: 0.3980
Epoch 3742/10000; Iter 51/80; Loss: 0.4752
Epoch 3742/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.047
Epoch 3743/10000; Iter 1/80; Loss: 0.4100
Epoch 3743/10000; Iter 51/80; Loss: 0.4238
Epoch 3743/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.042
Epoch 3744/10000; Iter 1/80; Loss: 0.4636
Epoch 3744/10000; Iter 51/80; Loss: 0.4155
Epoch 3744/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.055
Epoch 3745/10000; Iter 1/80; Loss: 0.4687
Epoch 3745/10000; Iter 51/80; Loss: 0.3829
Epoch 3745/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.039
Epoch 3746/10000; Iter 1/80; Loss: 0.3817
Epoch 3746/10000; Iter 51/80; Loss: 0.4608
Epoch 3746/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3747/10000; Iter 1/80; Loss: 0.3762
Epoch 3747/10000; Iter 51/80; Loss: 0.3365
Epoch 3747/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.048
Epoch 3748/10000; Iter 1/80; Loss: 0.4159
Epoch 3748/10000; Iter 51/80; Loss: 0.3912
Epoch 3748/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3749/10000; Iter 1/80; Loss: 0.4497
Epoch 3749/10000; Iter 51/80; Loss: 0.3505
Epoch 3749/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3750/10000; Iter 1/80; Loss: 0.4167
Epoch 3750/10000; Iter 51/80; Loss: 0.4353
Epoch 3750/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.041
Epoch 3751/10000; Iter 1/80; Loss: 0.3691
Epoch 3751/10000; Iter 51/80; Loss: 0.3822
Epoch 3751/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 3752/10000; Iter 1/80; Loss: 0.3974
Epoch 3752/10000; Iter 51/80; Loss: 0.3775
Epoch 3752/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3753/10000; Iter 1/80; Loss: 0.3546
Epoch 3753/10000; Iter 51/80; Loss: 0.3647
Epoch 3753/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.044
Epoch 3754/10000; Iter 1/80; Loss: 0.3634
Epoch 3754/10000; Iter 51/80; Loss: 0.5017
Epoch 3754/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 3755/10000; Iter 1/80; Loss: 0.4185
Epoch 3755/10000; Iter 51/80; Loss: 0.3444
Epoch 3755/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.037
Epoch 3756/10000; Iter 1/80; Loss: 0.3685
Epoch 3756/10000; Iter 51/80; Loss: 0.4084
Epoch 3756/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.044
Epoch 3757/10000; Iter 1/80; Loss: 0.3401
Epoch 3757/10000; Iter 51/80; Loss: 0.3908
Epoch 3757/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.047
Epoch 3758/10000; Iter 1/80; Loss: 0.4259
Epoch 3758/10000; Iter 51/80; Loss: 0.4178
Epoch 3758/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.048
Epoch 3759/10000; Iter 1/80; Loss: 0.4033
Epoch 3759/10000; Iter 51/80; Loss: 0.4033
Epoch 3759/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3760/10000; Iter 1/80; Loss: 0.3807
Epoch 3760/10000; Iter 51/80; Loss: 0.3752
Epoch 3760/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.039
Epoch 3761/10000; Iter 1/80; Loss: 0.3871
Epoch 3761/10000; Iter 51/80; Loss: 0.3890
Epoch 3761/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.039
Epoch 3762/10000; Iter 1/80; Loss: 0.4520
Epoch 3762/10000; Iter 51/80; Loss: 0.3893
Epoch 3762/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 3763/10000; Iter 1/80; Loss: 0.4198
Epoch 3763/10000; Iter 51/80; Loss: 0.3833
Epoch 3763/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.041
Epoch 3764/10000; Iter 1/80; Loss: 0.4572
Epoch 3764/10000; Iter 51/80; Loss: 0.3678
Epoch 3764/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.045
Epoch 3765/10000; Iter 1/80; Loss: 0.3649
Epoch 3765/10000; Iter 51/80; Loss: 0.3668
Epoch 3765/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.047
Epoch 3766/10000; Iter 1/80; Loss: 0.3708
Epoch 3766/10000; Iter 51/80; Loss: 0.3692
Epoch 3766/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.048
Epoch 3767/10000; Iter 1/80; Loss: 0.3538
Epoch 3767/10000; Iter 51/80; Loss: 0.3662
Epoch 3767/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3768/10000; Iter 1/80; Loss: 0.3509
Epoch 3768/10000; Iter 51/80; Loss: 0.4076
Epoch 3768/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 3769/10000; Iter 1/80; Loss: 0.3845
Epoch 3769/10000; Iter 51/80; Loss: 0.4620
Epoch 3769/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 3770/10000; Iter 1/80; Loss: 0.4433
Epoch 3770/10000; Iter 51/80; Loss: 0.4685
Epoch 3770/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3771/10000; Iter 1/80; Loss: 0.4347
Epoch 3771/10000; Iter 51/80; Loss: 0.3795
Epoch 3771/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3772/10000; Iter 1/80; Loss: 0.4232
Epoch 3772/10000; Iter 51/80; Loss: 0.3959
Epoch 3772/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.04
Epoch 3773/10000; Iter 1/80; Loss: 0.3707
Epoch 3773/10000; Iter 51/80; Loss: 0.3564
Epoch 3773/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.042
Epoch 3774/10000; Iter 1/80; Loss: 0.3964
Epoch 3774/10000; Iter 51/80; Loss: 0.4521
Epoch 3774/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.047
Epoch 3775/10000; Iter 1/80; Loss: 0.3562
Epoch 3775/10000; Iter 51/80; Loss: 0.3752
Epoch 3775/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.041
Epoch 3776/10000; Iter 1/80; Loss: 0.4411
Epoch 3776/10000; Iter 51/80; Loss: 0.4110
Epoch 3776/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3777/10000; Iter 1/80; Loss: 0.4762
Epoch 3777/10000; Iter 51/80; Loss: 0.4489
Epoch 3777/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.042
Epoch 3778/10000; Iter 1/80; Loss: 0.3986
Epoch 3778/10000; Iter 51/80; Loss: 0.4059
Epoch 3778/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3779/10000; Iter 1/80; Loss: 0.4672
Epoch 3779/10000; Iter 51/80; Loss: 0.3758
Epoch 3779/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3780/10000; Iter 1/80; Loss: 0.4349
Epoch 3780/10000; Iter 51/80; Loss: 0.3741
Epoch 3780/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 3781/10000; Iter 1/80; Loss: 0.4134
Epoch 3781/10000; Iter 51/80; Loss: 0.3654
Epoch 3781/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3782/10000; Iter 1/80; Loss: 0.4593
Epoch 3782/10000; Iter 51/80; Loss: 0.4132
Epoch 3782/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.05
Epoch 3783/10000; Iter 1/80; Loss: 0.4018
Epoch 3783/10000; Iter 51/80; Loss: 0.3998
Epoch 3783/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3784/10000; Iter 1/80; Loss: 0.3758
Epoch 3784/10000; Iter 51/80; Loss: 0.4057
Epoch 3784/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.04
Epoch 3785/10000; Iter 1/80; Loss: 0.3526
Epoch 3785/10000; Iter 51/80; Loss: 0.3780
Epoch 3785/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.05
Epoch 3786/10000; Iter 1/80; Loss: 0.4647
Epoch 3786/10000; Iter 51/80; Loss: 0.4069
Epoch 3786/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 3787/10000; Iter 1/80; Loss: 0.4662
Epoch 3787/10000; Iter 51/80; Loss: 0.3689
Epoch 3787/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 3788/10000; Iter 1/80; Loss: 0.3894
Epoch 3788/10000; Iter 51/80; Loss: 0.4057
Epoch 3788/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.047
Epoch 3789/10000; Iter 1/80; Loss: 0.4018
Epoch 3789/10000; Iter 51/80; Loss: 0.3661
Epoch 3789/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3790/10000; Iter 1/80; Loss: 0.3559
Epoch 3790/10000; Iter 51/80; Loss: 0.4094
Epoch 3790/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 3791/10000; Iter 1/80; Loss: 0.4115
Epoch 3791/10000; Iter 51/80; Loss: 0.4157
Epoch 3791/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.047
Epoch 3792/10000; Iter 1/80; Loss: 0.3491
Epoch 3792/10000; Iter 51/80; Loss: 0.4194
Epoch 3792/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3793/10000; Iter 1/80; Loss: 0.3899
Epoch 3793/10000; Iter 51/80; Loss: 0.3357
Epoch 3793/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 3794/10000; Iter 1/80; Loss: 0.4213
Epoch 3794/10000; Iter 51/80; Loss: 0.4481
Epoch 3794/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.051
Epoch 3795/10000; Iter 1/80; Loss: 0.3701
Epoch 3795/10000; Iter 51/80; Loss: 0.3691
Epoch 3795/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.045
Epoch 3796/10000; Iter 1/80; Loss: 0.4162
Epoch 3796/10000; Iter 51/80; Loss: 0.3876
Epoch 3796/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.04
Epoch 3797/10000; Iter 1/80; Loss: 0.3590
Epoch 3797/10000; Iter 51/80; Loss: 0.4037
Epoch 3797/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 3798/10000; Iter 1/80; Loss: 0.3456
Epoch 3798/10000; Iter 51/80; Loss: 0.3838
Epoch 3798/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.047
Epoch 3799/10000; Iter 1/80; Loss: 0.3894
Epoch 3799/10000; Iter 51/80; Loss: 0.3475
Epoch 3799/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.04
Epoch 3800/10000; Iter 1/80; Loss: 0.4125
Epoch 3800/10000; Iter 51/80; Loss: 0.3895
Epoch 3800/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 3801/10000; Iter 1/80; Loss: 0.4022
Epoch 3801/10000; Iter 51/80; Loss: 0.3647
Epoch 3801/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.047
Model saved
Epoch 3802/10000; Iter 1/80; Loss: 0.4031
Epoch 3802/10000; Iter 51/80; Loss: 0.4017
Epoch 3802/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.046
Epoch 3803/10000; Iter 1/80; Loss: 0.4165
Epoch 3803/10000; Iter 51/80; Loss: 0.4157
Epoch 3803/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.045
Epoch 3804/10000; Iter 1/80; Loss: 0.4333
Epoch 3804/10000; Iter 51/80; Loss: 0.3965
Epoch 3804/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.041
Epoch 3805/10000; Iter 1/80; Loss: 0.3446
Epoch 3805/10000; Iter 51/80; Loss: 0.3955
Epoch 3805/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.043
Epoch 3806/10000; Iter 1/80; Loss: 0.4230
Epoch 3806/10000; Iter 51/80; Loss: 0.4830
Epoch 3806/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.039
Epoch 3807/10000; Iter 1/80; Loss: 0.4473
Epoch 3807/10000; Iter 51/80; Loss: 0.3724
Epoch 3807/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3808/10000; Iter 1/80; Loss: 0.4435
Epoch 3808/10000; Iter 51/80; Loss: 0.4615
Epoch 3808/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.046
Epoch 3809/10000; Iter 1/80; Loss: 0.4029
Epoch 3809/10000; Iter 51/80; Loss: 0.4023
Epoch 3809/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 3810/10000; Iter 1/80; Loss: 0.3879
Epoch 3810/10000; Iter 51/80; Loss: 0.4191
Epoch 3810/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 3811/10000; Iter 1/80; Loss: 0.3987
Epoch 3811/10000; Iter 51/80; Loss: 0.4507
Epoch 3811/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.048
Epoch 3812/10000; Iter 1/80; Loss: 0.3875
Epoch 3812/10000; Iter 51/80; Loss: 0.4246
Epoch 3812/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.045
Epoch 3813/10000; Iter 1/80; Loss: 0.3523
Epoch 3813/10000; Iter 51/80; Loss: 0.3957
Epoch 3813/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.048
Epoch 3814/10000; Iter 1/80; Loss: 0.3435
Epoch 3814/10000; Iter 51/80; Loss: 0.4320
Epoch 3814/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3815/10000; Iter 1/80; Loss: 0.3860
Epoch 3815/10000; Iter 51/80; Loss: 0.4452
Epoch 3815/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 3816/10000; Iter 1/80; Loss: 0.3790
Epoch 3816/10000; Iter 51/80; Loss: 0.3346
Epoch 3816/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.04
Epoch 3817/10000; Iter 1/80; Loss: 0.4295
Epoch 3817/10000; Iter 51/80; Loss: 0.4313
Epoch 3817/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.048
Epoch 3818/10000; Iter 1/80; Loss: 0.3718
Epoch 3818/10000; Iter 51/80; Loss: 0.3540
Epoch 3818/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.047
Epoch 3819/10000; Iter 1/80; Loss: 0.4669
Epoch 3819/10000; Iter 51/80; Loss: 0.4204
Epoch 3819/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.053
Epoch 3820/10000; Iter 1/80; Loss: 0.3790
Epoch 3820/10000; Iter 51/80; Loss: 0.3443
Epoch 3820/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3821/10000; Iter 1/80; Loss: 0.4137
Epoch 3821/10000; Iter 51/80; Loss: 0.4672
Epoch 3821/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.043
Epoch 3822/10000; Iter 1/80; Loss: 0.4321
Epoch 3822/10000; Iter 51/80; Loss: 0.4025
Epoch 3822/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.052
Epoch 3823/10000; Iter 1/80; Loss: 0.4311
Epoch 3823/10000; Iter 51/80; Loss: 0.3839
Epoch 3823/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.045
Epoch 3824/10000; Iter 1/80; Loss: 0.4089
Epoch 3824/10000; Iter 51/80; Loss: 0.4012
Epoch 3824/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.051
Epoch 3825/10000; Iter 1/80; Loss: 0.3360
Epoch 3825/10000; Iter 51/80; Loss: 0.3522
Epoch 3825/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.041
Epoch 3826/10000; Iter 1/80; Loss: 0.3867
Epoch 3826/10000; Iter 51/80; Loss: 0.3893
Epoch 3826/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 3827/10000; Iter 1/80; Loss: 0.4701
Epoch 3827/10000; Iter 51/80; Loss: 0.4394
Epoch 3827/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.048
Epoch 3828/10000; Iter 1/80; Loss: 0.4041
Epoch 3828/10000; Iter 51/80; Loss: 0.4457
Epoch 3828/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3829/10000; Iter 1/80; Loss: 0.3932
Epoch 3829/10000; Iter 51/80; Loss: 0.3705
Epoch 3829/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3830/10000; Iter 1/80; Loss: 0.4313
Epoch 3830/10000; Iter 51/80; Loss: 0.3841
Epoch 3830/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 3831/10000; Iter 1/80; Loss: 0.3416
Epoch 3831/10000; Iter 51/80; Loss: 0.3949
Epoch 3831/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.045
Epoch 3832/10000; Iter 1/80; Loss: 0.3943
Epoch 3832/10000; Iter 51/80; Loss: 0.3989
Epoch 3832/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.038
Epoch 3833/10000; Iter 1/80; Loss: 0.3854
Epoch 3833/10000; Iter 51/80; Loss: 0.3639
Epoch 3833/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3834/10000; Iter 1/80; Loss: 0.4233
Epoch 3834/10000; Iter 51/80; Loss: 0.4243
Epoch 3834/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 3835/10000; Iter 1/80; Loss: 0.3844
Epoch 3835/10000; Iter 51/80; Loss: 0.4378
Epoch 3835/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.046
Epoch 3836/10000; Iter 1/80; Loss: 0.3769
Epoch 3836/10000; Iter 51/80; Loss: 0.3802
Epoch 3836/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.045
Epoch 3837/10000; Iter 1/80; Loss: 0.3619
Epoch 3837/10000; Iter 51/80; Loss: 0.4324
Epoch 3837/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 3838/10000; Iter 1/80; Loss: 0.4226
Epoch 3838/10000; Iter 51/80; Loss: 0.3798
Epoch 3838/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 3839/10000; Iter 1/80; Loss: 0.4247
Epoch 3839/10000; Iter 51/80; Loss: 0.3796
Epoch 3839/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 3840/10000; Iter 1/80; Loss: 0.4001
Epoch 3840/10000; Iter 51/80; Loss: 0.4040
Epoch 3840/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.042
Epoch 3841/10000; Iter 1/80; Loss: 0.4260
Epoch 3841/10000; Iter 51/80; Loss: 0.3921
Epoch 3841/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3842/10000; Iter 1/80; Loss: 0.3841
Epoch 3842/10000; Iter 51/80; Loss: 0.3987
Epoch 3842/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3843/10000; Iter 1/80; Loss: 0.3922
Epoch 3843/10000; Iter 51/80; Loss: 0.3574
Epoch 3843/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 3844/10000; Iter 1/80; Loss: 0.4174
Epoch 3844/10000; Iter 51/80; Loss: 0.3729
Epoch 3844/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3845/10000; Iter 1/80; Loss: 0.3580
Epoch 3845/10000; Iter 51/80; Loss: 0.4226
Epoch 3845/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 3846/10000; Iter 1/80; Loss: 0.3793
Epoch 3846/10000; Iter 51/80; Loss: 0.3406
Epoch 3846/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 3847/10000; Iter 1/80; Loss: 0.3230
Epoch 3847/10000; Iter 51/80; Loss: 0.4160
Epoch 3847/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3848/10000; Iter 1/80; Loss: 0.3562
Epoch 3848/10000; Iter 51/80; Loss: 0.4162
Epoch 3848/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.043
Epoch 3849/10000; Iter 1/80; Loss: 0.3628
Epoch 3849/10000; Iter 51/80; Loss: 0.3730
Epoch 3849/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 3850/10000; Iter 1/80; Loss: 0.4022
Epoch 3850/10000; Iter 51/80; Loss: 0.4090
Epoch 3850/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3851/10000; Iter 1/80; Loss: 0.4212
Epoch 3851/10000; Iter 51/80; Loss: 0.3345
Epoch 3851/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.04
Epoch 3852/10000; Iter 1/80; Loss: 0.3943
Epoch 3852/10000; Iter 51/80; Loss: 0.3607
Epoch 3852/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.046
Epoch 3853/10000; Iter 1/80; Loss: 0.3716
Epoch 3853/10000; Iter 51/80; Loss: 0.4292
Epoch 3853/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.047
Epoch 3854/10000; Iter 1/80; Loss: 0.3674
Epoch 3854/10000; Iter 51/80; Loss: 0.4238
Epoch 3854/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 3855/10000; Iter 1/80; Loss: 0.3886
Epoch 3855/10000; Iter 51/80; Loss: 0.3799
Epoch 3855/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.049
Epoch 3856/10000; Iter 1/80; Loss: 0.3848
Epoch 3856/10000; Iter 51/80; Loss: 0.4443
Epoch 3856/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.049
Epoch 3857/10000; Iter 1/80; Loss: 0.4106
Epoch 3857/10000; Iter 51/80; Loss: 0.4511
Epoch 3857/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.049
Epoch 3858/10000; Iter 1/80; Loss: 0.4325
Epoch 3858/10000; Iter 51/80; Loss: 0.3966
Epoch 3858/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3859/10000; Iter 1/80; Loss: 0.4051
Epoch 3859/10000; Iter 51/80; Loss: 0.4379
Epoch 3859/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.048
Epoch 3860/10000; Iter 1/80; Loss: 0.3997
Epoch 3860/10000; Iter 51/80; Loss: 0.3741
Epoch 3860/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.045
Epoch 3861/10000; Iter 1/80; Loss: 0.4315
Epoch 3861/10000; Iter 51/80; Loss: 0.4488
Epoch 3861/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.052
Epoch 3862/10000; Iter 1/80; Loss: 0.3666
Epoch 3862/10000; Iter 51/80; Loss: 0.3472
Epoch 3862/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3863/10000; Iter 1/80; Loss: 0.3529
Epoch 3863/10000; Iter 51/80; Loss: 0.4358
Epoch 3863/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.042
Epoch 3864/10000; Iter 1/80; Loss: 0.4228
Epoch 3864/10000; Iter 51/80; Loss: 0.3925
Epoch 3864/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.05
Epoch 3865/10000; Iter 1/80; Loss: 0.3916
Epoch 3865/10000; Iter 51/80; Loss: 0.4197
Epoch 3865/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 3866/10000; Iter 1/80; Loss: 0.3735
Epoch 3866/10000; Iter 51/80; Loss: 0.4194
Epoch 3866/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.049
Epoch 3867/10000; Iter 1/80; Loss: 0.3835
Epoch 3867/10000; Iter 51/80; Loss: 0.4016
Epoch 3867/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.043
Epoch 3868/10000; Iter 1/80; Loss: 0.3240
Epoch 3868/10000; Iter 51/80; Loss: 0.3775
Epoch 3868/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3869/10000; Iter 1/80; Loss: 0.3728
Epoch 3869/10000; Iter 51/80; Loss: 0.4299
Epoch 3869/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.045
Epoch 3870/10000; Iter 1/80; Loss: 0.3829
Epoch 3870/10000; Iter 51/80; Loss: 0.3655
Epoch 3870/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.048
Epoch 3871/10000; Iter 1/80; Loss: 0.3759
Epoch 3871/10000; Iter 51/80; Loss: 0.4234
Epoch 3871/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.05
Epoch 3872/10000; Iter 1/80; Loss: 0.4413
Epoch 3872/10000; Iter 51/80; Loss: 0.3264
Epoch 3872/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3873/10000; Iter 1/80; Loss: 0.4773
Epoch 3873/10000; Iter 51/80; Loss: 0.4556
Epoch 3873/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.04
Epoch 3874/10000; Iter 1/80; Loss: 0.4105
Epoch 3874/10000; Iter 51/80; Loss: 0.3921
Epoch 3874/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.043
Epoch 3875/10000; Iter 1/80; Loss: 0.3633
Epoch 3875/10000; Iter 51/80; Loss: 0.4144
Epoch 3875/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.038
Epoch 3876/10000; Iter 1/80; Loss: 0.3614
Epoch 3876/10000; Iter 51/80; Loss: 0.3953
Epoch 3876/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.044
Epoch 3877/10000; Iter 1/80; Loss: 0.3537
Epoch 3877/10000; Iter 51/80; Loss: 0.3575
Epoch 3877/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3878/10000; Iter 1/80; Loss: 0.4568
Epoch 3878/10000; Iter 51/80; Loss: 0.3711
Epoch 3878/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.041
Epoch 3879/10000; Iter 1/80; Loss: 0.3896
Epoch 3879/10000; Iter 51/80; Loss: 0.4561
Epoch 3879/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.044
Epoch 3880/10000; Iter 1/80; Loss: 0.3803
Epoch 3880/10000; Iter 51/80; Loss: 0.3823
Epoch 3880/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.041
Epoch 3881/10000; Iter 1/80; Loss: 0.5060
Epoch 3881/10000; Iter 51/80; Loss: 0.4181
Epoch 3881/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3882/10000; Iter 1/80; Loss: 0.3601
Epoch 3882/10000; Iter 51/80; Loss: 0.4335
Epoch 3882/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.041
Epoch 3883/10000; Iter 1/80; Loss: 0.3876
Epoch 3883/10000; Iter 51/80; Loss: 0.3846
Epoch 3883/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 3884/10000; Iter 1/80; Loss: 0.4534
Epoch 3884/10000; Iter 51/80; Loss: 0.3919
Epoch 3884/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.043
Epoch 3885/10000; Iter 1/80; Loss: 0.4518
Epoch 3885/10000; Iter 51/80; Loss: 0.3772
Epoch 3885/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3886/10000; Iter 1/80; Loss: 0.3988
Epoch 3886/10000; Iter 51/80; Loss: 0.3912
Epoch 3886/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.044
Epoch 3887/10000; Iter 1/80; Loss: 0.4039
Epoch 3887/10000; Iter 51/80; Loss: 0.3687
Epoch 3887/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 3888/10000; Iter 1/80; Loss: 0.3912
Epoch 3888/10000; Iter 51/80; Loss: 0.3498
Epoch 3888/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 3889/10000; Iter 1/80; Loss: 0.4035
Epoch 3889/10000; Iter 51/80; Loss: 0.4477
Epoch 3889/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.041
Epoch 3890/10000; Iter 1/80; Loss: 0.4506
Epoch 3890/10000; Iter 51/80; Loss: 0.4416
Epoch 3890/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 3891/10000; Iter 1/80; Loss: 0.3994
Epoch 3891/10000; Iter 51/80; Loss: 0.3246
Epoch 3891/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3892/10000; Iter 1/80; Loss: 0.3599
Epoch 3892/10000; Iter 51/80; Loss: 0.4421
Epoch 3892/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 3893/10000; Iter 1/80; Loss: 0.3448
Epoch 3893/10000; Iter 51/80; Loss: 0.3849
Epoch 3893/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.043
Epoch 3894/10000; Iter 1/80; Loss: 0.3083
Epoch 3894/10000; Iter 51/80; Loss: 0.3881
Epoch 3894/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3895/10000; Iter 1/80; Loss: 0.4123
Epoch 3895/10000; Iter 51/80; Loss: 0.3814
Epoch 3895/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3896/10000; Iter 1/80; Loss: 0.3992
Epoch 3896/10000; Iter 51/80; Loss: 0.3908
Epoch 3896/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.049
Epoch 3897/10000; Iter 1/80; Loss: 0.3934
Epoch 3897/10000; Iter 51/80; Loss: 0.4400
Epoch 3897/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.051
Epoch 3898/10000; Iter 1/80; Loss: 0.4037
Epoch 3898/10000; Iter 51/80; Loss: 0.3958
Epoch 3898/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.051
Epoch 3899/10000; Iter 1/80; Loss: 0.3955
Epoch 3899/10000; Iter 51/80; Loss: 0.4037
Epoch 3899/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 3900/10000; Iter 1/80; Loss: 0.3641
Epoch 3900/10000; Iter 51/80; Loss: 0.4003
Epoch 3900/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 3901/10000; Iter 1/80; Loss: 0.3803
Epoch 3901/10000; Iter 51/80; Loss: 0.4220
Epoch 3901/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.048
Model saved
Epoch 3902/10000; Iter 1/80; Loss: 0.4237
Epoch 3902/10000; Iter 51/80; Loss: 0.3825
Epoch 3902/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.05
Epoch 3903/10000; Iter 1/80; Loss: 0.4054
Epoch 3903/10000; Iter 51/80; Loss: 0.3544
Epoch 3903/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.045
Epoch 3904/10000; Iter 1/80; Loss: 0.4074
Epoch 3904/10000; Iter 51/80; Loss: 0.4467
Epoch 3904/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 3905/10000; Iter 1/80; Loss: 0.3343
Epoch 3905/10000; Iter 51/80; Loss: 0.4198
Epoch 3905/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 3906/10000; Iter 1/80; Loss: 0.4399
Epoch 3906/10000; Iter 51/80; Loss: 0.4668
Epoch 3906/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.049
Epoch 3907/10000; Iter 1/80; Loss: 0.4332
Epoch 3907/10000; Iter 51/80; Loss: 0.3878
Epoch 3907/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.047
Epoch 3908/10000; Iter 1/80; Loss: 0.3519
Epoch 3908/10000; Iter 51/80; Loss: 0.3899
Epoch 3908/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 3909/10000; Iter 1/80; Loss: 0.3863
Epoch 3909/10000; Iter 51/80; Loss: 0.3984
Epoch 3909/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.046
Epoch 3910/10000; Iter 1/80; Loss: 0.3516
Epoch 3910/10000; Iter 51/80; Loss: 0.3850
Epoch 3910/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 3911/10000; Iter 1/80; Loss: 0.3719
Epoch 3911/10000; Iter 51/80; Loss: 0.4138
Epoch 3911/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3912/10000; Iter 1/80; Loss: 0.3746
Epoch 3912/10000; Iter 51/80; Loss: 0.4189
Epoch 3912/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 3913/10000; Iter 1/80; Loss: 0.3878
Epoch 3913/10000; Iter 51/80; Loss: 0.4013
Epoch 3913/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 3914/10000; Iter 1/80; Loss: 0.3673
Epoch 3914/10000; Iter 51/80; Loss: 0.3353
Epoch 3914/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.037
Epoch 3915/10000; Iter 1/80; Loss: 0.4044
Epoch 3915/10000; Iter 51/80; Loss: 0.3862
Epoch 3915/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3916/10000; Iter 1/80; Loss: 0.3619
Epoch 3916/10000; Iter 51/80; Loss: 0.3482
Epoch 3916/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.05
Epoch 3917/10000; Iter 1/80; Loss: 0.3377
Epoch 3917/10000; Iter 51/80; Loss: 0.3425
Epoch 3917/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.038
Epoch 3918/10000; Iter 1/80; Loss: 0.3813
Epoch 3918/10000; Iter 51/80; Loss: 0.3834
Epoch 3918/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.035
Epoch 3919/10000; Iter 1/80; Loss: 0.4415
Epoch 3919/10000; Iter 51/80; Loss: 0.3640
Epoch 3919/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.039
Epoch 3920/10000; Iter 1/80; Loss: 0.3874
Epoch 3920/10000; Iter 51/80; Loss: 0.3605
Epoch 3920/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 3921/10000; Iter 1/80; Loss: 0.3973
Epoch 3921/10000; Iter 51/80; Loss: 0.4076
Epoch 3921/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.044
Epoch 3922/10000; Iter 1/80; Loss: 0.4723
Epoch 3922/10000; Iter 51/80; Loss: 0.4143
Epoch 3922/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.05
Epoch 3923/10000; Iter 1/80; Loss: 0.4507
Epoch 3923/10000; Iter 51/80; Loss: 0.4472
Epoch 3923/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3924/10000; Iter 1/80; Loss: 0.4222
Epoch 3924/10000; Iter 51/80; Loss: 0.3874
Epoch 3924/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 3925/10000; Iter 1/80; Loss: 0.3636
Epoch 3925/10000; Iter 51/80; Loss: 0.3722
Epoch 3925/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.046
Epoch 3926/10000; Iter 1/80; Loss: 0.4365
Epoch 3926/10000; Iter 51/80; Loss: 0.3635
Epoch 3926/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 3927/10000; Iter 1/80; Loss: 0.3326
Epoch 3927/10000; Iter 51/80; Loss: 0.4311
Epoch 3927/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 3928/10000; Iter 1/80; Loss: 0.4686
Epoch 3928/10000; Iter 51/80; Loss: 0.3637
Epoch 3928/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 3929/10000; Iter 1/80; Loss: 0.4011
Epoch 3929/10000; Iter 51/80; Loss: 0.3880
Epoch 3929/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.043
Epoch 3930/10000; Iter 1/80; Loss: 0.3226
Epoch 3930/10000; Iter 51/80; Loss: 0.3712
Epoch 3930/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 3931/10000; Iter 1/80; Loss: 0.4159
Epoch 3931/10000; Iter 51/80; Loss: 0.3991
Epoch 3931/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 3932/10000; Iter 1/80; Loss: 0.3682
Epoch 3932/10000; Iter 51/80; Loss: 0.4107
Epoch 3932/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 3933/10000; Iter 1/80; Loss: 0.3759
Epoch 3933/10000; Iter 51/80; Loss: 0.3624
Epoch 3933/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 3934/10000; Iter 1/80; Loss: 0.4524
Epoch 3934/10000; Iter 51/80; Loss: 0.3802
Epoch 3934/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 3935/10000; Iter 1/80; Loss: 0.4012
Epoch 3935/10000; Iter 51/80; Loss: 0.3579
Epoch 3935/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.045
Epoch 3936/10000; Iter 1/80; Loss: 0.4233
Epoch 3936/10000; Iter 51/80; Loss: 0.4393
Epoch 3936/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 3937/10000; Iter 1/80; Loss: 0.4362
Epoch 3937/10000; Iter 51/80; Loss: 0.3728
Epoch 3937/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 3938/10000; Iter 1/80; Loss: 0.3923
Epoch 3938/10000; Iter 51/80; Loss: 0.4259
Epoch 3938/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.039
Epoch 3939/10000; Iter 1/80; Loss: 0.3781
Epoch 3939/10000; Iter 51/80; Loss: 0.3737
Epoch 3939/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.045
Epoch 3940/10000; Iter 1/80; Loss: 0.3816
Epoch 3940/10000; Iter 51/80; Loss: 0.3942
Epoch 3940/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 3941/10000; Iter 1/80; Loss: 0.3730
Epoch 3941/10000; Iter 51/80; Loss: 0.3700
Epoch 3941/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.049
Epoch 3942/10000; Iter 1/80; Loss: 0.3640
Epoch 3942/10000; Iter 51/80; Loss: 0.4352
Epoch 3942/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 3943/10000; Iter 1/80; Loss: 0.3808
Epoch 3943/10000; Iter 51/80; Loss: 0.3725
Epoch 3943/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.045
Epoch 3944/10000; Iter 1/80; Loss: 0.4009
Epoch 3944/10000; Iter 51/80; Loss: 0.4102
Epoch 3944/10000; Iter 80/80; Training Loss: 0.4030, Test Loss: 0.039
Epoch 3945/10000; Iter 1/80; Loss: 0.4002
Epoch 3945/10000; Iter 51/80; Loss: 0.3785
Epoch 3945/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3946/10000; Iter 1/80; Loss: 0.3958
Epoch 3946/10000; Iter 51/80; Loss: 0.4571
Epoch 3946/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.048
Epoch 3947/10000; Iter 1/80; Loss: 0.3899
Epoch 3947/10000; Iter 51/80; Loss: 0.4576
Epoch 3947/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.044
Epoch 3948/10000; Iter 1/80; Loss: 0.3758
Epoch 3948/10000; Iter 51/80; Loss: 0.3633
Epoch 3948/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.046
Epoch 3949/10000; Iter 1/80; Loss: 0.3746
Epoch 3949/10000; Iter 51/80; Loss: 0.3419
Epoch 3949/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.051
Epoch 3950/10000; Iter 1/80; Loss: 0.3729
Epoch 3950/10000; Iter 51/80; Loss: 0.3536
Epoch 3950/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.046
Epoch 3951/10000; Iter 1/80; Loss: 0.4876
Epoch 3951/10000; Iter 51/80; Loss: 0.4034
Epoch 3951/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.046
Epoch 3952/10000; Iter 1/80; Loss: 0.3823
Epoch 3952/10000; Iter 51/80; Loss: 0.4170
Epoch 3952/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 3953/10000; Iter 1/80; Loss: 0.3952
Epoch 3953/10000; Iter 51/80; Loss: 0.3644
Epoch 3953/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.048
Epoch 3954/10000; Iter 1/80; Loss: 0.4094
Epoch 3954/10000; Iter 51/80; Loss: 0.4019
Epoch 3954/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.043
Epoch 3955/10000; Iter 1/80; Loss: 0.4070
Epoch 3955/10000; Iter 51/80; Loss: 0.3933
Epoch 3955/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.038
Epoch 3956/10000; Iter 1/80; Loss: 0.3997
Epoch 3956/10000; Iter 51/80; Loss: 0.4147
Epoch 3956/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 3957/10000; Iter 1/80; Loss: 0.4117
Epoch 3957/10000; Iter 51/80; Loss: 0.4446
Epoch 3957/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.039
Epoch 3958/10000; Iter 1/80; Loss: 0.4093
Epoch 3958/10000; Iter 51/80; Loss: 0.4420
Epoch 3958/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.041
Epoch 3959/10000; Iter 1/80; Loss: 0.4265
Epoch 3959/10000; Iter 51/80; Loss: 0.4076
Epoch 3959/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.039
Epoch 3960/10000; Iter 1/80; Loss: 0.4195
Epoch 3960/10000; Iter 51/80; Loss: 0.3978
Epoch 3960/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.043
Epoch 3961/10000; Iter 1/80; Loss: 0.3932
Epoch 3961/10000; Iter 51/80; Loss: 0.3577
Epoch 3961/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.046
Epoch 3962/10000; Iter 1/80; Loss: 0.4003
Epoch 3962/10000; Iter 51/80; Loss: 0.3760
Epoch 3962/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.038
Epoch 3963/10000; Iter 1/80; Loss: 0.3455
Epoch 3963/10000; Iter 51/80; Loss: 0.3491
Epoch 3963/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.044
Epoch 3964/10000; Iter 1/80; Loss: 0.3687
Epoch 3964/10000; Iter 51/80; Loss: 0.4265
Epoch 3964/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 3965/10000; Iter 1/80; Loss: 0.3750
Epoch 3965/10000; Iter 51/80; Loss: 0.3557
Epoch 3965/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.037
Epoch 3966/10000; Iter 1/80; Loss: 0.4063
Epoch 3966/10000; Iter 51/80; Loss: 0.3909
Epoch 3966/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.039
Epoch 3967/10000; Iter 1/80; Loss: 0.3823
Epoch 3967/10000; Iter 51/80; Loss: 0.3852
Epoch 3967/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.044
Epoch 3968/10000; Iter 1/80; Loss: 0.3418
Epoch 3968/10000; Iter 51/80; Loss: 0.3975
Epoch 3968/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 3969/10000; Iter 1/80; Loss: 0.3938
Epoch 3969/10000; Iter 51/80; Loss: 0.4419
Epoch 3969/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 3970/10000; Iter 1/80; Loss: 0.4281
Epoch 3970/10000; Iter 51/80; Loss: 0.4423
Epoch 3970/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.042
Epoch 3971/10000; Iter 1/80; Loss: 0.3377
Epoch 3971/10000; Iter 51/80; Loss: 0.3465
Epoch 3971/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.043
Epoch 3972/10000; Iter 1/80; Loss: 0.4152
Epoch 3972/10000; Iter 51/80; Loss: 0.3999
Epoch 3972/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 3973/10000; Iter 1/80; Loss: 0.4854
Epoch 3973/10000; Iter 51/80; Loss: 0.4393
Epoch 3973/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.049
Epoch 3974/10000; Iter 1/80; Loss: 0.3916
Epoch 3974/10000; Iter 51/80; Loss: 0.4742
Epoch 3974/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.038
Epoch 3975/10000; Iter 1/80; Loss: 0.4191
Epoch 3975/10000; Iter 51/80; Loss: 0.4241
Epoch 3975/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 3976/10000; Iter 1/80; Loss: 0.3489
Epoch 3976/10000; Iter 51/80; Loss: 0.3814
Epoch 3976/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.033
Epoch 3977/10000; Iter 1/80; Loss: 0.3648
Epoch 3977/10000; Iter 51/80; Loss: 0.3815
Epoch 3977/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.042
Epoch 3978/10000; Iter 1/80; Loss: 0.3952
Epoch 3978/10000; Iter 51/80; Loss: 0.3369
Epoch 3978/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 3979/10000; Iter 1/80; Loss: 0.4038
Epoch 3979/10000; Iter 51/80; Loss: 0.4124
Epoch 3979/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3980/10000; Iter 1/80; Loss: 0.3877
Epoch 3980/10000; Iter 51/80; Loss: 0.4003
Epoch 3980/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 3981/10000; Iter 1/80; Loss: 0.3737
Epoch 3981/10000; Iter 51/80; Loss: 0.3895
Epoch 3981/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 3982/10000; Iter 1/80; Loss: 0.3784
Epoch 3982/10000; Iter 51/80; Loss: 0.3719
Epoch 3982/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 3983/10000; Iter 1/80; Loss: 0.4899
Epoch 3983/10000; Iter 51/80; Loss: 0.3826
Epoch 3983/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.047
Epoch 3984/10000; Iter 1/80; Loss: 0.4168
Epoch 3984/10000; Iter 51/80; Loss: 0.4150
Epoch 3984/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 3985/10000; Iter 1/80; Loss: 0.3888
Epoch 3985/10000; Iter 51/80; Loss: 0.4006
Epoch 3985/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 3986/10000; Iter 1/80; Loss: 0.4049
Epoch 3986/10000; Iter 51/80; Loss: 0.4157
Epoch 3986/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.045
Epoch 3987/10000; Iter 1/80; Loss: 0.4123
Epoch 3987/10000; Iter 51/80; Loss: 0.3933
Epoch 3987/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.043
Epoch 3988/10000; Iter 1/80; Loss: 0.3732
Epoch 3988/10000; Iter 51/80; Loss: 0.4741
Epoch 3988/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.053
Epoch 3989/10000; Iter 1/80; Loss: 0.3704
Epoch 3989/10000; Iter 51/80; Loss: 0.3956
Epoch 3989/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 3990/10000; Iter 1/80; Loss: 0.3777
Epoch 3990/10000; Iter 51/80; Loss: 0.4329
Epoch 3990/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.039
Epoch 3991/10000; Iter 1/80; Loss: 0.4379
Epoch 3991/10000; Iter 51/80; Loss: 0.4272
Epoch 3991/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.048
Epoch 3992/10000; Iter 1/80; Loss: 0.4134
Epoch 3992/10000; Iter 51/80; Loss: 0.3583
Epoch 3992/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 3993/10000; Iter 1/80; Loss: 0.4288
Epoch 3993/10000; Iter 51/80; Loss: 0.4054
Epoch 3993/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.048
Epoch 3994/10000; Iter 1/80; Loss: 0.3496
Epoch 3994/10000; Iter 51/80; Loss: 0.4248
Epoch 3994/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.041
Epoch 3995/10000; Iter 1/80; Loss: 0.4510
Epoch 3995/10000; Iter 51/80; Loss: 0.3939
Epoch 3995/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.042
Epoch 3996/10000; Iter 1/80; Loss: 0.4493
Epoch 3996/10000; Iter 51/80; Loss: 0.4363
Epoch 3996/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 3997/10000; Iter 1/80; Loss: 0.3889
Epoch 3997/10000; Iter 51/80; Loss: 0.3843
Epoch 3997/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.042
Epoch 3998/10000; Iter 1/80; Loss: 0.4090
Epoch 3998/10000; Iter 51/80; Loss: 0.3649
Epoch 3998/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 3999/10000; Iter 1/80; Loss: 0.3715
Epoch 3999/10000; Iter 51/80; Loss: 0.4156
Epoch 3999/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.045
Epoch 4000/10000; Iter 1/80; Loss: 0.4108
Epoch 4000/10000; Iter 51/80; Loss: 0.3698
Epoch 4000/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.048
Epoch 4001/10000; Iter 1/80; Loss: 0.3867
Epoch 4001/10000; Iter 51/80; Loss: 0.3467
Epoch 4001/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.042
Model saved
Epoch 4002/10000; Iter 1/80; Loss: 0.4115
Epoch 4002/10000; Iter 51/80; Loss: 0.3877
Epoch 4002/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 4003/10000; Iter 1/80; Loss: 0.3518
Epoch 4003/10000; Iter 51/80; Loss: 0.4209
Epoch 4003/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4004/10000; Iter 1/80; Loss: 0.3830
Epoch 4004/10000; Iter 51/80; Loss: 0.3534
Epoch 4004/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 4005/10000; Iter 1/80; Loss: 0.4190
Epoch 4005/10000; Iter 51/80; Loss: 0.4308
Epoch 4005/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 4006/10000; Iter 1/80; Loss: 0.3303
Epoch 4006/10000; Iter 51/80; Loss: 0.4376
Epoch 4006/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.048
Epoch 4007/10000; Iter 1/80; Loss: 0.4170
Epoch 4007/10000; Iter 51/80; Loss: 0.4218
Epoch 4007/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 4008/10000; Iter 1/80; Loss: 0.3872
Epoch 4008/10000; Iter 51/80; Loss: 0.3880
Epoch 4008/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 4009/10000; Iter 1/80; Loss: 0.3823
Epoch 4009/10000; Iter 51/80; Loss: 0.3607
Epoch 4009/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4010/10000; Iter 1/80; Loss: 0.4113
Epoch 4010/10000; Iter 51/80; Loss: 0.3726
Epoch 4010/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.044
Epoch 4011/10000; Iter 1/80; Loss: 0.3780
Epoch 4011/10000; Iter 51/80; Loss: 0.3773
Epoch 4011/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 4012/10000; Iter 1/80; Loss: 0.4403
Epoch 4012/10000; Iter 51/80; Loss: 0.4166
Epoch 4012/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.039
Epoch 4013/10000; Iter 1/80; Loss: 0.3717
Epoch 4013/10000; Iter 51/80; Loss: 0.4523
Epoch 4013/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.038
Epoch 4014/10000; Iter 1/80; Loss: 0.3441
Epoch 4014/10000; Iter 51/80; Loss: 0.4380
Epoch 4014/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.05
Epoch 4015/10000; Iter 1/80; Loss: 0.4200
Epoch 4015/10000; Iter 51/80; Loss: 0.4284
Epoch 4015/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.036
Epoch 4016/10000; Iter 1/80; Loss: 0.4407
Epoch 4016/10000; Iter 51/80; Loss: 0.3883
Epoch 4016/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.045
Epoch 4017/10000; Iter 1/80; Loss: 0.3447
Epoch 4017/10000; Iter 51/80; Loss: 0.3599
Epoch 4017/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 4018/10000; Iter 1/80; Loss: 0.3967
Epoch 4018/10000; Iter 51/80; Loss: 0.3889
Epoch 4018/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.037
Epoch 4019/10000; Iter 1/80; Loss: 0.3943
Epoch 4019/10000; Iter 51/80; Loss: 0.4374
Epoch 4019/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 4020/10000; Iter 1/80; Loss: 0.4599
Epoch 4020/10000; Iter 51/80; Loss: 0.4213
Epoch 4020/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 4021/10000; Iter 1/80; Loss: 0.3597
Epoch 4021/10000; Iter 51/80; Loss: 0.4307
Epoch 4021/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.044
Epoch 4022/10000; Iter 1/80; Loss: 0.4007
Epoch 4022/10000; Iter 51/80; Loss: 0.4070
Epoch 4022/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.052
Epoch 4023/10000; Iter 1/80; Loss: 0.4316
Epoch 4023/10000; Iter 51/80; Loss: 0.3944
Epoch 4023/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 4024/10000; Iter 1/80; Loss: 0.3854
Epoch 4024/10000; Iter 51/80; Loss: 0.4254
Epoch 4024/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.043
Epoch 4025/10000; Iter 1/80; Loss: 0.4147
Epoch 4025/10000; Iter 51/80; Loss: 0.3648
Epoch 4025/10000; Iter 80/80; Training Loss: 0.4050, Test Loss: 0.044
Epoch 4026/10000; Iter 1/80; Loss: 0.4099
Epoch 4026/10000; Iter 51/80; Loss: 0.3847
Epoch 4026/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.039
Epoch 4027/10000; Iter 1/80; Loss: 0.4495
Epoch 4027/10000; Iter 51/80; Loss: 0.3559
Epoch 4027/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.043
Epoch 4028/10000; Iter 1/80; Loss: 0.3896
Epoch 4028/10000; Iter 51/80; Loss: 0.4138
Epoch 4028/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.047
Epoch 4029/10000; Iter 1/80; Loss: 0.4121
Epoch 4029/10000; Iter 51/80; Loss: 0.4435
Epoch 4029/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.045
Epoch 4030/10000; Iter 1/80; Loss: 0.3943
Epoch 4030/10000; Iter 51/80; Loss: 0.3900
Epoch 4030/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4031/10000; Iter 1/80; Loss: 0.3908
Epoch 4031/10000; Iter 51/80; Loss: 0.3645
Epoch 4031/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.037
Epoch 4032/10000; Iter 1/80; Loss: 0.3773
Epoch 4032/10000; Iter 51/80; Loss: 0.3656
Epoch 4032/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.043
Epoch 4033/10000; Iter 1/80; Loss: 0.3928
Epoch 4033/10000; Iter 51/80; Loss: 0.4173
Epoch 4033/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.046
Epoch 4034/10000; Iter 1/80; Loss: 0.4065
Epoch 4034/10000; Iter 51/80; Loss: 0.3951
Epoch 4034/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 4035/10000; Iter 1/80; Loss: 0.3735
Epoch 4035/10000; Iter 51/80; Loss: 0.3721
Epoch 4035/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4036/10000; Iter 1/80; Loss: 0.3945
Epoch 4036/10000; Iter 51/80; Loss: 0.3806
Epoch 4036/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.045
Epoch 4037/10000; Iter 1/80; Loss: 0.4117
Epoch 4037/10000; Iter 51/80; Loss: 0.3647
Epoch 4037/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.055
Epoch 4038/10000; Iter 1/80; Loss: 0.3389
Epoch 4038/10000; Iter 51/80; Loss: 0.3522
Epoch 4038/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.047
Epoch 4039/10000; Iter 1/80; Loss: 0.3701
Epoch 4039/10000; Iter 51/80; Loss: 0.3636
Epoch 4039/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 4040/10000; Iter 1/80; Loss: 0.3786
Epoch 4040/10000; Iter 51/80; Loss: 0.4632
Epoch 4040/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.039
Epoch 4041/10000; Iter 1/80; Loss: 0.4103
Epoch 4041/10000; Iter 51/80; Loss: 0.4400
Epoch 4041/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.041
Epoch 4042/10000; Iter 1/80; Loss: 0.3420
Epoch 4042/10000; Iter 51/80; Loss: 0.3963
Epoch 4042/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.051
Epoch 4043/10000; Iter 1/80; Loss: 0.4340
Epoch 4043/10000; Iter 51/80; Loss: 0.4494
Epoch 4043/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 4044/10000; Iter 1/80; Loss: 0.3579
Epoch 4044/10000; Iter 51/80; Loss: 0.3688
Epoch 4044/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4045/10000; Iter 1/80; Loss: 0.4124
Epoch 4045/10000; Iter 51/80; Loss: 0.4671
Epoch 4045/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.038
Epoch 4046/10000; Iter 1/80; Loss: 0.3751
Epoch 4046/10000; Iter 51/80; Loss: 0.3836
Epoch 4046/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.052
Epoch 4047/10000; Iter 1/80; Loss: 0.3251
Epoch 4047/10000; Iter 51/80; Loss: 0.3415
Epoch 4047/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.044
Epoch 4048/10000; Iter 1/80; Loss: 0.4159
Epoch 4048/10000; Iter 51/80; Loss: 0.4118
Epoch 4048/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.039
Epoch 4049/10000; Iter 1/80; Loss: 0.4466
Epoch 4049/10000; Iter 51/80; Loss: 0.4158
Epoch 4049/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.046
Epoch 4050/10000; Iter 1/80; Loss: 0.3733
Epoch 4050/10000; Iter 51/80; Loss: 0.3671
Epoch 4050/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.041
Epoch 4051/10000; Iter 1/80; Loss: 0.4365
Epoch 4051/10000; Iter 51/80; Loss: 0.4379
Epoch 4051/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4052/10000; Iter 1/80; Loss: 0.3394
Epoch 4052/10000; Iter 51/80; Loss: 0.3683
Epoch 4052/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.041
Epoch 4053/10000; Iter 1/80; Loss: 0.3292
Epoch 4053/10000; Iter 51/80; Loss: 0.4331
Epoch 4053/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.044
Epoch 4054/10000; Iter 1/80; Loss: 0.3817
Epoch 4054/10000; Iter 51/80; Loss: 0.3774
Epoch 4054/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4055/10000; Iter 1/80; Loss: 0.4381
Epoch 4055/10000; Iter 51/80; Loss: 0.4014
Epoch 4055/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4056/10000; Iter 1/80; Loss: 0.4678
Epoch 4056/10000; Iter 51/80; Loss: 0.4510
Epoch 4056/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.048
Epoch 4057/10000; Iter 1/80; Loss: 0.4067
Epoch 4057/10000; Iter 51/80; Loss: 0.4316
Epoch 4057/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 4058/10000; Iter 1/80; Loss: 0.3901
Epoch 4058/10000; Iter 51/80; Loss: 0.3843
Epoch 4058/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.042
Epoch 4059/10000; Iter 1/80; Loss: 0.3703
Epoch 4059/10000; Iter 51/80; Loss: 0.4197
Epoch 4059/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4060/10000; Iter 1/80; Loss: 0.4102
Epoch 4060/10000; Iter 51/80; Loss: 0.4111
Epoch 4060/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.043
Epoch 4061/10000; Iter 1/80; Loss: 0.3853
Epoch 4061/10000; Iter 51/80; Loss: 0.3651
Epoch 4061/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4062/10000; Iter 1/80; Loss: 0.4065
Epoch 4062/10000; Iter 51/80; Loss: 0.4335
Epoch 4062/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4063/10000; Iter 1/80; Loss: 0.3839
Epoch 4063/10000; Iter 51/80; Loss: 0.3794
Epoch 4063/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.048
Epoch 4064/10000; Iter 1/80; Loss: 0.3630
Epoch 4064/10000; Iter 51/80; Loss: 0.3725
Epoch 4064/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.043
Epoch 4065/10000; Iter 1/80; Loss: 0.4051
Epoch 4065/10000; Iter 51/80; Loss: 0.3385
Epoch 4065/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.038
Epoch 4066/10000; Iter 1/80; Loss: 0.4417
Epoch 4066/10000; Iter 51/80; Loss: 0.3968
Epoch 4066/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.042
Epoch 4067/10000; Iter 1/80; Loss: 0.4040
Epoch 4067/10000; Iter 51/80; Loss: 0.3564
Epoch 4067/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.047
Epoch 4068/10000; Iter 1/80; Loss: 0.3844
Epoch 4068/10000; Iter 51/80; Loss: 0.3773
Epoch 4068/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 4069/10000; Iter 1/80; Loss: 0.3461
Epoch 4069/10000; Iter 51/80; Loss: 0.4064
Epoch 4069/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 4070/10000; Iter 1/80; Loss: 0.3815
Epoch 4070/10000; Iter 51/80; Loss: 0.3835
Epoch 4070/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 4071/10000; Iter 1/80; Loss: 0.3802
Epoch 4071/10000; Iter 51/80; Loss: 0.3408
Epoch 4071/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 4072/10000; Iter 1/80; Loss: 0.3691
Epoch 4072/10000; Iter 51/80; Loss: 0.4098
Epoch 4072/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.048
Epoch 4073/10000; Iter 1/80; Loss: 0.3558
Epoch 4073/10000; Iter 51/80; Loss: 0.4276
Epoch 4073/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.05
Epoch 4074/10000; Iter 1/80; Loss: 0.4432
Epoch 4074/10000; Iter 51/80; Loss: 0.3922
Epoch 4074/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4075/10000; Iter 1/80; Loss: 0.4217
Epoch 4075/10000; Iter 51/80; Loss: 0.4043
Epoch 4075/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.037
Epoch 4076/10000; Iter 1/80; Loss: 0.3925
Epoch 4076/10000; Iter 51/80; Loss: 0.3274
Epoch 4076/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4077/10000; Iter 1/80; Loss: 0.3633
Epoch 4077/10000; Iter 51/80; Loss: 0.4029
Epoch 4077/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.044
Epoch 4078/10000; Iter 1/80; Loss: 0.3649
Epoch 4078/10000; Iter 51/80; Loss: 0.3827
Epoch 4078/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4079/10000; Iter 1/80; Loss: 0.3652
Epoch 4079/10000; Iter 51/80; Loss: 0.3804
Epoch 4079/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4080/10000; Iter 1/80; Loss: 0.3626
Epoch 4080/10000; Iter 51/80; Loss: 0.3720
Epoch 4080/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.045
Epoch 4081/10000; Iter 1/80; Loss: 0.4299
Epoch 4081/10000; Iter 51/80; Loss: 0.3861
Epoch 4081/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.05
Epoch 4082/10000; Iter 1/80; Loss: 0.4212
Epoch 4082/10000; Iter 51/80; Loss: 0.3628
Epoch 4082/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.047
Epoch 4083/10000; Iter 1/80; Loss: 0.3810
Epoch 4083/10000; Iter 51/80; Loss: 0.3368
Epoch 4083/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 4084/10000; Iter 1/80; Loss: 0.3785
Epoch 4084/10000; Iter 51/80; Loss: 0.4451
Epoch 4084/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4085/10000; Iter 1/80; Loss: 0.4000
Epoch 4085/10000; Iter 51/80; Loss: 0.4039
Epoch 4085/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4086/10000; Iter 1/80; Loss: 0.3903
Epoch 4086/10000; Iter 51/80; Loss: 0.3962
Epoch 4086/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.04
Epoch 4087/10000; Iter 1/80; Loss: 0.4523
Epoch 4087/10000; Iter 51/80; Loss: 0.4029
Epoch 4087/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.046
Epoch 4088/10000; Iter 1/80; Loss: 0.3689
Epoch 4088/10000; Iter 51/80; Loss: 0.4446
Epoch 4088/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.041
Epoch 4089/10000; Iter 1/80; Loss: 0.4773
Epoch 4089/10000; Iter 51/80; Loss: 0.3550
Epoch 4089/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.04
Epoch 4090/10000; Iter 1/80; Loss: 0.3503
Epoch 4090/10000; Iter 51/80; Loss: 0.4084
Epoch 4090/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.043
Epoch 4091/10000; Iter 1/80; Loss: 0.3682
Epoch 4091/10000; Iter 51/80; Loss: 0.4463
Epoch 4091/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4092/10000; Iter 1/80; Loss: 0.3889
Epoch 4092/10000; Iter 51/80; Loss: 0.3910
Epoch 4092/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.044
Epoch 4093/10000; Iter 1/80; Loss: 0.4131
Epoch 4093/10000; Iter 51/80; Loss: 0.4067
Epoch 4093/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4094/10000; Iter 1/80; Loss: 0.3550
Epoch 4094/10000; Iter 51/80; Loss: 0.3896
Epoch 4094/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.04
Epoch 4095/10000; Iter 1/80; Loss: 0.3608
Epoch 4095/10000; Iter 51/80; Loss: 0.3867
Epoch 4095/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.036
Epoch 4096/10000; Iter 1/80; Loss: 0.3817
Epoch 4096/10000; Iter 51/80; Loss: 0.4394
Epoch 4096/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.037
Epoch 4097/10000; Iter 1/80; Loss: 0.4533
Epoch 4097/10000; Iter 51/80; Loss: 0.4659
Epoch 4097/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.039
Epoch 4098/10000; Iter 1/80; Loss: 0.4158
Epoch 4098/10000; Iter 51/80; Loss: 0.3819
Epoch 4098/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.042
Epoch 4099/10000; Iter 1/80; Loss: 0.3866
Epoch 4099/10000; Iter 51/80; Loss: 0.3858
Epoch 4099/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 4100/10000; Iter 1/80; Loss: 0.3765
Epoch 4100/10000; Iter 51/80; Loss: 0.4169
Epoch 4100/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 4101/10000; Iter 1/80; Loss: 0.3885
Epoch 4101/10000; Iter 51/80; Loss: 0.3613
Epoch 4101/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Model saved
Epoch 4102/10000; Iter 1/80; Loss: 0.3591
Epoch 4102/10000; Iter 51/80; Loss: 0.3403
Epoch 4102/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 4103/10000; Iter 1/80; Loss: 0.3858
Epoch 4103/10000; Iter 51/80; Loss: 0.3943
Epoch 4103/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 4104/10000; Iter 1/80; Loss: 0.4354
Epoch 4104/10000; Iter 51/80; Loss: 0.3530
Epoch 4104/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.04
Epoch 4105/10000; Iter 1/80; Loss: 0.3788
Epoch 4105/10000; Iter 51/80; Loss: 0.4165
Epoch 4105/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.039
Epoch 4106/10000; Iter 1/80; Loss: 0.4047
Epoch 4106/10000; Iter 51/80; Loss: 0.4063
Epoch 4106/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.046
Epoch 4107/10000; Iter 1/80; Loss: 0.3614
Epoch 4107/10000; Iter 51/80; Loss: 0.3777
Epoch 4107/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.039
Epoch 4108/10000; Iter 1/80; Loss: 0.4947
Epoch 4108/10000; Iter 51/80; Loss: 0.4253
Epoch 4108/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.048
Epoch 4109/10000; Iter 1/80; Loss: 0.4064
Epoch 4109/10000; Iter 51/80; Loss: 0.3545
Epoch 4109/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4110/10000; Iter 1/80; Loss: 0.3650
Epoch 4110/10000; Iter 51/80; Loss: 0.3840
Epoch 4110/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.038
Epoch 4111/10000; Iter 1/80; Loss: 0.3638
Epoch 4111/10000; Iter 51/80; Loss: 0.3392
Epoch 4111/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.033
Epoch 4112/10000; Iter 1/80; Loss: 0.4334
Epoch 4112/10000; Iter 51/80; Loss: 0.4176
Epoch 4112/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 4113/10000; Iter 1/80; Loss: 0.3885
Epoch 4113/10000; Iter 51/80; Loss: 0.3117
Epoch 4113/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 4114/10000; Iter 1/80; Loss: 0.3708
Epoch 4114/10000; Iter 51/80; Loss: 0.3658
Epoch 4114/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 4115/10000; Iter 1/80; Loss: 0.4067
Epoch 4115/10000; Iter 51/80; Loss: 0.4228
Epoch 4115/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.038
Epoch 4116/10000; Iter 1/80; Loss: 0.3523
Epoch 4116/10000; Iter 51/80; Loss: 0.3572
Epoch 4116/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.049
Epoch 4117/10000; Iter 1/80; Loss: 0.4010
Epoch 4117/10000; Iter 51/80; Loss: 0.4120
Epoch 4117/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.041
Epoch 4118/10000; Iter 1/80; Loss: 0.3513
Epoch 4118/10000; Iter 51/80; Loss: 0.4262
Epoch 4118/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.048
Epoch 4119/10000; Iter 1/80; Loss: 0.3876
Epoch 4119/10000; Iter 51/80; Loss: 0.4267
Epoch 4119/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4120/10000; Iter 1/80; Loss: 0.3868
Epoch 4120/10000; Iter 51/80; Loss: 0.3756
Epoch 4120/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.05
Epoch 4121/10000; Iter 1/80; Loss: 0.3973
Epoch 4121/10000; Iter 51/80; Loss: 0.3572
Epoch 4121/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.049
Epoch 4122/10000; Iter 1/80; Loss: 0.3600
Epoch 4122/10000; Iter 51/80; Loss: 0.3644
Epoch 4122/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.048
Epoch 4123/10000; Iter 1/80; Loss: 0.3803
Epoch 4123/10000; Iter 51/80; Loss: 0.3384
Epoch 4123/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.038
Epoch 4124/10000; Iter 1/80; Loss: 0.4620
Epoch 4124/10000; Iter 51/80; Loss: 0.4136
Epoch 4124/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.048
Epoch 4125/10000; Iter 1/80; Loss: 0.3989
Epoch 4125/10000; Iter 51/80; Loss: 0.3956
Epoch 4125/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4126/10000; Iter 1/80; Loss: 0.3997
Epoch 4126/10000; Iter 51/80; Loss: 0.4248
Epoch 4126/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.047
Epoch 4127/10000; Iter 1/80; Loss: 0.3664
Epoch 4127/10000; Iter 51/80; Loss: 0.4905
Epoch 4127/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 4128/10000; Iter 1/80; Loss: 0.4180
Epoch 4128/10000; Iter 51/80; Loss: 0.3967
Epoch 4128/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 4129/10000; Iter 1/80; Loss: 0.3994
Epoch 4129/10000; Iter 51/80; Loss: 0.3479
Epoch 4129/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.053
Epoch 4130/10000; Iter 1/80; Loss: 0.3530
Epoch 4130/10000; Iter 51/80; Loss: 0.3998
Epoch 4130/10000; Iter 80/80; Training Loss: 0.4010, Test Loss: 0.038
Epoch 4131/10000; Iter 1/80; Loss: 0.4074
Epoch 4131/10000; Iter 51/80; Loss: 0.4302
Epoch 4131/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 4132/10000; Iter 1/80; Loss: 0.3749
Epoch 4132/10000; Iter 51/80; Loss: 0.4368
Epoch 4132/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.042
Epoch 4133/10000; Iter 1/80; Loss: 0.4400
Epoch 4133/10000; Iter 51/80; Loss: 0.4728
Epoch 4133/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 4134/10000; Iter 1/80; Loss: 0.3905
Epoch 4134/10000; Iter 51/80; Loss: 0.4005
Epoch 4134/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.039
Epoch 4135/10000; Iter 1/80; Loss: 0.3993
Epoch 4135/10000; Iter 51/80; Loss: 0.4558
Epoch 4135/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.039
Epoch 4136/10000; Iter 1/80; Loss: 0.4177
Epoch 4136/10000; Iter 51/80; Loss: 0.4045
Epoch 4136/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 4137/10000; Iter 1/80; Loss: 0.4099
Epoch 4137/10000; Iter 51/80; Loss: 0.3971
Epoch 4137/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.04
Epoch 4138/10000; Iter 1/80; Loss: 0.4371
Epoch 4138/10000; Iter 51/80; Loss: 0.3892
Epoch 4138/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4139/10000; Iter 1/80; Loss: 0.3529
Epoch 4139/10000; Iter 51/80; Loss: 0.3604
Epoch 4139/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.041
Epoch 4140/10000; Iter 1/80; Loss: 0.4526
Epoch 4140/10000; Iter 51/80; Loss: 0.3601
Epoch 4140/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 4141/10000; Iter 1/80; Loss: 0.4317
Epoch 4141/10000; Iter 51/80; Loss: 0.4493
Epoch 4141/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.041
Epoch 4142/10000; Iter 1/80; Loss: 0.4319
Epoch 4142/10000; Iter 51/80; Loss: 0.4103
Epoch 4142/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4143/10000; Iter 1/80; Loss: 0.4086
Epoch 4143/10000; Iter 51/80; Loss: 0.3829
Epoch 4143/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.054
Epoch 4144/10000; Iter 1/80; Loss: 0.3470
Epoch 4144/10000; Iter 51/80; Loss: 0.4353
Epoch 4144/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.039
Epoch 4145/10000; Iter 1/80; Loss: 0.4045
Epoch 4145/10000; Iter 51/80; Loss: 0.3883
Epoch 4145/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.044
Epoch 4146/10000; Iter 1/80; Loss: 0.4181
Epoch 4146/10000; Iter 51/80; Loss: 0.4104
Epoch 4146/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 4147/10000; Iter 1/80; Loss: 0.4172
Epoch 4147/10000; Iter 51/80; Loss: 0.3902
Epoch 4147/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.046
Epoch 4148/10000; Iter 1/80; Loss: 0.3709
Epoch 4148/10000; Iter 51/80; Loss: 0.3893
Epoch 4148/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.039
Epoch 4149/10000; Iter 1/80; Loss: 0.3784
Epoch 4149/10000; Iter 51/80; Loss: 0.3892
Epoch 4149/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 4150/10000; Iter 1/80; Loss: 0.3853
Epoch 4150/10000; Iter 51/80; Loss: 0.3948
Epoch 4150/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.04
Epoch 4151/10000; Iter 1/80; Loss: 0.4234
Epoch 4151/10000; Iter 51/80; Loss: 0.4225
Epoch 4151/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.036
Epoch 4152/10000; Iter 1/80; Loss: 0.4034
Epoch 4152/10000; Iter 51/80; Loss: 0.4336
Epoch 4152/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.043
Epoch 4153/10000; Iter 1/80; Loss: 0.3788
Epoch 4153/10000; Iter 51/80; Loss: 0.4003
Epoch 4153/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.039
Epoch 4154/10000; Iter 1/80; Loss: 0.3475
Epoch 4154/10000; Iter 51/80; Loss: 0.3834
Epoch 4154/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4155/10000; Iter 1/80; Loss: 0.4283
Epoch 4155/10000; Iter 51/80; Loss: 0.3829
Epoch 4155/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 4156/10000; Iter 1/80; Loss: 0.3772
Epoch 4156/10000; Iter 51/80; Loss: 0.4572
Epoch 4156/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 4157/10000; Iter 1/80; Loss: 0.4179
Epoch 4157/10000; Iter 51/80; Loss: 0.3830
Epoch 4157/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4158/10000; Iter 1/80; Loss: 0.3294
Epoch 4158/10000; Iter 51/80; Loss: 0.3686
Epoch 4158/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.052
Epoch 4159/10000; Iter 1/80; Loss: 0.3741
Epoch 4159/10000; Iter 51/80; Loss: 0.3596
Epoch 4159/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.035
Epoch 4160/10000; Iter 1/80; Loss: 0.3512
Epoch 4160/10000; Iter 51/80; Loss: 0.3585
Epoch 4160/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.047
Epoch 4161/10000; Iter 1/80; Loss: 0.3619
Epoch 4161/10000; Iter 51/80; Loss: 0.3670
Epoch 4161/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4162/10000; Iter 1/80; Loss: 0.3758
Epoch 4162/10000; Iter 51/80; Loss: 0.4290
Epoch 4162/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 4163/10000; Iter 1/80; Loss: 0.3734
Epoch 4163/10000; Iter 51/80; Loss: 0.4159
Epoch 4163/10000; Iter 80/80; Training Loss: 0.4040, Test Loss: 0.045
Epoch 4164/10000; Iter 1/80; Loss: 0.3600
Epoch 4164/10000; Iter 51/80; Loss: 0.4475
Epoch 4164/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.04
Epoch 4165/10000; Iter 1/80; Loss: 0.4065
Epoch 4165/10000; Iter 51/80; Loss: 0.3920
Epoch 4165/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 4166/10000; Iter 1/80; Loss: 0.3413
Epoch 4166/10000; Iter 51/80; Loss: 0.3937
Epoch 4166/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.046
Epoch 4167/10000; Iter 1/80; Loss: 0.3713
Epoch 4167/10000; Iter 51/80; Loss: 0.3531
Epoch 4167/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.05
Epoch 4168/10000; Iter 1/80; Loss: 0.4018
Epoch 4168/10000; Iter 51/80; Loss: 0.3300
Epoch 4168/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.048
Epoch 4169/10000; Iter 1/80; Loss: 0.4555
Epoch 4169/10000; Iter 51/80; Loss: 0.3829
Epoch 4169/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4170/10000; Iter 1/80; Loss: 0.4174
Epoch 4170/10000; Iter 51/80; Loss: 0.3829
Epoch 4170/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4171/10000; Iter 1/80; Loss: 0.4191
Epoch 4171/10000; Iter 51/80; Loss: 0.3900
Epoch 4171/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.048
Epoch 4172/10000; Iter 1/80; Loss: 0.3873
Epoch 4172/10000; Iter 51/80; Loss: 0.4076
Epoch 4172/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4173/10000; Iter 1/80; Loss: 0.3992
Epoch 4173/10000; Iter 51/80; Loss: 0.3631
Epoch 4173/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.045
Epoch 4174/10000; Iter 1/80; Loss: 0.3822
Epoch 4174/10000; Iter 51/80; Loss: 0.3799
Epoch 4174/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.041
Epoch 4175/10000; Iter 1/80; Loss: 0.3778
Epoch 4175/10000; Iter 51/80; Loss: 0.4004
Epoch 4175/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.044
Epoch 4176/10000; Iter 1/80; Loss: 0.3387
Epoch 4176/10000; Iter 51/80; Loss: 0.4562
Epoch 4176/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.05
Epoch 4177/10000; Iter 1/80; Loss: 0.4072
Epoch 4177/10000; Iter 51/80; Loss: 0.3805
Epoch 4177/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4178/10000; Iter 1/80; Loss: 0.3776
Epoch 4178/10000; Iter 51/80; Loss: 0.3659
Epoch 4178/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.037
Epoch 4179/10000; Iter 1/80; Loss: 0.3570
Epoch 4179/10000; Iter 51/80; Loss: 0.3583
Epoch 4179/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.039
Epoch 4180/10000; Iter 1/80; Loss: 0.3785
Epoch 4180/10000; Iter 51/80; Loss: 0.3595
Epoch 4180/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 4181/10000; Iter 1/80; Loss: 0.3512
Epoch 4181/10000; Iter 51/80; Loss: 0.4087
Epoch 4181/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4182/10000; Iter 1/80; Loss: 0.3624
Epoch 4182/10000; Iter 51/80; Loss: 0.3465
Epoch 4182/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.049
Epoch 4183/10000; Iter 1/80; Loss: 0.2831
Epoch 4183/10000; Iter 51/80; Loss: 0.4534
Epoch 4183/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 4184/10000; Iter 1/80; Loss: 0.4014
Epoch 4184/10000; Iter 51/80; Loss: 0.3539
Epoch 4184/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.045
Epoch 4185/10000; Iter 1/80; Loss: 0.3953
Epoch 4185/10000; Iter 51/80; Loss: 0.4083
Epoch 4185/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 4186/10000; Iter 1/80; Loss: 0.3448
Epoch 4186/10000; Iter 51/80; Loss: 0.3421
Epoch 4186/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.039
Epoch 4187/10000; Iter 1/80; Loss: 0.3486
Epoch 4187/10000; Iter 51/80; Loss: 0.3676
Epoch 4187/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4188/10000; Iter 1/80; Loss: 0.3590
Epoch 4188/10000; Iter 51/80; Loss: 0.3696
Epoch 4188/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4189/10000; Iter 1/80; Loss: 0.3810
Epoch 4189/10000; Iter 51/80; Loss: 0.4034
Epoch 4189/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.052
Epoch 4190/10000; Iter 1/80; Loss: 0.3543
Epoch 4190/10000; Iter 51/80; Loss: 0.3768
Epoch 4190/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.045
Epoch 4191/10000; Iter 1/80; Loss: 0.3508
Epoch 4191/10000; Iter 51/80; Loss: 0.4081
Epoch 4191/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.04
Epoch 4192/10000; Iter 1/80; Loss: 0.3856
Epoch 4192/10000; Iter 51/80; Loss: 0.4015
Epoch 4192/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4193/10000; Iter 1/80; Loss: 0.4573
Epoch 4193/10000; Iter 51/80; Loss: 0.3537
Epoch 4193/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.041
Epoch 4194/10000; Iter 1/80; Loss: 0.3429
Epoch 4194/10000; Iter 51/80; Loss: 0.4200
Epoch 4194/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.045
Epoch 4195/10000; Iter 1/80; Loss: 0.4085
Epoch 4195/10000; Iter 51/80; Loss: 0.3610
Epoch 4195/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.044
Epoch 4196/10000; Iter 1/80; Loss: 0.3705
Epoch 4196/10000; Iter 51/80; Loss: 0.3557
Epoch 4196/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.042
Epoch 4197/10000; Iter 1/80; Loss: 0.4520
Epoch 4197/10000; Iter 51/80; Loss: 0.3969
Epoch 4197/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4198/10000; Iter 1/80; Loss: 0.3863
Epoch 4198/10000; Iter 51/80; Loss: 0.3669
Epoch 4198/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.048
Epoch 4199/10000; Iter 1/80; Loss: 0.3852
Epoch 4199/10000; Iter 51/80; Loss: 0.3779
Epoch 4199/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4200/10000; Iter 1/80; Loss: 0.4624
Epoch 4200/10000; Iter 51/80; Loss: 0.3726
Epoch 4200/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4201/10000; Iter 1/80; Loss: 0.4432
Epoch 4201/10000; Iter 51/80; Loss: 0.4091
Epoch 4201/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.042
Model saved
Epoch 4202/10000; Iter 1/80; Loss: 0.3587
Epoch 4202/10000; Iter 51/80; Loss: 0.3370
Epoch 4202/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 4203/10000; Iter 1/80; Loss: 0.4040
Epoch 4203/10000; Iter 51/80; Loss: 0.4052
Epoch 4203/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.046
Epoch 4204/10000; Iter 1/80; Loss: 0.3926
Epoch 4204/10000; Iter 51/80; Loss: 0.3963
Epoch 4204/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.046
Epoch 4205/10000; Iter 1/80; Loss: 0.3459
Epoch 4205/10000; Iter 51/80; Loss: 0.3723
Epoch 4205/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4206/10000; Iter 1/80; Loss: 0.3818
Epoch 4206/10000; Iter 51/80; Loss: 0.4255
Epoch 4206/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.048
Epoch 4207/10000; Iter 1/80; Loss: 0.4678
Epoch 4207/10000; Iter 51/80; Loss: 0.3878
Epoch 4207/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.051
Epoch 4208/10000; Iter 1/80; Loss: 0.4158
Epoch 4208/10000; Iter 51/80; Loss: 0.3883
Epoch 4208/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 4209/10000; Iter 1/80; Loss: 0.3826
Epoch 4209/10000; Iter 51/80; Loss: 0.3741
Epoch 4209/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4210/10000; Iter 1/80; Loss: 0.3976
Epoch 4210/10000; Iter 51/80; Loss: 0.3627
Epoch 4210/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.039
Epoch 4211/10000; Iter 1/80; Loss: 0.4218
Epoch 4211/10000; Iter 51/80; Loss: 0.3807
Epoch 4211/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 4212/10000; Iter 1/80; Loss: 0.3998
Epoch 4212/10000; Iter 51/80; Loss: 0.3666
Epoch 4212/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.044
Epoch 4213/10000; Iter 1/80; Loss: 0.3943
Epoch 4213/10000; Iter 51/80; Loss: 0.4300
Epoch 4213/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 4214/10000; Iter 1/80; Loss: 0.3990
Epoch 4214/10000; Iter 51/80; Loss: 0.3468
Epoch 4214/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4215/10000; Iter 1/80; Loss: 0.4121
Epoch 4215/10000; Iter 51/80; Loss: 0.3997
Epoch 4215/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.037
Epoch 4216/10000; Iter 1/80; Loss: 0.4718
Epoch 4216/10000; Iter 51/80; Loss: 0.3657
Epoch 4216/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.04
Epoch 4217/10000; Iter 1/80; Loss: 0.3530
Epoch 4217/10000; Iter 51/80; Loss: 0.3922
Epoch 4217/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.039
Epoch 4218/10000; Iter 1/80; Loss: 0.3910
Epoch 4218/10000; Iter 51/80; Loss: 0.3765
Epoch 4218/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4219/10000; Iter 1/80; Loss: 0.3922
Epoch 4219/10000; Iter 51/80; Loss: 0.4380
Epoch 4219/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4220/10000; Iter 1/80; Loss: 0.3971
Epoch 4220/10000; Iter 51/80; Loss: 0.3884
Epoch 4220/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.041
Epoch 4221/10000; Iter 1/80; Loss: 0.3679
Epoch 4221/10000; Iter 51/80; Loss: 0.3926
Epoch 4221/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4222/10000; Iter 1/80; Loss: 0.4421
Epoch 4222/10000; Iter 51/80; Loss: 0.3936
Epoch 4222/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.045
Epoch 4223/10000; Iter 1/80; Loss: 0.3462
Epoch 4223/10000; Iter 51/80; Loss: 0.4167
Epoch 4223/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 4224/10000; Iter 1/80; Loss: 0.3710
Epoch 4224/10000; Iter 51/80; Loss: 0.3875
Epoch 4224/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.04
Epoch 4225/10000; Iter 1/80; Loss: 0.4195
Epoch 4225/10000; Iter 51/80; Loss: 0.4675
Epoch 4225/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4226/10000; Iter 1/80; Loss: 0.4323
Epoch 4226/10000; Iter 51/80; Loss: 0.3951
Epoch 4226/10000; Iter 80/80; Training Loss: 0.4020, Test Loss: 0.045
Epoch 4227/10000; Iter 1/80; Loss: 0.3749
Epoch 4227/10000; Iter 51/80; Loss: 0.3758
Epoch 4227/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4228/10000; Iter 1/80; Loss: 0.3617
Epoch 4228/10000; Iter 51/80; Loss: 0.3933
Epoch 4228/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4229/10000; Iter 1/80; Loss: 0.3404
Epoch 4229/10000; Iter 51/80; Loss: 0.3855
Epoch 4229/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.044
Epoch 4230/10000; Iter 1/80; Loss: 0.4101
Epoch 4230/10000; Iter 51/80; Loss: 0.4112
Epoch 4230/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.051
Epoch 4231/10000; Iter 1/80; Loss: 0.3909
Epoch 4231/10000; Iter 51/80; Loss: 0.3662
Epoch 4231/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.05
Epoch 4232/10000; Iter 1/80; Loss: 0.3655
Epoch 4232/10000; Iter 51/80; Loss: 0.4268
Epoch 4232/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 4233/10000; Iter 1/80; Loss: 0.4878
Epoch 4233/10000; Iter 51/80; Loss: 0.3725
Epoch 4233/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.05
Epoch 4234/10000; Iter 1/80; Loss: 0.3784
Epoch 4234/10000; Iter 51/80; Loss: 0.3897
Epoch 4234/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4235/10000; Iter 1/80; Loss: 0.4216
Epoch 4235/10000; Iter 51/80; Loss: 0.4740
Epoch 4235/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4236/10000; Iter 1/80; Loss: 0.3850
Epoch 4236/10000; Iter 51/80; Loss: 0.4063
Epoch 4236/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.038
Epoch 4237/10000; Iter 1/80; Loss: 0.3405
Epoch 4237/10000; Iter 51/80; Loss: 0.3450
Epoch 4237/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4238/10000; Iter 1/80; Loss: 0.3824
Epoch 4238/10000; Iter 51/80; Loss: 0.4130
Epoch 4238/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.041
Epoch 4239/10000; Iter 1/80; Loss: 0.4193
Epoch 4239/10000; Iter 51/80; Loss: 0.3909
Epoch 4239/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.044
Epoch 4240/10000; Iter 1/80; Loss: 0.3910
Epoch 4240/10000; Iter 51/80; Loss: 0.4233
Epoch 4240/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 4241/10000; Iter 1/80; Loss: 0.3543
Epoch 4241/10000; Iter 51/80; Loss: 0.3971
Epoch 4241/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4242/10000; Iter 1/80; Loss: 0.4113
Epoch 4242/10000; Iter 51/80; Loss: 0.3334
Epoch 4242/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4243/10000; Iter 1/80; Loss: 0.3621
Epoch 4243/10000; Iter 51/80; Loss: 0.3865
Epoch 4243/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4244/10000; Iter 1/80; Loss: 0.3425
Epoch 4244/10000; Iter 51/80; Loss: 0.3638
Epoch 4244/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 4245/10000; Iter 1/80; Loss: 0.3715
Epoch 4245/10000; Iter 51/80; Loss: 0.4176
Epoch 4245/10000; Iter 80/80; Training Loss: 0.4000, Test Loss: 0.043
Epoch 4246/10000; Iter 1/80; Loss: 0.3874
Epoch 4246/10000; Iter 51/80; Loss: 0.3714
Epoch 4246/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.035
Epoch 4247/10000; Iter 1/80; Loss: 0.4230
Epoch 4247/10000; Iter 51/80; Loss: 0.3728
Epoch 4247/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.042
Epoch 4248/10000; Iter 1/80; Loss: 0.3961
Epoch 4248/10000; Iter 51/80; Loss: 0.3964
Epoch 4248/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.046
Epoch 4249/10000; Iter 1/80; Loss: 0.3996
Epoch 4249/10000; Iter 51/80; Loss: 0.3777
Epoch 4249/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.04
Epoch 4250/10000; Iter 1/80; Loss: 0.4104
Epoch 4250/10000; Iter 51/80; Loss: 0.4364
Epoch 4250/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.036
Epoch 4251/10000; Iter 1/80; Loss: 0.3418
Epoch 4251/10000; Iter 51/80; Loss: 0.4447
Epoch 4251/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4252/10000; Iter 1/80; Loss: 0.3496
Epoch 4252/10000; Iter 51/80; Loss: 0.3671
Epoch 4252/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.048
Epoch 4253/10000; Iter 1/80; Loss: 0.3923
Epoch 4253/10000; Iter 51/80; Loss: 0.3736
Epoch 4253/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4254/10000; Iter 1/80; Loss: 0.3515
Epoch 4254/10000; Iter 51/80; Loss: 0.4017
Epoch 4254/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4255/10000; Iter 1/80; Loss: 0.3441
Epoch 4255/10000; Iter 51/80; Loss: 0.3637
Epoch 4255/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4256/10000; Iter 1/80; Loss: 0.3500
Epoch 4256/10000; Iter 51/80; Loss: 0.3973
Epoch 4256/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.045
Epoch 4257/10000; Iter 1/80; Loss: 0.4052
Epoch 4257/10000; Iter 51/80; Loss: 0.4024
Epoch 4257/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.041
Epoch 4258/10000; Iter 1/80; Loss: 0.4054
Epoch 4258/10000; Iter 51/80; Loss: 0.3847
Epoch 4258/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 4259/10000; Iter 1/80; Loss: 0.3550
Epoch 4259/10000; Iter 51/80; Loss: 0.3797
Epoch 4259/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.036
Epoch 4260/10000; Iter 1/80; Loss: 0.3962
Epoch 4260/10000; Iter 51/80; Loss: 0.3732
Epoch 4260/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.051
Epoch 4261/10000; Iter 1/80; Loss: 0.3656
Epoch 4261/10000; Iter 51/80; Loss: 0.3740
Epoch 4261/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.045
Epoch 4262/10000; Iter 1/80; Loss: 0.3526
Epoch 4262/10000; Iter 51/80; Loss: 0.3888
Epoch 4262/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.05
Epoch 4263/10000; Iter 1/80; Loss: 0.3872
Epoch 4263/10000; Iter 51/80; Loss: 0.3665
Epoch 4263/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4264/10000; Iter 1/80; Loss: 0.3593
Epoch 4264/10000; Iter 51/80; Loss: 0.4247
Epoch 4264/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 4265/10000; Iter 1/80; Loss: 0.4813
Epoch 4265/10000; Iter 51/80; Loss: 0.3405
Epoch 4265/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.043
Epoch 4266/10000; Iter 1/80; Loss: 0.3953
Epoch 4266/10000; Iter 51/80; Loss: 0.3403
Epoch 4266/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4267/10000; Iter 1/80; Loss: 0.3744
Epoch 4267/10000; Iter 51/80; Loss: 0.3560
Epoch 4267/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4268/10000; Iter 1/80; Loss: 0.3993
Epoch 4268/10000; Iter 51/80; Loss: 0.4152
Epoch 4268/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4269/10000; Iter 1/80; Loss: 0.3822
Epoch 4269/10000; Iter 51/80; Loss: 0.4080
Epoch 4269/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.046
Epoch 4270/10000; Iter 1/80; Loss: 0.3622
Epoch 4270/10000; Iter 51/80; Loss: 0.4800
Epoch 4270/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4271/10000; Iter 1/80; Loss: 0.3659
Epoch 4271/10000; Iter 51/80; Loss: 0.4071
Epoch 4271/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4272/10000; Iter 1/80; Loss: 0.4287
Epoch 4272/10000; Iter 51/80; Loss: 0.3681
Epoch 4272/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4273/10000; Iter 1/80; Loss: 0.3621
Epoch 4273/10000; Iter 51/80; Loss: 0.3679
Epoch 4273/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4274/10000; Iter 1/80; Loss: 0.3598
Epoch 4274/10000; Iter 51/80; Loss: 0.3924
Epoch 4274/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.048
Epoch 4275/10000; Iter 1/80; Loss: 0.3471
Epoch 4275/10000; Iter 51/80; Loss: 0.4281
Epoch 4275/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 4276/10000; Iter 1/80; Loss: 0.4481
Epoch 4276/10000; Iter 51/80; Loss: 0.4069
Epoch 4276/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.047
Epoch 4277/10000; Iter 1/80; Loss: 0.3887
Epoch 4277/10000; Iter 51/80; Loss: 0.3596
Epoch 4277/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.04
Epoch 4278/10000; Iter 1/80; Loss: 0.3980
Epoch 4278/10000; Iter 51/80; Loss: 0.3686
Epoch 4278/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 4279/10000; Iter 1/80; Loss: 0.5045
Epoch 4279/10000; Iter 51/80; Loss: 0.4285
Epoch 4279/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.051
Epoch 4280/10000; Iter 1/80; Loss: 0.4358
Epoch 4280/10000; Iter 51/80; Loss: 0.4306
Epoch 4280/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.037
Epoch 4281/10000; Iter 1/80; Loss: 0.3805
Epoch 4281/10000; Iter 51/80; Loss: 0.3943
Epoch 4281/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.045
Epoch 4282/10000; Iter 1/80; Loss: 0.3727
Epoch 4282/10000; Iter 51/80; Loss: 0.3999
Epoch 4282/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 4283/10000; Iter 1/80; Loss: 0.4036
Epoch 4283/10000; Iter 51/80; Loss: 0.3371
Epoch 4283/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4284/10000; Iter 1/80; Loss: 0.3972
Epoch 4284/10000; Iter 51/80; Loss: 0.4162
Epoch 4284/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 4285/10000; Iter 1/80; Loss: 0.4045
Epoch 4285/10000; Iter 51/80; Loss: 0.3453
Epoch 4285/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 4286/10000; Iter 1/80; Loss: 0.3836
Epoch 4286/10000; Iter 51/80; Loss: 0.4216
Epoch 4286/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4287/10000; Iter 1/80; Loss: 0.3931
Epoch 4287/10000; Iter 51/80; Loss: 0.3865
Epoch 4287/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4288/10000; Iter 1/80; Loss: 0.3669
Epoch 4288/10000; Iter 51/80; Loss: 0.3578
Epoch 4288/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.053
Epoch 4289/10000; Iter 1/80; Loss: 0.3291
Epoch 4289/10000; Iter 51/80; Loss: 0.3968
Epoch 4289/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.047
Epoch 4290/10000; Iter 1/80; Loss: 0.3580
Epoch 4290/10000; Iter 51/80; Loss: 0.4279
Epoch 4290/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.049
Epoch 4291/10000; Iter 1/80; Loss: 0.3458
Epoch 4291/10000; Iter 51/80; Loss: 0.3969
Epoch 4291/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.041
Epoch 4292/10000; Iter 1/80; Loss: 0.3549
Epoch 4292/10000; Iter 51/80; Loss: 0.3873
Epoch 4292/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4293/10000; Iter 1/80; Loss: 0.4473
Epoch 4293/10000; Iter 51/80; Loss: 0.3695
Epoch 4293/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.044
Epoch 4294/10000; Iter 1/80; Loss: 0.4041
Epoch 4294/10000; Iter 51/80; Loss: 0.3569
Epoch 4294/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 4295/10000; Iter 1/80; Loss: 0.4031
Epoch 4295/10000; Iter 51/80; Loss: 0.3616
Epoch 4295/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4296/10000; Iter 1/80; Loss: 0.4377
Epoch 4296/10000; Iter 51/80; Loss: 0.4057
Epoch 4296/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.048
Epoch 4297/10000; Iter 1/80; Loss: 0.3758
Epoch 4297/10000; Iter 51/80; Loss: 0.4687
Epoch 4297/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.05
Epoch 4298/10000; Iter 1/80; Loss: 0.4278
Epoch 4298/10000; Iter 51/80; Loss: 0.3817
Epoch 4298/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.055
Epoch 4299/10000; Iter 1/80; Loss: 0.4256
Epoch 4299/10000; Iter 51/80; Loss: 0.3466
Epoch 4299/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4300/10000; Iter 1/80; Loss: 0.3974
Epoch 4300/10000; Iter 51/80; Loss: 0.3815
Epoch 4300/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 4301/10000; Iter 1/80; Loss: 0.3846
Epoch 4301/10000; Iter 51/80; Loss: 0.3952
Epoch 4301/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.047
Model saved
Epoch 4302/10000; Iter 1/80; Loss: 0.3665
Epoch 4302/10000; Iter 51/80; Loss: 0.3927
Epoch 4302/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4303/10000; Iter 1/80; Loss: 0.3951
Epoch 4303/10000; Iter 51/80; Loss: 0.3505
Epoch 4303/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4304/10000; Iter 1/80; Loss: 0.3800
Epoch 4304/10000; Iter 51/80; Loss: 0.4083
Epoch 4304/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4305/10000; Iter 1/80; Loss: 0.3561
Epoch 4305/10000; Iter 51/80; Loss: 0.3992
Epoch 4305/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.047
Epoch 4306/10000; Iter 1/80; Loss: 0.3751
Epoch 4306/10000; Iter 51/80; Loss: 0.4573
Epoch 4306/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.038
Epoch 4307/10000; Iter 1/80; Loss: 0.3780
Epoch 4307/10000; Iter 51/80; Loss: 0.4532
Epoch 4307/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.042
Epoch 4308/10000; Iter 1/80; Loss: 0.3321
Epoch 4308/10000; Iter 51/80; Loss: 0.3973
Epoch 4308/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.047
Epoch 4309/10000; Iter 1/80; Loss: 0.3949
Epoch 4309/10000; Iter 51/80; Loss: 0.3901
Epoch 4309/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4310/10000; Iter 1/80; Loss: 0.4002
Epoch 4310/10000; Iter 51/80; Loss: 0.3786
Epoch 4310/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.041
Epoch 4311/10000; Iter 1/80; Loss: 0.3434
Epoch 4311/10000; Iter 51/80; Loss: 0.4007
Epoch 4311/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4312/10000; Iter 1/80; Loss: 0.3921
Epoch 4312/10000; Iter 51/80; Loss: 0.4027
Epoch 4312/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4313/10000; Iter 1/80; Loss: 0.3740
Epoch 4313/10000; Iter 51/80; Loss: 0.4142
Epoch 4313/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.04
Epoch 4314/10000; Iter 1/80; Loss: 0.3970
Epoch 4314/10000; Iter 51/80; Loss: 0.3600
Epoch 4314/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4315/10000; Iter 1/80; Loss: 0.4140
Epoch 4315/10000; Iter 51/80; Loss: 0.3449
Epoch 4315/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.04
Epoch 4316/10000; Iter 1/80; Loss: 0.3768
Epoch 4316/10000; Iter 51/80; Loss: 0.4286
Epoch 4316/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4317/10000; Iter 1/80; Loss: 0.4060
Epoch 4317/10000; Iter 51/80; Loss: 0.4187
Epoch 4317/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.047
Epoch 4318/10000; Iter 1/80; Loss: 0.3882
Epoch 4318/10000; Iter 51/80; Loss: 0.3956
Epoch 4318/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.041
Epoch 4319/10000; Iter 1/80; Loss: 0.4053
Epoch 4319/10000; Iter 51/80; Loss: 0.4381
Epoch 4319/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.052
Epoch 4320/10000; Iter 1/80; Loss: 0.4311
Epoch 4320/10000; Iter 51/80; Loss: 0.3555
Epoch 4320/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4321/10000; Iter 1/80; Loss: 0.3936
Epoch 4321/10000; Iter 51/80; Loss: 0.3752
Epoch 4321/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 4322/10000; Iter 1/80; Loss: 0.3576
Epoch 4322/10000; Iter 51/80; Loss: 0.4201
Epoch 4322/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.038
Epoch 4323/10000; Iter 1/80; Loss: 0.3809
Epoch 4323/10000; Iter 51/80; Loss: 0.3836
Epoch 4323/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 4324/10000; Iter 1/80; Loss: 0.4641
Epoch 4324/10000; Iter 51/80; Loss: 0.3606
Epoch 4324/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4325/10000; Iter 1/80; Loss: 0.4278
Epoch 4325/10000; Iter 51/80; Loss: 0.4016
Epoch 4325/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.042
Epoch 4326/10000; Iter 1/80; Loss: 0.3751
Epoch 4326/10000; Iter 51/80; Loss: 0.4438
Epoch 4326/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.041
Epoch 4327/10000; Iter 1/80; Loss: 0.3644
Epoch 4327/10000; Iter 51/80; Loss: 0.3880
Epoch 4327/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.039
Epoch 4328/10000; Iter 1/80; Loss: 0.4135
Epoch 4328/10000; Iter 51/80; Loss: 0.4550
Epoch 4328/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4329/10000; Iter 1/80; Loss: 0.3386
Epoch 4329/10000; Iter 51/80; Loss: 0.3018
Epoch 4329/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4330/10000; Iter 1/80; Loss: 0.4240
Epoch 4330/10000; Iter 51/80; Loss: 0.4106
Epoch 4330/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.044
Epoch 4331/10000; Iter 1/80; Loss: 0.4036
Epoch 4331/10000; Iter 51/80; Loss: 0.4080
Epoch 4331/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.042
Epoch 4332/10000; Iter 1/80; Loss: 0.4201
Epoch 4332/10000; Iter 51/80; Loss: 0.3314
Epoch 4332/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4333/10000; Iter 1/80; Loss: 0.3868
Epoch 4333/10000; Iter 51/80; Loss: 0.3633
Epoch 4333/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 4334/10000; Iter 1/80; Loss: 0.4105
Epoch 4334/10000; Iter 51/80; Loss: 0.3635
Epoch 4334/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.042
Epoch 4335/10000; Iter 1/80; Loss: 0.4042
Epoch 4335/10000; Iter 51/80; Loss: 0.4257
Epoch 4335/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.044
Epoch 4336/10000; Iter 1/80; Loss: 0.4389
Epoch 4336/10000; Iter 51/80; Loss: 0.4606
Epoch 4336/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.04
Epoch 4337/10000; Iter 1/80; Loss: 0.3991
Epoch 4337/10000; Iter 51/80; Loss: 0.4287
Epoch 4337/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.05
Epoch 4338/10000; Iter 1/80; Loss: 0.3998
Epoch 4338/10000; Iter 51/80; Loss: 0.3843
Epoch 4338/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4339/10000; Iter 1/80; Loss: 0.3703
Epoch 4339/10000; Iter 51/80; Loss: 0.4132
Epoch 4339/10000; Iter 80/80; Training Loss: 0.3970, Test Loss: 0.041
Epoch 4340/10000; Iter 1/80; Loss: 0.4029
Epoch 4340/10000; Iter 51/80; Loss: 0.3854
Epoch 4340/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.041
Epoch 4341/10000; Iter 1/80; Loss: 0.3765
Epoch 4341/10000; Iter 51/80; Loss: 0.3718
Epoch 4341/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.044
Epoch 4342/10000; Iter 1/80; Loss: 0.3359
Epoch 4342/10000; Iter 51/80; Loss: 0.3769
Epoch 4342/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.044
Epoch 4343/10000; Iter 1/80; Loss: 0.3780
Epoch 4343/10000; Iter 51/80; Loss: 0.3786
Epoch 4343/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.055
Epoch 4344/10000; Iter 1/80; Loss: 0.4104
Epoch 4344/10000; Iter 51/80; Loss: 0.3996
Epoch 4344/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4345/10000; Iter 1/80; Loss: 0.4190
Epoch 4345/10000; Iter 51/80; Loss: 0.3513
Epoch 4345/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.046
Epoch 4346/10000; Iter 1/80; Loss: 0.3241
Epoch 4346/10000; Iter 51/80; Loss: 0.3542
Epoch 4346/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.042
Epoch 4347/10000; Iter 1/80; Loss: 0.3572
Epoch 4347/10000; Iter 51/80; Loss: 0.3649
Epoch 4347/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.04
Epoch 4348/10000; Iter 1/80; Loss: 0.3445
Epoch 4348/10000; Iter 51/80; Loss: 0.3996
Epoch 4348/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4349/10000; Iter 1/80; Loss: 0.3600
Epoch 4349/10000; Iter 51/80; Loss: 0.3652
Epoch 4349/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.044
Epoch 4350/10000; Iter 1/80; Loss: 0.4050
Epoch 4350/10000; Iter 51/80; Loss: 0.3705
Epoch 4350/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.043
Epoch 4351/10000; Iter 1/80; Loss: 0.4208
Epoch 4351/10000; Iter 51/80; Loss: 0.4201
Epoch 4351/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4352/10000; Iter 1/80; Loss: 0.3943
Epoch 4352/10000; Iter 51/80; Loss: 0.4073
Epoch 4352/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.036
Epoch 4353/10000; Iter 1/80; Loss: 0.3868
Epoch 4353/10000; Iter 51/80; Loss: 0.4251
Epoch 4353/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4354/10000; Iter 1/80; Loss: 0.4526
Epoch 4354/10000; Iter 51/80; Loss: 0.3575
Epoch 4354/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.049
Epoch 4355/10000; Iter 1/80; Loss: 0.3902
Epoch 4355/10000; Iter 51/80; Loss: 0.4445
Epoch 4355/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.037
Epoch 4356/10000; Iter 1/80; Loss: 0.4736
Epoch 4356/10000; Iter 51/80; Loss: 0.4018
Epoch 4356/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4357/10000; Iter 1/80; Loss: 0.3511
Epoch 4357/10000; Iter 51/80; Loss: 0.4050
Epoch 4357/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.038
Epoch 4358/10000; Iter 1/80; Loss: 0.4044
Epoch 4358/10000; Iter 51/80; Loss: 0.3741
Epoch 4358/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.042
Epoch 4359/10000; Iter 1/80; Loss: 0.3808
Epoch 4359/10000; Iter 51/80; Loss: 0.3426
Epoch 4359/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4360/10000; Iter 1/80; Loss: 0.4060
Epoch 4360/10000; Iter 51/80; Loss: 0.3664
Epoch 4360/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 4361/10000; Iter 1/80; Loss: 0.4071
Epoch 4361/10000; Iter 51/80; Loss: 0.3743
Epoch 4361/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.046
Epoch 4362/10000; Iter 1/80; Loss: 0.3696
Epoch 4362/10000; Iter 51/80; Loss: 0.3745
Epoch 4362/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4363/10000; Iter 1/80; Loss: 0.3995
Epoch 4363/10000; Iter 51/80; Loss: 0.4452
Epoch 4363/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4364/10000; Iter 1/80; Loss: 0.3735
Epoch 4364/10000; Iter 51/80; Loss: 0.4353
Epoch 4364/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.044
Epoch 4365/10000; Iter 1/80; Loss: 0.4173
Epoch 4365/10000; Iter 51/80; Loss: 0.3748
Epoch 4365/10000; Iter 80/80; Training Loss: 0.3980, Test Loss: 0.049
Epoch 4366/10000; Iter 1/80; Loss: 0.4389
Epoch 4366/10000; Iter 51/80; Loss: 0.4334
Epoch 4366/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.038
Epoch 4367/10000; Iter 1/80; Loss: 0.3813
Epoch 4367/10000; Iter 51/80; Loss: 0.3736
Epoch 4367/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 4368/10000; Iter 1/80; Loss: 0.4132
Epoch 4368/10000; Iter 51/80; Loss: 0.3377
Epoch 4368/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 4369/10000; Iter 1/80; Loss: 0.3448
Epoch 4369/10000; Iter 51/80; Loss: 0.4089
Epoch 4369/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4370/10000; Iter 1/80; Loss: 0.4088
Epoch 4370/10000; Iter 51/80; Loss: 0.3497
Epoch 4370/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.044
Epoch 4371/10000; Iter 1/80; Loss: 0.4014
Epoch 4371/10000; Iter 51/80; Loss: 0.3751
Epoch 4371/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.051
Epoch 4372/10000; Iter 1/80; Loss: 0.2891
Epoch 4372/10000; Iter 51/80; Loss: 0.3387
Epoch 4372/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4373/10000; Iter 1/80; Loss: 0.3517
Epoch 4373/10000; Iter 51/80; Loss: 0.3703
Epoch 4373/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4374/10000; Iter 1/80; Loss: 0.4170
Epoch 4374/10000; Iter 51/80; Loss: 0.3585
Epoch 4374/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.038
Epoch 4375/10000; Iter 1/80; Loss: 0.3985
Epoch 4375/10000; Iter 51/80; Loss: 0.3794
Epoch 4375/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.045
Epoch 4376/10000; Iter 1/80; Loss: 0.4055
Epoch 4376/10000; Iter 51/80; Loss: 0.3812
Epoch 4376/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4377/10000; Iter 1/80; Loss: 0.3666
Epoch 4377/10000; Iter 51/80; Loss: 0.4349
Epoch 4377/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4378/10000; Iter 1/80; Loss: 0.3820
Epoch 4378/10000; Iter 51/80; Loss: 0.3560
Epoch 4378/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4379/10000; Iter 1/80; Loss: 0.3685
Epoch 4379/10000; Iter 51/80; Loss: 0.4172
Epoch 4379/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 4380/10000; Iter 1/80; Loss: 0.3864
Epoch 4380/10000; Iter 51/80; Loss: 0.4121
Epoch 4380/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.041
Epoch 4381/10000; Iter 1/80; Loss: 0.3887
Epoch 4381/10000; Iter 51/80; Loss: 0.3686
Epoch 4381/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.049
Epoch 4382/10000; Iter 1/80; Loss: 0.3810
Epoch 4382/10000; Iter 51/80; Loss: 0.3853
Epoch 4382/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4383/10000; Iter 1/80; Loss: 0.3336
Epoch 4383/10000; Iter 51/80; Loss: 0.3653
Epoch 4383/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.051
Epoch 4384/10000; Iter 1/80; Loss: 0.4084
Epoch 4384/10000; Iter 51/80; Loss: 0.3618
Epoch 4384/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.042
Epoch 4385/10000; Iter 1/80; Loss: 0.3688
Epoch 4385/10000; Iter 51/80; Loss: 0.3801
Epoch 4385/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 4386/10000; Iter 1/80; Loss: 0.4569
Epoch 4386/10000; Iter 51/80; Loss: 0.3936
Epoch 4386/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.054
Epoch 4387/10000; Iter 1/80; Loss: 0.3994
Epoch 4387/10000; Iter 51/80; Loss: 0.3217
Epoch 4387/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.05
Epoch 4388/10000; Iter 1/80; Loss: 0.4001
Epoch 4388/10000; Iter 51/80; Loss: 0.4001
Epoch 4388/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.043
Epoch 4389/10000; Iter 1/80; Loss: 0.3735
Epoch 4389/10000; Iter 51/80; Loss: 0.4269
Epoch 4389/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 4390/10000; Iter 1/80; Loss: 0.3733
Epoch 4390/10000; Iter 51/80; Loss: 0.3752
Epoch 4390/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.04
Epoch 4391/10000; Iter 1/80; Loss: 0.3798
Epoch 4391/10000; Iter 51/80; Loss: 0.4045
Epoch 4391/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4392/10000; Iter 1/80; Loss: 0.3623
Epoch 4392/10000; Iter 51/80; Loss: 0.4334
Epoch 4392/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.039
Epoch 4393/10000; Iter 1/80; Loss: 0.3918
Epoch 4393/10000; Iter 51/80; Loss: 0.4015
Epoch 4393/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4394/10000; Iter 1/80; Loss: 0.4071
Epoch 4394/10000; Iter 51/80; Loss: 0.3428
Epoch 4394/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4395/10000; Iter 1/80; Loss: 0.3375
Epoch 4395/10000; Iter 51/80; Loss: 0.4167
Epoch 4395/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.041
Epoch 4396/10000; Iter 1/80; Loss: 0.3846
Epoch 4396/10000; Iter 51/80; Loss: 0.4084
Epoch 4396/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4397/10000; Iter 1/80; Loss: 0.3489
Epoch 4397/10000; Iter 51/80; Loss: 0.3851
Epoch 4397/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.045
Epoch 4398/10000; Iter 1/80; Loss: 0.3701
Epoch 4398/10000; Iter 51/80; Loss: 0.3650
Epoch 4398/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 4399/10000; Iter 1/80; Loss: 0.4187
Epoch 4399/10000; Iter 51/80; Loss: 0.3983
Epoch 4399/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.051
Epoch 4400/10000; Iter 1/80; Loss: 0.4252
Epoch 4400/10000; Iter 51/80; Loss: 0.4107
Epoch 4400/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4401/10000; Iter 1/80; Loss: 0.4321
Epoch 4401/10000; Iter 51/80; Loss: 0.3919
Epoch 4401/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Model saved
Epoch 4402/10000; Iter 1/80; Loss: 0.3707
Epoch 4402/10000; Iter 51/80; Loss: 0.3819
Epoch 4402/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 4403/10000; Iter 1/80; Loss: 0.3516
Epoch 4403/10000; Iter 51/80; Loss: 0.3970
Epoch 4403/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.048
Epoch 4404/10000; Iter 1/80; Loss: 0.4397
Epoch 4404/10000; Iter 51/80; Loss: 0.4083
Epoch 4404/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4405/10000; Iter 1/80; Loss: 0.3991
Epoch 4405/10000; Iter 51/80; Loss: 0.3571
Epoch 4405/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4406/10000; Iter 1/80; Loss: 0.3582
Epoch 4406/10000; Iter 51/80; Loss: 0.4076
Epoch 4406/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.05
Epoch 4407/10000; Iter 1/80; Loss: 0.4190
Epoch 4407/10000; Iter 51/80; Loss: 0.4041
Epoch 4407/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 4408/10000; Iter 1/80; Loss: 0.3468
Epoch 4408/10000; Iter 51/80; Loss: 0.3863
Epoch 4408/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4409/10000; Iter 1/80; Loss: 0.3712
Epoch 4409/10000; Iter 51/80; Loss: 0.4395
Epoch 4409/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.047
Epoch 4410/10000; Iter 1/80; Loss: 0.4155
Epoch 4410/10000; Iter 51/80; Loss: 0.3660
Epoch 4410/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4411/10000; Iter 1/80; Loss: 0.3913
Epoch 4411/10000; Iter 51/80; Loss: 0.4020
Epoch 4411/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.043
Epoch 4412/10000; Iter 1/80; Loss: 0.4048
Epoch 4412/10000; Iter 51/80; Loss: 0.3783
Epoch 4412/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4413/10000; Iter 1/80; Loss: 0.3112
Epoch 4413/10000; Iter 51/80; Loss: 0.3683
Epoch 4413/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4414/10000; Iter 1/80; Loss: 0.3712
Epoch 4414/10000; Iter 51/80; Loss: 0.3674
Epoch 4414/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.038
Epoch 4415/10000; Iter 1/80; Loss: 0.3737
Epoch 4415/10000; Iter 51/80; Loss: 0.3992
Epoch 4415/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 4416/10000; Iter 1/80; Loss: 0.4071
Epoch 4416/10000; Iter 51/80; Loss: 0.4302
Epoch 4416/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.048
Epoch 4417/10000; Iter 1/80; Loss: 0.3832
Epoch 4417/10000; Iter 51/80; Loss: 0.3612
Epoch 4417/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.039
Epoch 4418/10000; Iter 1/80; Loss: 0.3762
Epoch 4418/10000; Iter 51/80; Loss: 0.3981
Epoch 4418/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4419/10000; Iter 1/80; Loss: 0.3742
Epoch 4419/10000; Iter 51/80; Loss: 0.3250
Epoch 4419/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4420/10000; Iter 1/80; Loss: 0.4000
Epoch 4420/10000; Iter 51/80; Loss: 0.3949
Epoch 4420/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.038
Epoch 4421/10000; Iter 1/80; Loss: 0.4128
Epoch 4421/10000; Iter 51/80; Loss: 0.3890
Epoch 4421/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.039
Epoch 4422/10000; Iter 1/80; Loss: 0.4046
Epoch 4422/10000; Iter 51/80; Loss: 0.4417
Epoch 4422/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 4423/10000; Iter 1/80; Loss: 0.3567
Epoch 4423/10000; Iter 51/80; Loss: 0.4239
Epoch 4423/10000; Iter 80/80; Training Loss: 0.3990, Test Loss: 0.049
Epoch 4424/10000; Iter 1/80; Loss: 0.3745
Epoch 4424/10000; Iter 51/80; Loss: 0.3341
Epoch 4424/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4425/10000; Iter 1/80; Loss: 0.3845
Epoch 4425/10000; Iter 51/80; Loss: 0.3776
Epoch 4425/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.042
Epoch 4426/10000; Iter 1/80; Loss: 0.4020
Epoch 4426/10000; Iter 51/80; Loss: 0.3694
Epoch 4426/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4427/10000; Iter 1/80; Loss: 0.3363
Epoch 4427/10000; Iter 51/80; Loss: 0.3433
Epoch 4427/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4428/10000; Iter 1/80; Loss: 0.3961
Epoch 4428/10000; Iter 51/80; Loss: 0.3605
Epoch 4428/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.041
Epoch 4429/10000; Iter 1/80; Loss: 0.4196
Epoch 4429/10000; Iter 51/80; Loss: 0.3761
Epoch 4429/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4430/10000; Iter 1/80; Loss: 0.3897
Epoch 4430/10000; Iter 51/80; Loss: 0.4247
Epoch 4430/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.038
Epoch 4431/10000; Iter 1/80; Loss: 0.3662
Epoch 4431/10000; Iter 51/80; Loss: 0.4105
Epoch 4431/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.038
Epoch 4432/10000; Iter 1/80; Loss: 0.3354
Epoch 4432/10000; Iter 51/80; Loss: 0.3761
Epoch 4432/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.049
Epoch 4433/10000; Iter 1/80; Loss: 0.3789
Epoch 4433/10000; Iter 51/80; Loss: 0.3783
Epoch 4433/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 4434/10000; Iter 1/80; Loss: 0.4018
Epoch 4434/10000; Iter 51/80; Loss: 0.3856
Epoch 4434/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4435/10000; Iter 1/80; Loss: 0.3834
Epoch 4435/10000; Iter 51/80; Loss: 0.3705
Epoch 4435/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4436/10000; Iter 1/80; Loss: 0.3295
Epoch 4436/10000; Iter 51/80; Loss: 0.3822
Epoch 4436/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.041
Epoch 4437/10000; Iter 1/80; Loss: 0.4500
Epoch 4437/10000; Iter 51/80; Loss: 0.3798
Epoch 4437/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.048
Epoch 4438/10000; Iter 1/80; Loss: 0.3970
Epoch 4438/10000; Iter 51/80; Loss: 0.4020
Epoch 4438/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.047
Epoch 4439/10000; Iter 1/80; Loss: 0.4090
Epoch 4439/10000; Iter 51/80; Loss: 0.3647
Epoch 4439/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4440/10000; Iter 1/80; Loss: 0.3914
Epoch 4440/10000; Iter 51/80; Loss: 0.3571
Epoch 4440/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.039
Epoch 4441/10000; Iter 1/80; Loss: 0.4082
Epoch 4441/10000; Iter 51/80; Loss: 0.3573
Epoch 4441/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.051
Epoch 4442/10000; Iter 1/80; Loss: 0.3524
Epoch 4442/10000; Iter 51/80; Loss: 0.3646
Epoch 4442/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4443/10000; Iter 1/80; Loss: 0.3908
Epoch 4443/10000; Iter 51/80; Loss: 0.3497
Epoch 4443/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4444/10000; Iter 1/80; Loss: 0.3437
Epoch 4444/10000; Iter 51/80; Loss: 0.3894
Epoch 4444/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.041
Epoch 4445/10000; Iter 1/80; Loss: 0.3745
Epoch 4445/10000; Iter 51/80; Loss: 0.3743
Epoch 4445/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4446/10000; Iter 1/80; Loss: 0.3990
Epoch 4446/10000; Iter 51/80; Loss: 0.3646
Epoch 4446/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4447/10000; Iter 1/80; Loss: 0.3754
Epoch 4447/10000; Iter 51/80; Loss: 0.4075
Epoch 4447/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4448/10000; Iter 1/80; Loss: 0.3280
Epoch 4448/10000; Iter 51/80; Loss: 0.4065
Epoch 4448/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4449/10000; Iter 1/80; Loss: 0.3401
Epoch 4449/10000; Iter 51/80; Loss: 0.3726
Epoch 4449/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4450/10000; Iter 1/80; Loss: 0.4260
Epoch 4450/10000; Iter 51/80; Loss: 0.3275
Epoch 4450/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4451/10000; Iter 1/80; Loss: 0.4354
Epoch 4451/10000; Iter 51/80; Loss: 0.3754
Epoch 4451/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.044
Epoch 4452/10000; Iter 1/80; Loss: 0.3424
Epoch 4452/10000; Iter 51/80; Loss: 0.4627
Epoch 4452/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 4453/10000; Iter 1/80; Loss: 0.3720
Epoch 4453/10000; Iter 51/80; Loss: 0.3856
Epoch 4453/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.044
Epoch 4454/10000; Iter 1/80; Loss: 0.3628
Epoch 4454/10000; Iter 51/80; Loss: 0.4010
Epoch 4454/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.04
Epoch 4455/10000; Iter 1/80; Loss: 0.3997
Epoch 4455/10000; Iter 51/80; Loss: 0.4087
Epoch 4455/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.048
Epoch 4456/10000; Iter 1/80; Loss: 0.3952
Epoch 4456/10000; Iter 51/80; Loss: 0.3467
Epoch 4456/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4457/10000; Iter 1/80; Loss: 0.3836
Epoch 4457/10000; Iter 51/80; Loss: 0.3813
Epoch 4457/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.038
Epoch 4458/10000; Iter 1/80; Loss: 0.3547
Epoch 4458/10000; Iter 51/80; Loss: 0.3375
Epoch 4458/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.051
Epoch 4459/10000; Iter 1/80; Loss: 0.3493
Epoch 4459/10000; Iter 51/80; Loss: 0.4464
Epoch 4459/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 4460/10000; Iter 1/80; Loss: 0.3954
Epoch 4460/10000; Iter 51/80; Loss: 0.3445
Epoch 4460/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.04
Epoch 4461/10000; Iter 1/80; Loss: 0.4017
Epoch 4461/10000; Iter 51/80; Loss: 0.3871
Epoch 4461/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.05
Epoch 4462/10000; Iter 1/80; Loss: 0.3890
Epoch 4462/10000; Iter 51/80; Loss: 0.3736
Epoch 4462/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.042
Epoch 4463/10000; Iter 1/80; Loss: 0.3899
Epoch 4463/10000; Iter 51/80; Loss: 0.3423
Epoch 4463/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4464/10000; Iter 1/80; Loss: 0.3702
Epoch 4464/10000; Iter 51/80; Loss: 0.3759
Epoch 4464/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4465/10000; Iter 1/80; Loss: 0.4099
Epoch 4465/10000; Iter 51/80; Loss: 0.4049
Epoch 4465/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4466/10000; Iter 1/80; Loss: 0.4122
Epoch 4466/10000; Iter 51/80; Loss: 0.4274
Epoch 4466/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4467/10000; Iter 1/80; Loss: 0.4051
Epoch 4467/10000; Iter 51/80; Loss: 0.4713
Epoch 4467/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4468/10000; Iter 1/80; Loss: 0.3713
Epoch 4468/10000; Iter 51/80; Loss: 0.4533
Epoch 4468/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.041
Epoch 4469/10000; Iter 1/80; Loss: 0.3643
Epoch 4469/10000; Iter 51/80; Loss: 0.3493
Epoch 4469/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4470/10000; Iter 1/80; Loss: 0.4277
Epoch 4470/10000; Iter 51/80; Loss: 0.3665
Epoch 4470/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.041
Epoch 4471/10000; Iter 1/80; Loss: 0.3519
Epoch 4471/10000; Iter 51/80; Loss: 0.3731
Epoch 4471/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.048
Epoch 4472/10000; Iter 1/80; Loss: 0.3736
Epoch 4472/10000; Iter 51/80; Loss: 0.3830
Epoch 4472/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 4473/10000; Iter 1/80; Loss: 0.4327
Epoch 4473/10000; Iter 51/80; Loss: 0.3461
Epoch 4473/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4474/10000; Iter 1/80; Loss: 0.4069
Epoch 4474/10000; Iter 51/80; Loss: 0.3803
Epoch 4474/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.046
Epoch 4475/10000; Iter 1/80; Loss: 0.4705
Epoch 4475/10000; Iter 51/80; Loss: 0.3932
Epoch 4475/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.047
Epoch 4476/10000; Iter 1/80; Loss: 0.4092
Epoch 4476/10000; Iter 51/80; Loss: 0.3365
Epoch 4476/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4477/10000; Iter 1/80; Loss: 0.4378
Epoch 4477/10000; Iter 51/80; Loss: 0.4605
Epoch 4477/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.05
Epoch 4478/10000; Iter 1/80; Loss: 0.3340
Epoch 4478/10000; Iter 51/80; Loss: 0.3563
Epoch 4478/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4479/10000; Iter 1/80; Loss: 0.3710
Epoch 4479/10000; Iter 51/80; Loss: 0.3686
Epoch 4479/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 4480/10000; Iter 1/80; Loss: 0.3639
Epoch 4480/10000; Iter 51/80; Loss: 0.3797
Epoch 4480/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 4481/10000; Iter 1/80; Loss: 0.3815
Epoch 4481/10000; Iter 51/80; Loss: 0.3873
Epoch 4481/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 4482/10000; Iter 1/80; Loss: 0.3608
Epoch 4482/10000; Iter 51/80; Loss: 0.4071
Epoch 4482/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.039
Epoch 4483/10000; Iter 1/80; Loss: 0.3405
Epoch 4483/10000; Iter 51/80; Loss: 0.4089
Epoch 4483/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.038
Epoch 4484/10000; Iter 1/80; Loss: 0.3844
Epoch 4484/10000; Iter 51/80; Loss: 0.3515
Epoch 4484/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4485/10000; Iter 1/80; Loss: 0.4003
Epoch 4485/10000; Iter 51/80; Loss: 0.4564
Epoch 4485/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4486/10000; Iter 1/80; Loss: 0.3988
Epoch 4486/10000; Iter 51/80; Loss: 0.4234
Epoch 4486/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4487/10000; Iter 1/80; Loss: 0.3509
Epoch 4487/10000; Iter 51/80; Loss: 0.3573
Epoch 4487/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4488/10000; Iter 1/80; Loss: 0.4097
Epoch 4488/10000; Iter 51/80; Loss: 0.4667
Epoch 4488/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4489/10000; Iter 1/80; Loss: 0.3989
Epoch 4489/10000; Iter 51/80; Loss: 0.3574
Epoch 4489/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4490/10000; Iter 1/80; Loss: 0.4304
Epoch 4490/10000; Iter 51/80; Loss: 0.3543
Epoch 4490/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4491/10000; Iter 1/80; Loss: 0.3484
Epoch 4491/10000; Iter 51/80; Loss: 0.4267
Epoch 4491/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.052
Epoch 4492/10000; Iter 1/80; Loss: 0.3881
Epoch 4492/10000; Iter 51/80; Loss: 0.3699
Epoch 4492/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.041
Epoch 4493/10000; Iter 1/80; Loss: 0.4063
Epoch 4493/10000; Iter 51/80; Loss: 0.3745
Epoch 4493/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.046
Epoch 4494/10000; Iter 1/80; Loss: 0.4318
Epoch 4494/10000; Iter 51/80; Loss: 0.3401
Epoch 4494/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4495/10000; Iter 1/80; Loss: 0.3366
Epoch 4495/10000; Iter 51/80; Loss: 0.3485
Epoch 4495/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.05
Epoch 4496/10000; Iter 1/80; Loss: 0.4000
Epoch 4496/10000; Iter 51/80; Loss: 0.3759
Epoch 4496/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.044
Epoch 4497/10000; Iter 1/80; Loss: 0.4336
Epoch 4497/10000; Iter 51/80; Loss: 0.3423
Epoch 4497/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.047
Epoch 4498/10000; Iter 1/80; Loss: 0.4108
Epoch 4498/10000; Iter 51/80; Loss: 0.3740
Epoch 4498/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.042
Epoch 4499/10000; Iter 1/80; Loss: 0.3665
Epoch 4499/10000; Iter 51/80; Loss: 0.3517
Epoch 4499/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.038
Epoch 4500/10000; Iter 1/80; Loss: 0.3680
Epoch 4500/10000; Iter 51/80; Loss: 0.3940
Epoch 4500/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.048
Epoch 4501/10000; Iter 1/80; Loss: 0.3450
Epoch 4501/10000; Iter 51/80; Loss: 0.3883
Epoch 4501/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.051
Model saved
Epoch 4502/10000; Iter 1/80; Loss: 0.3744
Epoch 4502/10000; Iter 51/80; Loss: 0.3358
Epoch 4502/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4503/10000; Iter 1/80; Loss: 0.4459
Epoch 4503/10000; Iter 51/80; Loss: 0.4277
Epoch 4503/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.036
Epoch 4504/10000; Iter 1/80; Loss: 0.3918
Epoch 4504/10000; Iter 51/80; Loss: 0.3823
Epoch 4504/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.05
Epoch 4505/10000; Iter 1/80; Loss: 0.3309
Epoch 4505/10000; Iter 51/80; Loss: 0.3900
Epoch 4505/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 4506/10000; Iter 1/80; Loss: 0.3536
Epoch 4506/10000; Iter 51/80; Loss: 0.4001
Epoch 4506/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.051
Epoch 4507/10000; Iter 1/80; Loss: 0.4419
Epoch 4507/10000; Iter 51/80; Loss: 0.4144
Epoch 4507/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.048
Epoch 4508/10000; Iter 1/80; Loss: 0.4087
Epoch 4508/10000; Iter 51/80; Loss: 0.3439
Epoch 4508/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.047
Epoch 4509/10000; Iter 1/80; Loss: 0.4415
Epoch 4509/10000; Iter 51/80; Loss: 0.4411
Epoch 4509/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4510/10000; Iter 1/80; Loss: 0.3979
Epoch 4510/10000; Iter 51/80; Loss: 0.4255
Epoch 4510/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.05
Epoch 4511/10000; Iter 1/80; Loss: 0.4486
Epoch 4511/10000; Iter 51/80; Loss: 0.3671
Epoch 4511/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4512/10000; Iter 1/80; Loss: 0.3874
Epoch 4512/10000; Iter 51/80; Loss: 0.3814
Epoch 4512/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.043
Epoch 4513/10000; Iter 1/80; Loss: 0.4465
Epoch 4513/10000; Iter 51/80; Loss: 0.4318
Epoch 4513/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.053
Epoch 4514/10000; Iter 1/80; Loss: 0.3959
Epoch 4514/10000; Iter 51/80; Loss: 0.4165
Epoch 4514/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.039
Epoch 4515/10000; Iter 1/80; Loss: 0.4163
Epoch 4515/10000; Iter 51/80; Loss: 0.3772
Epoch 4515/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.041
Epoch 4516/10000; Iter 1/80; Loss: 0.3501
Epoch 4516/10000; Iter 51/80; Loss: 0.4549
Epoch 4516/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.042
Epoch 4517/10000; Iter 1/80; Loss: 0.3846
Epoch 4517/10000; Iter 51/80; Loss: 0.4261
Epoch 4517/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 4518/10000; Iter 1/80; Loss: 0.4333
Epoch 4518/10000; Iter 51/80; Loss: 0.3381
Epoch 4518/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4519/10000; Iter 1/80; Loss: 0.3950
Epoch 4519/10000; Iter 51/80; Loss: 0.4385
Epoch 4519/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4520/10000; Iter 1/80; Loss: 0.4368
Epoch 4520/10000; Iter 51/80; Loss: 0.3349
Epoch 4520/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4521/10000; Iter 1/80; Loss: 0.3682
Epoch 4521/10000; Iter 51/80; Loss: 0.4243
Epoch 4521/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4522/10000; Iter 1/80; Loss: 0.3548
Epoch 4522/10000; Iter 51/80; Loss: 0.3989
Epoch 4522/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.045
Epoch 4523/10000; Iter 1/80; Loss: 0.3814
Epoch 4523/10000; Iter 51/80; Loss: 0.3885
Epoch 4523/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4524/10000; Iter 1/80; Loss: 0.3670
Epoch 4524/10000; Iter 51/80; Loss: 0.4035
Epoch 4524/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4525/10000; Iter 1/80; Loss: 0.3276
Epoch 4525/10000; Iter 51/80; Loss: 0.3724
Epoch 4525/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.037
Epoch 4526/10000; Iter 1/80; Loss: 0.4032
Epoch 4526/10000; Iter 51/80; Loss: 0.3938
Epoch 4526/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.038
Epoch 4527/10000; Iter 1/80; Loss: 0.4183
Epoch 4527/10000; Iter 51/80; Loss: 0.3882
Epoch 4527/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.045
Epoch 4528/10000; Iter 1/80; Loss: 0.3614
Epoch 4528/10000; Iter 51/80; Loss: 0.4063
Epoch 4528/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.041
Epoch 4529/10000; Iter 1/80; Loss: 0.4044
Epoch 4529/10000; Iter 51/80; Loss: 0.4055
Epoch 4529/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.049
Epoch 4530/10000; Iter 1/80; Loss: 0.4034
Epoch 4530/10000; Iter 51/80; Loss: 0.3434
Epoch 4530/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4531/10000; Iter 1/80; Loss: 0.3759
Epoch 4531/10000; Iter 51/80; Loss: 0.3047
Epoch 4531/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.045
Epoch 4532/10000; Iter 1/80; Loss: 0.4119
Epoch 4532/10000; Iter 51/80; Loss: 0.3968
Epoch 4532/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.042
Epoch 4533/10000; Iter 1/80; Loss: 0.3570
Epoch 4533/10000; Iter 51/80; Loss: 0.3794
Epoch 4533/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.037
Epoch 4534/10000; Iter 1/80; Loss: 0.4341
Epoch 4534/10000; Iter 51/80; Loss: 0.4212
Epoch 4534/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.048
Epoch 4535/10000; Iter 1/80; Loss: 0.4333
Epoch 4535/10000; Iter 51/80; Loss: 0.3660
Epoch 4535/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.046
Epoch 4536/10000; Iter 1/80; Loss: 0.4018
Epoch 4536/10000; Iter 51/80; Loss: 0.3635
Epoch 4536/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.041
Epoch 4537/10000; Iter 1/80; Loss: 0.3668
Epoch 4537/10000; Iter 51/80; Loss: 0.3998
Epoch 4537/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4538/10000; Iter 1/80; Loss: 0.3792
Epoch 4538/10000; Iter 51/80; Loss: 0.3701
Epoch 4538/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.048
Epoch 4539/10000; Iter 1/80; Loss: 0.3827
Epoch 4539/10000; Iter 51/80; Loss: 0.4634
Epoch 4539/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.039
Epoch 4540/10000; Iter 1/80; Loss: 0.3704
Epoch 4540/10000; Iter 51/80; Loss: 0.4365
Epoch 4540/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.049
Epoch 4541/10000; Iter 1/80; Loss: 0.3996
Epoch 4541/10000; Iter 51/80; Loss: 0.3833
Epoch 4541/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4542/10000; Iter 1/80; Loss: 0.4157
Epoch 4542/10000; Iter 51/80; Loss: 0.4837
Epoch 4542/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4543/10000; Iter 1/80; Loss: 0.3075
Epoch 4543/10000; Iter 51/80; Loss: 0.4000
Epoch 4543/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.049
Epoch 4544/10000; Iter 1/80; Loss: 0.3842
Epoch 4544/10000; Iter 51/80; Loss: 0.3401
Epoch 4544/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 4545/10000; Iter 1/80; Loss: 0.3925
Epoch 4545/10000; Iter 51/80; Loss: 0.4061
Epoch 4545/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.046
Epoch 4546/10000; Iter 1/80; Loss: 0.4058
Epoch 4546/10000; Iter 51/80; Loss: 0.4017
Epoch 4546/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 4547/10000; Iter 1/80; Loss: 0.4385
Epoch 4547/10000; Iter 51/80; Loss: 0.4180
Epoch 4547/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.04
Epoch 4548/10000; Iter 1/80; Loss: 0.3586
Epoch 4548/10000; Iter 51/80; Loss: 0.3693
Epoch 4548/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.04
Epoch 4549/10000; Iter 1/80; Loss: 0.3300
Epoch 4549/10000; Iter 51/80; Loss: 0.3000
Epoch 4549/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.048
Epoch 4550/10000; Iter 1/80; Loss: 0.3947
Epoch 4550/10000; Iter 51/80; Loss: 0.3780
Epoch 4550/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.048
Epoch 4551/10000; Iter 1/80; Loss: 0.4326
Epoch 4551/10000; Iter 51/80; Loss: 0.4136
Epoch 4551/10000; Iter 80/80; Training Loss: 0.3950, Test Loss: 0.05
Epoch 4552/10000; Iter 1/80; Loss: 0.4530
Epoch 4552/10000; Iter 51/80; Loss: 0.3729
Epoch 4552/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4553/10000; Iter 1/80; Loss: 0.4282
Epoch 4553/10000; Iter 51/80; Loss: 0.4425
Epoch 4553/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4554/10000; Iter 1/80; Loss: 0.3580
Epoch 4554/10000; Iter 51/80; Loss: 0.4066
Epoch 4554/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.041
Epoch 4555/10000; Iter 1/80; Loss: 0.3812
Epoch 4555/10000; Iter 51/80; Loss: 0.4100
Epoch 4555/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4556/10000; Iter 1/80; Loss: 0.3938
Epoch 4556/10000; Iter 51/80; Loss: 0.4873
Epoch 4556/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.042
Epoch 4557/10000; Iter 1/80; Loss: 0.4088
Epoch 4557/10000; Iter 51/80; Loss: 0.3917
Epoch 4557/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.048
Epoch 4558/10000; Iter 1/80; Loss: 0.3622
Epoch 4558/10000; Iter 51/80; Loss: 0.3925
Epoch 4558/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4559/10000; Iter 1/80; Loss: 0.4803
Epoch 4559/10000; Iter 51/80; Loss: 0.4082
Epoch 4559/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.038
Epoch 4560/10000; Iter 1/80; Loss: 0.4466
Epoch 4560/10000; Iter 51/80; Loss: 0.3497
Epoch 4560/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4561/10000; Iter 1/80; Loss: 0.3761
Epoch 4561/10000; Iter 51/80; Loss: 0.3265
Epoch 4561/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 4562/10000; Iter 1/80; Loss: 0.3508
Epoch 4562/10000; Iter 51/80; Loss: 0.4330
Epoch 4562/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.046
Epoch 4563/10000; Iter 1/80; Loss: 0.4181
Epoch 4563/10000; Iter 51/80; Loss: 0.4296
Epoch 4563/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4564/10000; Iter 1/80; Loss: 0.3892
Epoch 4564/10000; Iter 51/80; Loss: 0.4049
Epoch 4564/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 4565/10000; Iter 1/80; Loss: 0.3867
Epoch 4565/10000; Iter 51/80; Loss: 0.3612
Epoch 4565/10000; Iter 80/80; Training Loss: 0.3960, Test Loss: 0.041
Epoch 4566/10000; Iter 1/80; Loss: 0.4091
Epoch 4566/10000; Iter 51/80; Loss: 0.3642
Epoch 4566/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4567/10000; Iter 1/80; Loss: 0.3886
Epoch 4567/10000; Iter 51/80; Loss: 0.3668
Epoch 4567/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.049
Epoch 4568/10000; Iter 1/80; Loss: 0.3564
Epoch 4568/10000; Iter 51/80; Loss: 0.3485
Epoch 4568/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.038
Epoch 4569/10000; Iter 1/80; Loss: 0.4308
Epoch 4569/10000; Iter 51/80; Loss: 0.4026
Epoch 4569/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.052
Epoch 4570/10000; Iter 1/80; Loss: 0.3470
Epoch 4570/10000; Iter 51/80; Loss: 0.4152
Epoch 4570/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4571/10000; Iter 1/80; Loss: 0.3774
Epoch 4571/10000; Iter 51/80; Loss: 0.3315
Epoch 4571/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 4572/10000; Iter 1/80; Loss: 0.4481
Epoch 4572/10000; Iter 51/80; Loss: 0.3650
Epoch 4572/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4573/10000; Iter 1/80; Loss: 0.3047
Epoch 4573/10000; Iter 51/80; Loss: 0.4691
Epoch 4573/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.055
Epoch 4574/10000; Iter 1/80; Loss: 0.3743
Epoch 4574/10000; Iter 51/80; Loss: 0.3875
Epoch 4574/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4575/10000; Iter 1/80; Loss: 0.3302
Epoch 4575/10000; Iter 51/80; Loss: 0.4145
Epoch 4575/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4576/10000; Iter 1/80; Loss: 0.3474
Epoch 4576/10000; Iter 51/80; Loss: 0.3724
Epoch 4576/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.047
Epoch 4577/10000; Iter 1/80; Loss: 0.3674
Epoch 4577/10000; Iter 51/80; Loss: 0.3995
Epoch 4577/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4578/10000; Iter 1/80; Loss: 0.3916
Epoch 4578/10000; Iter 51/80; Loss: 0.3622
Epoch 4578/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4579/10000; Iter 1/80; Loss: 0.3417
Epoch 4579/10000; Iter 51/80; Loss: 0.3797
Epoch 4579/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.039
Epoch 4580/10000; Iter 1/80; Loss: 0.3998
Epoch 4580/10000; Iter 51/80; Loss: 0.3873
Epoch 4580/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.049
Epoch 4581/10000; Iter 1/80; Loss: 0.3328
Epoch 4581/10000; Iter 51/80; Loss: 0.4181
Epoch 4581/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.04
Epoch 4582/10000; Iter 1/80; Loss: 0.4096
Epoch 4582/10000; Iter 51/80; Loss: 0.3974
Epoch 4582/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.045
Epoch 4583/10000; Iter 1/80; Loss: 0.3832
Epoch 4583/10000; Iter 51/80; Loss: 0.4669
Epoch 4583/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4584/10000; Iter 1/80; Loss: 0.3766
Epoch 4584/10000; Iter 51/80; Loss: 0.4030
Epoch 4584/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4585/10000; Iter 1/80; Loss: 0.3698
Epoch 4585/10000; Iter 51/80; Loss: 0.4141
Epoch 4585/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.049
Epoch 4586/10000; Iter 1/80; Loss: 0.3819
Epoch 4586/10000; Iter 51/80; Loss: 0.3304
Epoch 4586/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.041
Epoch 4587/10000; Iter 1/80; Loss: 0.3677
Epoch 4587/10000; Iter 51/80; Loss: 0.3668
Epoch 4587/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 4588/10000; Iter 1/80; Loss: 0.3815
Epoch 4588/10000; Iter 51/80; Loss: 0.4315
Epoch 4588/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.038
Epoch 4589/10000; Iter 1/80; Loss: 0.3860
Epoch 4589/10000; Iter 51/80; Loss: 0.3704
Epoch 4589/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4590/10000; Iter 1/80; Loss: 0.4117
Epoch 4590/10000; Iter 51/80; Loss: 0.3504
Epoch 4590/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.049
Epoch 4591/10000; Iter 1/80; Loss: 0.4354
Epoch 4591/10000; Iter 51/80; Loss: 0.3788
Epoch 4591/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4592/10000; Iter 1/80; Loss: 0.3934
Epoch 4592/10000; Iter 51/80; Loss: 0.3823
Epoch 4592/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.041
Epoch 4593/10000; Iter 1/80; Loss: 0.3216
Epoch 4593/10000; Iter 51/80; Loss: 0.3790
Epoch 4593/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.041
Epoch 4594/10000; Iter 1/80; Loss: 0.4098
Epoch 4594/10000; Iter 51/80; Loss: 0.3772
Epoch 4594/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4595/10000; Iter 1/80; Loss: 0.3621
Epoch 4595/10000; Iter 51/80; Loss: 0.3755
Epoch 4595/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4596/10000; Iter 1/80; Loss: 0.3709
Epoch 4596/10000; Iter 51/80; Loss: 0.3697
Epoch 4596/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4597/10000; Iter 1/80; Loss: 0.3828
Epoch 4597/10000; Iter 51/80; Loss: 0.3534
Epoch 4597/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4598/10000; Iter 1/80; Loss: 0.4110
Epoch 4598/10000; Iter 51/80; Loss: 0.4399
Epoch 4598/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4599/10000; Iter 1/80; Loss: 0.4218
Epoch 4599/10000; Iter 51/80; Loss: 0.3482
Epoch 4599/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.041
Epoch 4600/10000; Iter 1/80; Loss: 0.4333
Epoch 4600/10000; Iter 51/80; Loss: 0.3669
Epoch 4600/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4601/10000; Iter 1/80; Loss: 0.3707
Epoch 4601/10000; Iter 51/80; Loss: 0.3703
Epoch 4601/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.039
Model saved
Epoch 4602/10000; Iter 1/80; Loss: 0.3865
Epoch 4602/10000; Iter 51/80; Loss: 0.4090
Epoch 4602/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.045
Epoch 4603/10000; Iter 1/80; Loss: 0.3673
Epoch 4603/10000; Iter 51/80; Loss: 0.3971
Epoch 4603/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4604/10000; Iter 1/80; Loss: 0.3973
Epoch 4604/10000; Iter 51/80; Loss: 0.4198
Epoch 4604/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4605/10000; Iter 1/80; Loss: 0.4222
Epoch 4605/10000; Iter 51/80; Loss: 0.4242
Epoch 4605/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.04
Epoch 4606/10000; Iter 1/80; Loss: 0.3932
Epoch 4606/10000; Iter 51/80; Loss: 0.3520
Epoch 4606/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.04
Epoch 4607/10000; Iter 1/80; Loss: 0.4028
Epoch 4607/10000; Iter 51/80; Loss: 0.3993
Epoch 4607/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.049
Epoch 4608/10000; Iter 1/80; Loss: 0.3540
Epoch 4608/10000; Iter 51/80; Loss: 0.3797
Epoch 4608/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4609/10000; Iter 1/80; Loss: 0.3828
Epoch 4609/10000; Iter 51/80; Loss: 0.3991
Epoch 4609/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4610/10000; Iter 1/80; Loss: 0.3936
Epoch 4610/10000; Iter 51/80; Loss: 0.4298
Epoch 4610/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.037
Epoch 4611/10000; Iter 1/80; Loss: 0.3329
Epoch 4611/10000; Iter 51/80; Loss: 0.3382
Epoch 4611/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4612/10000; Iter 1/80; Loss: 0.4416
Epoch 4612/10000; Iter 51/80; Loss: 0.4211
Epoch 4612/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.046
Epoch 4613/10000; Iter 1/80; Loss: 0.3573
Epoch 4613/10000; Iter 51/80; Loss: 0.4227
Epoch 4613/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4614/10000; Iter 1/80; Loss: 0.4220
Epoch 4614/10000; Iter 51/80; Loss: 0.3318
Epoch 4614/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.039
Epoch 4615/10000; Iter 1/80; Loss: 0.3803
Epoch 4615/10000; Iter 51/80; Loss: 0.3436
Epoch 4615/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4616/10000; Iter 1/80; Loss: 0.3392
Epoch 4616/10000; Iter 51/80; Loss: 0.4651
Epoch 4616/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4617/10000; Iter 1/80; Loss: 0.3702
Epoch 4617/10000; Iter 51/80; Loss: 0.3671
Epoch 4617/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.037
Epoch 4618/10000; Iter 1/80; Loss: 0.3471
Epoch 4618/10000; Iter 51/80; Loss: 0.3925
Epoch 4618/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4619/10000; Iter 1/80; Loss: 0.4681
Epoch 4619/10000; Iter 51/80; Loss: 0.4219
Epoch 4619/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4620/10000; Iter 1/80; Loss: 0.4126
Epoch 4620/10000; Iter 51/80; Loss: 0.4230
Epoch 4620/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.051
Epoch 4621/10000; Iter 1/80; Loss: 0.3594
Epoch 4621/10000; Iter 51/80; Loss: 0.3337
Epoch 4621/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4622/10000; Iter 1/80; Loss: 0.3786
Epoch 4622/10000; Iter 51/80; Loss: 0.4161
Epoch 4622/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4623/10000; Iter 1/80; Loss: 0.4514
Epoch 4623/10000; Iter 51/80; Loss: 0.4033
Epoch 4623/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.051
Epoch 4624/10000; Iter 1/80; Loss: 0.3436
Epoch 4624/10000; Iter 51/80; Loss: 0.4919
Epoch 4624/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.046
Epoch 4625/10000; Iter 1/80; Loss: 0.3999
Epoch 4625/10000; Iter 51/80; Loss: 0.4115
Epoch 4625/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.042
Epoch 4626/10000; Iter 1/80; Loss: 0.4103
Epoch 4626/10000; Iter 51/80; Loss: 0.4172
Epoch 4626/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.051
Epoch 4627/10000; Iter 1/80; Loss: 0.3936
Epoch 4627/10000; Iter 51/80; Loss: 0.3954
Epoch 4627/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.044
Epoch 4628/10000; Iter 1/80; Loss: 0.4363
Epoch 4628/10000; Iter 51/80; Loss: 0.3794
Epoch 4628/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 4629/10000; Iter 1/80; Loss: 0.3771
Epoch 4629/10000; Iter 51/80; Loss: 0.3458
Epoch 4629/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4630/10000; Iter 1/80; Loss: 0.3763
Epoch 4630/10000; Iter 51/80; Loss: 0.3879
Epoch 4630/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4631/10000; Iter 1/80; Loss: 0.4154
Epoch 4631/10000; Iter 51/80; Loss: 0.3701
Epoch 4631/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.039
Epoch 4632/10000; Iter 1/80; Loss: 0.4115
Epoch 4632/10000; Iter 51/80; Loss: 0.4286
Epoch 4632/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.041
Epoch 4633/10000; Iter 1/80; Loss: 0.4330
Epoch 4633/10000; Iter 51/80; Loss: 0.4068
Epoch 4633/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.04
Epoch 4634/10000; Iter 1/80; Loss: 0.3564
Epoch 4634/10000; Iter 51/80; Loss: 0.3793
Epoch 4634/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.038
Epoch 4635/10000; Iter 1/80; Loss: 0.3801
Epoch 4635/10000; Iter 51/80; Loss: 0.3762
Epoch 4635/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.044
Epoch 4636/10000; Iter 1/80; Loss: 0.3960
Epoch 4636/10000; Iter 51/80; Loss: 0.4015
Epoch 4636/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.038
Epoch 4637/10000; Iter 1/80; Loss: 0.3650
Epoch 4637/10000; Iter 51/80; Loss: 0.3566
Epoch 4637/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 4638/10000; Iter 1/80; Loss: 0.3783
Epoch 4638/10000; Iter 51/80; Loss: 0.3696
Epoch 4638/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4639/10000; Iter 1/80; Loss: 0.3297
Epoch 4639/10000; Iter 51/80; Loss: 0.3543
Epoch 4639/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.04
Epoch 4640/10000; Iter 1/80; Loss: 0.3811
Epoch 4640/10000; Iter 51/80; Loss: 0.3812
Epoch 4640/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.048
Epoch 4641/10000; Iter 1/80; Loss: 0.3819
Epoch 4641/10000; Iter 51/80; Loss: 0.4033
Epoch 4641/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4642/10000; Iter 1/80; Loss: 0.3584
Epoch 4642/10000; Iter 51/80; Loss: 0.3307
Epoch 4642/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4643/10000; Iter 1/80; Loss: 0.4022
Epoch 4643/10000; Iter 51/80; Loss: 0.3640
Epoch 4643/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.039
Epoch 4644/10000; Iter 1/80; Loss: 0.4054
Epoch 4644/10000; Iter 51/80; Loss: 0.4117
Epoch 4644/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.04
Epoch 4645/10000; Iter 1/80; Loss: 0.3714
Epoch 4645/10000; Iter 51/80; Loss: 0.3502
Epoch 4645/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.038
Epoch 4646/10000; Iter 1/80; Loss: 0.4379
Epoch 4646/10000; Iter 51/80; Loss: 0.4122
Epoch 4646/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 4647/10000; Iter 1/80; Loss: 0.3830
Epoch 4647/10000; Iter 51/80; Loss: 0.3928
Epoch 4647/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4648/10000; Iter 1/80; Loss: 0.3889
Epoch 4648/10000; Iter 51/80; Loss: 0.3820
Epoch 4648/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.048
Epoch 4649/10000; Iter 1/80; Loss: 0.3745
Epoch 4649/10000; Iter 51/80; Loss: 0.3557
Epoch 4649/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4650/10000; Iter 1/80; Loss: 0.3606
Epoch 4650/10000; Iter 51/80; Loss: 0.4144
Epoch 4650/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 4651/10000; Iter 1/80; Loss: 0.3147
Epoch 4651/10000; Iter 51/80; Loss: 0.3652
Epoch 4651/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.047
Epoch 4652/10000; Iter 1/80; Loss: 0.3522
Epoch 4652/10000; Iter 51/80; Loss: 0.3690
Epoch 4652/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.047
Epoch 4653/10000; Iter 1/80; Loss: 0.3517
Epoch 4653/10000; Iter 51/80; Loss: 0.3816
Epoch 4653/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.04
Epoch 4654/10000; Iter 1/80; Loss: 0.3852
Epoch 4654/10000; Iter 51/80; Loss: 0.3654
Epoch 4654/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4655/10000; Iter 1/80; Loss: 0.3670
Epoch 4655/10000; Iter 51/80; Loss: 0.3476
Epoch 4655/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.044
Epoch 4656/10000; Iter 1/80; Loss: 0.3414
Epoch 4656/10000; Iter 51/80; Loss: 0.3731
Epoch 4656/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.038
Epoch 4657/10000; Iter 1/80; Loss: 0.3787
Epoch 4657/10000; Iter 51/80; Loss: 0.3682
Epoch 4657/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.036
Epoch 4658/10000; Iter 1/80; Loss: 0.3776
Epoch 4658/10000; Iter 51/80; Loss: 0.3496
Epoch 4658/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.047
Epoch 4659/10000; Iter 1/80; Loss: 0.3322
Epoch 4659/10000; Iter 51/80; Loss: 0.4081
Epoch 4659/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.04
Epoch 4660/10000; Iter 1/80; Loss: 0.3633
Epoch 4660/10000; Iter 51/80; Loss: 0.4126
Epoch 4660/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4661/10000; Iter 1/80; Loss: 0.3951
Epoch 4661/10000; Iter 51/80; Loss: 0.3804
Epoch 4661/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.043
Epoch 4662/10000; Iter 1/80; Loss: 0.4096
Epoch 4662/10000; Iter 51/80; Loss: 0.3676
Epoch 4662/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4663/10000; Iter 1/80; Loss: 0.3980
Epoch 4663/10000; Iter 51/80; Loss: 0.3505
Epoch 4663/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.044
Epoch 4664/10000; Iter 1/80; Loss: 0.4280
Epoch 4664/10000; Iter 51/80; Loss: 0.4104
Epoch 4664/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.043
Epoch 4665/10000; Iter 1/80; Loss: 0.3778
Epoch 4665/10000; Iter 51/80; Loss: 0.3754
Epoch 4665/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.041
Epoch 4666/10000; Iter 1/80; Loss: 0.4457
Epoch 4666/10000; Iter 51/80; Loss: 0.4662
Epoch 4666/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4667/10000; Iter 1/80; Loss: 0.3869
Epoch 4667/10000; Iter 51/80; Loss: 0.4233
Epoch 4667/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.039
Epoch 4668/10000; Iter 1/80; Loss: 0.3818
Epoch 4668/10000; Iter 51/80; Loss: 0.5191
Epoch 4668/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.047
Epoch 4669/10000; Iter 1/80; Loss: 0.3745
Epoch 4669/10000; Iter 51/80; Loss: 0.3716
Epoch 4669/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.044
Epoch 4670/10000; Iter 1/80; Loss: 0.3969
Epoch 4670/10000; Iter 51/80; Loss: 0.3505
Epoch 4670/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.048
Epoch 4671/10000; Iter 1/80; Loss: 0.3585
Epoch 4671/10000; Iter 51/80; Loss: 0.4154
Epoch 4671/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.043
Epoch 4672/10000; Iter 1/80; Loss: 0.3809
Epoch 4672/10000; Iter 51/80; Loss: 0.3896
Epoch 4672/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4673/10000; Iter 1/80; Loss: 0.3146
Epoch 4673/10000; Iter 51/80; Loss: 0.4493
Epoch 4673/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.049
Epoch 4674/10000; Iter 1/80; Loss: 0.3233
Epoch 4674/10000; Iter 51/80; Loss: 0.4378
Epoch 4674/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.038
Epoch 4675/10000; Iter 1/80; Loss: 0.3507
Epoch 4675/10000; Iter 51/80; Loss: 0.3925
Epoch 4675/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4676/10000; Iter 1/80; Loss: 0.3940
Epoch 4676/10000; Iter 51/80; Loss: 0.3323
Epoch 4676/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.039
Epoch 4677/10000; Iter 1/80; Loss: 0.3638
Epoch 4677/10000; Iter 51/80; Loss: 0.3076
Epoch 4677/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.039
Epoch 4678/10000; Iter 1/80; Loss: 0.3848
Epoch 4678/10000; Iter 51/80; Loss: 0.3915
Epoch 4678/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4679/10000; Iter 1/80; Loss: 0.4079
Epoch 4679/10000; Iter 51/80; Loss: 0.3965
Epoch 4679/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4680/10000; Iter 1/80; Loss: 0.3933
Epoch 4680/10000; Iter 51/80; Loss: 0.4287
Epoch 4680/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.045
Epoch 4681/10000; Iter 1/80; Loss: 0.3608
Epoch 4681/10000; Iter 51/80; Loss: 0.4042
Epoch 4681/10000; Iter 80/80; Training Loss: 0.3940, Test Loss: 0.039
Epoch 4682/10000; Iter 1/80; Loss: 0.3771
Epoch 4682/10000; Iter 51/80; Loss: 0.4016
Epoch 4682/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.042
Epoch 4683/10000; Iter 1/80; Loss: 0.3446
Epoch 4683/10000; Iter 51/80; Loss: 0.4572
Epoch 4683/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.05
Epoch 4684/10000; Iter 1/80; Loss: 0.4242
Epoch 4684/10000; Iter 51/80; Loss: 0.4119
Epoch 4684/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.046
Epoch 4685/10000; Iter 1/80; Loss: 0.3786
Epoch 4685/10000; Iter 51/80; Loss: 0.4204
Epoch 4685/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.043
Epoch 4686/10000; Iter 1/80; Loss: 0.3801
Epoch 4686/10000; Iter 51/80; Loss: 0.3940
Epoch 4686/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.04
Epoch 4687/10000; Iter 1/80; Loss: 0.4498
Epoch 4687/10000; Iter 51/80; Loss: 0.3653
Epoch 4687/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.049
Epoch 4688/10000; Iter 1/80; Loss: 0.3862
Epoch 4688/10000; Iter 51/80; Loss: 0.4375
Epoch 4688/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.043
Epoch 4689/10000; Iter 1/80; Loss: 0.3884
Epoch 4689/10000; Iter 51/80; Loss: 0.3097
Epoch 4689/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.044
Epoch 4690/10000; Iter 1/80; Loss: 0.3555
Epoch 4690/10000; Iter 51/80; Loss: 0.3655
Epoch 4690/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 4691/10000; Iter 1/80; Loss: 0.3527
Epoch 4691/10000; Iter 51/80; Loss: 0.3610
Epoch 4691/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4692/10000; Iter 1/80; Loss: 0.4030
Epoch 4692/10000; Iter 51/80; Loss: 0.3789
Epoch 4692/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4693/10000; Iter 1/80; Loss: 0.3919
Epoch 4693/10000; Iter 51/80; Loss: 0.3716
Epoch 4693/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4694/10000; Iter 1/80; Loss: 0.3969
Epoch 4694/10000; Iter 51/80; Loss: 0.4459
Epoch 4694/10000; Iter 80/80; Training Loss: 0.3930, Test Loss: 0.042
Epoch 4695/10000; Iter 1/80; Loss: 0.4535
Epoch 4695/10000; Iter 51/80; Loss: 0.4247
Epoch 4695/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4696/10000; Iter 1/80; Loss: 0.4266
Epoch 4696/10000; Iter 51/80; Loss: 0.3745
Epoch 4696/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.048
Epoch 4697/10000; Iter 1/80; Loss: 0.4015
Epoch 4697/10000; Iter 51/80; Loss: 0.3879
Epoch 4697/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4698/10000; Iter 1/80; Loss: 0.3434
Epoch 4698/10000; Iter 51/80; Loss: 0.3599
Epoch 4698/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.042
Epoch 4699/10000; Iter 1/80; Loss: 0.4080
Epoch 4699/10000; Iter 51/80; Loss: 0.3720
Epoch 4699/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 4700/10000; Iter 1/80; Loss: 0.4094
Epoch 4700/10000; Iter 51/80; Loss: 0.3949
Epoch 4700/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4701/10000; Iter 1/80; Loss: 0.3559
Epoch 4701/10000; Iter 51/80; Loss: 0.3901
Epoch 4701/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.047
Model saved
Epoch 4702/10000; Iter 1/80; Loss: 0.3623
Epoch 4702/10000; Iter 51/80; Loss: 0.3989
Epoch 4702/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.044
Epoch 4703/10000; Iter 1/80; Loss: 0.3923
Epoch 4703/10000; Iter 51/80; Loss: 0.3926
Epoch 4703/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 4704/10000; Iter 1/80; Loss: 0.3462
Epoch 4704/10000; Iter 51/80; Loss: 0.4058
Epoch 4704/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.051
Epoch 4705/10000; Iter 1/80; Loss: 0.3892
Epoch 4705/10000; Iter 51/80; Loss: 0.3677
Epoch 4705/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4706/10000; Iter 1/80; Loss: 0.3871
Epoch 4706/10000; Iter 51/80; Loss: 0.3699
Epoch 4706/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4707/10000; Iter 1/80; Loss: 0.3637
Epoch 4707/10000; Iter 51/80; Loss: 0.3095
Epoch 4707/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.051
Epoch 4708/10000; Iter 1/80; Loss: 0.3536
Epoch 4708/10000; Iter 51/80; Loss: 0.3686
Epoch 4708/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 4709/10000; Iter 1/80; Loss: 0.4172
Epoch 4709/10000; Iter 51/80; Loss: 0.4261
Epoch 4709/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.042
Epoch 4710/10000; Iter 1/80; Loss: 0.3569
Epoch 4710/10000; Iter 51/80; Loss: 0.4090
Epoch 4710/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.047
Epoch 4711/10000; Iter 1/80; Loss: 0.3768
Epoch 4711/10000; Iter 51/80; Loss: 0.3694
Epoch 4711/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.037
Epoch 4712/10000; Iter 1/80; Loss: 0.4177
Epoch 4712/10000; Iter 51/80; Loss: 0.4279
Epoch 4712/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.042
Epoch 4713/10000; Iter 1/80; Loss: 0.4015
Epoch 4713/10000; Iter 51/80; Loss: 0.3660
Epoch 4713/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.04
Epoch 4714/10000; Iter 1/80; Loss: 0.3139
Epoch 4714/10000; Iter 51/80; Loss: 0.3730
Epoch 4714/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.043
Epoch 4715/10000; Iter 1/80; Loss: 0.4738
Epoch 4715/10000; Iter 51/80; Loss: 0.4218
Epoch 4715/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4716/10000; Iter 1/80; Loss: 0.4609
Epoch 4716/10000; Iter 51/80; Loss: 0.3424
Epoch 4716/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 4717/10000; Iter 1/80; Loss: 0.3843
Epoch 4717/10000; Iter 51/80; Loss: 0.3793
Epoch 4717/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 4718/10000; Iter 1/80; Loss: 0.4047
Epoch 4718/10000; Iter 51/80; Loss: 0.3663
Epoch 4718/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4719/10000; Iter 1/80; Loss: 0.4693
Epoch 4719/10000; Iter 51/80; Loss: 0.3642
Epoch 4719/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.047
Epoch 4720/10000; Iter 1/80; Loss: 0.3483
Epoch 4720/10000; Iter 51/80; Loss: 0.3622
Epoch 4720/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.043
Epoch 4721/10000; Iter 1/80; Loss: 0.3613
Epoch 4721/10000; Iter 51/80; Loss: 0.3803
Epoch 4721/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 4722/10000; Iter 1/80; Loss: 0.3763
Epoch 4722/10000; Iter 51/80; Loss: 0.3989
Epoch 4722/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.04
Epoch 4723/10000; Iter 1/80; Loss: 0.3716
Epoch 4723/10000; Iter 51/80; Loss: 0.3467
Epoch 4723/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.043
Epoch 4724/10000; Iter 1/80; Loss: 0.3912
Epoch 4724/10000; Iter 51/80; Loss: 0.3875
Epoch 4724/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.04
Epoch 4725/10000; Iter 1/80; Loss: 0.3914
Epoch 4725/10000; Iter 51/80; Loss: 0.3605
Epoch 4725/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4726/10000; Iter 1/80; Loss: 0.3781
Epoch 4726/10000; Iter 51/80; Loss: 0.3825
Epoch 4726/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.038
Epoch 4727/10000; Iter 1/80; Loss: 0.3679
Epoch 4727/10000; Iter 51/80; Loss: 0.3643
Epoch 4727/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4728/10000; Iter 1/80; Loss: 0.3867
Epoch 4728/10000; Iter 51/80; Loss: 0.3881
Epoch 4728/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.042
Epoch 4729/10000; Iter 1/80; Loss: 0.3211
Epoch 4729/10000; Iter 51/80; Loss: 0.3418
Epoch 4729/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.04
Epoch 4730/10000; Iter 1/80; Loss: 0.4119
Epoch 4730/10000; Iter 51/80; Loss: 0.4065
Epoch 4730/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4731/10000; Iter 1/80; Loss: 0.3568
Epoch 4731/10000; Iter 51/80; Loss: 0.3616
Epoch 4731/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 4732/10000; Iter 1/80; Loss: 0.3621
Epoch 4732/10000; Iter 51/80; Loss: 0.4415
Epoch 4732/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4733/10000; Iter 1/80; Loss: 0.3894
Epoch 4733/10000; Iter 51/80; Loss: 0.3778
Epoch 4733/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4734/10000; Iter 1/80; Loss: 0.4022
Epoch 4734/10000; Iter 51/80; Loss: 0.4219
Epoch 4734/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 4735/10000; Iter 1/80; Loss: 0.4039
Epoch 4735/10000; Iter 51/80; Loss: 0.3708
Epoch 4735/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 4736/10000; Iter 1/80; Loss: 0.3867
Epoch 4736/10000; Iter 51/80; Loss: 0.4226
Epoch 4736/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.038
Epoch 4737/10000; Iter 1/80; Loss: 0.3914
Epoch 4737/10000; Iter 51/80; Loss: 0.3423
Epoch 4737/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4738/10000; Iter 1/80; Loss: 0.3458
Epoch 4738/10000; Iter 51/80; Loss: 0.3785
Epoch 4738/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.053
Epoch 4739/10000; Iter 1/80; Loss: 0.3291
Epoch 4739/10000; Iter 51/80; Loss: 0.3236
Epoch 4739/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4740/10000; Iter 1/80; Loss: 0.3143
Epoch 4740/10000; Iter 51/80; Loss: 0.3987
Epoch 4740/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.037
Epoch 4741/10000; Iter 1/80; Loss: 0.3739
Epoch 4741/10000; Iter 51/80; Loss: 0.4479
Epoch 4741/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.046
Epoch 4742/10000; Iter 1/80; Loss: 0.4342
Epoch 4742/10000; Iter 51/80; Loss: 0.3771
Epoch 4742/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4743/10000; Iter 1/80; Loss: 0.4255
Epoch 4743/10000; Iter 51/80; Loss: 0.4042
Epoch 4743/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.046
Epoch 4744/10000; Iter 1/80; Loss: 0.4461
Epoch 4744/10000; Iter 51/80; Loss: 0.3228
Epoch 4744/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 4745/10000; Iter 1/80; Loss: 0.3580
Epoch 4745/10000; Iter 51/80; Loss: 0.3587
Epoch 4745/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.042
Epoch 4746/10000; Iter 1/80; Loss: 0.4307
Epoch 4746/10000; Iter 51/80; Loss: 0.3788
Epoch 4746/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4747/10000; Iter 1/80; Loss: 0.4235
Epoch 4747/10000; Iter 51/80; Loss: 0.4147
Epoch 4747/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.039
Epoch 4748/10000; Iter 1/80; Loss: 0.3674
Epoch 4748/10000; Iter 51/80; Loss: 0.3743
Epoch 4748/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.04
Epoch 4749/10000; Iter 1/80; Loss: 0.3764
Epoch 4749/10000; Iter 51/80; Loss: 0.3675
Epoch 4749/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.041
Epoch 4750/10000; Iter 1/80; Loss: 0.3317
Epoch 4750/10000; Iter 51/80; Loss: 0.3818
Epoch 4750/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4751/10000; Iter 1/80; Loss: 0.4262
Epoch 4751/10000; Iter 51/80; Loss: 0.3955
Epoch 4751/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.052
Epoch 4752/10000; Iter 1/80; Loss: 0.3931
Epoch 4752/10000; Iter 51/80; Loss: 0.3907
Epoch 4752/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4753/10000; Iter 1/80; Loss: 0.3442
Epoch 4753/10000; Iter 51/80; Loss: 0.3537
Epoch 4753/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4754/10000; Iter 1/80; Loss: 0.3802
Epoch 4754/10000; Iter 51/80; Loss: 0.3975
Epoch 4754/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.049
Epoch 4755/10000; Iter 1/80; Loss: 0.3957
Epoch 4755/10000; Iter 51/80; Loss: 0.3948
Epoch 4755/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.043
Epoch 4756/10000; Iter 1/80; Loss: 0.4616
Epoch 4756/10000; Iter 51/80; Loss: 0.3989
Epoch 4756/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4757/10000; Iter 1/80; Loss: 0.4170
Epoch 4757/10000; Iter 51/80; Loss: 0.3778
Epoch 4757/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.048
Epoch 4758/10000; Iter 1/80; Loss: 0.3622
Epoch 4758/10000; Iter 51/80; Loss: 0.3471
Epoch 4758/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4759/10000; Iter 1/80; Loss: 0.3512
Epoch 4759/10000; Iter 51/80; Loss: 0.3589
Epoch 4759/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4760/10000; Iter 1/80; Loss: 0.3917
Epoch 4760/10000; Iter 51/80; Loss: 0.3391
Epoch 4760/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.046
Epoch 4761/10000; Iter 1/80; Loss: 0.4334
Epoch 4761/10000; Iter 51/80; Loss: 0.3855
Epoch 4761/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.048
Epoch 4762/10000; Iter 1/80; Loss: 0.3723
Epoch 4762/10000; Iter 51/80; Loss: 0.3984
Epoch 4762/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 4763/10000; Iter 1/80; Loss: 0.3307
Epoch 4763/10000; Iter 51/80; Loss: 0.3753
Epoch 4763/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 4764/10000; Iter 1/80; Loss: 0.3549
Epoch 4764/10000; Iter 51/80; Loss: 0.3513
Epoch 4764/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.038
Epoch 4765/10000; Iter 1/80; Loss: 0.3223
Epoch 4765/10000; Iter 51/80; Loss: 0.4414
Epoch 4765/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4766/10000; Iter 1/80; Loss: 0.3948
Epoch 4766/10000; Iter 51/80; Loss: 0.3856
Epoch 4766/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.04
Epoch 4767/10000; Iter 1/80; Loss: 0.3520
Epoch 4767/10000; Iter 51/80; Loss: 0.5132
Epoch 4767/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4768/10000; Iter 1/80; Loss: 0.3254
Epoch 4768/10000; Iter 51/80; Loss: 0.3218
Epoch 4768/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 4769/10000; Iter 1/80; Loss: 0.4225
Epoch 4769/10000; Iter 51/80; Loss: 0.4520
Epoch 4769/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.047
Epoch 4770/10000; Iter 1/80; Loss: 0.3969
Epoch 4770/10000; Iter 51/80; Loss: 0.3597
Epoch 4770/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.054
Epoch 4771/10000; Iter 1/80; Loss: 0.4121
Epoch 4771/10000; Iter 51/80; Loss: 0.4753
Epoch 4771/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.047
Epoch 4772/10000; Iter 1/80; Loss: 0.3669
Epoch 4772/10000; Iter 51/80; Loss: 0.3847
Epoch 4772/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.055
Epoch 4773/10000; Iter 1/80; Loss: 0.3491
Epoch 4773/10000; Iter 51/80; Loss: 0.3535
Epoch 4773/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.041
Epoch 4774/10000; Iter 1/80; Loss: 0.3317
Epoch 4774/10000; Iter 51/80; Loss: 0.3699
Epoch 4774/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4775/10000; Iter 1/80; Loss: 0.3839
Epoch 4775/10000; Iter 51/80; Loss: 0.3603
Epoch 4775/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.041
Epoch 4776/10000; Iter 1/80; Loss: 0.3474
Epoch 4776/10000; Iter 51/80; Loss: 0.4610
Epoch 4776/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.044
Epoch 4777/10000; Iter 1/80; Loss: 0.3373
Epoch 4777/10000; Iter 51/80; Loss: 0.3665
Epoch 4777/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.042
Epoch 4778/10000; Iter 1/80; Loss: 0.3781
Epoch 4778/10000; Iter 51/80; Loss: 0.4400
Epoch 4778/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4779/10000; Iter 1/80; Loss: 0.3964
Epoch 4779/10000; Iter 51/80; Loss: 0.3901
Epoch 4779/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4780/10000; Iter 1/80; Loss: 0.4166
Epoch 4780/10000; Iter 51/80; Loss: 0.4082
Epoch 4780/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4781/10000; Iter 1/80; Loss: 0.3715
Epoch 4781/10000; Iter 51/80; Loss: 0.3525
Epoch 4781/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4782/10000; Iter 1/80; Loss: 0.3549
Epoch 4782/10000; Iter 51/80; Loss: 0.3732
Epoch 4782/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.041
Epoch 4783/10000; Iter 1/80; Loss: 0.4130
Epoch 4783/10000; Iter 51/80; Loss: 0.4159
Epoch 4783/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4784/10000; Iter 1/80; Loss: 0.3884
Epoch 4784/10000; Iter 51/80; Loss: 0.3822
Epoch 4784/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.049
Epoch 4785/10000; Iter 1/80; Loss: 0.4070
Epoch 4785/10000; Iter 51/80; Loss: 0.3229
Epoch 4785/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 4786/10000; Iter 1/80; Loss: 0.3514
Epoch 4786/10000; Iter 51/80; Loss: 0.3786
Epoch 4786/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.039
Epoch 4787/10000; Iter 1/80; Loss: 0.3635
Epoch 4787/10000; Iter 51/80; Loss: 0.3692
Epoch 4787/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.037
Epoch 4788/10000; Iter 1/80; Loss: 0.3533
Epoch 4788/10000; Iter 51/80; Loss: 0.3316
Epoch 4788/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.044
Epoch 4789/10000; Iter 1/80; Loss: 0.3190
Epoch 4789/10000; Iter 51/80; Loss: 0.3444
Epoch 4789/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4790/10000; Iter 1/80; Loss: 0.4059
Epoch 4790/10000; Iter 51/80; Loss: 0.3802
Epoch 4790/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.043
Epoch 4791/10000; Iter 1/80; Loss: 0.3570
Epoch 4791/10000; Iter 51/80; Loss: 0.3889
Epoch 4791/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4792/10000; Iter 1/80; Loss: 0.3500
Epoch 4792/10000; Iter 51/80; Loss: 0.3325
Epoch 4792/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.05
Epoch 4793/10000; Iter 1/80; Loss: 0.3405
Epoch 4793/10000; Iter 51/80; Loss: 0.3781
Epoch 4793/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 4794/10000; Iter 1/80; Loss: 0.4304
Epoch 4794/10000; Iter 51/80; Loss: 0.3884
Epoch 4794/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.041
Epoch 4795/10000; Iter 1/80; Loss: 0.3520
Epoch 4795/10000; Iter 51/80; Loss: 0.4150
Epoch 4795/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 4796/10000; Iter 1/80; Loss: 0.4331
Epoch 4796/10000; Iter 51/80; Loss: 0.4649
Epoch 4796/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.039
Epoch 4797/10000; Iter 1/80; Loss: 0.3632
Epoch 4797/10000; Iter 51/80; Loss: 0.3604
Epoch 4797/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 4798/10000; Iter 1/80; Loss: 0.4114
Epoch 4798/10000; Iter 51/80; Loss: 0.4680
Epoch 4798/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.048
Epoch 4799/10000; Iter 1/80; Loss: 0.3714
Epoch 4799/10000; Iter 51/80; Loss: 0.3527
Epoch 4799/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 4800/10000; Iter 1/80; Loss: 0.3617
Epoch 4800/10000; Iter 51/80; Loss: 0.3971
Epoch 4800/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.039
Epoch 4801/10000; Iter 1/80; Loss: 0.3018
Epoch 4801/10000; Iter 51/80; Loss: 0.4303
Epoch 4801/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.046
Model saved
Epoch 4802/10000; Iter 1/80; Loss: 0.4096
Epoch 4802/10000; Iter 51/80; Loss: 0.3792
Epoch 4802/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.046
Epoch 4803/10000; Iter 1/80; Loss: 0.3761
Epoch 4803/10000; Iter 51/80; Loss: 0.3768
Epoch 4803/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.04
Epoch 4804/10000; Iter 1/80; Loss: 0.4186
Epoch 4804/10000; Iter 51/80; Loss: 0.3760
Epoch 4804/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4805/10000; Iter 1/80; Loss: 0.4266
Epoch 4805/10000; Iter 51/80; Loss: 0.3647
Epoch 4805/10000; Iter 80/80; Training Loss: 0.3920, Test Loss: 0.039
Epoch 4806/10000; Iter 1/80; Loss: 0.3516
Epoch 4806/10000; Iter 51/80; Loss: 0.4356
Epoch 4806/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.04
Epoch 4807/10000; Iter 1/80; Loss: 0.3904
Epoch 4807/10000; Iter 51/80; Loss: 0.4084
Epoch 4807/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.048
Epoch 4808/10000; Iter 1/80; Loss: 0.3607
Epoch 4808/10000; Iter 51/80; Loss: 0.3572
Epoch 4808/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.041
Epoch 4809/10000; Iter 1/80; Loss: 0.3420
Epoch 4809/10000; Iter 51/80; Loss: 0.3289
Epoch 4809/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.053
Epoch 4810/10000; Iter 1/80; Loss: 0.3359
Epoch 4810/10000; Iter 51/80; Loss: 0.4120
Epoch 4810/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4811/10000; Iter 1/80; Loss: 0.4274
Epoch 4811/10000; Iter 51/80; Loss: 0.4105
Epoch 4811/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.051
Epoch 4812/10000; Iter 1/80; Loss: 0.3750
Epoch 4812/10000; Iter 51/80; Loss: 0.3771
Epoch 4812/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4813/10000; Iter 1/80; Loss: 0.3663
Epoch 4813/10000; Iter 51/80; Loss: 0.3449
Epoch 4813/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 4814/10000; Iter 1/80; Loss: 0.4179
Epoch 4814/10000; Iter 51/80; Loss: 0.3945
Epoch 4814/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 4815/10000; Iter 1/80; Loss: 0.3329
Epoch 4815/10000; Iter 51/80; Loss: 0.4471
Epoch 4815/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.047
Epoch 4816/10000; Iter 1/80; Loss: 0.3936
Epoch 4816/10000; Iter 51/80; Loss: 0.4241
Epoch 4816/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 4817/10000; Iter 1/80; Loss: 0.4082
Epoch 4817/10000; Iter 51/80; Loss: 0.3756
Epoch 4817/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4818/10000; Iter 1/80; Loss: 0.4138
Epoch 4818/10000; Iter 51/80; Loss: 0.4167
Epoch 4818/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.047
Epoch 4819/10000; Iter 1/80; Loss: 0.3306
Epoch 4819/10000; Iter 51/80; Loss: 0.3220
Epoch 4819/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.044
Epoch 4820/10000; Iter 1/80; Loss: 0.3658
Epoch 4820/10000; Iter 51/80; Loss: 0.4152
Epoch 4820/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.042
Epoch 4821/10000; Iter 1/80; Loss: 0.3857
Epoch 4821/10000; Iter 51/80; Loss: 0.3779
Epoch 4821/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4822/10000; Iter 1/80; Loss: 0.3820
Epoch 4822/10000; Iter 51/80; Loss: 0.3603
Epoch 4822/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4823/10000; Iter 1/80; Loss: 0.3882
Epoch 4823/10000; Iter 51/80; Loss: 0.4171
Epoch 4823/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 4824/10000; Iter 1/80; Loss: 0.4457
Epoch 4824/10000; Iter 51/80; Loss: 0.3829
Epoch 4824/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.045
Epoch 4825/10000; Iter 1/80; Loss: 0.4059
Epoch 4825/10000; Iter 51/80; Loss: 0.3980
Epoch 4825/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4826/10000; Iter 1/80; Loss: 0.3799
Epoch 4826/10000; Iter 51/80; Loss: 0.4097
Epoch 4826/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 4827/10000; Iter 1/80; Loss: 0.3658
Epoch 4827/10000; Iter 51/80; Loss: 0.3510
Epoch 4827/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.038
Epoch 4828/10000; Iter 1/80; Loss: 0.3786
Epoch 4828/10000; Iter 51/80; Loss: 0.3969
Epoch 4828/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 4829/10000; Iter 1/80; Loss: 0.4079
Epoch 4829/10000; Iter 51/80; Loss: 0.3884
Epoch 4829/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4830/10000; Iter 1/80; Loss: 0.3443
Epoch 4830/10000; Iter 51/80; Loss: 0.4433
Epoch 4830/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.049
Epoch 4831/10000; Iter 1/80; Loss: 0.3905
Epoch 4831/10000; Iter 51/80; Loss: 0.4483
Epoch 4831/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 4832/10000; Iter 1/80; Loss: 0.3547
Epoch 4832/10000; Iter 51/80; Loss: 0.3225
Epoch 4832/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.054
Epoch 4833/10000; Iter 1/80; Loss: 0.4257
Epoch 4833/10000; Iter 51/80; Loss: 0.3801
Epoch 4833/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.046
Epoch 4834/10000; Iter 1/80; Loss: 0.3509
Epoch 4834/10000; Iter 51/80; Loss: 0.3352
Epoch 4834/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.049
Epoch 4835/10000; Iter 1/80; Loss: 0.3863
Epoch 4835/10000; Iter 51/80; Loss: 0.4142
Epoch 4835/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4836/10000; Iter 1/80; Loss: 0.4188
Epoch 4836/10000; Iter 51/80; Loss: 0.3427
Epoch 4836/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 4837/10000; Iter 1/80; Loss: 0.4700
Epoch 4837/10000; Iter 51/80; Loss: 0.3746
Epoch 4837/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.047
Epoch 4838/10000; Iter 1/80; Loss: 0.3567
Epoch 4838/10000; Iter 51/80; Loss: 0.4095
Epoch 4838/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 4839/10000; Iter 1/80; Loss: 0.4072
Epoch 4839/10000; Iter 51/80; Loss: 0.3437
Epoch 4839/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.05
Epoch 4840/10000; Iter 1/80; Loss: 0.4104
Epoch 4840/10000; Iter 51/80; Loss: 0.3612
Epoch 4840/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4841/10000; Iter 1/80; Loss: 0.3904
Epoch 4841/10000; Iter 51/80; Loss: 0.3355
Epoch 4841/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.041
Epoch 4842/10000; Iter 1/80; Loss: 0.4171
Epoch 4842/10000; Iter 51/80; Loss: 0.3713
Epoch 4842/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.049
Epoch 4843/10000; Iter 1/80; Loss: 0.4599
Epoch 4843/10000; Iter 51/80; Loss: 0.3811
Epoch 4843/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.044
Epoch 4844/10000; Iter 1/80; Loss: 0.4200
Epoch 4844/10000; Iter 51/80; Loss: 0.3253
Epoch 4844/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.04
Epoch 4845/10000; Iter 1/80; Loss: 0.4380
Epoch 4845/10000; Iter 51/80; Loss: 0.4362
Epoch 4845/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4846/10000; Iter 1/80; Loss: 0.3271
Epoch 4846/10000; Iter 51/80; Loss: 0.3445
Epoch 4846/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4847/10000; Iter 1/80; Loss: 0.4244
Epoch 4847/10000; Iter 51/80; Loss: 0.4019
Epoch 4847/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4848/10000; Iter 1/80; Loss: 0.4242
Epoch 4848/10000; Iter 51/80; Loss: 0.4338
Epoch 4848/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.036
Epoch 4849/10000; Iter 1/80; Loss: 0.3724
Epoch 4849/10000; Iter 51/80; Loss: 0.3849
Epoch 4849/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 4850/10000; Iter 1/80; Loss: 0.3412
Epoch 4850/10000; Iter 51/80; Loss: 0.4256
Epoch 4850/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 4851/10000; Iter 1/80; Loss: 0.3620
Epoch 4851/10000; Iter 51/80; Loss: 0.4254
Epoch 4851/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.047
Epoch 4852/10000; Iter 1/80; Loss: 0.3676
Epoch 4852/10000; Iter 51/80; Loss: 0.3727
Epoch 4852/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.043
Epoch 4853/10000; Iter 1/80; Loss: 0.3537
Epoch 4853/10000; Iter 51/80; Loss: 0.4026
Epoch 4853/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.047
Epoch 4854/10000; Iter 1/80; Loss: 0.4000
Epoch 4854/10000; Iter 51/80; Loss: 0.3952
Epoch 4854/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.04
Epoch 4855/10000; Iter 1/80; Loss: 0.4464
Epoch 4855/10000; Iter 51/80; Loss: 0.4167
Epoch 4855/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.043
Epoch 4856/10000; Iter 1/80; Loss: 0.3864
Epoch 4856/10000; Iter 51/80; Loss: 0.4183
Epoch 4856/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.05
Epoch 4857/10000; Iter 1/80; Loss: 0.3455
Epoch 4857/10000; Iter 51/80; Loss: 0.3751
Epoch 4857/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4858/10000; Iter 1/80; Loss: 0.3926
Epoch 4858/10000; Iter 51/80; Loss: 0.3858
Epoch 4858/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.044
Epoch 4859/10000; Iter 1/80; Loss: 0.3909
Epoch 4859/10000; Iter 51/80; Loss: 0.3476
Epoch 4859/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.047
Epoch 4860/10000; Iter 1/80; Loss: 0.4185
Epoch 4860/10000; Iter 51/80; Loss: 0.3576
Epoch 4860/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.041
Epoch 4861/10000; Iter 1/80; Loss: 0.3872
Epoch 4861/10000; Iter 51/80; Loss: 0.3638
Epoch 4861/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.045
Epoch 4862/10000; Iter 1/80; Loss: 0.4400
Epoch 4862/10000; Iter 51/80; Loss: 0.3655
Epoch 4862/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4863/10000; Iter 1/80; Loss: 0.4543
Epoch 4863/10000; Iter 51/80; Loss: 0.4339
Epoch 4863/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4864/10000; Iter 1/80; Loss: 0.4167
Epoch 4864/10000; Iter 51/80; Loss: 0.3743
Epoch 4864/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.036
Epoch 4865/10000; Iter 1/80; Loss: 0.3097
Epoch 4865/10000; Iter 51/80; Loss: 0.3782
Epoch 4865/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.037
Epoch 4866/10000; Iter 1/80; Loss: 0.3379
Epoch 4866/10000; Iter 51/80; Loss: 0.3544
Epoch 4866/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.046
Epoch 4867/10000; Iter 1/80; Loss: 0.3416
Epoch 4867/10000; Iter 51/80; Loss: 0.3864
Epoch 4867/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.04
Epoch 4868/10000; Iter 1/80; Loss: 0.3493
Epoch 4868/10000; Iter 51/80; Loss: 0.3943
Epoch 4868/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.048
Epoch 4869/10000; Iter 1/80; Loss: 0.4139
Epoch 4869/10000; Iter 51/80; Loss: 0.4145
Epoch 4869/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.044
Epoch 4870/10000; Iter 1/80; Loss: 0.4252
Epoch 4870/10000; Iter 51/80; Loss: 0.3897
Epoch 4870/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 4871/10000; Iter 1/80; Loss: 0.3551
Epoch 4871/10000; Iter 51/80; Loss: 0.4514
Epoch 4871/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4872/10000; Iter 1/80; Loss: 0.3458
Epoch 4872/10000; Iter 51/80; Loss: 0.3457
Epoch 4872/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.048
Epoch 4873/10000; Iter 1/80; Loss: 0.3471
Epoch 4873/10000; Iter 51/80; Loss: 0.3814
Epoch 4873/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.047
Epoch 4874/10000; Iter 1/80; Loss: 0.3789
Epoch 4874/10000; Iter 51/80; Loss: 0.4244
Epoch 4874/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.039
Epoch 4875/10000; Iter 1/80; Loss: 0.3468
Epoch 4875/10000; Iter 51/80; Loss: 0.3976
Epoch 4875/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 4876/10000; Iter 1/80; Loss: 0.4110
Epoch 4876/10000; Iter 51/80; Loss: 0.3539
Epoch 4876/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.041
Epoch 4877/10000; Iter 1/80; Loss: 0.3927
Epoch 4877/10000; Iter 51/80; Loss: 0.3884
Epoch 4877/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.05
Epoch 4878/10000; Iter 1/80; Loss: 0.4060
Epoch 4878/10000; Iter 51/80; Loss: 0.4500
Epoch 4878/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.049
Epoch 4879/10000; Iter 1/80; Loss: 0.3754
Epoch 4879/10000; Iter 51/80; Loss: 0.3836
Epoch 4879/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4880/10000; Iter 1/80; Loss: 0.4205
Epoch 4880/10000; Iter 51/80; Loss: 0.4183
Epoch 4880/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.049
Epoch 4881/10000; Iter 1/80; Loss: 0.3871
Epoch 4881/10000; Iter 51/80; Loss: 0.3642
Epoch 4881/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4882/10000; Iter 1/80; Loss: 0.3915
Epoch 4882/10000; Iter 51/80; Loss: 0.4234
Epoch 4882/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.04
Epoch 4883/10000; Iter 1/80; Loss: 0.3300
Epoch 4883/10000; Iter 51/80; Loss: 0.4098
Epoch 4883/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.045
Epoch 4884/10000; Iter 1/80; Loss: 0.4741
Epoch 4884/10000; Iter 51/80; Loss: 0.4024
Epoch 4884/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4885/10000; Iter 1/80; Loss: 0.4121
Epoch 4885/10000; Iter 51/80; Loss: 0.4160
Epoch 4885/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4886/10000; Iter 1/80; Loss: 0.3233
Epoch 4886/10000; Iter 51/80; Loss: 0.3669
Epoch 4886/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 4887/10000; Iter 1/80; Loss: 0.3576
Epoch 4887/10000; Iter 51/80; Loss: 0.4382
Epoch 4887/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4888/10000; Iter 1/80; Loss: 0.4091
Epoch 4888/10000; Iter 51/80; Loss: 0.3973
Epoch 4888/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.039
Epoch 4889/10000; Iter 1/80; Loss: 0.4047
Epoch 4889/10000; Iter 51/80; Loss: 0.3583
Epoch 4889/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.038
Epoch 4890/10000; Iter 1/80; Loss: 0.3454
Epoch 4890/10000; Iter 51/80; Loss: 0.4491
Epoch 4890/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.045
Epoch 4891/10000; Iter 1/80; Loss: 0.3571
Epoch 4891/10000; Iter 51/80; Loss: 0.3932
Epoch 4891/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 4892/10000; Iter 1/80; Loss: 0.3719
Epoch 4892/10000; Iter 51/80; Loss: 0.3448
Epoch 4892/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4893/10000; Iter 1/80; Loss: 0.3473
Epoch 4893/10000; Iter 51/80; Loss: 0.3642
Epoch 4893/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4894/10000; Iter 1/80; Loss: 0.3305
Epoch 4894/10000; Iter 51/80; Loss: 0.3348
Epoch 4894/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.046
Epoch 4895/10000; Iter 1/80; Loss: 0.3971
Epoch 4895/10000; Iter 51/80; Loss: 0.3497
Epoch 4895/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.041
Epoch 4896/10000; Iter 1/80; Loss: 0.3495
Epoch 4896/10000; Iter 51/80; Loss: 0.3416
Epoch 4896/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.039
Epoch 4897/10000; Iter 1/80; Loss: 0.3860
Epoch 4897/10000; Iter 51/80; Loss: 0.4877
Epoch 4897/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.049
Epoch 4898/10000; Iter 1/80; Loss: 0.3787
Epoch 4898/10000; Iter 51/80; Loss: 0.4395
Epoch 4898/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 4899/10000; Iter 1/80; Loss: 0.3536
Epoch 4899/10000; Iter 51/80; Loss: 0.3553
Epoch 4899/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.044
Epoch 4900/10000; Iter 1/80; Loss: 0.3700
Epoch 4900/10000; Iter 51/80; Loss: 0.3907
Epoch 4900/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.042
Epoch 4901/10000; Iter 1/80; Loss: 0.3710
Epoch 4901/10000; Iter 51/80; Loss: 0.3450
Epoch 4901/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.037
Model saved
Epoch 4902/10000; Iter 1/80; Loss: 0.3981
Epoch 4902/10000; Iter 51/80; Loss: 0.3433
Epoch 4902/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4903/10000; Iter 1/80; Loss: 0.3591
Epoch 4903/10000; Iter 51/80; Loss: 0.3885
Epoch 4903/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.041
Epoch 4904/10000; Iter 1/80; Loss: 0.3651
Epoch 4904/10000; Iter 51/80; Loss: 0.4163
Epoch 4904/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.043
Epoch 4905/10000; Iter 1/80; Loss: 0.3999
Epoch 4905/10000; Iter 51/80; Loss: 0.4355
Epoch 4905/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.047
Epoch 4906/10000; Iter 1/80; Loss: 0.4400
Epoch 4906/10000; Iter 51/80; Loss: 0.3518
Epoch 4906/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.049
Epoch 4907/10000; Iter 1/80; Loss: 0.3744
Epoch 4907/10000; Iter 51/80; Loss: 0.3671
Epoch 4907/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.038
Epoch 4908/10000; Iter 1/80; Loss: 0.4127
Epoch 4908/10000; Iter 51/80; Loss: 0.4251
Epoch 4908/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.041
Epoch 4909/10000; Iter 1/80; Loss: 0.4179
Epoch 4909/10000; Iter 51/80; Loss: 0.4291
Epoch 4909/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 4910/10000; Iter 1/80; Loss: 0.3894
Epoch 4910/10000; Iter 51/80; Loss: 0.3661
Epoch 4910/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.042
Epoch 4911/10000; Iter 1/80; Loss: 0.4069
Epoch 4911/10000; Iter 51/80; Loss: 0.3357
Epoch 4911/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.041
Epoch 4912/10000; Iter 1/80; Loss: 0.3438
Epoch 4912/10000; Iter 51/80; Loss: 0.3537
Epoch 4912/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 4913/10000; Iter 1/80; Loss: 0.3491
Epoch 4913/10000; Iter 51/80; Loss: 0.3824
Epoch 4913/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4914/10000; Iter 1/80; Loss: 0.4150
Epoch 4914/10000; Iter 51/80; Loss: 0.3704
Epoch 4914/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 4915/10000; Iter 1/80; Loss: 0.3945
Epoch 4915/10000; Iter 51/80; Loss: 0.3799
Epoch 4915/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.046
Epoch 4916/10000; Iter 1/80; Loss: 0.3489
Epoch 4916/10000; Iter 51/80; Loss: 0.3245
Epoch 4916/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.044
Epoch 4917/10000; Iter 1/80; Loss: 0.4195
Epoch 4917/10000; Iter 51/80; Loss: 0.3801
Epoch 4917/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 4918/10000; Iter 1/80; Loss: 0.3552
Epoch 4918/10000; Iter 51/80; Loss: 0.3682
Epoch 4918/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4919/10000; Iter 1/80; Loss: 0.4079
Epoch 4919/10000; Iter 51/80; Loss: 0.4163
Epoch 4919/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.043
Epoch 4920/10000; Iter 1/80; Loss: 0.4075
Epoch 4920/10000; Iter 51/80; Loss: 0.3889
Epoch 4920/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.038
Epoch 4921/10000; Iter 1/80; Loss: 0.4610
Epoch 4921/10000; Iter 51/80; Loss: 0.3814
Epoch 4921/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.049
Epoch 4922/10000; Iter 1/80; Loss: 0.4290
Epoch 4922/10000; Iter 51/80; Loss: 0.3896
Epoch 4922/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 4923/10000; Iter 1/80; Loss: 0.4174
Epoch 4923/10000; Iter 51/80; Loss: 0.3609
Epoch 4923/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 4924/10000; Iter 1/80; Loss: 0.3255
Epoch 4924/10000; Iter 51/80; Loss: 0.3894
Epoch 4924/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4925/10000; Iter 1/80; Loss: 0.3581
Epoch 4925/10000; Iter 51/80; Loss: 0.3699
Epoch 4925/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.037
Epoch 4926/10000; Iter 1/80; Loss: 0.4194
Epoch 4926/10000; Iter 51/80; Loss: 0.3726
Epoch 4926/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.047
Epoch 4927/10000; Iter 1/80; Loss: 0.4123
Epoch 4927/10000; Iter 51/80; Loss: 0.3558
Epoch 4927/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.055
Epoch 4928/10000; Iter 1/80; Loss: 0.3457
Epoch 4928/10000; Iter 51/80; Loss: 0.3251
Epoch 4928/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.047
Epoch 4929/10000; Iter 1/80; Loss: 0.3473
Epoch 4929/10000; Iter 51/80; Loss: 0.3518
Epoch 4929/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 4930/10000; Iter 1/80; Loss: 0.3509
Epoch 4930/10000; Iter 51/80; Loss: 0.3869
Epoch 4930/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.049
Epoch 4931/10000; Iter 1/80; Loss: 0.4600
Epoch 4931/10000; Iter 51/80; Loss: 0.3645
Epoch 4931/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.05
Epoch 4932/10000; Iter 1/80; Loss: 0.3697
Epoch 4932/10000; Iter 51/80; Loss: 0.3887
Epoch 4932/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.047
Epoch 4933/10000; Iter 1/80; Loss: 0.3369
Epoch 4933/10000; Iter 51/80; Loss: 0.3762
Epoch 4933/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 4934/10000; Iter 1/80; Loss: 0.3402
Epoch 4934/10000; Iter 51/80; Loss: 0.3785
Epoch 4934/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.051
Epoch 4935/10000; Iter 1/80; Loss: 0.3902
Epoch 4935/10000; Iter 51/80; Loss: 0.5049
Epoch 4935/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.038
Epoch 4936/10000; Iter 1/80; Loss: 0.3793
Epoch 4936/10000; Iter 51/80; Loss: 0.3843
Epoch 4936/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.042
Epoch 4937/10000; Iter 1/80; Loss: 0.3651
Epoch 4937/10000; Iter 51/80; Loss: 0.3498
Epoch 4937/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.047
Epoch 4938/10000; Iter 1/80; Loss: 0.3343
Epoch 4938/10000; Iter 51/80; Loss: 0.3353
Epoch 4938/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 4939/10000; Iter 1/80; Loss: 0.3646
Epoch 4939/10000; Iter 51/80; Loss: 0.3422
Epoch 4939/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4940/10000; Iter 1/80; Loss: 0.3248
Epoch 4940/10000; Iter 51/80; Loss: 0.4055
Epoch 4940/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4941/10000; Iter 1/80; Loss: 0.3986
Epoch 4941/10000; Iter 51/80; Loss: 0.3699
Epoch 4941/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.051
Epoch 4942/10000; Iter 1/80; Loss: 0.3633
Epoch 4942/10000; Iter 51/80; Loss: 0.3671
Epoch 4942/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.041
Epoch 4943/10000; Iter 1/80; Loss: 0.3671
Epoch 4943/10000; Iter 51/80; Loss: 0.3533
Epoch 4943/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.041
Epoch 4944/10000; Iter 1/80; Loss: 0.4249
Epoch 4944/10000; Iter 51/80; Loss: 0.4493
Epoch 4944/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 4945/10000; Iter 1/80; Loss: 0.3515
Epoch 4945/10000; Iter 51/80; Loss: 0.3903
Epoch 4945/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 4946/10000; Iter 1/80; Loss: 0.4197
Epoch 4946/10000; Iter 51/80; Loss: 0.3878
Epoch 4946/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.044
Epoch 4947/10000; Iter 1/80; Loss: 0.3620
Epoch 4947/10000; Iter 51/80; Loss: 0.4151
Epoch 4947/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 4948/10000; Iter 1/80; Loss: 0.4083
Epoch 4948/10000; Iter 51/80; Loss: 0.3201
Epoch 4948/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.041
Epoch 4949/10000; Iter 1/80; Loss: 0.3610
Epoch 4949/10000; Iter 51/80; Loss: 0.3783
Epoch 4949/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 4950/10000; Iter 1/80; Loss: 0.3865
Epoch 4950/10000; Iter 51/80; Loss: 0.3890
Epoch 4950/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.041
Epoch 4951/10000; Iter 1/80; Loss: 0.3552
Epoch 4951/10000; Iter 51/80; Loss: 0.3283
Epoch 4951/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 4952/10000; Iter 1/80; Loss: 0.3702
Epoch 4952/10000; Iter 51/80; Loss: 0.3602
Epoch 4952/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.039
Epoch 4953/10000; Iter 1/80; Loss: 0.3815
Epoch 4953/10000; Iter 51/80; Loss: 0.4048
Epoch 4953/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.038
Epoch 4954/10000; Iter 1/80; Loss: 0.3810
Epoch 4954/10000; Iter 51/80; Loss: 0.3331
Epoch 4954/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 4955/10000; Iter 1/80; Loss: 0.3420
Epoch 4955/10000; Iter 51/80; Loss: 0.3762
Epoch 4955/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 4956/10000; Iter 1/80; Loss: 0.3756
Epoch 4956/10000; Iter 51/80; Loss: 0.3607
Epoch 4956/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.045
Epoch 4957/10000; Iter 1/80; Loss: 0.3227
Epoch 4957/10000; Iter 51/80; Loss: 0.3445
Epoch 4957/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.052
Epoch 4958/10000; Iter 1/80; Loss: 0.3898
Epoch 4958/10000; Iter 51/80; Loss: 0.3443
Epoch 4958/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4959/10000; Iter 1/80; Loss: 0.3826
Epoch 4959/10000; Iter 51/80; Loss: 0.3817
Epoch 4959/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 4960/10000; Iter 1/80; Loss: 0.3432
Epoch 4960/10000; Iter 51/80; Loss: 0.3724
Epoch 4960/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4961/10000; Iter 1/80; Loss: 0.3776
Epoch 4961/10000; Iter 51/80; Loss: 0.4310
Epoch 4961/10000; Iter 80/80; Training Loss: 0.3900, Test Loss: 0.041
Epoch 4962/10000; Iter 1/80; Loss: 0.3879
Epoch 4962/10000; Iter 51/80; Loss: 0.3966
Epoch 4962/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 4963/10000; Iter 1/80; Loss: 0.3127
Epoch 4963/10000; Iter 51/80; Loss: 0.3706
Epoch 4963/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 4964/10000; Iter 1/80; Loss: 0.3829
Epoch 4964/10000; Iter 51/80; Loss: 0.3809
Epoch 4964/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.04
Epoch 4965/10000; Iter 1/80; Loss: 0.4332
Epoch 4965/10000; Iter 51/80; Loss: 0.3910
Epoch 4965/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.041
Epoch 4966/10000; Iter 1/80; Loss: 0.3452
Epoch 4966/10000; Iter 51/80; Loss: 0.3625
Epoch 4966/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.046
Epoch 4967/10000; Iter 1/80; Loss: 0.4194
Epoch 4967/10000; Iter 51/80; Loss: 0.3648
Epoch 4967/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.044
Epoch 4968/10000; Iter 1/80; Loss: 0.3659
Epoch 4968/10000; Iter 51/80; Loss: 0.3815
Epoch 4968/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.041
Epoch 4969/10000; Iter 1/80; Loss: 0.3567
Epoch 4969/10000; Iter 51/80; Loss: 0.3143
Epoch 4969/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.041
Epoch 4970/10000; Iter 1/80; Loss: 0.4272
Epoch 4970/10000; Iter 51/80; Loss: 0.3741
Epoch 4970/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.045
Epoch 4971/10000; Iter 1/80; Loss: 0.3348
Epoch 4971/10000; Iter 51/80; Loss: 0.3945
Epoch 4971/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 4972/10000; Iter 1/80; Loss: 0.3557
Epoch 4972/10000; Iter 51/80; Loss: 0.3641
Epoch 4972/10000; Iter 80/80; Training Loss: 0.3910, Test Loss: 0.045
Epoch 4973/10000; Iter 1/80; Loss: 0.4010
Epoch 4973/10000; Iter 51/80; Loss: 0.4107
Epoch 4973/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 4974/10000; Iter 1/80; Loss: 0.3734
Epoch 4974/10000; Iter 51/80; Loss: 0.4121
Epoch 4974/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.045
Epoch 4975/10000; Iter 1/80; Loss: 0.4556
Epoch 4975/10000; Iter 51/80; Loss: 0.3977
Epoch 4975/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 4976/10000; Iter 1/80; Loss: 0.3768
Epoch 4976/10000; Iter 51/80; Loss: 0.4227
Epoch 4976/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 4977/10000; Iter 1/80; Loss: 0.3214
Epoch 4977/10000; Iter 51/80; Loss: 0.3900
Epoch 4977/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.04
Epoch 4978/10000; Iter 1/80; Loss: 0.3259
Epoch 4978/10000; Iter 51/80; Loss: 0.4146
Epoch 4978/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.038
Epoch 4979/10000; Iter 1/80; Loss: 0.4043
Epoch 4979/10000; Iter 51/80; Loss: 0.3916
Epoch 4979/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.046
Epoch 4980/10000; Iter 1/80; Loss: 0.3885
Epoch 4980/10000; Iter 51/80; Loss: 0.3943
Epoch 4980/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.046
Epoch 4981/10000; Iter 1/80; Loss: 0.3819
Epoch 4981/10000; Iter 51/80; Loss: 0.4227
Epoch 4981/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.048
Epoch 4982/10000; Iter 1/80; Loss: 0.3128
Epoch 4982/10000; Iter 51/80; Loss: 0.3566
Epoch 4982/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.046
Epoch 4983/10000; Iter 1/80; Loss: 0.3836
Epoch 4983/10000; Iter 51/80; Loss: 0.3526
Epoch 4983/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 4984/10000; Iter 1/80; Loss: 0.3715
Epoch 4984/10000; Iter 51/80; Loss: 0.4051
Epoch 4984/10000; Iter 80/80; Training Loss: 0.3870, Test Loss: 0.043
Epoch 4985/10000; Iter 1/80; Loss: 0.3690
Epoch 4985/10000; Iter 51/80; Loss: 0.3696
Epoch 4985/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.045
Epoch 4986/10000; Iter 1/80; Loss: 0.4736
Epoch 4986/10000; Iter 51/80; Loss: 0.3968
Epoch 4986/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 4987/10000; Iter 1/80; Loss: 0.4073
Epoch 4987/10000; Iter 51/80; Loss: 0.3855
Epoch 4987/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.049
Epoch 4988/10000; Iter 1/80; Loss: 0.4188
Epoch 4988/10000; Iter 51/80; Loss: 0.3660
Epoch 4988/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.049
Epoch 4989/10000; Iter 1/80; Loss: 0.3464
Epoch 4989/10000; Iter 51/80; Loss: 0.3635
Epoch 4989/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.042
Epoch 4990/10000; Iter 1/80; Loss: 0.3857
Epoch 4990/10000; Iter 51/80; Loss: 0.4557
Epoch 4990/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.049
Epoch 4991/10000; Iter 1/80; Loss: 0.4406
Epoch 4991/10000; Iter 51/80; Loss: 0.3441
Epoch 4991/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 4992/10000; Iter 1/80; Loss: 0.4240
Epoch 4992/10000; Iter 51/80; Loss: 0.3670
Epoch 4992/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.041
Epoch 4993/10000; Iter 1/80; Loss: 0.4274
Epoch 4993/10000; Iter 51/80; Loss: 0.3749
Epoch 4993/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 4994/10000; Iter 1/80; Loss: 0.3883
Epoch 4994/10000; Iter 51/80; Loss: 0.3724
Epoch 4994/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.044
Epoch 4995/10000; Iter 1/80; Loss: 0.3745
Epoch 4995/10000; Iter 51/80; Loss: 0.4075
Epoch 4995/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.039
Epoch 4996/10000; Iter 1/80; Loss: 0.3840
Epoch 4996/10000; Iter 51/80; Loss: 0.4156
Epoch 4996/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.052
Epoch 4997/10000; Iter 1/80; Loss: 0.3413
Epoch 4997/10000; Iter 51/80; Loss: 0.3578
Epoch 4997/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 4998/10000; Iter 1/80; Loss: 0.4546
Epoch 4998/10000; Iter 51/80; Loss: 0.3743
Epoch 4998/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 4999/10000; Iter 1/80; Loss: 0.3491
Epoch 4999/10000; Iter 51/80; Loss: 0.3850
Epoch 4999/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.043
Epoch 5000/10000; Iter 1/80; Loss: 0.3987
Epoch 5000/10000; Iter 51/80; Loss: 0.3970
Epoch 5000/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 5001/10000; Iter 1/80; Loss: 0.3541
Epoch 5001/10000; Iter 51/80; Loss: 0.3830
Epoch 5001/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Model saved
Epoch 5002/10000; Iter 1/80; Loss: 0.3861
Epoch 5002/10000; Iter 51/80; Loss: 0.3423
Epoch 5002/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 5003/10000; Iter 1/80; Loss: 0.3792
Epoch 5003/10000; Iter 51/80; Loss: 0.4317
Epoch 5003/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 5004/10000; Iter 1/80; Loss: 0.3745
Epoch 5004/10000; Iter 51/80; Loss: 0.4704
Epoch 5004/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 5005/10000; Iter 1/80; Loss: 0.3800
Epoch 5005/10000; Iter 51/80; Loss: 0.4006
Epoch 5005/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.049
Epoch 5006/10000; Iter 1/80; Loss: 0.4232
Epoch 5006/10000; Iter 51/80; Loss: 0.2826
Epoch 5006/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5007/10000; Iter 1/80; Loss: 0.3399
Epoch 5007/10000; Iter 51/80; Loss: 0.3668
Epoch 5007/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.04
Epoch 5008/10000; Iter 1/80; Loss: 0.3821
Epoch 5008/10000; Iter 51/80; Loss: 0.3344
Epoch 5008/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5009/10000; Iter 1/80; Loss: 0.3762
Epoch 5009/10000; Iter 51/80; Loss: 0.4025
Epoch 5009/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.041
Epoch 5010/10000; Iter 1/80; Loss: 0.3925
Epoch 5010/10000; Iter 51/80; Loss: 0.3447
Epoch 5010/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 5011/10000; Iter 1/80; Loss: 0.3195
Epoch 5011/10000; Iter 51/80; Loss: 0.3720
Epoch 5011/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.049
Epoch 5012/10000; Iter 1/80; Loss: 0.3913
Epoch 5012/10000; Iter 51/80; Loss: 0.3972
Epoch 5012/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.039
Epoch 5013/10000; Iter 1/80; Loss: 0.4206
Epoch 5013/10000; Iter 51/80; Loss: 0.3954
Epoch 5013/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5014/10000; Iter 1/80; Loss: 0.3585
Epoch 5014/10000; Iter 51/80; Loss: 0.4792
Epoch 5014/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5015/10000; Iter 1/80; Loss: 0.4185
Epoch 5015/10000; Iter 51/80; Loss: 0.3906
Epoch 5015/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5016/10000; Iter 1/80; Loss: 0.3559
Epoch 5016/10000; Iter 51/80; Loss: 0.4357
Epoch 5016/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5017/10000; Iter 1/80; Loss: 0.3699
Epoch 5017/10000; Iter 51/80; Loss: 0.3318
Epoch 5017/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 5018/10000; Iter 1/80; Loss: 0.3479
Epoch 5018/10000; Iter 51/80; Loss: 0.4196
Epoch 5018/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 5019/10000; Iter 1/80; Loss: 0.4079
Epoch 5019/10000; Iter 51/80; Loss: 0.3388
Epoch 5019/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5020/10000; Iter 1/80; Loss: 0.2985
Epoch 5020/10000; Iter 51/80; Loss: 0.4139
Epoch 5020/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.044
Epoch 5021/10000; Iter 1/80; Loss: 0.3597
Epoch 5021/10000; Iter 51/80; Loss: 0.3721
Epoch 5021/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 5022/10000; Iter 1/80; Loss: 0.4376
Epoch 5022/10000; Iter 51/80; Loss: 0.4358
Epoch 5022/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.043
Epoch 5023/10000; Iter 1/80; Loss: 0.3547
Epoch 5023/10000; Iter 51/80; Loss: 0.3560
Epoch 5023/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 5024/10000; Iter 1/80; Loss: 0.3620
Epoch 5024/10000; Iter 51/80; Loss: 0.3724
Epoch 5024/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.038
Epoch 5025/10000; Iter 1/80; Loss: 0.3752
Epoch 5025/10000; Iter 51/80; Loss: 0.3529
Epoch 5025/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.045
Epoch 5026/10000; Iter 1/80; Loss: 0.4045
Epoch 5026/10000; Iter 51/80; Loss: 0.4988
Epoch 5026/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.047
Epoch 5027/10000; Iter 1/80; Loss: 0.3781
Epoch 5027/10000; Iter 51/80; Loss: 0.4308
Epoch 5027/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 5028/10000; Iter 1/80; Loss: 0.3893
Epoch 5028/10000; Iter 51/80; Loss: 0.3768
Epoch 5028/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5029/10000; Iter 1/80; Loss: 0.4137
Epoch 5029/10000; Iter 51/80; Loss: 0.3952
Epoch 5029/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.044
Epoch 5030/10000; Iter 1/80; Loss: 0.4235
Epoch 5030/10000; Iter 51/80; Loss: 0.3878
Epoch 5030/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.047
Epoch 5031/10000; Iter 1/80; Loss: 0.3819
Epoch 5031/10000; Iter 51/80; Loss: 0.3660
Epoch 5031/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.046
Epoch 5032/10000; Iter 1/80; Loss: 0.3460
Epoch 5032/10000; Iter 51/80; Loss: 0.3123
Epoch 5032/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.041
Epoch 5033/10000; Iter 1/80; Loss: 0.3793
Epoch 5033/10000; Iter 51/80; Loss: 0.3830
Epoch 5033/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.048
Epoch 5034/10000; Iter 1/80; Loss: 0.4228
Epoch 5034/10000; Iter 51/80; Loss: 0.3471
Epoch 5034/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5035/10000; Iter 1/80; Loss: 0.3665
Epoch 5035/10000; Iter 51/80; Loss: 0.3706
Epoch 5035/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.046
Epoch 5036/10000; Iter 1/80; Loss: 0.4047
Epoch 5036/10000; Iter 51/80; Loss: 0.2858
Epoch 5036/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.04
Epoch 5037/10000; Iter 1/80; Loss: 0.4088
Epoch 5037/10000; Iter 51/80; Loss: 0.3748
Epoch 5037/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.042
Epoch 5038/10000; Iter 1/80; Loss: 0.3888
Epoch 5038/10000; Iter 51/80; Loss: 0.4015
Epoch 5038/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.046
Epoch 5039/10000; Iter 1/80; Loss: 0.3996
Epoch 5039/10000; Iter 51/80; Loss: 0.3479
Epoch 5039/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.038
Epoch 5040/10000; Iter 1/80; Loss: 0.3714
Epoch 5040/10000; Iter 51/80; Loss: 0.4057
Epoch 5040/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.049
Epoch 5041/10000; Iter 1/80; Loss: 0.3676
Epoch 5041/10000; Iter 51/80; Loss: 0.3616
Epoch 5041/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 5042/10000; Iter 1/80; Loss: 0.3865
Epoch 5042/10000; Iter 51/80; Loss: 0.3698
Epoch 5042/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 5043/10000; Iter 1/80; Loss: 0.3600
Epoch 5043/10000; Iter 51/80; Loss: 0.3475
Epoch 5043/10000; Iter 80/80; Training Loss: 0.3890, Test Loss: 0.038
Epoch 5044/10000; Iter 1/80; Loss: 0.3702
Epoch 5044/10000; Iter 51/80; Loss: 0.4399
Epoch 5044/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5045/10000; Iter 1/80; Loss: 0.3745
Epoch 5045/10000; Iter 51/80; Loss: 0.3480
Epoch 5045/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.04
Epoch 5046/10000; Iter 1/80; Loss: 0.3407
Epoch 5046/10000; Iter 51/80; Loss: 0.3552
Epoch 5046/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 5047/10000; Iter 1/80; Loss: 0.3722
Epoch 5047/10000; Iter 51/80; Loss: 0.3428
Epoch 5047/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5048/10000; Iter 1/80; Loss: 0.4309
Epoch 5048/10000; Iter 51/80; Loss: 0.3641
Epoch 5048/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 5049/10000; Iter 1/80; Loss: 0.3465
Epoch 5049/10000; Iter 51/80; Loss: 0.4094
Epoch 5049/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.05
Epoch 5050/10000; Iter 1/80; Loss: 0.3945
Epoch 5050/10000; Iter 51/80; Loss: 0.3858
Epoch 5050/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 5051/10000; Iter 1/80; Loss: 0.3854
Epoch 5051/10000; Iter 51/80; Loss: 0.3274
Epoch 5051/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.038
Epoch 5052/10000; Iter 1/80; Loss: 0.3509
Epoch 5052/10000; Iter 51/80; Loss: 0.4221
Epoch 5052/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5053/10000; Iter 1/80; Loss: 0.3751
Epoch 5053/10000; Iter 51/80; Loss: 0.3951
Epoch 5053/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.039
Epoch 5054/10000; Iter 1/80; Loss: 0.3947
Epoch 5054/10000; Iter 51/80; Loss: 0.3531
Epoch 5054/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.051
Epoch 5055/10000; Iter 1/80; Loss: 0.3696
Epoch 5055/10000; Iter 51/80; Loss: 0.4293
Epoch 5055/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.048
Epoch 5056/10000; Iter 1/80; Loss: 0.3879
Epoch 5056/10000; Iter 51/80; Loss: 0.4121
Epoch 5056/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.053
Epoch 5057/10000; Iter 1/80; Loss: 0.3988
Epoch 5057/10000; Iter 51/80; Loss: 0.4260
Epoch 5057/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.046
Epoch 5058/10000; Iter 1/80; Loss: 0.4141
Epoch 5058/10000; Iter 51/80; Loss: 0.3698
Epoch 5058/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.046
Epoch 5059/10000; Iter 1/80; Loss: 0.4009
Epoch 5059/10000; Iter 51/80; Loss: 0.3803
Epoch 5059/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.045
Epoch 5060/10000; Iter 1/80; Loss: 0.3793
Epoch 5060/10000; Iter 51/80; Loss: 0.4069
Epoch 5060/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.049
Epoch 5061/10000; Iter 1/80; Loss: 0.3927
Epoch 5061/10000; Iter 51/80; Loss: 0.3157
Epoch 5061/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.042
Epoch 5062/10000; Iter 1/80; Loss: 0.3889
Epoch 5062/10000; Iter 51/80; Loss: 0.3693
Epoch 5062/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5063/10000; Iter 1/80; Loss: 0.3574
Epoch 5063/10000; Iter 51/80; Loss: 0.4169
Epoch 5063/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.044
Epoch 5064/10000; Iter 1/80; Loss: 0.4196
Epoch 5064/10000; Iter 51/80; Loss: 0.3765
Epoch 5064/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 5065/10000; Iter 1/80; Loss: 0.3634
Epoch 5065/10000; Iter 51/80; Loss: 0.3727
Epoch 5065/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.043
Epoch 5066/10000; Iter 1/80; Loss: 0.3896
Epoch 5066/10000; Iter 51/80; Loss: 0.3988
Epoch 5066/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 5067/10000; Iter 1/80; Loss: 0.3407
Epoch 5067/10000; Iter 51/80; Loss: 0.3820
Epoch 5067/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.048
Epoch 5068/10000; Iter 1/80; Loss: 0.3567
Epoch 5068/10000; Iter 51/80; Loss: 0.4359
Epoch 5068/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5069/10000; Iter 1/80; Loss: 0.3414
Epoch 5069/10000; Iter 51/80; Loss: 0.3620
Epoch 5069/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 5070/10000; Iter 1/80; Loss: 0.3504
Epoch 5070/10000; Iter 51/80; Loss: 0.3585
Epoch 5070/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.043
Epoch 5071/10000; Iter 1/80; Loss: 0.3578
Epoch 5071/10000; Iter 51/80; Loss: 0.3486
Epoch 5071/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.051
Epoch 5072/10000; Iter 1/80; Loss: 0.3917
Epoch 5072/10000; Iter 51/80; Loss: 0.3369
Epoch 5072/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.047
Epoch 5073/10000; Iter 1/80; Loss: 0.3958
Epoch 5073/10000; Iter 51/80; Loss: 0.3166
Epoch 5073/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.048
Epoch 5074/10000; Iter 1/80; Loss: 0.4075
Epoch 5074/10000; Iter 51/80; Loss: 0.4424
Epoch 5074/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 5075/10000; Iter 1/80; Loss: 0.3038
Epoch 5075/10000; Iter 51/80; Loss: 0.4143
Epoch 5075/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5076/10000; Iter 1/80; Loss: 0.3744
Epoch 5076/10000; Iter 51/80; Loss: 0.4386
Epoch 5076/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.049
Epoch 5077/10000; Iter 1/80; Loss: 0.3523
Epoch 5077/10000; Iter 51/80; Loss: 0.3640
Epoch 5077/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5078/10000; Iter 1/80; Loss: 0.4358
Epoch 5078/10000; Iter 51/80; Loss: 0.3880
Epoch 5078/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.046
Epoch 5079/10000; Iter 1/80; Loss: 0.3840
Epoch 5079/10000; Iter 51/80; Loss: 0.3578
Epoch 5079/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 5080/10000; Iter 1/80; Loss: 0.3788
Epoch 5080/10000; Iter 51/80; Loss: 0.3371
Epoch 5080/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.042
Epoch 5081/10000; Iter 1/80; Loss: 0.3337
Epoch 5081/10000; Iter 51/80; Loss: 0.4224
Epoch 5081/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.041
Epoch 5082/10000; Iter 1/80; Loss: 0.3370
Epoch 5082/10000; Iter 51/80; Loss: 0.3679
Epoch 5082/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 5083/10000; Iter 1/80; Loss: 0.4024
Epoch 5083/10000; Iter 51/80; Loss: 0.3846
Epoch 5083/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.052
Epoch 5084/10000; Iter 1/80; Loss: 0.4133
Epoch 5084/10000; Iter 51/80; Loss: 0.4505
Epoch 5084/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.042
Epoch 5085/10000; Iter 1/80; Loss: 0.4406
Epoch 5085/10000; Iter 51/80; Loss: 0.3870
Epoch 5085/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.05
Epoch 5086/10000; Iter 1/80; Loss: 0.4093
Epoch 5086/10000; Iter 51/80; Loss: 0.4179
Epoch 5086/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5087/10000; Iter 1/80; Loss: 0.4122
Epoch 5087/10000; Iter 51/80; Loss: 0.3625
Epoch 5087/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.044
Epoch 5088/10000; Iter 1/80; Loss: 0.3903
Epoch 5088/10000; Iter 51/80; Loss: 0.3608
Epoch 5088/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 5089/10000; Iter 1/80; Loss: 0.3870
Epoch 5089/10000; Iter 51/80; Loss: 0.3589
Epoch 5089/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 5090/10000; Iter 1/80; Loss: 0.3744
Epoch 5090/10000; Iter 51/80; Loss: 0.3729
Epoch 5090/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 5091/10000; Iter 1/80; Loss: 0.3780
Epoch 5091/10000; Iter 51/80; Loss: 0.3324
Epoch 5091/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5092/10000; Iter 1/80; Loss: 0.3881
Epoch 5092/10000; Iter 51/80; Loss: 0.3433
Epoch 5092/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.043
Epoch 5093/10000; Iter 1/80; Loss: 0.3135
Epoch 5093/10000; Iter 51/80; Loss: 0.3775
Epoch 5093/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.048
Epoch 5094/10000; Iter 1/80; Loss: 0.3316
Epoch 5094/10000; Iter 51/80; Loss: 0.3566
Epoch 5094/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.041
Epoch 5095/10000; Iter 1/80; Loss: 0.4627
Epoch 5095/10000; Iter 51/80; Loss: 0.3779
Epoch 5095/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 5096/10000; Iter 1/80; Loss: 0.4260
Epoch 5096/10000; Iter 51/80; Loss: 0.3631
Epoch 5096/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5097/10000; Iter 1/80; Loss: 0.4459
Epoch 5097/10000; Iter 51/80; Loss: 0.3850
Epoch 5097/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 5098/10000; Iter 1/80; Loss: 0.3623
Epoch 5098/10000; Iter 51/80; Loss: 0.3715
Epoch 5098/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.036
Epoch 5099/10000; Iter 1/80; Loss: 0.3642
Epoch 5099/10000; Iter 51/80; Loss: 0.3432
Epoch 5099/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5100/10000; Iter 1/80; Loss: 0.4027
Epoch 5100/10000; Iter 51/80; Loss: 0.3721
Epoch 5100/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.047
Epoch 5101/10000; Iter 1/80; Loss: 0.3952
Epoch 5101/10000; Iter 51/80; Loss: 0.3617
Epoch 5101/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.041
Model saved
Epoch 5102/10000; Iter 1/80; Loss: 0.3496
Epoch 5102/10000; Iter 51/80; Loss: 0.3690
Epoch 5102/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 5103/10000; Iter 1/80; Loss: 0.3294
Epoch 5103/10000; Iter 51/80; Loss: 0.3816
Epoch 5103/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.047
Epoch 5104/10000; Iter 1/80; Loss: 0.3603
Epoch 5104/10000; Iter 51/80; Loss: 0.3656
Epoch 5104/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5105/10000; Iter 1/80; Loss: 0.4256
Epoch 5105/10000; Iter 51/80; Loss: 0.4181
Epoch 5105/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 5106/10000; Iter 1/80; Loss: 0.3733
Epoch 5106/10000; Iter 51/80; Loss: 0.3663
Epoch 5106/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 5107/10000; Iter 1/80; Loss: 0.3665
Epoch 5107/10000; Iter 51/80; Loss: 0.3273
Epoch 5107/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.041
Epoch 5108/10000; Iter 1/80; Loss: 0.3267
Epoch 5108/10000; Iter 51/80; Loss: 0.4281
Epoch 5108/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5109/10000; Iter 1/80; Loss: 0.3485
Epoch 5109/10000; Iter 51/80; Loss: 0.3549
Epoch 5109/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5110/10000; Iter 1/80; Loss: 0.3917
Epoch 5110/10000; Iter 51/80; Loss: 0.3708
Epoch 5110/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.048
Epoch 5111/10000; Iter 1/80; Loss: 0.4388
Epoch 5111/10000; Iter 51/80; Loss: 0.3830
Epoch 5111/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.046
Epoch 5112/10000; Iter 1/80; Loss: 0.3938
Epoch 5112/10000; Iter 51/80; Loss: 0.3520
Epoch 5112/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5113/10000; Iter 1/80; Loss: 0.3450
Epoch 5113/10000; Iter 51/80; Loss: 0.3448
Epoch 5113/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5114/10000; Iter 1/80; Loss: 0.4217
Epoch 5114/10000; Iter 51/80; Loss: 0.4412
Epoch 5114/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 5115/10000; Iter 1/80; Loss: 0.4151
Epoch 5115/10000; Iter 51/80; Loss: 0.3460
Epoch 5115/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.042
Epoch 5116/10000; Iter 1/80; Loss: 0.4390
Epoch 5116/10000; Iter 51/80; Loss: 0.3659
Epoch 5116/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 5117/10000; Iter 1/80; Loss: 0.3647
Epoch 5117/10000; Iter 51/80; Loss: 0.4874
Epoch 5117/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5118/10000; Iter 1/80; Loss: 0.3617
Epoch 5118/10000; Iter 51/80; Loss: 0.3760
Epoch 5118/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.041
Epoch 5119/10000; Iter 1/80; Loss: 0.4474
Epoch 5119/10000; Iter 51/80; Loss: 0.4267
Epoch 5119/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.05
Epoch 5120/10000; Iter 1/80; Loss: 0.3580
Epoch 5120/10000; Iter 51/80; Loss: 0.3360
Epoch 5120/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 5121/10000; Iter 1/80; Loss: 0.3770
Epoch 5121/10000; Iter 51/80; Loss: 0.3646
Epoch 5121/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.049
Epoch 5122/10000; Iter 1/80; Loss: 0.3372
Epoch 5122/10000; Iter 51/80; Loss: 0.3853
Epoch 5122/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.05
Epoch 5123/10000; Iter 1/80; Loss: 0.3934
Epoch 5123/10000; Iter 51/80; Loss: 0.3539
Epoch 5123/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.038
Epoch 5124/10000; Iter 1/80; Loss: 0.4056
Epoch 5124/10000; Iter 51/80; Loss: 0.3843
Epoch 5124/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.04
Epoch 5125/10000; Iter 1/80; Loss: 0.4000
Epoch 5125/10000; Iter 51/80; Loss: 0.3847
Epoch 5125/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 5126/10000; Iter 1/80; Loss: 0.3794
Epoch 5126/10000; Iter 51/80; Loss: 0.3784
Epoch 5126/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.053
Epoch 5127/10000; Iter 1/80; Loss: 0.4188
Epoch 5127/10000; Iter 51/80; Loss: 0.3894
Epoch 5127/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.041
Epoch 5128/10000; Iter 1/80; Loss: 0.4041
Epoch 5128/10000; Iter 51/80; Loss: 0.3834
Epoch 5128/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.048
Epoch 5129/10000; Iter 1/80; Loss: 0.4631
Epoch 5129/10000; Iter 51/80; Loss: 0.3385
Epoch 5129/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.041
Epoch 5130/10000; Iter 1/80; Loss: 0.4179
Epoch 5130/10000; Iter 51/80; Loss: 0.3016
Epoch 5130/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.048
Epoch 5131/10000; Iter 1/80; Loss: 0.3589
Epoch 5131/10000; Iter 51/80; Loss: 0.3272
Epoch 5131/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.048
Epoch 5132/10000; Iter 1/80; Loss: 0.3671
Epoch 5132/10000; Iter 51/80; Loss: 0.3534
Epoch 5132/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.05
Epoch 5133/10000; Iter 1/80; Loss: 0.3418
Epoch 5133/10000; Iter 51/80; Loss: 0.4232
Epoch 5133/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.049
Epoch 5134/10000; Iter 1/80; Loss: 0.3790
Epoch 5134/10000; Iter 51/80; Loss: 0.3758
Epoch 5134/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 5135/10000; Iter 1/80; Loss: 0.3684
Epoch 5135/10000; Iter 51/80; Loss: 0.3422
Epoch 5135/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.044
Epoch 5136/10000; Iter 1/80; Loss: 0.4231
Epoch 5136/10000; Iter 51/80; Loss: 0.4420
Epoch 5136/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.048
Epoch 5137/10000; Iter 1/80; Loss: 0.3994
Epoch 5137/10000; Iter 51/80; Loss: 0.3784
Epoch 5137/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.047
Epoch 5138/10000; Iter 1/80; Loss: 0.3559
Epoch 5138/10000; Iter 51/80; Loss: 0.3794
Epoch 5138/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.048
Epoch 5139/10000; Iter 1/80; Loss: 0.3394
Epoch 5139/10000; Iter 51/80; Loss: 0.3686
Epoch 5139/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.05
Epoch 5140/10000; Iter 1/80; Loss: 0.3988
Epoch 5140/10000; Iter 51/80; Loss: 0.4527
Epoch 5140/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 5141/10000; Iter 1/80; Loss: 0.3471
Epoch 5141/10000; Iter 51/80; Loss: 0.3176
Epoch 5141/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5142/10000; Iter 1/80; Loss: 0.3703
Epoch 5142/10000; Iter 51/80; Loss: 0.3508
Epoch 5142/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.048
Epoch 5143/10000; Iter 1/80; Loss: 0.3866
Epoch 5143/10000; Iter 51/80; Loss: 0.4725
Epoch 5143/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 5144/10000; Iter 1/80; Loss: 0.3335
Epoch 5144/10000; Iter 51/80; Loss: 0.4012
Epoch 5144/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.038
Epoch 5145/10000; Iter 1/80; Loss: 0.3887
Epoch 5145/10000; Iter 51/80; Loss: 0.3362
Epoch 5145/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5146/10000; Iter 1/80; Loss: 0.4426
Epoch 5146/10000; Iter 51/80; Loss: 0.3964
Epoch 5146/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.041
Epoch 5147/10000; Iter 1/80; Loss: 0.3389
Epoch 5147/10000; Iter 51/80; Loss: 0.3322
Epoch 5147/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.038
Epoch 5148/10000; Iter 1/80; Loss: 0.3602
Epoch 5148/10000; Iter 51/80; Loss: 0.4020
Epoch 5148/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5149/10000; Iter 1/80; Loss: 0.3991
Epoch 5149/10000; Iter 51/80; Loss: 0.4171
Epoch 5149/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.041
Epoch 5150/10000; Iter 1/80; Loss: 0.4108
Epoch 5150/10000; Iter 51/80; Loss: 0.3881
Epoch 5150/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.044
Epoch 5151/10000; Iter 1/80; Loss: 0.3676
Epoch 5151/10000; Iter 51/80; Loss: 0.3360
Epoch 5151/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.039
Epoch 5152/10000; Iter 1/80; Loss: 0.3679
Epoch 5152/10000; Iter 51/80; Loss: 0.3128
Epoch 5152/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.04
Epoch 5153/10000; Iter 1/80; Loss: 0.4372
Epoch 5153/10000; Iter 51/80; Loss: 0.3895
Epoch 5153/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.05
Epoch 5154/10000; Iter 1/80; Loss: 0.3293
Epoch 5154/10000; Iter 51/80; Loss: 0.3800
Epoch 5154/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 5155/10000; Iter 1/80; Loss: 0.3257
Epoch 5155/10000; Iter 51/80; Loss: 0.4005
Epoch 5155/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.055
Epoch 5156/10000; Iter 1/80; Loss: 0.3987
Epoch 5156/10000; Iter 51/80; Loss: 0.4000
Epoch 5156/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.047
Epoch 5157/10000; Iter 1/80; Loss: 0.3663
Epoch 5157/10000; Iter 51/80; Loss: 0.3619
Epoch 5157/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.045
Epoch 5158/10000; Iter 1/80; Loss: 0.3768
Epoch 5158/10000; Iter 51/80; Loss: 0.3966
Epoch 5158/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5159/10000; Iter 1/80; Loss: 0.3845
Epoch 5159/10000; Iter 51/80; Loss: 0.4528
Epoch 5159/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.041
Epoch 5160/10000; Iter 1/80; Loss: 0.3745
Epoch 5160/10000; Iter 51/80; Loss: 0.3470
Epoch 5160/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 5161/10000; Iter 1/80; Loss: 0.4349
Epoch 5161/10000; Iter 51/80; Loss: 0.3627
Epoch 5161/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.05
Epoch 5162/10000; Iter 1/80; Loss: 0.3717
Epoch 5162/10000; Iter 51/80; Loss: 0.3547
Epoch 5162/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.051
Epoch 5163/10000; Iter 1/80; Loss: 0.3932
Epoch 5163/10000; Iter 51/80; Loss: 0.3818
Epoch 5163/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.04
Epoch 5164/10000; Iter 1/80; Loss: 0.4044
Epoch 5164/10000; Iter 51/80; Loss: 0.3554
Epoch 5164/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.055
Epoch 5165/10000; Iter 1/80; Loss: 0.3950
Epoch 5165/10000; Iter 51/80; Loss: 0.3638
Epoch 5165/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.047
Epoch 5166/10000; Iter 1/80; Loss: 0.3774
Epoch 5166/10000; Iter 51/80; Loss: 0.3982
Epoch 5166/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.052
Epoch 5167/10000; Iter 1/80; Loss: 0.3178
Epoch 5167/10000; Iter 51/80; Loss: 0.3972
Epoch 5167/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 5168/10000; Iter 1/80; Loss: 0.3418
Epoch 5168/10000; Iter 51/80; Loss: 0.3776
Epoch 5168/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.047
Epoch 5169/10000; Iter 1/80; Loss: 0.3903
Epoch 5169/10000; Iter 51/80; Loss: 0.3744
Epoch 5169/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.05
Epoch 5170/10000; Iter 1/80; Loss: 0.3339
Epoch 5170/10000; Iter 51/80; Loss: 0.3940
Epoch 5170/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 5171/10000; Iter 1/80; Loss: 0.3334
Epoch 5171/10000; Iter 51/80; Loss: 0.3836
Epoch 5171/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.047
Epoch 5172/10000; Iter 1/80; Loss: 0.3433
Epoch 5172/10000; Iter 51/80; Loss: 0.4083
Epoch 5172/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 5173/10000; Iter 1/80; Loss: 0.4718
Epoch 5173/10000; Iter 51/80; Loss: 0.3375
Epoch 5173/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.045
Epoch 5174/10000; Iter 1/80; Loss: 0.3815
Epoch 5174/10000; Iter 51/80; Loss: 0.3619
Epoch 5174/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.047
Epoch 5175/10000; Iter 1/80; Loss: 0.3934
Epoch 5175/10000; Iter 51/80; Loss: 0.3419
Epoch 5175/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.04
Epoch 5176/10000; Iter 1/80; Loss: 0.4253
Epoch 5176/10000; Iter 51/80; Loss: 0.3596
Epoch 5176/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5177/10000; Iter 1/80; Loss: 0.3914
Epoch 5177/10000; Iter 51/80; Loss: 0.3887
Epoch 5177/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.043
Epoch 5178/10000; Iter 1/80; Loss: 0.3519
Epoch 5178/10000; Iter 51/80; Loss: 0.3481
Epoch 5178/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.039
Epoch 5179/10000; Iter 1/80; Loss: 0.3244
Epoch 5179/10000; Iter 51/80; Loss: 0.3577
Epoch 5179/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.053
Epoch 5180/10000; Iter 1/80; Loss: 0.3814
Epoch 5180/10000; Iter 51/80; Loss: 0.3735
Epoch 5180/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.042
Epoch 5181/10000; Iter 1/80; Loss: 0.4180
Epoch 5181/10000; Iter 51/80; Loss: 0.3336
Epoch 5181/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.04
Epoch 5182/10000; Iter 1/80; Loss: 0.3586
Epoch 5182/10000; Iter 51/80; Loss: 0.3893
Epoch 5182/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5183/10000; Iter 1/80; Loss: 0.4052
Epoch 5183/10000; Iter 51/80; Loss: 0.4276
Epoch 5183/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.041
Epoch 5184/10000; Iter 1/80; Loss: 0.3737
Epoch 5184/10000; Iter 51/80; Loss: 0.3151
Epoch 5184/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.041
Epoch 5185/10000; Iter 1/80; Loss: 0.3745
Epoch 5185/10000; Iter 51/80; Loss: 0.3851
Epoch 5185/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.036
Epoch 5186/10000; Iter 1/80; Loss: 0.3628
Epoch 5186/10000; Iter 51/80; Loss: 0.4031
Epoch 5186/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.043
Epoch 5187/10000; Iter 1/80; Loss: 0.3161
Epoch 5187/10000; Iter 51/80; Loss: 0.4500
Epoch 5187/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.046
Epoch 5188/10000; Iter 1/80; Loss: 0.3634
Epoch 5188/10000; Iter 51/80; Loss: 0.4117
Epoch 5188/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.039
Epoch 5189/10000; Iter 1/80; Loss: 0.3689
Epoch 5189/10000; Iter 51/80; Loss: 0.3669
Epoch 5189/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.05
Epoch 5190/10000; Iter 1/80; Loss: 0.3849
Epoch 5190/10000; Iter 51/80; Loss: 0.3466
Epoch 5190/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.043
Epoch 5191/10000; Iter 1/80; Loss: 0.3710
Epoch 5191/10000; Iter 51/80; Loss: 0.3813
Epoch 5191/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 5192/10000; Iter 1/80; Loss: 0.3782
Epoch 5192/10000; Iter 51/80; Loss: 0.2961
Epoch 5192/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5193/10000; Iter 1/80; Loss: 0.4630
Epoch 5193/10000; Iter 51/80; Loss: 0.3281
Epoch 5193/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.038
Epoch 5194/10000; Iter 1/80; Loss: 0.3965
Epoch 5194/10000; Iter 51/80; Loss: 0.3653
Epoch 5194/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.046
Epoch 5195/10000; Iter 1/80; Loss: 0.4104
Epoch 5195/10000; Iter 51/80; Loss: 0.4404
Epoch 5195/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5196/10000; Iter 1/80; Loss: 0.3024
Epoch 5196/10000; Iter 51/80; Loss: 0.3192
Epoch 5196/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.044
Epoch 5197/10000; Iter 1/80; Loss: 0.4067
Epoch 5197/10000; Iter 51/80; Loss: 0.3882
Epoch 5197/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 5198/10000; Iter 1/80; Loss: 0.3540
Epoch 5198/10000; Iter 51/80; Loss: 0.4279
Epoch 5198/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.04
Epoch 5199/10000; Iter 1/80; Loss: 0.3514
Epoch 5199/10000; Iter 51/80; Loss: 0.4226
Epoch 5199/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.053
Epoch 5200/10000; Iter 1/80; Loss: 0.3564
Epoch 5200/10000; Iter 51/80; Loss: 0.4295
Epoch 5200/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 5201/10000; Iter 1/80; Loss: 0.3531
Epoch 5201/10000; Iter 51/80; Loss: 0.3779
Epoch 5201/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.045
Model saved
Epoch 5202/10000; Iter 1/80; Loss: 0.3484
Epoch 5202/10000; Iter 51/80; Loss: 0.3647
Epoch 5202/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.046
Epoch 5203/10000; Iter 1/80; Loss: 0.3357
Epoch 5203/10000; Iter 51/80; Loss: 0.4212
Epoch 5203/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5204/10000; Iter 1/80; Loss: 0.4035
Epoch 5204/10000; Iter 51/80; Loss: 0.3931
Epoch 5204/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 5205/10000; Iter 1/80; Loss: 0.3948
Epoch 5205/10000; Iter 51/80; Loss: 0.3828
Epoch 5205/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.048
Epoch 5206/10000; Iter 1/80; Loss: 0.3575
Epoch 5206/10000; Iter 51/80; Loss: 0.3966
Epoch 5206/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5207/10000; Iter 1/80; Loss: 0.3899
Epoch 5207/10000; Iter 51/80; Loss: 0.4712
Epoch 5207/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.041
Epoch 5208/10000; Iter 1/80; Loss: 0.3825
Epoch 5208/10000; Iter 51/80; Loss: 0.4613
Epoch 5208/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.051
Epoch 5209/10000; Iter 1/80; Loss: 0.3822
Epoch 5209/10000; Iter 51/80; Loss: 0.3881
Epoch 5209/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.042
Epoch 5210/10000; Iter 1/80; Loss: 0.3718
Epoch 5210/10000; Iter 51/80; Loss: 0.3319
Epoch 5210/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5211/10000; Iter 1/80; Loss: 0.3734
Epoch 5211/10000; Iter 51/80; Loss: 0.3762
Epoch 5211/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.049
Epoch 5212/10000; Iter 1/80; Loss: 0.3809
Epoch 5212/10000; Iter 51/80; Loss: 0.3807
Epoch 5212/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.052
Epoch 5213/10000; Iter 1/80; Loss: 0.4075
Epoch 5213/10000; Iter 51/80; Loss: 0.4221
Epoch 5213/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.046
Epoch 5214/10000; Iter 1/80; Loss: 0.3721
Epoch 5214/10000; Iter 51/80; Loss: 0.4297
Epoch 5214/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5215/10000; Iter 1/80; Loss: 0.4682
Epoch 5215/10000; Iter 51/80; Loss: 0.3659
Epoch 5215/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.04
Epoch 5216/10000; Iter 1/80; Loss: 0.4405
Epoch 5216/10000; Iter 51/80; Loss: 0.3828
Epoch 5216/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.041
Epoch 5217/10000; Iter 1/80; Loss: 0.3476
Epoch 5217/10000; Iter 51/80; Loss: 0.3804
Epoch 5217/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.044
Epoch 5218/10000; Iter 1/80; Loss: 0.4003
Epoch 5218/10000; Iter 51/80; Loss: 0.3660
Epoch 5218/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5219/10000; Iter 1/80; Loss: 0.3822
Epoch 5219/10000; Iter 51/80; Loss: 0.3456
Epoch 5219/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5220/10000; Iter 1/80; Loss: 0.4347
Epoch 5220/10000; Iter 51/80; Loss: 0.3940
Epoch 5220/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.047
Epoch 5221/10000; Iter 1/80; Loss: 0.4235
Epoch 5221/10000; Iter 51/80; Loss: 0.3710
Epoch 5221/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 5222/10000; Iter 1/80; Loss: 0.3862
Epoch 5222/10000; Iter 51/80; Loss: 0.3706
Epoch 5222/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 5223/10000; Iter 1/80; Loss: 0.3355
Epoch 5223/10000; Iter 51/80; Loss: 0.3972
Epoch 5223/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5224/10000; Iter 1/80; Loss: 0.3714
Epoch 5224/10000; Iter 51/80; Loss: 0.3804
Epoch 5224/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.046
Epoch 5225/10000; Iter 1/80; Loss: 0.4323
Epoch 5225/10000; Iter 51/80; Loss: 0.3545
Epoch 5225/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.045
Epoch 5226/10000; Iter 1/80; Loss: 0.3866
Epoch 5226/10000; Iter 51/80; Loss: 0.3571
Epoch 5226/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 5227/10000; Iter 1/80; Loss: 0.3700
Epoch 5227/10000; Iter 51/80; Loss: 0.4176
Epoch 5227/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5228/10000; Iter 1/80; Loss: 0.4039
Epoch 5228/10000; Iter 51/80; Loss: 0.3584
Epoch 5228/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.052
Epoch 5229/10000; Iter 1/80; Loss: 0.3706
Epoch 5229/10000; Iter 51/80; Loss: 0.4084
Epoch 5229/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.045
Epoch 5230/10000; Iter 1/80; Loss: 0.3783
Epoch 5230/10000; Iter 51/80; Loss: 0.3467
Epoch 5230/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.044
Epoch 5231/10000; Iter 1/80; Loss: 0.3664
Epoch 5231/10000; Iter 51/80; Loss: 0.3755
Epoch 5231/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.05
Epoch 5232/10000; Iter 1/80; Loss: 0.3673
Epoch 5232/10000; Iter 51/80; Loss: 0.4199
Epoch 5232/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5233/10000; Iter 1/80; Loss: 0.3923
Epoch 5233/10000; Iter 51/80; Loss: 0.3766
Epoch 5233/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.05
Epoch 5234/10000; Iter 1/80; Loss: 0.4002
Epoch 5234/10000; Iter 51/80; Loss: 0.3663
Epoch 5234/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 5235/10000; Iter 1/80; Loss: 0.4035
Epoch 5235/10000; Iter 51/80; Loss: 0.3177
Epoch 5235/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.045
Epoch 5236/10000; Iter 1/80; Loss: 0.4157
Epoch 5236/10000; Iter 51/80; Loss: 0.3694
Epoch 5236/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.05
Epoch 5237/10000; Iter 1/80; Loss: 0.4020
Epoch 5237/10000; Iter 51/80; Loss: 0.3726
Epoch 5237/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 5238/10000; Iter 1/80; Loss: 0.4254
Epoch 5238/10000; Iter 51/80; Loss: 0.4113
Epoch 5238/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 5239/10000; Iter 1/80; Loss: 0.3452
Epoch 5239/10000; Iter 51/80; Loss: 0.3994
Epoch 5239/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5240/10000; Iter 1/80; Loss: 0.3534
Epoch 5240/10000; Iter 51/80; Loss: 0.4035
Epoch 5240/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.052
Epoch 5241/10000; Iter 1/80; Loss: 0.3323
Epoch 5241/10000; Iter 51/80; Loss: 0.4043
Epoch 5241/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5242/10000; Iter 1/80; Loss: 0.3989
Epoch 5242/10000; Iter 51/80; Loss: 0.3513
Epoch 5242/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.04
Epoch 5243/10000; Iter 1/80; Loss: 0.3989
Epoch 5243/10000; Iter 51/80; Loss: 0.3334
Epoch 5243/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5244/10000; Iter 1/80; Loss: 0.3180
Epoch 5244/10000; Iter 51/80; Loss: 0.3390
Epoch 5244/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5245/10000; Iter 1/80; Loss: 0.3821
Epoch 5245/10000; Iter 51/80; Loss: 0.3448
Epoch 5245/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5246/10000; Iter 1/80; Loss: 0.4585
Epoch 5246/10000; Iter 51/80; Loss: 0.3736
Epoch 5246/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5247/10000; Iter 1/80; Loss: 0.3365
Epoch 5247/10000; Iter 51/80; Loss: 0.4059
Epoch 5247/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.053
Epoch 5248/10000; Iter 1/80; Loss: 0.3775
Epoch 5248/10000; Iter 51/80; Loss: 0.4124
Epoch 5248/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5249/10000; Iter 1/80; Loss: 0.3508
Epoch 5249/10000; Iter 51/80; Loss: 0.4036
Epoch 5249/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.043
Epoch 5250/10000; Iter 1/80; Loss: 0.3594
Epoch 5250/10000; Iter 51/80; Loss: 0.3099
Epoch 5250/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.05
Epoch 5251/10000; Iter 1/80; Loss: 0.3807
Epoch 5251/10000; Iter 51/80; Loss: 0.4118
Epoch 5251/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.048
Epoch 5252/10000; Iter 1/80; Loss: 0.3352
Epoch 5252/10000; Iter 51/80; Loss: 0.3895
Epoch 5252/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5253/10000; Iter 1/80; Loss: 0.4230
Epoch 5253/10000; Iter 51/80; Loss: 0.4213
Epoch 5253/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.044
Epoch 5254/10000; Iter 1/80; Loss: 0.3607
Epoch 5254/10000; Iter 51/80; Loss: 0.3979
Epoch 5254/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.036
Epoch 5255/10000; Iter 1/80; Loss: 0.3576
Epoch 5255/10000; Iter 51/80; Loss: 0.3372
Epoch 5255/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.042
Epoch 5256/10000; Iter 1/80; Loss: 0.3486
Epoch 5256/10000; Iter 51/80; Loss: 0.3311
Epoch 5256/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.041
Epoch 5257/10000; Iter 1/80; Loss: 0.4131
Epoch 5257/10000; Iter 51/80; Loss: 0.3813
Epoch 5257/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.05
Epoch 5258/10000; Iter 1/80; Loss: 0.4617
Epoch 5258/10000; Iter 51/80; Loss: 0.4081
Epoch 5258/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.042
Epoch 5259/10000; Iter 1/80; Loss: 0.4422
Epoch 5259/10000; Iter 51/80; Loss: 0.3536
Epoch 5259/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.04
Epoch 5260/10000; Iter 1/80; Loss: 0.3925
Epoch 5260/10000; Iter 51/80; Loss: 0.3997
Epoch 5260/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5261/10000; Iter 1/80; Loss: 0.4497
Epoch 5261/10000; Iter 51/80; Loss: 0.3642
Epoch 5261/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5262/10000; Iter 1/80; Loss: 0.3342
Epoch 5262/10000; Iter 51/80; Loss: 0.4048
Epoch 5262/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 5263/10000; Iter 1/80; Loss: 0.3641
Epoch 5263/10000; Iter 51/80; Loss: 0.3358
Epoch 5263/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.044
Epoch 5264/10000; Iter 1/80; Loss: 0.3765
Epoch 5264/10000; Iter 51/80; Loss: 0.3437
Epoch 5264/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5265/10000; Iter 1/80; Loss: 0.3850
Epoch 5265/10000; Iter 51/80; Loss: 0.4129
Epoch 5265/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5266/10000; Iter 1/80; Loss: 0.3535
Epoch 5266/10000; Iter 51/80; Loss: 0.3550
Epoch 5266/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.046
Epoch 5267/10000; Iter 1/80; Loss: 0.4277
Epoch 5267/10000; Iter 51/80; Loss: 0.3780
Epoch 5267/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5268/10000; Iter 1/80; Loss: 0.4201
Epoch 5268/10000; Iter 51/80; Loss: 0.3784
Epoch 5268/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 5269/10000; Iter 1/80; Loss: 0.3492
Epoch 5269/10000; Iter 51/80; Loss: 0.3645
Epoch 5269/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 5270/10000; Iter 1/80; Loss: 0.4252
Epoch 5270/10000; Iter 51/80; Loss: 0.3785
Epoch 5270/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5271/10000; Iter 1/80; Loss: 0.4058
Epoch 5271/10000; Iter 51/80; Loss: 0.3371
Epoch 5271/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.047
Epoch 5272/10000; Iter 1/80; Loss: 0.3700
Epoch 5272/10000; Iter 51/80; Loss: 0.3983
Epoch 5272/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5273/10000; Iter 1/80; Loss: 0.3925
Epoch 5273/10000; Iter 51/80; Loss: 0.3755
Epoch 5273/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.041
Epoch 5274/10000; Iter 1/80; Loss: 0.3486
Epoch 5274/10000; Iter 51/80; Loss: 0.3490
Epoch 5274/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.044
Epoch 5275/10000; Iter 1/80; Loss: 0.3044
Epoch 5275/10000; Iter 51/80; Loss: 0.4189
Epoch 5275/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.048
Epoch 5276/10000; Iter 1/80; Loss: 0.4065
Epoch 5276/10000; Iter 51/80; Loss: 0.3853
Epoch 5276/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.049
Epoch 5277/10000; Iter 1/80; Loss: 0.3228
Epoch 5277/10000; Iter 51/80; Loss: 0.4295
Epoch 5277/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.042
Epoch 5278/10000; Iter 1/80; Loss: 0.3620
Epoch 5278/10000; Iter 51/80; Loss: 0.3771
Epoch 5278/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5279/10000; Iter 1/80; Loss: 0.3667
Epoch 5279/10000; Iter 51/80; Loss: 0.4049
Epoch 5279/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.038
Epoch 5280/10000; Iter 1/80; Loss: 0.4937
Epoch 5280/10000; Iter 51/80; Loss: 0.3360
Epoch 5280/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.039
Epoch 5281/10000; Iter 1/80; Loss: 0.4180
Epoch 5281/10000; Iter 51/80; Loss: 0.4148
Epoch 5281/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.044
Epoch 5282/10000; Iter 1/80; Loss: 0.3655
Epoch 5282/10000; Iter 51/80; Loss: 0.3329
Epoch 5282/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.051
Epoch 5283/10000; Iter 1/80; Loss: 0.3853
Epoch 5283/10000; Iter 51/80; Loss: 0.4081
Epoch 5283/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5284/10000; Iter 1/80; Loss: 0.3103
Epoch 5284/10000; Iter 51/80; Loss: 0.3750
Epoch 5284/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.051
Epoch 5285/10000; Iter 1/80; Loss: 0.3900
Epoch 5285/10000; Iter 51/80; Loss: 0.3921
Epoch 5285/10000; Iter 80/80; Training Loss: 0.3880, Test Loss: 0.05
Epoch 5286/10000; Iter 1/80; Loss: 0.3965
Epoch 5286/10000; Iter 51/80; Loss: 0.3648
Epoch 5286/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.048
Epoch 5287/10000; Iter 1/80; Loss: 0.3437
Epoch 5287/10000; Iter 51/80; Loss: 0.3324
Epoch 5287/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5288/10000; Iter 1/80; Loss: 0.3558
Epoch 5288/10000; Iter 51/80; Loss: 0.4142
Epoch 5288/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.048
Epoch 5289/10000; Iter 1/80; Loss: 0.3571
Epoch 5289/10000; Iter 51/80; Loss: 0.3180
Epoch 5289/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.042
Epoch 5290/10000; Iter 1/80; Loss: 0.4391
Epoch 5290/10000; Iter 51/80; Loss: 0.3691
Epoch 5290/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.044
Epoch 5291/10000; Iter 1/80; Loss: 0.3522
Epoch 5291/10000; Iter 51/80; Loss: 0.4453
Epoch 5291/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.048
Epoch 5292/10000; Iter 1/80; Loss: 0.4178
Epoch 5292/10000; Iter 51/80; Loss: 0.4060
Epoch 5292/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5293/10000; Iter 1/80; Loss: 0.3843
Epoch 5293/10000; Iter 51/80; Loss: 0.4366
Epoch 5293/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5294/10000; Iter 1/80; Loss: 0.3671
Epoch 5294/10000; Iter 51/80; Loss: 0.3426
Epoch 5294/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.044
Epoch 5295/10000; Iter 1/80; Loss: 0.3917
Epoch 5295/10000; Iter 51/80; Loss: 0.4094
Epoch 5295/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.045
Epoch 5296/10000; Iter 1/80; Loss: 0.3767
Epoch 5296/10000; Iter 51/80; Loss: 0.3745
Epoch 5296/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.052
Epoch 5297/10000; Iter 1/80; Loss: 0.3716
Epoch 5297/10000; Iter 51/80; Loss: 0.3782
Epoch 5297/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5298/10000; Iter 1/80; Loss: 0.3337
Epoch 5298/10000; Iter 51/80; Loss: 0.4422
Epoch 5298/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5299/10000; Iter 1/80; Loss: 0.3599
Epoch 5299/10000; Iter 51/80; Loss: 0.3859
Epoch 5299/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5300/10000; Iter 1/80; Loss: 0.4519
Epoch 5300/10000; Iter 51/80; Loss: 0.3865
Epoch 5300/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5301/10000; Iter 1/80; Loss: 0.3815
Epoch 5301/10000; Iter 51/80; Loss: 0.3561
Epoch 5301/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.046
Model saved
Epoch 5302/10000; Iter 1/80; Loss: 0.4324
Epoch 5302/10000; Iter 51/80; Loss: 0.3682
Epoch 5302/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.048
Epoch 5303/10000; Iter 1/80; Loss: 0.4776
Epoch 5303/10000; Iter 51/80; Loss: 0.3756
Epoch 5303/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.046
Epoch 5304/10000; Iter 1/80; Loss: 0.3943
Epoch 5304/10000; Iter 51/80; Loss: 0.3736
Epoch 5304/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.048
Epoch 5305/10000; Iter 1/80; Loss: 0.3683
Epoch 5305/10000; Iter 51/80; Loss: 0.4317
Epoch 5305/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.044
Epoch 5306/10000; Iter 1/80; Loss: 0.4023
Epoch 5306/10000; Iter 51/80; Loss: 0.4109
Epoch 5306/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.053
Epoch 5307/10000; Iter 1/80; Loss: 0.3901
Epoch 5307/10000; Iter 51/80; Loss: 0.3428
Epoch 5307/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5308/10000; Iter 1/80; Loss: 0.4153
Epoch 5308/10000; Iter 51/80; Loss: 0.4195
Epoch 5308/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.045
Epoch 5309/10000; Iter 1/80; Loss: 0.4138
Epoch 5309/10000; Iter 51/80; Loss: 0.3731
Epoch 5309/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5310/10000; Iter 1/80; Loss: 0.4953
Epoch 5310/10000; Iter 51/80; Loss: 0.3822
Epoch 5310/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 5311/10000; Iter 1/80; Loss: 0.3260
Epoch 5311/10000; Iter 51/80; Loss: 0.3942
Epoch 5311/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.049
Epoch 5312/10000; Iter 1/80; Loss: 0.4289
Epoch 5312/10000; Iter 51/80; Loss: 0.3939
Epoch 5312/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5313/10000; Iter 1/80; Loss: 0.4153
Epoch 5313/10000; Iter 51/80; Loss: 0.3515
Epoch 5313/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.042
Epoch 5314/10000; Iter 1/80; Loss: 0.3677
Epoch 5314/10000; Iter 51/80; Loss: 0.3526
Epoch 5314/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.052
Epoch 5315/10000; Iter 1/80; Loss: 0.3975
Epoch 5315/10000; Iter 51/80; Loss: 0.4008
Epoch 5315/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.045
Epoch 5316/10000; Iter 1/80; Loss: 0.4372
Epoch 5316/10000; Iter 51/80; Loss: 0.4229
Epoch 5316/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.048
Epoch 5317/10000; Iter 1/80; Loss: 0.3548
Epoch 5317/10000; Iter 51/80; Loss: 0.3818
Epoch 5317/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.043
Epoch 5318/10000; Iter 1/80; Loss: 0.3821
Epoch 5318/10000; Iter 51/80; Loss: 0.4180
Epoch 5318/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.049
Epoch 5319/10000; Iter 1/80; Loss: 0.3601
Epoch 5319/10000; Iter 51/80; Loss: 0.3678
Epoch 5319/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5320/10000; Iter 1/80; Loss: 0.3528
Epoch 5320/10000; Iter 51/80; Loss: 0.4004
Epoch 5320/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5321/10000; Iter 1/80; Loss: 0.4075
Epoch 5321/10000; Iter 51/80; Loss: 0.3486
Epoch 5321/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.04
Epoch 5322/10000; Iter 1/80; Loss: 0.3514
Epoch 5322/10000; Iter 51/80; Loss: 0.4128
Epoch 5322/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.041
Epoch 5323/10000; Iter 1/80; Loss: 0.3919
Epoch 5323/10000; Iter 51/80; Loss: 0.3589
Epoch 5323/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5324/10000; Iter 1/80; Loss: 0.3822
Epoch 5324/10000; Iter 51/80; Loss: 0.4500
Epoch 5324/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.054
Epoch 5325/10000; Iter 1/80; Loss: 0.3849
Epoch 5325/10000; Iter 51/80; Loss: 0.4234
Epoch 5325/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 5326/10000; Iter 1/80; Loss: 0.3937
Epoch 5326/10000; Iter 51/80; Loss: 0.3547
Epoch 5326/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5327/10000; Iter 1/80; Loss: 0.3757
Epoch 5327/10000; Iter 51/80; Loss: 0.3368
Epoch 5327/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.039
Epoch 5328/10000; Iter 1/80; Loss: 0.3498
Epoch 5328/10000; Iter 51/80; Loss: 0.4087
Epoch 5328/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.042
Epoch 5329/10000; Iter 1/80; Loss: 0.3820
Epoch 5329/10000; Iter 51/80; Loss: 0.4301
Epoch 5329/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.044
Epoch 5330/10000; Iter 1/80; Loss: 0.3383
Epoch 5330/10000; Iter 51/80; Loss: 0.3317
Epoch 5330/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5331/10000; Iter 1/80; Loss: 0.3929
Epoch 5331/10000; Iter 51/80; Loss: 0.3531
Epoch 5331/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.055
Epoch 5332/10000; Iter 1/80; Loss: 0.3739
Epoch 5332/10000; Iter 51/80; Loss: 0.3761
Epoch 5332/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.044
Epoch 5333/10000; Iter 1/80; Loss: 0.3387
Epoch 5333/10000; Iter 51/80; Loss: 0.3779
Epoch 5333/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.051
Epoch 5334/10000; Iter 1/80; Loss: 0.4173
Epoch 5334/10000; Iter 51/80; Loss: 0.3648
Epoch 5334/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.045
Epoch 5335/10000; Iter 1/80; Loss: 0.3307
Epoch 5335/10000; Iter 51/80; Loss: 0.3053
Epoch 5335/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.046
Epoch 5336/10000; Iter 1/80; Loss: 0.3518
Epoch 5336/10000; Iter 51/80; Loss: 0.3987
Epoch 5336/10000; Iter 80/80; Training Loss: 0.3860, Test Loss: 0.047
Epoch 5337/10000; Iter 1/80; Loss: 0.3977
Epoch 5337/10000; Iter 51/80; Loss: 0.3676
Epoch 5337/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.044
Epoch 5338/10000; Iter 1/80; Loss: 0.3921
Epoch 5338/10000; Iter 51/80; Loss: 0.3805
Epoch 5338/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5339/10000; Iter 1/80; Loss: 0.3372
Epoch 5339/10000; Iter 51/80; Loss: 0.3624
Epoch 5339/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5340/10000; Iter 1/80; Loss: 0.3548
Epoch 5340/10000; Iter 51/80; Loss: 0.3601
Epoch 5340/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.046
Epoch 5341/10000; Iter 1/80; Loss: 0.3643
Epoch 5341/10000; Iter 51/80; Loss: 0.4136
Epoch 5341/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.045
Epoch 5342/10000; Iter 1/80; Loss: 0.3683
Epoch 5342/10000; Iter 51/80; Loss: 0.3728
Epoch 5342/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.042
Epoch 5343/10000; Iter 1/80; Loss: 0.3802
Epoch 5343/10000; Iter 51/80; Loss: 0.3778
Epoch 5343/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.039
Epoch 5344/10000; Iter 1/80; Loss: 0.3343
Epoch 5344/10000; Iter 51/80; Loss: 0.4920
Epoch 5344/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.038
Epoch 5345/10000; Iter 1/80; Loss: 0.3436
Epoch 5345/10000; Iter 51/80; Loss: 0.4864
Epoch 5345/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5346/10000; Iter 1/80; Loss: 0.4716
Epoch 5346/10000; Iter 51/80; Loss: 0.3862
Epoch 5346/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5347/10000; Iter 1/80; Loss: 0.3928
Epoch 5347/10000; Iter 51/80; Loss: 0.3421
Epoch 5347/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.044
Epoch 5348/10000; Iter 1/80; Loss: 0.4029
Epoch 5348/10000; Iter 51/80; Loss: 0.3555
Epoch 5348/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.05
Epoch 5349/10000; Iter 1/80; Loss: 0.4142
Epoch 5349/10000; Iter 51/80; Loss: 0.3476
Epoch 5349/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.052
Epoch 5350/10000; Iter 1/80; Loss: 0.4814
Epoch 5350/10000; Iter 51/80; Loss: 0.3572
Epoch 5350/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.044
Epoch 5351/10000; Iter 1/80; Loss: 0.3645
Epoch 5351/10000; Iter 51/80; Loss: 0.3695
Epoch 5351/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5352/10000; Iter 1/80; Loss: 0.4051
Epoch 5352/10000; Iter 51/80; Loss: 0.4259
Epoch 5352/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.042
Epoch 5353/10000; Iter 1/80; Loss: 0.4248
Epoch 5353/10000; Iter 51/80; Loss: 0.3590
Epoch 5353/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.048
Epoch 5354/10000; Iter 1/80; Loss: 0.3553
Epoch 5354/10000; Iter 51/80; Loss: 0.3531
Epoch 5354/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.047
Epoch 5355/10000; Iter 1/80; Loss: 0.3877
Epoch 5355/10000; Iter 51/80; Loss: 0.3839
Epoch 5355/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.048
Epoch 5356/10000; Iter 1/80; Loss: 0.4068
Epoch 5356/10000; Iter 51/80; Loss: 0.4217
Epoch 5356/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.044
Epoch 5357/10000; Iter 1/80; Loss: 0.3522
Epoch 5357/10000; Iter 51/80; Loss: 0.3828
Epoch 5357/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.041
Epoch 5358/10000; Iter 1/80; Loss: 0.4306
Epoch 5358/10000; Iter 51/80; Loss: 0.3319
Epoch 5358/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.043
Epoch 5359/10000; Iter 1/80; Loss: 0.3645
Epoch 5359/10000; Iter 51/80; Loss: 0.4020
Epoch 5359/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.042
Epoch 5360/10000; Iter 1/80; Loss: 0.3228
Epoch 5360/10000; Iter 51/80; Loss: 0.3627
Epoch 5360/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.052
Epoch 5361/10000; Iter 1/80; Loss: 0.4291
Epoch 5361/10000; Iter 51/80; Loss: 0.3593
Epoch 5361/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5362/10000; Iter 1/80; Loss: 0.3502
Epoch 5362/10000; Iter 51/80; Loss: 0.3652
Epoch 5362/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.045
Epoch 5363/10000; Iter 1/80; Loss: 0.3583
Epoch 5363/10000; Iter 51/80; Loss: 0.3773
Epoch 5363/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.041
Epoch 5364/10000; Iter 1/80; Loss: 0.3976
Epoch 5364/10000; Iter 51/80; Loss: 0.4310
Epoch 5364/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.045
Epoch 5365/10000; Iter 1/80; Loss: 0.3953
Epoch 5365/10000; Iter 51/80; Loss: 0.3299
Epoch 5365/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5366/10000; Iter 1/80; Loss: 0.3660
Epoch 5366/10000; Iter 51/80; Loss: 0.3145
Epoch 5366/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5367/10000; Iter 1/80; Loss: 0.3624
Epoch 5367/10000; Iter 51/80; Loss: 0.3334
Epoch 5367/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.048
Epoch 5368/10000; Iter 1/80; Loss: 0.3739
Epoch 5368/10000; Iter 51/80; Loss: 0.3532
Epoch 5368/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.054
Epoch 5369/10000; Iter 1/80; Loss: 0.3298
Epoch 5369/10000; Iter 51/80; Loss: 0.3644
Epoch 5369/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.046
Epoch 5370/10000; Iter 1/80; Loss: 0.4027
Epoch 5370/10000; Iter 51/80; Loss: 0.3774
Epoch 5370/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5371/10000; Iter 1/80; Loss: 0.4033
Epoch 5371/10000; Iter 51/80; Loss: 0.4143
Epoch 5371/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.044
Epoch 5372/10000; Iter 1/80; Loss: 0.3465
Epoch 5372/10000; Iter 51/80; Loss: 0.3798
Epoch 5372/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.049
Epoch 5373/10000; Iter 1/80; Loss: 0.3681
Epoch 5373/10000; Iter 51/80; Loss: 0.3580
Epoch 5373/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.052
Epoch 5374/10000; Iter 1/80; Loss: 0.3635
Epoch 5374/10000; Iter 51/80; Loss: 0.4503
Epoch 5374/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.047
Epoch 5375/10000; Iter 1/80; Loss: 0.3438
Epoch 5375/10000; Iter 51/80; Loss: 0.3501
Epoch 5375/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.046
Epoch 5376/10000; Iter 1/80; Loss: 0.3954
Epoch 5376/10000; Iter 51/80; Loss: 0.4020
Epoch 5376/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.048
Epoch 5377/10000; Iter 1/80; Loss: 0.4108
Epoch 5377/10000; Iter 51/80; Loss: 0.4287
Epoch 5377/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.043
Epoch 5378/10000; Iter 1/80; Loss: 0.3510
Epoch 5378/10000; Iter 51/80; Loss: 0.3468
Epoch 5378/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 5379/10000; Iter 1/80; Loss: 0.3921
Epoch 5379/10000; Iter 51/80; Loss: 0.3001
Epoch 5379/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.049
Epoch 5380/10000; Iter 1/80; Loss: 0.3879
Epoch 5380/10000; Iter 51/80; Loss: 0.3504
Epoch 5380/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5381/10000; Iter 1/80; Loss: 0.3936
Epoch 5381/10000; Iter 51/80; Loss: 0.3716
Epoch 5381/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.048
Epoch 5382/10000; Iter 1/80; Loss: 0.3825
Epoch 5382/10000; Iter 51/80; Loss: 0.5444
Epoch 5382/10000; Iter 80/80; Training Loss: 0.3850, Test Loss: 0.043
Epoch 5383/10000; Iter 1/80; Loss: 0.3779
Epoch 5383/10000; Iter 51/80; Loss: 0.2982
Epoch 5383/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.05
Epoch 5384/10000; Iter 1/80; Loss: 0.3903
Epoch 5384/10000; Iter 51/80; Loss: 0.3849
Epoch 5384/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5385/10000; Iter 1/80; Loss: 0.3707
Epoch 5385/10000; Iter 51/80; Loss: 0.4610
Epoch 5385/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.045
Epoch 5386/10000; Iter 1/80; Loss: 0.4126
Epoch 5386/10000; Iter 51/80; Loss: 0.4515
Epoch 5386/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.044
Epoch 5387/10000; Iter 1/80; Loss: 0.3534
Epoch 5387/10000; Iter 51/80; Loss: 0.3578
Epoch 5387/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5388/10000; Iter 1/80; Loss: 0.3378
Epoch 5388/10000; Iter 51/80; Loss: 0.3591
Epoch 5388/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.046
Epoch 5389/10000; Iter 1/80; Loss: 0.3962
Epoch 5389/10000; Iter 51/80; Loss: 0.3588
Epoch 5389/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.043
Epoch 5390/10000; Iter 1/80; Loss: 0.3798
Epoch 5390/10000; Iter 51/80; Loss: 0.4331
Epoch 5390/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.048
Epoch 5391/10000; Iter 1/80; Loss: 0.4017
Epoch 5391/10000; Iter 51/80; Loss: 0.3513
Epoch 5391/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.05
Epoch 5392/10000; Iter 1/80; Loss: 0.3598
Epoch 5392/10000; Iter 51/80; Loss: 0.3487
Epoch 5392/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.045
Epoch 5393/10000; Iter 1/80; Loss: 0.3667
Epoch 5393/10000; Iter 51/80; Loss: 0.4252
Epoch 5393/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5394/10000; Iter 1/80; Loss: 0.3868
Epoch 5394/10000; Iter 51/80; Loss: 0.4100
Epoch 5394/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.042
Epoch 5395/10000; Iter 1/80; Loss: 0.3937
Epoch 5395/10000; Iter 51/80; Loss: 0.4081
Epoch 5395/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.047
Epoch 5396/10000; Iter 1/80; Loss: 0.4253
Epoch 5396/10000; Iter 51/80; Loss: 0.3611
Epoch 5396/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.045
Epoch 5397/10000; Iter 1/80; Loss: 0.3793
Epoch 5397/10000; Iter 51/80; Loss: 0.3928
Epoch 5397/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.045
Epoch 5398/10000; Iter 1/80; Loss: 0.3814
Epoch 5398/10000; Iter 51/80; Loss: 0.3352
Epoch 5398/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.045
Epoch 5399/10000; Iter 1/80; Loss: 0.3492
Epoch 5399/10000; Iter 51/80; Loss: 0.3875
Epoch 5399/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.05
Epoch 5400/10000; Iter 1/80; Loss: 0.3920
Epoch 5400/10000; Iter 51/80; Loss: 0.3564
Epoch 5400/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5401/10000; Iter 1/80; Loss: 0.4188
Epoch 5401/10000; Iter 51/80; Loss: 0.3690
Epoch 5401/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.047
Model saved
Epoch 5402/10000; Iter 1/80; Loss: 0.3821
Epoch 5402/10000; Iter 51/80; Loss: 0.3622
Epoch 5402/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5403/10000; Iter 1/80; Loss: 0.3852
Epoch 5403/10000; Iter 51/80; Loss: 0.3738
Epoch 5403/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.042
Epoch 5404/10000; Iter 1/80; Loss: 0.3864
Epoch 5404/10000; Iter 51/80; Loss: 0.4168
Epoch 5404/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.045
Epoch 5405/10000; Iter 1/80; Loss: 0.3637
Epoch 5405/10000; Iter 51/80; Loss: 0.4414
Epoch 5405/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.051
Epoch 5406/10000; Iter 1/80; Loss: 0.3683
Epoch 5406/10000; Iter 51/80; Loss: 0.3442
Epoch 5406/10000; Iter 80/80; Training Loss: 0.3830, Test Loss: 0.048
Epoch 5407/10000; Iter 1/80; Loss: 0.3901
Epoch 5407/10000; Iter 51/80; Loss: 0.4580
Epoch 5407/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5408/10000; Iter 1/80; Loss: 0.4213
Epoch 5408/10000; Iter 51/80; Loss: 0.3584
Epoch 5408/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.043
Epoch 5409/10000; Iter 1/80; Loss: 0.3453
Epoch 5409/10000; Iter 51/80; Loss: 0.4049
Epoch 5409/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.046
Epoch 5410/10000; Iter 1/80; Loss: 0.3736
Epoch 5410/10000; Iter 51/80; Loss: 0.3731
Epoch 5410/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5411/10000; Iter 1/80; Loss: 0.3817
Epoch 5411/10000; Iter 51/80; Loss: 0.4402
Epoch 5411/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.046
Epoch 5412/10000; Iter 1/80; Loss: 0.4034
Epoch 5412/10000; Iter 51/80; Loss: 0.3307
Epoch 5412/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.046
Epoch 5413/10000; Iter 1/80; Loss: 0.4832
Epoch 5413/10000; Iter 51/80; Loss: 0.3762
Epoch 5413/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.049
Epoch 5414/10000; Iter 1/80; Loss: 0.2994
Epoch 5414/10000; Iter 51/80; Loss: 0.3872
Epoch 5414/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Epoch 5415/10000; Iter 1/80; Loss: 0.3595
Epoch 5415/10000; Iter 51/80; Loss: 0.4248
Epoch 5415/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.041
Epoch 5416/10000; Iter 1/80; Loss: 0.3363
Epoch 5416/10000; Iter 51/80; Loss: 0.3729
Epoch 5416/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.052
Epoch 5417/10000; Iter 1/80; Loss: 0.4248
Epoch 5417/10000; Iter 51/80; Loss: 0.3884
Epoch 5417/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.044
Epoch 5418/10000; Iter 1/80; Loss: 0.3605
Epoch 5418/10000; Iter 51/80; Loss: 0.4561
Epoch 5418/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5419/10000; Iter 1/80; Loss: 0.3648
Epoch 5419/10000; Iter 51/80; Loss: 0.3992
Epoch 5419/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.047
Epoch 5420/10000; Iter 1/80; Loss: 0.3623
Epoch 5420/10000; Iter 51/80; Loss: 0.3750
Epoch 5420/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.04
Epoch 5421/10000; Iter 1/80; Loss: 0.4394
Epoch 5421/10000; Iter 51/80; Loss: 0.3489
Epoch 5421/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.047
Epoch 5422/10000; Iter 1/80; Loss: 0.3791
Epoch 5422/10000; Iter 51/80; Loss: 0.4172
Epoch 5422/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5423/10000; Iter 1/80; Loss: 0.3455
Epoch 5423/10000; Iter 51/80; Loss: 0.4061
Epoch 5423/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5424/10000; Iter 1/80; Loss: 0.3975
Epoch 5424/10000; Iter 51/80; Loss: 0.3661
Epoch 5424/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.049
Epoch 5425/10000; Iter 1/80; Loss: 0.3743
Epoch 5425/10000; Iter 51/80; Loss: 0.3974
Epoch 5425/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.042
Epoch 5426/10000; Iter 1/80; Loss: 0.3995
Epoch 5426/10000; Iter 51/80; Loss: 0.4022
Epoch 5426/10000; Iter 80/80; Training Loss: 0.3840, Test Loss: 0.05
Epoch 5427/10000; Iter 1/80; Loss: 0.3348
Epoch 5427/10000; Iter 51/80; Loss: 0.4056
Epoch 5427/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.051
Epoch 5428/10000; Iter 1/80; Loss: 0.3806
Epoch 5428/10000; Iter 51/80; Loss: 0.4161
Epoch 5428/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5429/10000; Iter 1/80; Loss: 0.3645
Epoch 5429/10000; Iter 51/80; Loss: 0.3338
Epoch 5429/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5430/10000; Iter 1/80; Loss: 0.3309
Epoch 5430/10000; Iter 51/80; Loss: 0.3547
Epoch 5430/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.043
Epoch 5431/10000; Iter 1/80; Loss: 0.3676
Epoch 5431/10000; Iter 51/80; Loss: 0.3624
Epoch 5431/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.043
Epoch 5432/10000; Iter 1/80; Loss: 0.3720
Epoch 5432/10000; Iter 51/80; Loss: 0.3613
Epoch 5432/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.038
Epoch 5433/10000; Iter 1/80; Loss: 0.3351
Epoch 5433/10000; Iter 51/80; Loss: 0.4089
Epoch 5433/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.046
Epoch 5434/10000; Iter 1/80; Loss: 0.3393
Epoch 5434/10000; Iter 51/80; Loss: 0.3748
Epoch 5434/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5435/10000; Iter 1/80; Loss: 0.3607
Epoch 5435/10000; Iter 51/80; Loss: 0.3604
Epoch 5435/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.044
Epoch 5436/10000; Iter 1/80; Loss: 0.3461
Epoch 5436/10000; Iter 51/80; Loss: 0.3774
Epoch 5436/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.05
Epoch 5437/10000; Iter 1/80; Loss: 0.3882
Epoch 5437/10000; Iter 51/80; Loss: 0.3324
Epoch 5437/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5438/10000; Iter 1/80; Loss: 0.4074
Epoch 5438/10000; Iter 51/80; Loss: 0.4004
Epoch 5438/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.048
Epoch 5439/10000; Iter 1/80; Loss: 0.3592
Epoch 5439/10000; Iter 51/80; Loss: 0.3797
Epoch 5439/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5440/10000; Iter 1/80; Loss: 0.4177
Epoch 5440/10000; Iter 51/80; Loss: 0.4003
Epoch 5440/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.038
Epoch 5441/10000; Iter 1/80; Loss: 0.4131
Epoch 5441/10000; Iter 51/80; Loss: 0.4122
Epoch 5441/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.048
Epoch 5442/10000; Iter 1/80; Loss: 0.3823
Epoch 5442/10000; Iter 51/80; Loss: 0.4192
Epoch 5442/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.051
Epoch 5443/10000; Iter 1/80; Loss: 0.4080
Epoch 5443/10000; Iter 51/80; Loss: 0.3926
Epoch 5443/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.046
Epoch 5444/10000; Iter 1/80; Loss: 0.3290
Epoch 5444/10000; Iter 51/80; Loss: 0.3797
Epoch 5444/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.05
Epoch 5445/10000; Iter 1/80; Loss: 0.3704
Epoch 5445/10000; Iter 51/80; Loss: 0.3570
Epoch 5445/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.048
Epoch 5446/10000; Iter 1/80; Loss: 0.3537
Epoch 5446/10000; Iter 51/80; Loss: 0.4170
Epoch 5446/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.047
Epoch 5447/10000; Iter 1/80; Loss: 0.4264
Epoch 5447/10000; Iter 51/80; Loss: 0.3735
Epoch 5447/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.05
Epoch 5448/10000; Iter 1/80; Loss: 0.4467
Epoch 5448/10000; Iter 51/80; Loss: 0.3296
Epoch 5448/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.043
Epoch 5449/10000; Iter 1/80; Loss: 0.3010
Epoch 5449/10000; Iter 51/80; Loss: 0.3902
Epoch 5449/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.043
Epoch 5450/10000; Iter 1/80; Loss: 0.3164
Epoch 5450/10000; Iter 51/80; Loss: 0.3515
Epoch 5450/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5451/10000; Iter 1/80; Loss: 0.3472
Epoch 5451/10000; Iter 51/80; Loss: 0.3914
Epoch 5451/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.045
Epoch 5452/10000; Iter 1/80; Loss: 0.3381
Epoch 5452/10000; Iter 51/80; Loss: 0.3348
Epoch 5452/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.052
Epoch 5453/10000; Iter 1/80; Loss: 0.4135
Epoch 5453/10000; Iter 51/80; Loss: 0.3283
Epoch 5453/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.052
Epoch 5454/10000; Iter 1/80; Loss: 0.4019
Epoch 5454/10000; Iter 51/80; Loss: 0.3187
Epoch 5454/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.054
Epoch 5455/10000; Iter 1/80; Loss: 0.3472
Epoch 5455/10000; Iter 51/80; Loss: 0.3390
Epoch 5455/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Epoch 5456/10000; Iter 1/80; Loss: 0.3622
Epoch 5456/10000; Iter 51/80; Loss: 0.3574
Epoch 5456/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.048
Epoch 5457/10000; Iter 1/80; Loss: 0.3549
Epoch 5457/10000; Iter 51/80; Loss: 0.4048
Epoch 5457/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5458/10000; Iter 1/80; Loss: 0.3576
Epoch 5458/10000; Iter 51/80; Loss: 0.3317
Epoch 5458/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.044
Epoch 5459/10000; Iter 1/80; Loss: 0.4026
Epoch 5459/10000; Iter 51/80; Loss: 0.3747
Epoch 5459/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.051
Epoch 5460/10000; Iter 1/80; Loss: 0.3944
Epoch 5460/10000; Iter 51/80; Loss: 0.4432
Epoch 5460/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.048
Epoch 5461/10000; Iter 1/80; Loss: 0.3659
Epoch 5461/10000; Iter 51/80; Loss: 0.3198
Epoch 5461/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.048
Epoch 5462/10000; Iter 1/80; Loss: 0.3343
Epoch 5462/10000; Iter 51/80; Loss: 0.3517
Epoch 5462/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.053
Epoch 5463/10000; Iter 1/80; Loss: 0.3479
Epoch 5463/10000; Iter 51/80; Loss: 0.4339
Epoch 5463/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.047
Epoch 5464/10000; Iter 1/80; Loss: 0.3924
Epoch 5464/10000; Iter 51/80; Loss: 0.3914
Epoch 5464/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.046
Epoch 5465/10000; Iter 1/80; Loss: 0.3934
Epoch 5465/10000; Iter 51/80; Loss: 0.4068
Epoch 5465/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.048
Epoch 5466/10000; Iter 1/80; Loss: 0.3546
Epoch 5466/10000; Iter 51/80; Loss: 0.4535
Epoch 5466/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5467/10000; Iter 1/80; Loss: 0.2958
Epoch 5467/10000; Iter 51/80; Loss: 0.4033
Epoch 5467/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.052
Epoch 5468/10000; Iter 1/80; Loss: 0.4065
Epoch 5468/10000; Iter 51/80; Loss: 0.4233
Epoch 5468/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5469/10000; Iter 1/80; Loss: 0.3586
Epoch 5469/10000; Iter 51/80; Loss: 0.3637
Epoch 5469/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.049
Epoch 5470/10000; Iter 1/80; Loss: 0.3824
Epoch 5470/10000; Iter 51/80; Loss: 0.3806
Epoch 5470/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.052
Epoch 5471/10000; Iter 1/80; Loss: 0.3968
Epoch 5471/10000; Iter 51/80; Loss: 0.3513
Epoch 5471/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.04
Epoch 5472/10000; Iter 1/80; Loss: 0.4130
Epoch 5472/10000; Iter 51/80; Loss: 0.3717
Epoch 5472/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.047
Epoch 5473/10000; Iter 1/80; Loss: 0.4499
Epoch 5473/10000; Iter 51/80; Loss: 0.3894
Epoch 5473/10000; Iter 80/80; Training Loss: 0.3810, Test Loss: 0.049
Epoch 5474/10000; Iter 1/80; Loss: 0.3868
Epoch 5474/10000; Iter 51/80; Loss: 0.3643
Epoch 5474/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.052
Epoch 5475/10000; Iter 1/80; Loss: 0.4194
Epoch 5475/10000; Iter 51/80; Loss: 0.3067
Epoch 5475/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.044
Epoch 5476/10000; Iter 1/80; Loss: 0.3478
Epoch 5476/10000; Iter 51/80; Loss: 0.3509
Epoch 5476/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.054
Epoch 5477/10000; Iter 1/80; Loss: 0.3472
Epoch 5477/10000; Iter 51/80; Loss: 0.3742
Epoch 5477/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Epoch 5478/10000; Iter 1/80; Loss: 0.3777
Epoch 5478/10000; Iter 51/80; Loss: 0.3565
Epoch 5478/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.041
Epoch 5479/10000; Iter 1/80; Loss: 0.3797
Epoch 5479/10000; Iter 51/80; Loss: 0.3500
Epoch 5479/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.04
Epoch 5480/10000; Iter 1/80; Loss: 0.3966
Epoch 5480/10000; Iter 51/80; Loss: 0.3857
Epoch 5480/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.05
Epoch 5481/10000; Iter 1/80; Loss: 0.3669
Epoch 5481/10000; Iter 51/80; Loss: 0.3828
Epoch 5481/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.051
Epoch 5482/10000; Iter 1/80; Loss: 0.3491
Epoch 5482/10000; Iter 51/80; Loss: 0.3783
Epoch 5482/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5483/10000; Iter 1/80; Loss: 0.3631
Epoch 5483/10000; Iter 51/80; Loss: 0.3446
Epoch 5483/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.047
Epoch 5484/10000; Iter 1/80; Loss: 0.3676
Epoch 5484/10000; Iter 51/80; Loss: 0.4343
Epoch 5484/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.042
Epoch 5485/10000; Iter 1/80; Loss: 0.4309
Epoch 5485/10000; Iter 51/80; Loss: 0.3797
Epoch 5485/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.048
Epoch 5486/10000; Iter 1/80; Loss: 0.3594
Epoch 5486/10000; Iter 51/80; Loss: 0.3552
Epoch 5486/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.043
Epoch 5487/10000; Iter 1/80; Loss: 0.3362
Epoch 5487/10000; Iter 51/80; Loss: 0.3998
Epoch 5487/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5488/10000; Iter 1/80; Loss: 0.2885
Epoch 5488/10000; Iter 51/80; Loss: 0.4178
Epoch 5488/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.043
Epoch 5489/10000; Iter 1/80; Loss: 0.3311
Epoch 5489/10000; Iter 51/80; Loss: 0.3591
Epoch 5489/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.048
Epoch 5490/10000; Iter 1/80; Loss: 0.3272
Epoch 5490/10000; Iter 51/80; Loss: 0.3722
Epoch 5490/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.049
Epoch 5491/10000; Iter 1/80; Loss: 0.4042
Epoch 5491/10000; Iter 51/80; Loss: 0.4249
Epoch 5491/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.05
Epoch 5492/10000; Iter 1/80; Loss: 0.3564
Epoch 5492/10000; Iter 51/80; Loss: 0.3952
Epoch 5492/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5493/10000; Iter 1/80; Loss: 0.3402
Epoch 5493/10000; Iter 51/80; Loss: 0.3282
Epoch 5493/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.048
Epoch 5494/10000; Iter 1/80; Loss: 0.4207
Epoch 5494/10000; Iter 51/80; Loss: 0.3764
Epoch 5494/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.046
Epoch 5495/10000; Iter 1/80; Loss: 0.3977
Epoch 5495/10000; Iter 51/80; Loss: 0.3559
Epoch 5495/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.053
Epoch 5496/10000; Iter 1/80; Loss: 0.4060
Epoch 5496/10000; Iter 51/80; Loss: 0.3546
Epoch 5496/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.042
Epoch 5497/10000; Iter 1/80; Loss: 0.3161
Epoch 5497/10000; Iter 51/80; Loss: 0.3762
Epoch 5497/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5498/10000; Iter 1/80; Loss: 0.3329
Epoch 5498/10000; Iter 51/80; Loss: 0.3672
Epoch 5498/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5499/10000; Iter 1/80; Loss: 0.3248
Epoch 5499/10000; Iter 51/80; Loss: 0.3904
Epoch 5499/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5500/10000; Iter 1/80; Loss: 0.3203
Epoch 5500/10000; Iter 51/80; Loss: 0.4124
Epoch 5500/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.045
Epoch 5501/10000; Iter 1/80; Loss: 0.3940
Epoch 5501/10000; Iter 51/80; Loss: 0.3712
Epoch 5501/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Model saved
Epoch 5502/10000; Iter 1/80; Loss: 0.3639
Epoch 5502/10000; Iter 51/80; Loss: 0.4114
Epoch 5502/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.048
Epoch 5503/10000; Iter 1/80; Loss: 0.3109
Epoch 5503/10000; Iter 51/80; Loss: 0.3959
Epoch 5503/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.04
Epoch 5504/10000; Iter 1/80; Loss: 0.3784
Epoch 5504/10000; Iter 51/80; Loss: 0.3600
Epoch 5504/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5505/10000; Iter 1/80; Loss: 0.4093
Epoch 5505/10000; Iter 51/80; Loss: 0.3755
Epoch 5505/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.048
Epoch 5506/10000; Iter 1/80; Loss: 0.3387
Epoch 5506/10000; Iter 51/80; Loss: 0.3299
Epoch 5506/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.053
Epoch 5507/10000; Iter 1/80; Loss: 0.4170
Epoch 5507/10000; Iter 51/80; Loss: 0.3810
Epoch 5507/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.054
Epoch 5508/10000; Iter 1/80; Loss: 0.3944
Epoch 5508/10000; Iter 51/80; Loss: 0.3942
Epoch 5508/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.051
Epoch 5509/10000; Iter 1/80; Loss: 0.4015
Epoch 5509/10000; Iter 51/80; Loss: 0.3977
Epoch 5509/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.046
Epoch 5510/10000; Iter 1/80; Loss: 0.4004
Epoch 5510/10000; Iter 51/80; Loss: 0.3418
Epoch 5510/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.039
Epoch 5511/10000; Iter 1/80; Loss: 0.3889
Epoch 5511/10000; Iter 51/80; Loss: 0.3780
Epoch 5511/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.053
Epoch 5512/10000; Iter 1/80; Loss: 0.3772
Epoch 5512/10000; Iter 51/80; Loss: 0.3759
Epoch 5512/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5513/10000; Iter 1/80; Loss: 0.3569
Epoch 5513/10000; Iter 51/80; Loss: 0.3767
Epoch 5513/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.049
Epoch 5514/10000; Iter 1/80; Loss: 0.4301
Epoch 5514/10000; Iter 51/80; Loss: 0.3934
Epoch 5514/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.053
Epoch 5515/10000; Iter 1/80; Loss: 0.3557
Epoch 5515/10000; Iter 51/80; Loss: 0.2948
Epoch 5515/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.044
Epoch 5516/10000; Iter 1/80; Loss: 0.3327
Epoch 5516/10000; Iter 51/80; Loss: 0.3359
Epoch 5516/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.047
Epoch 5517/10000; Iter 1/80; Loss: 0.3783
Epoch 5517/10000; Iter 51/80; Loss: 0.3977
Epoch 5517/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5518/10000; Iter 1/80; Loss: 0.3613
Epoch 5518/10000; Iter 51/80; Loss: 0.3546
Epoch 5518/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5519/10000; Iter 1/80; Loss: 0.3547
Epoch 5519/10000; Iter 51/80; Loss: 0.3813
Epoch 5519/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.05
Epoch 5520/10000; Iter 1/80; Loss: 0.3245
Epoch 5520/10000; Iter 51/80; Loss: 0.3794
Epoch 5520/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.056
Epoch 5521/10000; Iter 1/80; Loss: 0.3729
Epoch 5521/10000; Iter 51/80; Loss: 0.4047
Epoch 5521/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.05
Epoch 5522/10000; Iter 1/80; Loss: 0.3624
Epoch 5522/10000; Iter 51/80; Loss: 0.4143
Epoch 5522/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5523/10000; Iter 1/80; Loss: 0.4035
Epoch 5523/10000; Iter 51/80; Loss: 0.3901
Epoch 5523/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.049
Epoch 5524/10000; Iter 1/80; Loss: 0.3623
Epoch 5524/10000; Iter 51/80; Loss: 0.4175
Epoch 5524/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.048
Epoch 5525/10000; Iter 1/80; Loss: 0.3871
Epoch 5525/10000; Iter 51/80; Loss: 0.4268
Epoch 5525/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5526/10000; Iter 1/80; Loss: 0.3795
Epoch 5526/10000; Iter 51/80; Loss: 0.3299
Epoch 5526/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.054
Epoch 5527/10000; Iter 1/80; Loss: 0.3599
Epoch 5527/10000; Iter 51/80; Loss: 0.3682
Epoch 5527/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5528/10000; Iter 1/80; Loss: 0.3343
Epoch 5528/10000; Iter 51/80; Loss: 0.3696
Epoch 5528/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.048
Epoch 5529/10000; Iter 1/80; Loss: 0.3975
Epoch 5529/10000; Iter 51/80; Loss: 0.3873
Epoch 5529/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.048
Epoch 5530/10000; Iter 1/80; Loss: 0.4383
Epoch 5530/10000; Iter 51/80; Loss: 0.4304
Epoch 5530/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.05
Epoch 5531/10000; Iter 1/80; Loss: 0.3065
Epoch 5531/10000; Iter 51/80; Loss: 0.3377
Epoch 5531/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.046
Epoch 5532/10000; Iter 1/80; Loss: 0.3445
Epoch 5532/10000; Iter 51/80; Loss: 0.3872
Epoch 5532/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.043
Epoch 5533/10000; Iter 1/80; Loss: 0.3635
Epoch 5533/10000; Iter 51/80; Loss: 0.3891
Epoch 5533/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5534/10000; Iter 1/80; Loss: 0.3990
Epoch 5534/10000; Iter 51/80; Loss: 0.4400
Epoch 5534/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.045
Epoch 5535/10000; Iter 1/80; Loss: 0.3538
Epoch 5535/10000; Iter 51/80; Loss: 0.3451
Epoch 5535/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.045
Epoch 5536/10000; Iter 1/80; Loss: 0.3046
Epoch 5536/10000; Iter 51/80; Loss: 0.4011
Epoch 5536/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5537/10000; Iter 1/80; Loss: 0.3495
Epoch 5537/10000; Iter 51/80; Loss: 0.3724
Epoch 5537/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.049
Epoch 5538/10000; Iter 1/80; Loss: 0.4050
Epoch 5538/10000; Iter 51/80; Loss: 0.3370
Epoch 5538/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.052
Epoch 5539/10000; Iter 1/80; Loss: 0.3422
Epoch 5539/10000; Iter 51/80; Loss: 0.4236
Epoch 5539/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5540/10000; Iter 1/80; Loss: 0.3284
Epoch 5540/10000; Iter 51/80; Loss: 0.3595
Epoch 5540/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.048
Epoch 5541/10000; Iter 1/80; Loss: 0.3539
Epoch 5541/10000; Iter 51/80; Loss: 0.3695
Epoch 5541/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.049
Epoch 5542/10000; Iter 1/80; Loss: 0.3473
Epoch 5542/10000; Iter 51/80; Loss: 0.4192
Epoch 5542/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.046
Epoch 5543/10000; Iter 1/80; Loss: 0.3525
Epoch 5543/10000; Iter 51/80; Loss: 0.3324
Epoch 5543/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.043
Epoch 5544/10000; Iter 1/80; Loss: 0.3508
Epoch 5544/10000; Iter 51/80; Loss: 0.3963
Epoch 5544/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.044
Epoch 5545/10000; Iter 1/80; Loss: 0.3667
Epoch 5545/10000; Iter 51/80; Loss: 0.3629
Epoch 5545/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.05
Epoch 5546/10000; Iter 1/80; Loss: 0.4097
Epoch 5546/10000; Iter 51/80; Loss: 0.3448
Epoch 5546/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Epoch 5547/10000; Iter 1/80; Loss: 0.3686
Epoch 5547/10000; Iter 51/80; Loss: 0.3620
Epoch 5547/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5548/10000; Iter 1/80; Loss: 0.3661
Epoch 5548/10000; Iter 51/80; Loss: 0.3762
Epoch 5548/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.043
Epoch 5549/10000; Iter 1/80; Loss: 0.3352
Epoch 5549/10000; Iter 51/80; Loss: 0.3357
Epoch 5549/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.047
Epoch 5550/10000; Iter 1/80; Loss: 0.3473
Epoch 5550/10000; Iter 51/80; Loss: 0.3564
Epoch 5550/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.048
Epoch 5551/10000; Iter 1/80; Loss: 0.3942
Epoch 5551/10000; Iter 51/80; Loss: 0.3721
Epoch 5551/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.047
Epoch 5552/10000; Iter 1/80; Loss: 0.4326
Epoch 5552/10000; Iter 51/80; Loss: 0.3505
Epoch 5552/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.044
Epoch 5553/10000; Iter 1/80; Loss: 0.3864
Epoch 5553/10000; Iter 51/80; Loss: 0.3537
Epoch 5553/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.045
Epoch 5554/10000; Iter 1/80; Loss: 0.3540
Epoch 5554/10000; Iter 51/80; Loss: 0.4280
Epoch 5554/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5555/10000; Iter 1/80; Loss: 0.3563
Epoch 5555/10000; Iter 51/80; Loss: 0.3845
Epoch 5555/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.049
Epoch 5556/10000; Iter 1/80; Loss: 0.3510
Epoch 5556/10000; Iter 51/80; Loss: 0.3446
Epoch 5556/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Epoch 5557/10000; Iter 1/80; Loss: 0.3897
Epoch 5557/10000; Iter 51/80; Loss: 0.3295
Epoch 5557/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.054
Epoch 5558/10000; Iter 1/80; Loss: 0.3541
Epoch 5558/10000; Iter 51/80; Loss: 0.3513
Epoch 5558/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5559/10000; Iter 1/80; Loss: 0.3789
Epoch 5559/10000; Iter 51/80; Loss: 0.3929
Epoch 5559/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.044
Epoch 5560/10000; Iter 1/80; Loss: 0.4206
Epoch 5560/10000; Iter 51/80; Loss: 0.4182
Epoch 5560/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Epoch 5561/10000; Iter 1/80; Loss: 0.3906
Epoch 5561/10000; Iter 51/80; Loss: 0.4052
Epoch 5561/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Epoch 5562/10000; Iter 1/80; Loss: 0.4192
Epoch 5562/10000; Iter 51/80; Loss: 0.4255
Epoch 5562/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.044
Epoch 5563/10000; Iter 1/80; Loss: 0.3625
Epoch 5563/10000; Iter 51/80; Loss: 0.3502
Epoch 5563/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.042
Epoch 5564/10000; Iter 1/80; Loss: 0.4308
Epoch 5564/10000; Iter 51/80; Loss: 0.3280
Epoch 5564/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.051
Epoch 5565/10000; Iter 1/80; Loss: 0.3453
Epoch 5565/10000; Iter 51/80; Loss: 0.4361
Epoch 5565/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.052
Epoch 5566/10000; Iter 1/80; Loss: 0.3752
Epoch 5566/10000; Iter 51/80; Loss: 0.3869
Epoch 5566/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5567/10000; Iter 1/80; Loss: 0.3978
Epoch 5567/10000; Iter 51/80; Loss: 0.3309
Epoch 5567/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5568/10000; Iter 1/80; Loss: 0.3920
Epoch 5568/10000; Iter 51/80; Loss: 0.3537
Epoch 5568/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.053
Epoch 5569/10000; Iter 1/80; Loss: 0.3651
Epoch 5569/10000; Iter 51/80; Loss: 0.3750
Epoch 5569/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.049
Epoch 5570/10000; Iter 1/80; Loss: 0.3879
Epoch 5570/10000; Iter 51/80; Loss: 0.3768
Epoch 5570/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.045
Epoch 5571/10000; Iter 1/80; Loss: 0.3742
Epoch 5571/10000; Iter 51/80; Loss: 0.3507
Epoch 5571/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.049
Epoch 5572/10000; Iter 1/80; Loss: 0.4370
Epoch 5572/10000; Iter 51/80; Loss: 0.3923
Epoch 5572/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.055
Epoch 5573/10000; Iter 1/80; Loss: 0.4395
Epoch 5573/10000; Iter 51/80; Loss: 0.4023
Epoch 5573/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.045
Epoch 5574/10000; Iter 1/80; Loss: 0.3849
Epoch 5574/10000; Iter 51/80; Loss: 0.3671
Epoch 5574/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Epoch 5575/10000; Iter 1/80; Loss: 0.3571
Epoch 5575/10000; Iter 51/80; Loss: 0.3384
Epoch 5575/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.045
Epoch 5576/10000; Iter 1/80; Loss: 0.4046
Epoch 5576/10000; Iter 51/80; Loss: 0.3889
Epoch 5576/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5577/10000; Iter 1/80; Loss: 0.3993
Epoch 5577/10000; Iter 51/80; Loss: 0.3410
Epoch 5577/10000; Iter 80/80; Training Loss: 0.3780, Test Loss: 0.05
Epoch 5578/10000; Iter 1/80; Loss: 0.3703
Epoch 5578/10000; Iter 51/80; Loss: 0.3619
Epoch 5578/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.046
Epoch 5579/10000; Iter 1/80; Loss: 0.2871
Epoch 5579/10000; Iter 51/80; Loss: 0.3551
Epoch 5579/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5580/10000; Iter 1/80; Loss: 0.3640
Epoch 5580/10000; Iter 51/80; Loss: 0.3868
Epoch 5580/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5581/10000; Iter 1/80; Loss: 0.3598
Epoch 5581/10000; Iter 51/80; Loss: 0.3513
Epoch 5581/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.049
Epoch 5582/10000; Iter 1/80; Loss: 0.4194
Epoch 5582/10000; Iter 51/80; Loss: 0.3540
Epoch 5582/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.046
Epoch 5583/10000; Iter 1/80; Loss: 0.3282
Epoch 5583/10000; Iter 51/80; Loss: 0.3957
Epoch 5583/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.05
Epoch 5584/10000; Iter 1/80; Loss: 0.3774
Epoch 5584/10000; Iter 51/80; Loss: 0.3186
Epoch 5584/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.048
Epoch 5585/10000; Iter 1/80; Loss: 0.3710
Epoch 5585/10000; Iter 51/80; Loss: 0.3656
Epoch 5585/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.046
Epoch 5586/10000; Iter 1/80; Loss: 0.3931
Epoch 5586/10000; Iter 51/80; Loss: 0.3695
Epoch 5586/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.049
Epoch 5587/10000; Iter 1/80; Loss: 0.3611
Epoch 5587/10000; Iter 51/80; Loss: 0.3728
Epoch 5587/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.042
Epoch 5588/10000; Iter 1/80; Loss: 0.3661
Epoch 5588/10000; Iter 51/80; Loss: 0.3207
Epoch 5588/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.05
Epoch 5589/10000; Iter 1/80; Loss: 0.3858
Epoch 5589/10000; Iter 51/80; Loss: 0.3681
Epoch 5589/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5590/10000; Iter 1/80; Loss: 0.3676
Epoch 5590/10000; Iter 51/80; Loss: 0.3952
Epoch 5590/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.046
Epoch 5591/10000; Iter 1/80; Loss: 0.3360
Epoch 5591/10000; Iter 51/80; Loss: 0.3513
Epoch 5591/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.046
Epoch 5592/10000; Iter 1/80; Loss: 0.3632
Epoch 5592/10000; Iter 51/80; Loss: 0.4045
Epoch 5592/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.053
Epoch 5593/10000; Iter 1/80; Loss: 0.3944
Epoch 5593/10000; Iter 51/80; Loss: 0.3283
Epoch 5593/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.055
Epoch 5594/10000; Iter 1/80; Loss: 0.3610
Epoch 5594/10000; Iter 51/80; Loss: 0.3576
Epoch 5594/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5595/10000; Iter 1/80; Loss: 0.3473
Epoch 5595/10000; Iter 51/80; Loss: 0.3671
Epoch 5595/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.046
Epoch 5596/10000; Iter 1/80; Loss: 0.4019
Epoch 5596/10000; Iter 51/80; Loss: 0.3762
Epoch 5596/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5597/10000; Iter 1/80; Loss: 0.3958
Epoch 5597/10000; Iter 51/80; Loss: 0.3284
Epoch 5597/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.044
Epoch 5598/10000; Iter 1/80; Loss: 0.3271
Epoch 5598/10000; Iter 51/80; Loss: 0.4027
Epoch 5598/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.048
Epoch 5599/10000; Iter 1/80; Loss: 0.3009
Epoch 5599/10000; Iter 51/80; Loss: 0.3080
Epoch 5599/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.045
Epoch 5600/10000; Iter 1/80; Loss: 0.3598
Epoch 5600/10000; Iter 51/80; Loss: 0.3588
Epoch 5600/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.046
Epoch 5601/10000; Iter 1/80; Loss: 0.3825
Epoch 5601/10000; Iter 51/80; Loss: 0.3313
Epoch 5601/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.047
Model saved
Epoch 5602/10000; Iter 1/80; Loss: 0.2760
Epoch 5602/10000; Iter 51/80; Loss: 0.4026
Epoch 5602/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.045
Epoch 5603/10000; Iter 1/80; Loss: 0.3767
Epoch 5603/10000; Iter 51/80; Loss: 0.3431
Epoch 5603/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.05
Epoch 5604/10000; Iter 1/80; Loss: 0.4545
Epoch 5604/10000; Iter 51/80; Loss: 0.3824
Epoch 5604/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.045
Epoch 5605/10000; Iter 1/80; Loss: 0.3781
Epoch 5605/10000; Iter 51/80; Loss: 0.3272
Epoch 5605/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.046
Epoch 5606/10000; Iter 1/80; Loss: 0.3839
Epoch 5606/10000; Iter 51/80; Loss: 0.3493
Epoch 5606/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.048
Epoch 5607/10000; Iter 1/80; Loss: 0.3909
Epoch 5607/10000; Iter 51/80; Loss: 0.3504
Epoch 5607/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.046
Epoch 5608/10000; Iter 1/80; Loss: 0.3701
Epoch 5608/10000; Iter 51/80; Loss: 0.4369
Epoch 5608/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.055
Epoch 5609/10000; Iter 1/80; Loss: 0.3370
Epoch 5609/10000; Iter 51/80; Loss: 0.3493
Epoch 5609/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.045
Epoch 5610/10000; Iter 1/80; Loss: 0.3072
Epoch 5610/10000; Iter 51/80; Loss: 0.3739
Epoch 5610/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.046
Epoch 5611/10000; Iter 1/80; Loss: 0.4014
Epoch 5611/10000; Iter 51/80; Loss: 0.3503
Epoch 5611/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.042
Epoch 5612/10000; Iter 1/80; Loss: 0.4184
Epoch 5612/10000; Iter 51/80; Loss: 0.3871
Epoch 5612/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5613/10000; Iter 1/80; Loss: 0.3692
Epoch 5613/10000; Iter 51/80; Loss: 0.3516
Epoch 5613/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.051
Epoch 5614/10000; Iter 1/80; Loss: 0.3833
Epoch 5614/10000; Iter 51/80; Loss: 0.2684
Epoch 5614/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5615/10000; Iter 1/80; Loss: 0.4511
Epoch 5615/10000; Iter 51/80; Loss: 0.3272
Epoch 5615/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.048
Epoch 5616/10000; Iter 1/80; Loss: 0.3329
Epoch 5616/10000; Iter 51/80; Loss: 0.3275
Epoch 5616/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.054
Epoch 5617/10000; Iter 1/80; Loss: 0.3923
Epoch 5617/10000; Iter 51/80; Loss: 0.3804
Epoch 5617/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.049
Epoch 5618/10000; Iter 1/80; Loss: 0.3910
Epoch 5618/10000; Iter 51/80; Loss: 0.3597
Epoch 5618/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.051
Epoch 5619/10000; Iter 1/80; Loss: 0.3982
Epoch 5619/10000; Iter 51/80; Loss: 0.3585
Epoch 5619/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5620/10000; Iter 1/80; Loss: 0.3170
Epoch 5620/10000; Iter 51/80; Loss: 0.3583
Epoch 5620/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.055
Epoch 5621/10000; Iter 1/80; Loss: 0.4314
Epoch 5621/10000; Iter 51/80; Loss: 0.3477
Epoch 5621/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.051
Epoch 5622/10000; Iter 1/80; Loss: 0.3890
Epoch 5622/10000; Iter 51/80; Loss: 0.3257
Epoch 5622/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.049
Epoch 5623/10000; Iter 1/80; Loss: 0.3409
Epoch 5623/10000; Iter 51/80; Loss: 0.3221
Epoch 5623/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5624/10000; Iter 1/80; Loss: 0.3880
Epoch 5624/10000; Iter 51/80; Loss: 0.4489
Epoch 5624/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.045
Epoch 5625/10000; Iter 1/80; Loss: 0.3648
Epoch 5625/10000; Iter 51/80; Loss: 0.3576
Epoch 5625/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.045
Epoch 5626/10000; Iter 1/80; Loss: 0.3470
Epoch 5626/10000; Iter 51/80; Loss: 0.4140
Epoch 5626/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5627/10000; Iter 1/80; Loss: 0.4011
Epoch 5627/10000; Iter 51/80; Loss: 0.4162
Epoch 5627/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.055
Epoch 5628/10000; Iter 1/80; Loss: 0.3653
Epoch 5628/10000; Iter 51/80; Loss: 0.4051
Epoch 5628/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.055
Epoch 5629/10000; Iter 1/80; Loss: 0.3552
Epoch 5629/10000; Iter 51/80; Loss: 0.4295
Epoch 5629/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.052
Epoch 5630/10000; Iter 1/80; Loss: 0.3313
Epoch 5630/10000; Iter 51/80; Loss: 0.3551
Epoch 5630/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.041
Epoch 5631/10000; Iter 1/80; Loss: 0.4126
Epoch 5631/10000; Iter 51/80; Loss: 0.3728
Epoch 5631/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.045
Epoch 5632/10000; Iter 1/80; Loss: 0.3356
Epoch 5632/10000; Iter 51/80; Loss: 0.4048
Epoch 5632/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5633/10000; Iter 1/80; Loss: 0.3671
Epoch 5633/10000; Iter 51/80; Loss: 0.4222
Epoch 5633/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5634/10000; Iter 1/80; Loss: 0.3311
Epoch 5634/10000; Iter 51/80; Loss: 0.3366
Epoch 5634/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.044
Epoch 5635/10000; Iter 1/80; Loss: 0.3901
Epoch 5635/10000; Iter 51/80; Loss: 0.4142
Epoch 5635/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5636/10000; Iter 1/80; Loss: 0.3465
Epoch 5636/10000; Iter 51/80; Loss: 0.3540
Epoch 5636/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.053
Epoch 5637/10000; Iter 1/80; Loss: 0.3432
Epoch 5637/10000; Iter 51/80; Loss: 0.3583
Epoch 5637/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.049
Epoch 5638/10000; Iter 1/80; Loss: 0.3585
Epoch 5638/10000; Iter 51/80; Loss: 0.3738
Epoch 5638/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.049
Epoch 5639/10000; Iter 1/80; Loss: 0.4157
Epoch 5639/10000; Iter 51/80; Loss: 0.3357
Epoch 5639/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.05
Epoch 5640/10000; Iter 1/80; Loss: 0.4893
Epoch 5640/10000; Iter 51/80; Loss: 0.3424
Epoch 5640/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.046
Epoch 5641/10000; Iter 1/80; Loss: 0.3724
Epoch 5641/10000; Iter 51/80; Loss: 0.3909
Epoch 5641/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.049
Epoch 5642/10000; Iter 1/80; Loss: 0.3647
Epoch 5642/10000; Iter 51/80; Loss: 0.3094
Epoch 5642/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.053
Epoch 5643/10000; Iter 1/80; Loss: 0.3316
Epoch 5643/10000; Iter 51/80; Loss: 0.3865
Epoch 5643/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5644/10000; Iter 1/80; Loss: 0.4520
Epoch 5644/10000; Iter 51/80; Loss: 0.3785
Epoch 5644/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.052
Epoch 5645/10000; Iter 1/80; Loss: 0.3706
Epoch 5645/10000; Iter 51/80; Loss: 0.3944
Epoch 5645/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5646/10000; Iter 1/80; Loss: 0.3287
Epoch 5646/10000; Iter 51/80; Loss: 0.3860
Epoch 5646/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.044
Epoch 5647/10000; Iter 1/80; Loss: 0.4039
Epoch 5647/10000; Iter 51/80; Loss: 0.3964
Epoch 5647/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.048
Epoch 5648/10000; Iter 1/80; Loss: 0.3571
Epoch 5648/10000; Iter 51/80; Loss: 0.3156
Epoch 5648/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5649/10000; Iter 1/80; Loss: 0.3738
Epoch 5649/10000; Iter 51/80; Loss: 0.4251
Epoch 5649/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5650/10000; Iter 1/80; Loss: 0.3734
Epoch 5650/10000; Iter 51/80; Loss: 0.3529
Epoch 5650/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.048
Epoch 5651/10000; Iter 1/80; Loss: 0.3884
Epoch 5651/10000; Iter 51/80; Loss: 0.3459
Epoch 5651/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5652/10000; Iter 1/80; Loss: 0.3142
Epoch 5652/10000; Iter 51/80; Loss: 0.3929
Epoch 5652/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.047
Epoch 5653/10000; Iter 1/80; Loss: 0.3801
Epoch 5653/10000; Iter 51/80; Loss: 0.3798
Epoch 5653/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.048
Epoch 5654/10000; Iter 1/80; Loss: 0.3768
Epoch 5654/10000; Iter 51/80; Loss: 0.3165
Epoch 5654/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5655/10000; Iter 1/80; Loss: 0.4049
Epoch 5655/10000; Iter 51/80; Loss: 0.3435
Epoch 5655/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5656/10000; Iter 1/80; Loss: 0.3535
Epoch 5656/10000; Iter 51/80; Loss: 0.3979
Epoch 5656/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5657/10000; Iter 1/80; Loss: 0.3374
Epoch 5657/10000; Iter 51/80; Loss: 0.3746
Epoch 5657/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.053
Epoch 5658/10000; Iter 1/80; Loss: 0.3474
Epoch 5658/10000; Iter 51/80; Loss: 0.3488
Epoch 5658/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5659/10000; Iter 1/80; Loss: 0.4260
Epoch 5659/10000; Iter 51/80; Loss: 0.3408
Epoch 5659/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.054
Epoch 5660/10000; Iter 1/80; Loss: 0.3798
Epoch 5660/10000; Iter 51/80; Loss: 0.3902
Epoch 5660/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5661/10000; Iter 1/80; Loss: 0.3997
Epoch 5661/10000; Iter 51/80; Loss: 0.3258
Epoch 5661/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5662/10000; Iter 1/80; Loss: 0.3520
Epoch 5662/10000; Iter 51/80; Loss: 0.3677
Epoch 5662/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.047
Epoch 5663/10000; Iter 1/80; Loss: 0.3684
Epoch 5663/10000; Iter 51/80; Loss: 0.3729
Epoch 5663/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.048
Epoch 5664/10000; Iter 1/80; Loss: 0.3829
Epoch 5664/10000; Iter 51/80; Loss: 0.3703
Epoch 5664/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.054
Epoch 5665/10000; Iter 1/80; Loss: 0.3072
Epoch 5665/10000; Iter 51/80; Loss: 0.3998
Epoch 5665/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.053
Epoch 5666/10000; Iter 1/80; Loss: 0.3631
Epoch 5666/10000; Iter 51/80; Loss: 0.4014
Epoch 5666/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5667/10000; Iter 1/80; Loss: 0.3998
Epoch 5667/10000; Iter 51/80; Loss: 0.3765
Epoch 5667/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.048
Epoch 5668/10000; Iter 1/80; Loss: 0.3567
Epoch 5668/10000; Iter 51/80; Loss: 0.3799
Epoch 5668/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.046
Epoch 5669/10000; Iter 1/80; Loss: 0.3307
Epoch 5669/10000; Iter 51/80; Loss: 0.3692
Epoch 5669/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.044
Epoch 5670/10000; Iter 1/80; Loss: 0.3553
Epoch 5670/10000; Iter 51/80; Loss: 0.4301
Epoch 5670/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.05
Epoch 5671/10000; Iter 1/80; Loss: 0.3477
Epoch 5671/10000; Iter 51/80; Loss: 0.3237
Epoch 5671/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.048
Epoch 5672/10000; Iter 1/80; Loss: 0.3587
Epoch 5672/10000; Iter 51/80; Loss: 0.3710
Epoch 5672/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5673/10000; Iter 1/80; Loss: 0.3913
Epoch 5673/10000; Iter 51/80; Loss: 0.3772
Epoch 5673/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.049
Epoch 5674/10000; Iter 1/80; Loss: 0.3113
Epoch 5674/10000; Iter 51/80; Loss: 0.4123
Epoch 5674/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.052
Epoch 5675/10000; Iter 1/80; Loss: 0.3631
Epoch 5675/10000; Iter 51/80; Loss: 0.5283
Epoch 5675/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.048
Epoch 5676/10000; Iter 1/80; Loss: 0.3516
Epoch 5676/10000; Iter 51/80; Loss: 0.3166
Epoch 5676/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5677/10000; Iter 1/80; Loss: 0.4069
Epoch 5677/10000; Iter 51/80; Loss: 0.4224
Epoch 5677/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.047
Epoch 5678/10000; Iter 1/80; Loss: 0.3411
Epoch 5678/10000; Iter 51/80; Loss: 0.3602
Epoch 5678/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Epoch 5679/10000; Iter 1/80; Loss: 0.3661
Epoch 5679/10000; Iter 51/80; Loss: 0.3559
Epoch 5679/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.051
Epoch 5680/10000; Iter 1/80; Loss: 0.3649
Epoch 5680/10000; Iter 51/80; Loss: 0.4136
Epoch 5680/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.052
Epoch 5681/10000; Iter 1/80; Loss: 0.3970
Epoch 5681/10000; Iter 51/80; Loss: 0.4787
Epoch 5681/10000; Iter 80/80; Training Loss: 0.3820, Test Loss: 0.044
Epoch 5682/10000; Iter 1/80; Loss: 0.3873
Epoch 5682/10000; Iter 51/80; Loss: 0.3650
Epoch 5682/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.05
Epoch 5683/10000; Iter 1/80; Loss: 0.3956
Epoch 5683/10000; Iter 51/80; Loss: 0.4222
Epoch 5683/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.045
Epoch 5684/10000; Iter 1/80; Loss: 0.3679
Epoch 5684/10000; Iter 51/80; Loss: 0.4182
Epoch 5684/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.049
Epoch 5685/10000; Iter 1/80; Loss: 0.3469
Epoch 5685/10000; Iter 51/80; Loss: 0.3705
Epoch 5685/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5686/10000; Iter 1/80; Loss: 0.3528
Epoch 5686/10000; Iter 51/80; Loss: 0.3452
Epoch 5686/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5687/10000; Iter 1/80; Loss: 0.3991
Epoch 5687/10000; Iter 51/80; Loss: 0.3583
Epoch 5687/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.047
Epoch 5688/10000; Iter 1/80; Loss: 0.3696
Epoch 5688/10000; Iter 51/80; Loss: 0.3722
Epoch 5688/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5689/10000; Iter 1/80; Loss: 0.4108
Epoch 5689/10000; Iter 51/80; Loss: 0.3622
Epoch 5689/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5690/10000; Iter 1/80; Loss: 0.3777
Epoch 5690/10000; Iter 51/80; Loss: 0.3391
Epoch 5690/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5691/10000; Iter 1/80; Loss: 0.3867
Epoch 5691/10000; Iter 51/80; Loss: 0.3314
Epoch 5691/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5692/10000; Iter 1/80; Loss: 0.3998
Epoch 5692/10000; Iter 51/80; Loss: 0.4126
Epoch 5692/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.054
Epoch 5693/10000; Iter 1/80; Loss: 0.3997
Epoch 5693/10000; Iter 51/80; Loss: 0.3581
Epoch 5693/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.049
Epoch 5694/10000; Iter 1/80; Loss: 0.3391
Epoch 5694/10000; Iter 51/80; Loss: 0.4381
Epoch 5694/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.053
Epoch 5695/10000; Iter 1/80; Loss: 0.4424
Epoch 5695/10000; Iter 51/80; Loss: 0.3875
Epoch 5695/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.047
Epoch 5696/10000; Iter 1/80; Loss: 0.3863
Epoch 5696/10000; Iter 51/80; Loss: 0.3730
Epoch 5696/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.049
Epoch 5697/10000; Iter 1/80; Loss: 0.4130
Epoch 5697/10000; Iter 51/80; Loss: 0.4377
Epoch 5697/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.054
Epoch 5698/10000; Iter 1/80; Loss: 0.3713
Epoch 5698/10000; Iter 51/80; Loss: 0.3688
Epoch 5698/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.054
Epoch 5699/10000; Iter 1/80; Loss: 0.3507
Epoch 5699/10000; Iter 51/80; Loss: 0.3550
Epoch 5699/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Epoch 5700/10000; Iter 1/80; Loss: 0.4112
Epoch 5700/10000; Iter 51/80; Loss: 0.3313
Epoch 5700/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.047
Epoch 5701/10000; Iter 1/80; Loss: 0.3695
Epoch 5701/10000; Iter 51/80; Loss: 0.3884
Epoch 5701/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Model saved
Epoch 5702/10000; Iter 1/80; Loss: 0.3755
Epoch 5702/10000; Iter 51/80; Loss: 0.3363
Epoch 5702/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.05
Epoch 5703/10000; Iter 1/80; Loss: 0.4009
Epoch 5703/10000; Iter 51/80; Loss: 0.3171
Epoch 5703/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.049
Epoch 5704/10000; Iter 1/80; Loss: 0.3927
Epoch 5704/10000; Iter 51/80; Loss: 0.3243
Epoch 5704/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.053
Epoch 5705/10000; Iter 1/80; Loss: 0.3656
Epoch 5705/10000; Iter 51/80; Loss: 0.3797
Epoch 5705/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.051
Epoch 5706/10000; Iter 1/80; Loss: 0.3963
Epoch 5706/10000; Iter 51/80; Loss: 0.3944
Epoch 5706/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.05
Epoch 5707/10000; Iter 1/80; Loss: 0.3579
Epoch 5707/10000; Iter 51/80; Loss: 0.3742
Epoch 5707/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5708/10000; Iter 1/80; Loss: 0.3306
Epoch 5708/10000; Iter 51/80; Loss: 0.3950
Epoch 5708/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.053
Epoch 5709/10000; Iter 1/80; Loss: 0.3543
Epoch 5709/10000; Iter 51/80; Loss: 0.2849
Epoch 5709/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.044
Epoch 5710/10000; Iter 1/80; Loss: 0.3549
Epoch 5710/10000; Iter 51/80; Loss: 0.3459
Epoch 5710/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.046
Epoch 5711/10000; Iter 1/80; Loss: 0.3818
Epoch 5711/10000; Iter 51/80; Loss: 0.3914
Epoch 5711/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.051
Epoch 5712/10000; Iter 1/80; Loss: 0.3943
Epoch 5712/10000; Iter 51/80; Loss: 0.3844
Epoch 5712/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.052
Epoch 5713/10000; Iter 1/80; Loss: 0.3457
Epoch 5713/10000; Iter 51/80; Loss: 0.3816
Epoch 5713/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5714/10000; Iter 1/80; Loss: 0.3370
Epoch 5714/10000; Iter 51/80; Loss: 0.3509
Epoch 5714/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.051
Epoch 5715/10000; Iter 1/80; Loss: 0.3784
Epoch 5715/10000; Iter 51/80; Loss: 0.3546
Epoch 5715/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.046
Epoch 5716/10000; Iter 1/80; Loss: 0.3594
Epoch 5716/10000; Iter 51/80; Loss: 0.3432
Epoch 5716/10000; Iter 80/80; Training Loss: 0.3800, Test Loss: 0.05
Epoch 5717/10000; Iter 1/80; Loss: 0.3914
Epoch 5717/10000; Iter 51/80; Loss: 0.3451
Epoch 5717/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.048
Epoch 5718/10000; Iter 1/80; Loss: 0.3480
Epoch 5718/10000; Iter 51/80; Loss: 0.3429
Epoch 5718/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.052
Epoch 5719/10000; Iter 1/80; Loss: 0.3871
Epoch 5719/10000; Iter 51/80; Loss: 0.3436
Epoch 5719/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.05
Epoch 5720/10000; Iter 1/80; Loss: 0.3454
Epoch 5720/10000; Iter 51/80; Loss: 0.3892
Epoch 5720/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.051
Epoch 5721/10000; Iter 1/80; Loss: 0.3541
Epoch 5721/10000; Iter 51/80; Loss: 0.3351
Epoch 5721/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5722/10000; Iter 1/80; Loss: 0.3263
Epoch 5722/10000; Iter 51/80; Loss: 0.2905
Epoch 5722/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.049
Epoch 5723/10000; Iter 1/80; Loss: 0.3943
Epoch 5723/10000; Iter 51/80; Loss: 0.3031
Epoch 5723/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.05
Epoch 5724/10000; Iter 1/80; Loss: 0.3586
Epoch 5724/10000; Iter 51/80; Loss: 0.3610
Epoch 5724/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.048
Epoch 5725/10000; Iter 1/80; Loss: 0.4021
Epoch 5725/10000; Iter 51/80; Loss: 0.3097
Epoch 5725/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.055
Epoch 5726/10000; Iter 1/80; Loss: 0.3696
Epoch 5726/10000; Iter 51/80; Loss: 0.3615
Epoch 5726/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5727/10000; Iter 1/80; Loss: 0.2795
Epoch 5727/10000; Iter 51/80; Loss: 0.3930
Epoch 5727/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.047
Epoch 5728/10000; Iter 1/80; Loss: 0.4069
Epoch 5728/10000; Iter 51/80; Loss: 0.4088
Epoch 5728/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.047
Epoch 5729/10000; Iter 1/80; Loss: 0.3596
Epoch 5729/10000; Iter 51/80; Loss: 0.3900
Epoch 5729/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.051
Epoch 5730/10000; Iter 1/80; Loss: 0.3682
Epoch 5730/10000; Iter 51/80; Loss: 0.3422
Epoch 5730/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.052
Epoch 5731/10000; Iter 1/80; Loss: 0.3465
Epoch 5731/10000; Iter 51/80; Loss: 0.4129
Epoch 5731/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.049
Epoch 5732/10000; Iter 1/80; Loss: 0.3672
Epoch 5732/10000; Iter 51/80; Loss: 0.3605
Epoch 5732/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.048
Epoch 5733/10000; Iter 1/80; Loss: 0.3749
Epoch 5733/10000; Iter 51/80; Loss: 0.3491
Epoch 5733/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.047
Epoch 5734/10000; Iter 1/80; Loss: 0.4129
Epoch 5734/10000; Iter 51/80; Loss: 0.3500
Epoch 5734/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.048
Epoch 5735/10000; Iter 1/80; Loss: 0.3488
Epoch 5735/10000; Iter 51/80; Loss: 0.3908
Epoch 5735/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.053
Epoch 5736/10000; Iter 1/80; Loss: 0.3772
Epoch 5736/10000; Iter 51/80; Loss: 0.4378
Epoch 5736/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.049
Epoch 5737/10000; Iter 1/80; Loss: 0.3726
Epoch 5737/10000; Iter 51/80; Loss: 0.4066
Epoch 5737/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.05
Epoch 5738/10000; Iter 1/80; Loss: 0.3679
Epoch 5738/10000; Iter 51/80; Loss: 0.3981
Epoch 5738/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.047
Epoch 5739/10000; Iter 1/80; Loss: 0.3644
Epoch 5739/10000; Iter 51/80; Loss: 0.3799
Epoch 5739/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.049
Epoch 5740/10000; Iter 1/80; Loss: 0.4200
Epoch 5740/10000; Iter 51/80; Loss: 0.4207
Epoch 5740/10000; Iter 80/80; Training Loss: 0.3790, Test Loss: 0.052
Epoch 5741/10000; Iter 1/80; Loss: 0.3533
Epoch 5741/10000; Iter 51/80; Loss: 0.3458
Epoch 5741/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.054
Epoch 5742/10000; Iter 1/80; Loss: 0.2999
Epoch 5742/10000; Iter 51/80; Loss: 0.3769
Epoch 5742/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5743/10000; Iter 1/80; Loss: 0.4126
Epoch 5743/10000; Iter 51/80; Loss: 0.3422
Epoch 5743/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.05
Epoch 5744/10000; Iter 1/80; Loss: 0.3945
Epoch 5744/10000; Iter 51/80; Loss: 0.3557
Epoch 5744/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5745/10000; Iter 1/80; Loss: 0.3916
Epoch 5745/10000; Iter 51/80; Loss: 0.3595
Epoch 5745/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.049
Epoch 5746/10000; Iter 1/80; Loss: 0.3810
Epoch 5746/10000; Iter 51/80; Loss: 0.3523
Epoch 5746/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.051
Epoch 5747/10000; Iter 1/80; Loss: 0.3306
Epoch 5747/10000; Iter 51/80; Loss: 0.3525
Epoch 5747/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.058
Epoch 5748/10000; Iter 1/80; Loss: 0.4253
Epoch 5748/10000; Iter 51/80; Loss: 0.3738
Epoch 5748/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5749/10000; Iter 1/80; Loss: 0.3886
Epoch 5749/10000; Iter 51/80; Loss: 0.3666
Epoch 5749/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.049
Epoch 5750/10000; Iter 1/80; Loss: 0.3191
Epoch 5750/10000; Iter 51/80; Loss: 0.3418
Epoch 5750/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.051
Epoch 5751/10000; Iter 1/80; Loss: 0.3632
Epoch 5751/10000; Iter 51/80; Loss: 0.3570
Epoch 5751/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.048
Epoch 5752/10000; Iter 1/80; Loss: 0.3506
Epoch 5752/10000; Iter 51/80; Loss: 0.3488
Epoch 5752/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.053
Epoch 5753/10000; Iter 1/80; Loss: 0.3683
Epoch 5753/10000; Iter 51/80; Loss: 0.3917
Epoch 5753/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.051
Epoch 5754/10000; Iter 1/80; Loss: 0.2997
Epoch 5754/10000; Iter 51/80; Loss: 0.4111
Epoch 5754/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.047
Epoch 5755/10000; Iter 1/80; Loss: 0.3557
Epoch 5755/10000; Iter 51/80; Loss: 0.3236
Epoch 5755/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.047
Epoch 5756/10000; Iter 1/80; Loss: 0.3903
Epoch 5756/10000; Iter 51/80; Loss: 0.4038
Epoch 5756/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5757/10000; Iter 1/80; Loss: 0.3677
Epoch 5757/10000; Iter 51/80; Loss: 0.4029
Epoch 5757/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.055
Epoch 5758/10000; Iter 1/80; Loss: 0.3639
Epoch 5758/10000; Iter 51/80; Loss: 0.3637
Epoch 5758/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.05
Epoch 5759/10000; Iter 1/80; Loss: 0.4018
Epoch 5759/10000; Iter 51/80; Loss: 0.3213
Epoch 5759/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.047
Epoch 5760/10000; Iter 1/80; Loss: 0.3109
Epoch 5760/10000; Iter 51/80; Loss: 0.4030
Epoch 5760/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.047
Epoch 5761/10000; Iter 1/80; Loss: 0.3381
Epoch 5761/10000; Iter 51/80; Loss: 0.3852
Epoch 5761/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.045
Epoch 5762/10000; Iter 1/80; Loss: 0.4763
Epoch 5762/10000; Iter 51/80; Loss: 0.3010
Epoch 5762/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.042
Epoch 5763/10000; Iter 1/80; Loss: 0.3394
Epoch 5763/10000; Iter 51/80; Loss: 0.3642
Epoch 5763/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.047
Epoch 5764/10000; Iter 1/80; Loss: 0.3136
Epoch 5764/10000; Iter 51/80; Loss: 0.3559
Epoch 5764/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5765/10000; Iter 1/80; Loss: 0.3650
Epoch 5765/10000; Iter 51/80; Loss: 0.3579
Epoch 5765/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.047
Epoch 5766/10000; Iter 1/80; Loss: 0.3404
Epoch 5766/10000; Iter 51/80; Loss: 0.3764
Epoch 5766/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.052
Epoch 5767/10000; Iter 1/80; Loss: 0.3220
Epoch 5767/10000; Iter 51/80; Loss: 0.3107
Epoch 5767/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.051
Epoch 5768/10000; Iter 1/80; Loss: 0.3816
Epoch 5768/10000; Iter 51/80; Loss: 0.3812
Epoch 5768/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.053
Epoch 5769/10000; Iter 1/80; Loss: 0.3659
Epoch 5769/10000; Iter 51/80; Loss: 0.3819
Epoch 5769/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.052
Epoch 5770/10000; Iter 1/80; Loss: 0.3571
Epoch 5770/10000; Iter 51/80; Loss: 0.4160
Epoch 5770/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.052
Epoch 5771/10000; Iter 1/80; Loss: 0.3126
Epoch 5771/10000; Iter 51/80; Loss: 0.3467
Epoch 5771/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.047
Epoch 5772/10000; Iter 1/80; Loss: 0.3529
Epoch 5772/10000; Iter 51/80; Loss: 0.3368
Epoch 5772/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.05
Epoch 5773/10000; Iter 1/80; Loss: 0.4304
Epoch 5773/10000; Iter 51/80; Loss: 0.3644
Epoch 5773/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5774/10000; Iter 1/80; Loss: 0.3263
Epoch 5774/10000; Iter 51/80; Loss: 0.3813
Epoch 5774/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.052
Epoch 5775/10000; Iter 1/80; Loss: 0.3463
Epoch 5775/10000; Iter 51/80; Loss: 0.3669
Epoch 5775/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.048
Epoch 5776/10000; Iter 1/80; Loss: 0.3683
Epoch 5776/10000; Iter 51/80; Loss: 0.2756
Epoch 5776/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.049
Epoch 5777/10000; Iter 1/80; Loss: 0.3615
Epoch 5777/10000; Iter 51/80; Loss: 0.3323
Epoch 5777/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.053
Epoch 5778/10000; Iter 1/80; Loss: 0.3424
Epoch 5778/10000; Iter 51/80; Loss: 0.3784
Epoch 5778/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.049
Epoch 5779/10000; Iter 1/80; Loss: 0.3708
Epoch 5779/10000; Iter 51/80; Loss: 0.3874
Epoch 5779/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.054
Epoch 5780/10000; Iter 1/80; Loss: 0.4007
Epoch 5780/10000; Iter 51/80; Loss: 0.4448
Epoch 5780/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.05
Epoch 5781/10000; Iter 1/80; Loss: 0.3200
Epoch 5781/10000; Iter 51/80; Loss: 0.3665
Epoch 5781/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.05
Epoch 5782/10000; Iter 1/80; Loss: 0.3900
Epoch 5782/10000; Iter 51/80; Loss: 0.4179
Epoch 5782/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.054
Epoch 5783/10000; Iter 1/80; Loss: 0.3451
Epoch 5783/10000; Iter 51/80; Loss: 0.4142
Epoch 5783/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.051
Epoch 5784/10000; Iter 1/80; Loss: 0.2939
Epoch 5784/10000; Iter 51/80; Loss: 0.3411
Epoch 5784/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.045
Epoch 5785/10000; Iter 1/80; Loss: 0.3096
Epoch 5785/10000; Iter 51/80; Loss: 0.3797
Epoch 5785/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.047
Epoch 5786/10000; Iter 1/80; Loss: 0.3638
Epoch 5786/10000; Iter 51/80; Loss: 0.4009
Epoch 5786/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.055
Epoch 5787/10000; Iter 1/80; Loss: 0.3188
Epoch 5787/10000; Iter 51/80; Loss: 0.4012
Epoch 5787/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5788/10000; Iter 1/80; Loss: 0.3680
Epoch 5788/10000; Iter 51/80; Loss: 0.4325
Epoch 5788/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.055
Epoch 5789/10000; Iter 1/80; Loss: 0.3986
Epoch 5789/10000; Iter 51/80; Loss: 0.3618
Epoch 5789/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.048
Epoch 5790/10000; Iter 1/80; Loss: 0.3968
Epoch 5790/10000; Iter 51/80; Loss: 0.3801
Epoch 5790/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.053
Epoch 5791/10000; Iter 1/80; Loss: 0.3187
Epoch 5791/10000; Iter 51/80; Loss: 0.4057
Epoch 5791/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.056
Epoch 5792/10000; Iter 1/80; Loss: 0.4625
Epoch 5792/10000; Iter 51/80; Loss: 0.4124
Epoch 5792/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.046
Epoch 5793/10000; Iter 1/80; Loss: 0.4598
Epoch 5793/10000; Iter 51/80; Loss: 0.3857
Epoch 5793/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.055
Epoch 5794/10000; Iter 1/80; Loss: 0.3457
Epoch 5794/10000; Iter 51/80; Loss: 0.4095
Epoch 5794/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5795/10000; Iter 1/80; Loss: 0.4043
Epoch 5795/10000; Iter 51/80; Loss: 0.3702
Epoch 5795/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.052
Epoch 5796/10000; Iter 1/80; Loss: 0.3639
Epoch 5796/10000; Iter 51/80; Loss: 0.3454
Epoch 5796/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.053
Epoch 5797/10000; Iter 1/80; Loss: 0.3229
Epoch 5797/10000; Iter 51/80; Loss: 0.3878
Epoch 5797/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.048
Epoch 5798/10000; Iter 1/80; Loss: 0.3538
Epoch 5798/10000; Iter 51/80; Loss: 0.3489
Epoch 5798/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.052
Epoch 5799/10000; Iter 1/80; Loss: 0.3306
Epoch 5799/10000; Iter 51/80; Loss: 0.3558
Epoch 5799/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.053
Epoch 5800/10000; Iter 1/80; Loss: 0.3768
Epoch 5800/10000; Iter 51/80; Loss: 0.3453
Epoch 5800/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.058
Epoch 5801/10000; Iter 1/80; Loss: 0.3755
Epoch 5801/10000; Iter 51/80; Loss: 0.3277
Epoch 5801/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.052
Model saved
Epoch 5802/10000; Iter 1/80; Loss: 0.3471
Epoch 5802/10000; Iter 51/80; Loss: 0.4387
Epoch 5802/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.058
Epoch 5803/10000; Iter 1/80; Loss: 0.3484
Epoch 5803/10000; Iter 51/80; Loss: 0.3515
Epoch 5803/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.047
Epoch 5804/10000; Iter 1/80; Loss: 0.3222
Epoch 5804/10000; Iter 51/80; Loss: 0.4338
Epoch 5804/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.048
Epoch 5805/10000; Iter 1/80; Loss: 0.3544
Epoch 5805/10000; Iter 51/80; Loss: 0.3704
Epoch 5805/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.05
Epoch 5806/10000; Iter 1/80; Loss: 0.3844
Epoch 5806/10000; Iter 51/80; Loss: 0.3084
Epoch 5806/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5807/10000; Iter 1/80; Loss: 0.3373
Epoch 5807/10000; Iter 51/80; Loss: 0.4040
Epoch 5807/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.044
Epoch 5808/10000; Iter 1/80; Loss: 0.3706
Epoch 5808/10000; Iter 51/80; Loss: 0.3548
Epoch 5808/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5809/10000; Iter 1/80; Loss: 0.4437
Epoch 5809/10000; Iter 51/80; Loss: 0.3810
Epoch 5809/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.053
Epoch 5810/10000; Iter 1/80; Loss: 0.3621
Epoch 5810/10000; Iter 51/80; Loss: 0.3837
Epoch 5810/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.053
Epoch 5811/10000; Iter 1/80; Loss: 0.3277
Epoch 5811/10000; Iter 51/80; Loss: 0.3525
Epoch 5811/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.052
Epoch 5812/10000; Iter 1/80; Loss: 0.4308
Epoch 5812/10000; Iter 51/80; Loss: 0.4325
Epoch 5812/10000; Iter 80/80; Training Loss: 0.3750, Test Loss: 0.051
Epoch 5813/10000; Iter 1/80; Loss: 0.3795
Epoch 5813/10000; Iter 51/80; Loss: 0.3494
Epoch 5813/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5814/10000; Iter 1/80; Loss: 0.3653
Epoch 5814/10000; Iter 51/80; Loss: 0.3564
Epoch 5814/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.051
Epoch 5815/10000; Iter 1/80; Loss: 0.4380
Epoch 5815/10000; Iter 51/80; Loss: 0.3754
Epoch 5815/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.055
Epoch 5816/10000; Iter 1/80; Loss: 0.3521
Epoch 5816/10000; Iter 51/80; Loss: 0.3517
Epoch 5816/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.054
Epoch 5817/10000; Iter 1/80; Loss: 0.3641
Epoch 5817/10000; Iter 51/80; Loss: 0.3906
Epoch 5817/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.05
Epoch 5818/10000; Iter 1/80; Loss: 0.3492
Epoch 5818/10000; Iter 51/80; Loss: 0.3967
Epoch 5818/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.053
Epoch 5819/10000; Iter 1/80; Loss: 0.3559
Epoch 5819/10000; Iter 51/80; Loss: 0.3969
Epoch 5819/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.053
Epoch 5820/10000; Iter 1/80; Loss: 0.3338
Epoch 5820/10000; Iter 51/80; Loss: 0.3879
Epoch 5820/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.049
Epoch 5821/10000; Iter 1/80; Loss: 0.3764
Epoch 5821/10000; Iter 51/80; Loss: 0.3387
Epoch 5821/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.053
Epoch 5822/10000; Iter 1/80; Loss: 0.3859
Epoch 5822/10000; Iter 51/80; Loss: 0.3777
Epoch 5822/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.047
Epoch 5823/10000; Iter 1/80; Loss: 0.3979
Epoch 5823/10000; Iter 51/80; Loss: 0.3887
Epoch 5823/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.054
Epoch 5824/10000; Iter 1/80; Loss: 0.3532
Epoch 5824/10000; Iter 51/80; Loss: 0.3193
Epoch 5824/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.053
Epoch 5825/10000; Iter 1/80; Loss: 0.4585
Epoch 5825/10000; Iter 51/80; Loss: 0.3168
Epoch 5825/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.05
Epoch 5826/10000; Iter 1/80; Loss: 0.3859
Epoch 5826/10000; Iter 51/80; Loss: 0.3468
Epoch 5826/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.047
Epoch 5827/10000; Iter 1/80; Loss: 0.3552
Epoch 5827/10000; Iter 51/80; Loss: 0.3322
Epoch 5827/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.051
Epoch 5828/10000; Iter 1/80; Loss: 0.3299
Epoch 5828/10000; Iter 51/80; Loss: 0.3838
Epoch 5828/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.048
Epoch 5829/10000; Iter 1/80; Loss: 0.3664
Epoch 5829/10000; Iter 51/80; Loss: 0.3983
Epoch 5829/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.047
Epoch 5830/10000; Iter 1/80; Loss: 0.3361
Epoch 5830/10000; Iter 51/80; Loss: 0.3753
Epoch 5830/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.052
Epoch 5831/10000; Iter 1/80; Loss: 0.3376
Epoch 5831/10000; Iter 51/80; Loss: 0.3754
Epoch 5831/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5832/10000; Iter 1/80; Loss: 0.3717
Epoch 5832/10000; Iter 51/80; Loss: 0.3349
Epoch 5832/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.052
Epoch 5833/10000; Iter 1/80; Loss: 0.3017
Epoch 5833/10000; Iter 51/80; Loss: 0.3671
Epoch 5833/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.051
Epoch 5834/10000; Iter 1/80; Loss: 0.3811
Epoch 5834/10000; Iter 51/80; Loss: 0.3556
Epoch 5834/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.046
Epoch 5835/10000; Iter 1/80; Loss: 0.3820
Epoch 5835/10000; Iter 51/80; Loss: 0.3230
Epoch 5835/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.055
Epoch 5836/10000; Iter 1/80; Loss: 0.3581
Epoch 5836/10000; Iter 51/80; Loss: 0.4476
Epoch 5836/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.05
Epoch 5837/10000; Iter 1/80; Loss: 0.3888
Epoch 5837/10000; Iter 51/80; Loss: 0.3582
Epoch 5837/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.049
Epoch 5838/10000; Iter 1/80; Loss: 0.4488
Epoch 5838/10000; Iter 51/80; Loss: 0.3245
Epoch 5838/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.052
Epoch 5839/10000; Iter 1/80; Loss: 0.3210
Epoch 5839/10000; Iter 51/80; Loss: 0.3379
Epoch 5839/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.047
Epoch 5840/10000; Iter 1/80; Loss: 0.3163
Epoch 5840/10000; Iter 51/80; Loss: 0.3507
Epoch 5840/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.052
Epoch 5841/10000; Iter 1/80; Loss: 0.3923
Epoch 5841/10000; Iter 51/80; Loss: 0.3543
Epoch 5841/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.048
Epoch 5842/10000; Iter 1/80; Loss: 0.3450
Epoch 5842/10000; Iter 51/80; Loss: 0.3117
Epoch 5842/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.054
Epoch 5843/10000; Iter 1/80; Loss: 0.4390
Epoch 5843/10000; Iter 51/80; Loss: 0.3513
Epoch 5843/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.049
Epoch 5844/10000; Iter 1/80; Loss: 0.3399
Epoch 5844/10000; Iter 51/80; Loss: 0.3577
Epoch 5844/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.05
Epoch 5845/10000; Iter 1/80; Loss: 0.3717
Epoch 5845/10000; Iter 51/80; Loss: 0.3342
Epoch 5845/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.053
Epoch 5846/10000; Iter 1/80; Loss: 0.3808
Epoch 5846/10000; Iter 51/80; Loss: 0.3421
Epoch 5846/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.052
Epoch 5847/10000; Iter 1/80; Loss: 0.3495
Epoch 5847/10000; Iter 51/80; Loss: 0.3641
Epoch 5847/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.05
Epoch 5848/10000; Iter 1/80; Loss: 0.3245
Epoch 5848/10000; Iter 51/80; Loss: 0.3977
Epoch 5848/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.049
Epoch 5849/10000; Iter 1/80; Loss: 0.4016
Epoch 5849/10000; Iter 51/80; Loss: 0.3487
Epoch 5849/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.045
Epoch 5850/10000; Iter 1/80; Loss: 0.3568
Epoch 5850/10000; Iter 51/80; Loss: 0.3609
Epoch 5850/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.054
Epoch 5851/10000; Iter 1/80; Loss: 0.4039
Epoch 5851/10000; Iter 51/80; Loss: 0.3448
Epoch 5851/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.047
Epoch 5852/10000; Iter 1/80; Loss: 0.3763
Epoch 5852/10000; Iter 51/80; Loss: 0.3452
Epoch 5852/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.055
Epoch 5853/10000; Iter 1/80; Loss: 0.3614
Epoch 5853/10000; Iter 51/80; Loss: 0.3434
Epoch 5853/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.046
Epoch 5854/10000; Iter 1/80; Loss: 0.3277
Epoch 5854/10000; Iter 51/80; Loss: 0.3205
Epoch 5854/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5855/10000; Iter 1/80; Loss: 0.3237
Epoch 5855/10000; Iter 51/80; Loss: 0.3302
Epoch 5855/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.056
Epoch 5856/10000; Iter 1/80; Loss: 0.3449
Epoch 5856/10000; Iter 51/80; Loss: 0.4604
Epoch 5856/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.05
Epoch 5857/10000; Iter 1/80; Loss: 0.3395
Epoch 5857/10000; Iter 51/80; Loss: 0.4020
Epoch 5857/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.042
Epoch 5858/10000; Iter 1/80; Loss: 0.4026
Epoch 5858/10000; Iter 51/80; Loss: 0.3603
Epoch 5858/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.051
Epoch 5859/10000; Iter 1/80; Loss: 0.3725
Epoch 5859/10000; Iter 51/80; Loss: 0.3605
Epoch 5859/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5860/10000; Iter 1/80; Loss: 0.3727
Epoch 5860/10000; Iter 51/80; Loss: 0.3810
Epoch 5860/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.052
Epoch 5861/10000; Iter 1/80; Loss: 0.4160
Epoch 5861/10000; Iter 51/80; Loss: 0.3654
Epoch 5861/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.051
Epoch 5862/10000; Iter 1/80; Loss: 0.3705
Epoch 5862/10000; Iter 51/80; Loss: 0.3961
Epoch 5862/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.055
Epoch 5863/10000; Iter 1/80; Loss: 0.3887
Epoch 5863/10000; Iter 51/80; Loss: 0.4313
Epoch 5863/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.05
Epoch 5864/10000; Iter 1/80; Loss: 0.4185
Epoch 5864/10000; Iter 51/80; Loss: 0.3217
Epoch 5864/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.045
Epoch 5865/10000; Iter 1/80; Loss: 0.3878
Epoch 5865/10000; Iter 51/80; Loss: 0.3844
Epoch 5865/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.053
Epoch 5866/10000; Iter 1/80; Loss: 0.3289
Epoch 5866/10000; Iter 51/80; Loss: 0.3611
Epoch 5866/10000; Iter 80/80; Training Loss: 0.3770, Test Loss: 0.053
Epoch 5867/10000; Iter 1/80; Loss: 0.3977
Epoch 5867/10000; Iter 51/80; Loss: 0.4140
Epoch 5867/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.054
Epoch 5868/10000; Iter 1/80; Loss: 0.4185
Epoch 5868/10000; Iter 51/80; Loss: 0.3728
Epoch 5868/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.054
Epoch 5869/10000; Iter 1/80; Loss: 0.3224
Epoch 5869/10000; Iter 51/80; Loss: 0.3816
Epoch 5869/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.056
Epoch 5870/10000; Iter 1/80; Loss: 0.3198
Epoch 5870/10000; Iter 51/80; Loss: 0.3530
Epoch 5870/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.056
Epoch 5871/10000; Iter 1/80; Loss: 0.3701
Epoch 5871/10000; Iter 51/80; Loss: 0.4449
Epoch 5871/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.057
Epoch 5872/10000; Iter 1/80; Loss: 0.3738
Epoch 5872/10000; Iter 51/80; Loss: 0.3412
Epoch 5872/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.053
Epoch 5873/10000; Iter 1/80; Loss: 0.3885
Epoch 5873/10000; Iter 51/80; Loss: 0.3262
Epoch 5873/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.06
Epoch 5874/10000; Iter 1/80; Loss: 0.3121
Epoch 5874/10000; Iter 51/80; Loss: 0.3489
Epoch 5874/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.052
Epoch 5875/10000; Iter 1/80; Loss: 0.3283
Epoch 5875/10000; Iter 51/80; Loss: 0.3897
Epoch 5875/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.05
Epoch 5876/10000; Iter 1/80; Loss: 0.3374
Epoch 5876/10000; Iter 51/80; Loss: 0.3461
Epoch 5876/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.052
Epoch 5877/10000; Iter 1/80; Loss: 0.3603
Epoch 5877/10000; Iter 51/80; Loss: 0.3969
Epoch 5877/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.052
Epoch 5878/10000; Iter 1/80; Loss: 0.3812
Epoch 5878/10000; Iter 51/80; Loss: 0.3300
Epoch 5878/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.049
Epoch 5879/10000; Iter 1/80; Loss: 0.4167
Epoch 5879/10000; Iter 51/80; Loss: 0.3836
Epoch 5879/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.053
Epoch 5880/10000; Iter 1/80; Loss: 0.3431
Epoch 5880/10000; Iter 51/80; Loss: 0.3697
Epoch 5880/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.054
Epoch 5881/10000; Iter 1/80; Loss: 0.3466
Epoch 5881/10000; Iter 51/80; Loss: 0.3577
Epoch 5881/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.049
Epoch 5882/10000; Iter 1/80; Loss: 0.3913
Epoch 5882/10000; Iter 51/80; Loss: 0.3562
Epoch 5882/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.058
Epoch 5883/10000; Iter 1/80; Loss: 0.3314
Epoch 5883/10000; Iter 51/80; Loss: 0.3478
Epoch 5883/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.06
Epoch 5884/10000; Iter 1/80; Loss: 0.4082
Epoch 5884/10000; Iter 51/80; Loss: 0.3477
Epoch 5884/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.055
Epoch 5885/10000; Iter 1/80; Loss: 0.2972
Epoch 5885/10000; Iter 51/80; Loss: 0.3752
Epoch 5885/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.057
Epoch 5886/10000; Iter 1/80; Loss: 0.3636
Epoch 5886/10000; Iter 51/80; Loss: 0.3687
Epoch 5886/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.05
Epoch 5887/10000; Iter 1/80; Loss: 0.4501
Epoch 5887/10000; Iter 51/80; Loss: 0.3647
Epoch 5887/10000; Iter 80/80; Training Loss: 0.3740, Test Loss: 0.045
Epoch 5888/10000; Iter 1/80; Loss: 0.3330
Epoch 5888/10000; Iter 51/80; Loss: 0.3027
Epoch 5888/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.046
Epoch 5889/10000; Iter 1/80; Loss: 0.3378
Epoch 5889/10000; Iter 51/80; Loss: 0.3691
Epoch 5889/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.058
Epoch 5890/10000; Iter 1/80; Loss: 0.3402
Epoch 5890/10000; Iter 51/80; Loss: 0.3606
Epoch 5890/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.047
Epoch 5891/10000; Iter 1/80; Loss: 0.3210
Epoch 5891/10000; Iter 51/80; Loss: 0.3667
Epoch 5891/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.053
Epoch 5892/10000; Iter 1/80; Loss: 0.3276
Epoch 5892/10000; Iter 51/80; Loss: 0.3749
Epoch 5892/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.049
Epoch 5893/10000; Iter 1/80; Loss: 0.3703
Epoch 5893/10000; Iter 51/80; Loss: 0.3820
Epoch 5893/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.057
Epoch 5894/10000; Iter 1/80; Loss: 0.3603
Epoch 5894/10000; Iter 51/80; Loss: 0.3907
Epoch 5894/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.054
Epoch 5895/10000; Iter 1/80; Loss: 0.3620
Epoch 5895/10000; Iter 51/80; Loss: 0.3617
Epoch 5895/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.059
Epoch 5896/10000; Iter 1/80; Loss: 0.3498
Epoch 5896/10000; Iter 51/80; Loss: 0.3760
Epoch 5896/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.048
Epoch 5897/10000; Iter 1/80; Loss: 0.3951
Epoch 5897/10000; Iter 51/80; Loss: 0.3628
Epoch 5897/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.055
Epoch 5898/10000; Iter 1/80; Loss: 0.3456
Epoch 5898/10000; Iter 51/80; Loss: 0.3527
Epoch 5898/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.05
Epoch 5899/10000; Iter 1/80; Loss: 0.3352
Epoch 5899/10000; Iter 51/80; Loss: 0.3608
Epoch 5899/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.052
Epoch 5900/10000; Iter 1/80; Loss: 0.3395
Epoch 5900/10000; Iter 51/80; Loss: 0.2864
Epoch 5900/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.047
Epoch 5901/10000; Iter 1/80; Loss: 0.3693
Epoch 5901/10000; Iter 51/80; Loss: 0.3486
Epoch 5901/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.049
Model saved
Epoch 5902/10000; Iter 1/80; Loss: 0.3652
Epoch 5902/10000; Iter 51/80; Loss: 0.3773
Epoch 5902/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.06
Epoch 5903/10000; Iter 1/80; Loss: 0.4252
Epoch 5903/10000; Iter 51/80; Loss: 0.3663
Epoch 5903/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.05
Epoch 5904/10000; Iter 1/80; Loss: 0.3926
Epoch 5904/10000; Iter 51/80; Loss: 0.3363
Epoch 5904/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.053
Epoch 5905/10000; Iter 1/80; Loss: 0.3665
Epoch 5905/10000; Iter 51/80; Loss: 0.3702
Epoch 5905/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.049
Epoch 5906/10000; Iter 1/80; Loss: 0.3521
Epoch 5906/10000; Iter 51/80; Loss: 0.3268
Epoch 5906/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.048
Epoch 5907/10000; Iter 1/80; Loss: 0.3719
Epoch 5907/10000; Iter 51/80; Loss: 0.2810
Epoch 5907/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.06
Epoch 5908/10000; Iter 1/80; Loss: 0.3946
Epoch 5908/10000; Iter 51/80; Loss: 0.3531
Epoch 5908/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.053
Epoch 5909/10000; Iter 1/80; Loss: 0.3996
Epoch 5909/10000; Iter 51/80; Loss: 0.3459
Epoch 5909/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.051
Epoch 5910/10000; Iter 1/80; Loss: 0.3619
Epoch 5910/10000; Iter 51/80; Loss: 0.3799
Epoch 5910/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.051
Epoch 5911/10000; Iter 1/80; Loss: 0.3899
Epoch 5911/10000; Iter 51/80; Loss: 0.3633
Epoch 5911/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.052
Epoch 5912/10000; Iter 1/80; Loss: 0.3171
Epoch 5912/10000; Iter 51/80; Loss: 0.3449
Epoch 5912/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.051
Epoch 5913/10000; Iter 1/80; Loss: 0.4025
Epoch 5913/10000; Iter 51/80; Loss: 0.4425
Epoch 5913/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.053
Epoch 5914/10000; Iter 1/80; Loss: 0.3725
Epoch 5914/10000; Iter 51/80; Loss: 0.3321
Epoch 5914/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.05
Epoch 5915/10000; Iter 1/80; Loss: 0.3407
Epoch 5915/10000; Iter 51/80; Loss: 0.3498
Epoch 5915/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.052
Epoch 5916/10000; Iter 1/80; Loss: 0.3250
Epoch 5916/10000; Iter 51/80; Loss: 0.3863
Epoch 5916/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.061
Epoch 5917/10000; Iter 1/80; Loss: 0.3730
Epoch 5917/10000; Iter 51/80; Loss: 0.3534
Epoch 5917/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.057
Epoch 5918/10000; Iter 1/80; Loss: 0.4271
Epoch 5918/10000; Iter 51/80; Loss: 0.3421
Epoch 5918/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.053
Epoch 5919/10000; Iter 1/80; Loss: 0.4253
Epoch 5919/10000; Iter 51/80; Loss: 0.4322
Epoch 5919/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.053
Epoch 5920/10000; Iter 1/80; Loss: 0.4006
Epoch 5920/10000; Iter 51/80; Loss: 0.3409
Epoch 5920/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.057
Epoch 5921/10000; Iter 1/80; Loss: 0.3786
Epoch 5921/10000; Iter 51/80; Loss: 0.4129
Epoch 5921/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.056
Epoch 5922/10000; Iter 1/80; Loss: 0.3691
Epoch 5922/10000; Iter 51/80; Loss: 0.3350
Epoch 5922/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.053
Epoch 5923/10000; Iter 1/80; Loss: 0.4153
Epoch 5923/10000; Iter 51/80; Loss: 0.3567
Epoch 5923/10000; Iter 80/80; Training Loss: 0.3720, Test Loss: 0.054
Epoch 5924/10000; Iter 1/80; Loss: 0.3255
Epoch 5924/10000; Iter 51/80; Loss: 0.3382
Epoch 5924/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.051
Epoch 5925/10000; Iter 1/80; Loss: 0.3971
Epoch 5925/10000; Iter 51/80; Loss: 0.3288
Epoch 5925/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.049
Epoch 5926/10000; Iter 1/80; Loss: 0.3669
Epoch 5926/10000; Iter 51/80; Loss: 0.3325
Epoch 5926/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.055
Epoch 5927/10000; Iter 1/80; Loss: 0.4017
Epoch 5927/10000; Iter 51/80; Loss: 0.3388
Epoch 5927/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.046
Epoch 5928/10000; Iter 1/80; Loss: 0.3401
Epoch 5928/10000; Iter 51/80; Loss: 0.4540
Epoch 5928/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.051
Epoch 5929/10000; Iter 1/80; Loss: 0.3996
Epoch 5929/10000; Iter 51/80; Loss: 0.4277
Epoch 5929/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.047
Epoch 5930/10000; Iter 1/80; Loss: 0.4053
Epoch 5930/10000; Iter 51/80; Loss: 0.3641
Epoch 5930/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.052
Epoch 5931/10000; Iter 1/80; Loss: 0.3072
Epoch 5931/10000; Iter 51/80; Loss: 0.3382
Epoch 5931/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.057
Epoch 5932/10000; Iter 1/80; Loss: 0.3576
Epoch 5932/10000; Iter 51/80; Loss: 0.3992
Epoch 5932/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.051
Epoch 5933/10000; Iter 1/80; Loss: 0.3745
Epoch 5933/10000; Iter 51/80; Loss: 0.4000
Epoch 5933/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.059
Epoch 5934/10000; Iter 1/80; Loss: 0.3859
Epoch 5934/10000; Iter 51/80; Loss: 0.3587
Epoch 5934/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.058
Epoch 5935/10000; Iter 1/80; Loss: 0.3833
Epoch 5935/10000; Iter 51/80; Loss: 0.3491
Epoch 5935/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.056
Epoch 5936/10000; Iter 1/80; Loss: 0.3937
Epoch 5936/10000; Iter 51/80; Loss: 0.3870
Epoch 5936/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.052
Epoch 5937/10000; Iter 1/80; Loss: 0.3979
Epoch 5937/10000; Iter 51/80; Loss: 0.3184
Epoch 5937/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.05
Epoch 5938/10000; Iter 1/80; Loss: 0.3099
Epoch 5938/10000; Iter 51/80; Loss: 0.3590
Epoch 5938/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.056
Epoch 5939/10000; Iter 1/80; Loss: 0.4058
Epoch 5939/10000; Iter 51/80; Loss: 0.3850
Epoch 5939/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.059
Epoch 5940/10000; Iter 1/80; Loss: 0.4109
Epoch 5940/10000; Iter 51/80; Loss: 0.3618
Epoch 5940/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.054
Epoch 5941/10000; Iter 1/80; Loss: 0.3895
Epoch 5941/10000; Iter 51/80; Loss: 0.3771
Epoch 5941/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.053
Epoch 5942/10000; Iter 1/80; Loss: 0.3118
Epoch 5942/10000; Iter 51/80; Loss: 0.3779
Epoch 5942/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.048
Epoch 5943/10000; Iter 1/80; Loss: 0.3198
Epoch 5943/10000; Iter 51/80; Loss: 0.3369
Epoch 5943/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.055
Epoch 5944/10000; Iter 1/80; Loss: 0.3393
Epoch 5944/10000; Iter 51/80; Loss: 0.3688
Epoch 5944/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.055
Epoch 5945/10000; Iter 1/80; Loss: 0.4053
Epoch 5945/10000; Iter 51/80; Loss: 0.3887
Epoch 5945/10000; Iter 80/80; Training Loss: 0.3760, Test Loss: 0.057
Epoch 5946/10000; Iter 1/80; Loss: 0.3313
Epoch 5946/10000; Iter 51/80; Loss: 0.3949
Epoch 5946/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.054
Epoch 5947/10000; Iter 1/80; Loss: 0.3868
Epoch 5947/10000; Iter 51/80; Loss: 0.3859
Epoch 5947/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.055
Epoch 5948/10000; Iter 1/80; Loss: 0.3457
Epoch 5948/10000; Iter 51/80; Loss: 0.3654
Epoch 5948/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.052
Epoch 5949/10000; Iter 1/80; Loss: 0.4033
Epoch 5949/10000; Iter 51/80; Loss: 0.3855
Epoch 5949/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.048
Epoch 5950/10000; Iter 1/80; Loss: 0.3577
Epoch 5950/10000; Iter 51/80; Loss: 0.3588
Epoch 5950/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.056
Epoch 5951/10000; Iter 1/80; Loss: 0.3301
Epoch 5951/10000; Iter 51/80; Loss: 0.4871
Epoch 5951/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.049
Epoch 5952/10000; Iter 1/80; Loss: 0.3493
Epoch 5952/10000; Iter 51/80; Loss: 0.3451
Epoch 5952/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.057
Epoch 5953/10000; Iter 1/80; Loss: 0.3351
Epoch 5953/10000; Iter 51/80; Loss: 0.4146
Epoch 5953/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.056
Epoch 5954/10000; Iter 1/80; Loss: 0.3440
Epoch 5954/10000; Iter 51/80; Loss: 0.3662
Epoch 5954/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.044
Epoch 5955/10000; Iter 1/80; Loss: 0.3391
Epoch 5955/10000; Iter 51/80; Loss: 0.3336
Epoch 5955/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.052
Epoch 5956/10000; Iter 1/80; Loss: 0.4226
Epoch 5956/10000; Iter 51/80; Loss: 0.4138
Epoch 5956/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.058
Epoch 5957/10000; Iter 1/80; Loss: 0.3570
Epoch 5957/10000; Iter 51/80; Loss: 0.3123
Epoch 5957/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.056
Epoch 5958/10000; Iter 1/80; Loss: 0.3607
Epoch 5958/10000; Iter 51/80; Loss: 0.3254
Epoch 5958/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.055
Epoch 5959/10000; Iter 1/80; Loss: 0.3716
Epoch 5959/10000; Iter 51/80; Loss: 0.3854
Epoch 5959/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.055
Epoch 5960/10000; Iter 1/80; Loss: 0.3657
Epoch 5960/10000; Iter 51/80; Loss: 0.3647
Epoch 5960/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.049
Epoch 5961/10000; Iter 1/80; Loss: 0.3289
Epoch 5961/10000; Iter 51/80; Loss: 0.3437
Epoch 5961/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.056
Epoch 5962/10000; Iter 1/80; Loss: 0.3649
Epoch 5962/10000; Iter 51/80; Loss: 0.3729
Epoch 5962/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.06
Epoch 5963/10000; Iter 1/80; Loss: 0.3388
Epoch 5963/10000; Iter 51/80; Loss: 0.3746
Epoch 5963/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.049
Epoch 5964/10000; Iter 1/80; Loss: 0.3393
Epoch 5964/10000; Iter 51/80; Loss: 0.3556
Epoch 5964/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.048
Epoch 5965/10000; Iter 1/80; Loss: 0.3860
Epoch 5965/10000; Iter 51/80; Loss: 0.3535
Epoch 5965/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.052
Epoch 5966/10000; Iter 1/80; Loss: 0.3673
Epoch 5966/10000; Iter 51/80; Loss: 0.3397
Epoch 5966/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.046
Epoch 5967/10000; Iter 1/80; Loss: 0.3656
Epoch 5967/10000; Iter 51/80; Loss: 0.3263
Epoch 5967/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.047
Epoch 5968/10000; Iter 1/80; Loss: 0.4000
Epoch 5968/10000; Iter 51/80; Loss: 0.3703
Epoch 5968/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.056
Epoch 5969/10000; Iter 1/80; Loss: 0.3640
Epoch 5969/10000; Iter 51/80; Loss: 0.3534
Epoch 5969/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.046
Epoch 5970/10000; Iter 1/80; Loss: 0.3397
Epoch 5970/10000; Iter 51/80; Loss: 0.3581
Epoch 5970/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.051
Epoch 5971/10000; Iter 1/80; Loss: 0.3182
Epoch 5971/10000; Iter 51/80; Loss: 0.3647
Epoch 5971/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.054
Epoch 5972/10000; Iter 1/80; Loss: 0.3599
Epoch 5972/10000; Iter 51/80; Loss: 0.3244
Epoch 5972/10000; Iter 80/80; Training Loss: 0.3700, Test Loss: 0.054
Epoch 5973/10000; Iter 1/80; Loss: 0.3533
Epoch 5973/10000; Iter 51/80; Loss: 0.3529
Epoch 5973/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.057
Epoch 5974/10000; Iter 1/80; Loss: 0.4426
Epoch 5974/10000; Iter 51/80; Loss: 0.3641
Epoch 5974/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.069
Epoch 5975/10000; Iter 1/80; Loss: 0.3711
Epoch 5975/10000; Iter 51/80; Loss: 0.3632
Epoch 5975/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.059
Epoch 5976/10000; Iter 1/80; Loss: 0.3615
Epoch 5976/10000; Iter 51/80; Loss: 0.3580
Epoch 5976/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.054
Epoch 5977/10000; Iter 1/80; Loss: 0.3610
Epoch 5977/10000; Iter 51/80; Loss: 0.3611
Epoch 5977/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.061
Epoch 5978/10000; Iter 1/80; Loss: 0.3160
Epoch 5978/10000; Iter 51/80; Loss: 0.3312
Epoch 5978/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.052
Epoch 5979/10000; Iter 1/80; Loss: 0.3136
Epoch 5979/10000; Iter 51/80; Loss: 0.3381
Epoch 5979/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.053
Epoch 5980/10000; Iter 1/80; Loss: 0.3949
Epoch 5980/10000; Iter 51/80; Loss: 0.3383
Epoch 5980/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.059
Epoch 5981/10000; Iter 1/80; Loss: 0.3915
Epoch 5981/10000; Iter 51/80; Loss: 0.3949
Epoch 5981/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.053
Epoch 5982/10000; Iter 1/80; Loss: 0.4262
Epoch 5982/10000; Iter 51/80; Loss: 0.3751
Epoch 5982/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.05
Epoch 5983/10000; Iter 1/80; Loss: 0.3876
Epoch 5983/10000; Iter 51/80; Loss: 0.3652
Epoch 5983/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.051
Epoch 5984/10000; Iter 1/80; Loss: 0.4077
Epoch 5984/10000; Iter 51/80; Loss: 0.3854
Epoch 5984/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.058
Epoch 5985/10000; Iter 1/80; Loss: 0.3444
Epoch 5985/10000; Iter 51/80; Loss: 0.3784
Epoch 5985/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.047
Epoch 5986/10000; Iter 1/80; Loss: 0.3601
Epoch 5986/10000; Iter 51/80; Loss: 0.3609
Epoch 5986/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.056
Epoch 5987/10000; Iter 1/80; Loss: 0.3567
Epoch 5987/10000; Iter 51/80; Loss: 0.3904
Epoch 5987/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.053
Epoch 5988/10000; Iter 1/80; Loss: 0.3400
Epoch 5988/10000; Iter 51/80; Loss: 0.3837
Epoch 5988/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.051
Epoch 5989/10000; Iter 1/80; Loss: 0.3941
Epoch 5989/10000; Iter 51/80; Loss: 0.3760
Epoch 5989/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.053
Epoch 5990/10000; Iter 1/80; Loss: 0.3493
Epoch 5990/10000; Iter 51/80; Loss: 0.3985
Epoch 5990/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.063
Epoch 5991/10000; Iter 1/80; Loss: 0.2990
Epoch 5991/10000; Iter 51/80; Loss: 0.3588
Epoch 5991/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.05
Epoch 5992/10000; Iter 1/80; Loss: 0.4067
Epoch 5992/10000; Iter 51/80; Loss: 0.3154
Epoch 5992/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.057
Epoch 5993/10000; Iter 1/80; Loss: 0.3516
Epoch 5993/10000; Iter 51/80; Loss: 0.3229
Epoch 5993/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.055
Epoch 5994/10000; Iter 1/80; Loss: 0.3168
Epoch 5994/10000; Iter 51/80; Loss: 0.3852
Epoch 5994/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.053
Epoch 5995/10000; Iter 1/80; Loss: 0.3342
Epoch 5995/10000; Iter 51/80; Loss: 0.3170
Epoch 5995/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.052
Epoch 5996/10000; Iter 1/80; Loss: 0.3832
Epoch 5996/10000; Iter 51/80; Loss: 0.4429
Epoch 5996/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.056
Epoch 5997/10000; Iter 1/80; Loss: 0.3767
Epoch 5997/10000; Iter 51/80; Loss: 0.3784
Epoch 5997/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.052
Epoch 5998/10000; Iter 1/80; Loss: 0.3454
Epoch 5998/10000; Iter 51/80; Loss: 0.3890
Epoch 5998/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.053
Epoch 5999/10000; Iter 1/80; Loss: 0.3442
Epoch 5999/10000; Iter 51/80; Loss: 0.3335
Epoch 5999/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.057
Epoch 6000/10000; Iter 1/80; Loss: 0.3897
Epoch 6000/10000; Iter 51/80; Loss: 0.3150
Epoch 6000/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.05
Epoch 6001/10000; Iter 1/80; Loss: 0.3856
Epoch 6001/10000; Iter 51/80; Loss: 0.3658
Epoch 6001/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.054
Model saved
Epoch 6002/10000; Iter 1/80; Loss: 0.3801
Epoch 6002/10000; Iter 51/80; Loss: 0.4426
Epoch 6002/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.053
Epoch 6003/10000; Iter 1/80; Loss: 0.3554
Epoch 6003/10000; Iter 51/80; Loss: 0.3833
Epoch 6003/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.056
Epoch 6004/10000; Iter 1/80; Loss: 0.3635
Epoch 6004/10000; Iter 51/80; Loss: 0.3405
Epoch 6004/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.058
Epoch 6005/10000; Iter 1/80; Loss: 0.3844
Epoch 6005/10000; Iter 51/80; Loss: 0.4356
Epoch 6005/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.055
Epoch 6006/10000; Iter 1/80; Loss: 0.3590
Epoch 6006/10000; Iter 51/80; Loss: 0.3359
Epoch 6006/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.053
Epoch 6007/10000; Iter 1/80; Loss: 0.3467
Epoch 6007/10000; Iter 51/80; Loss: 0.3388
Epoch 6007/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.051
Epoch 6008/10000; Iter 1/80; Loss: 0.3564
Epoch 6008/10000; Iter 51/80; Loss: 0.3378
Epoch 6008/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.062
Epoch 6009/10000; Iter 1/80; Loss: 0.3370
Epoch 6009/10000; Iter 51/80; Loss: 0.3831
Epoch 6009/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.058
Epoch 6010/10000; Iter 1/80; Loss: 0.4057
Epoch 6010/10000; Iter 51/80; Loss: 0.3370
Epoch 6010/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.052
Epoch 6011/10000; Iter 1/80; Loss: 0.3985
Epoch 6011/10000; Iter 51/80; Loss: 0.3546
Epoch 6011/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.051
Epoch 6012/10000; Iter 1/80; Loss: 0.3463
Epoch 6012/10000; Iter 51/80; Loss: 0.3584
Epoch 6012/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.056
Epoch 6013/10000; Iter 1/80; Loss: 0.3372
Epoch 6013/10000; Iter 51/80; Loss: 0.3511
Epoch 6013/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.053
Epoch 6014/10000; Iter 1/80; Loss: 0.3413
Epoch 6014/10000; Iter 51/80; Loss: 0.3659
Epoch 6014/10000; Iter 80/80; Training Loss: 0.3730, Test Loss: 0.05
Epoch 6015/10000; Iter 1/80; Loss: 0.3633
Epoch 6015/10000; Iter 51/80; Loss: 0.3502
Epoch 6015/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.062
Epoch 6016/10000; Iter 1/80; Loss: 0.3548
Epoch 6016/10000; Iter 51/80; Loss: 0.3368
Epoch 6016/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.056
Epoch 6017/10000; Iter 1/80; Loss: 0.3378
Epoch 6017/10000; Iter 51/80; Loss: 0.3558
Epoch 6017/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.056
Epoch 6018/10000; Iter 1/80; Loss: 0.3413
Epoch 6018/10000; Iter 51/80; Loss: 0.3340
Epoch 6018/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.056
Epoch 6019/10000; Iter 1/80; Loss: 0.3430
Epoch 6019/10000; Iter 51/80; Loss: 0.3477
Epoch 6019/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.055
Epoch 6020/10000; Iter 1/80; Loss: 0.4498
Epoch 6020/10000; Iter 51/80; Loss: 0.3824
Epoch 6020/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.056
Epoch 6021/10000; Iter 1/80; Loss: 0.4178
Epoch 6021/10000; Iter 51/80; Loss: 0.3195
Epoch 6021/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.067
Epoch 6022/10000; Iter 1/80; Loss: 0.4330
Epoch 6022/10000; Iter 51/80; Loss: 0.3689
Epoch 6022/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.058
Epoch 6023/10000; Iter 1/80; Loss: 0.3707
Epoch 6023/10000; Iter 51/80; Loss: 0.3768
Epoch 6023/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.06
Epoch 6024/10000; Iter 1/80; Loss: 0.3846
Epoch 6024/10000; Iter 51/80; Loss: 0.3960
Epoch 6024/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.056
Epoch 6025/10000; Iter 1/80; Loss: 0.3509
Epoch 6025/10000; Iter 51/80; Loss: 0.3089
Epoch 6025/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.056
Epoch 6026/10000; Iter 1/80; Loss: 0.3675
Epoch 6026/10000; Iter 51/80; Loss: 0.4290
Epoch 6026/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.056
Epoch 6027/10000; Iter 1/80; Loss: 0.3819
Epoch 6027/10000; Iter 51/80; Loss: 0.3993
Epoch 6027/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.057
Epoch 6028/10000; Iter 1/80; Loss: 0.3989
Epoch 6028/10000; Iter 51/80; Loss: 0.3430
Epoch 6028/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.056
Epoch 6029/10000; Iter 1/80; Loss: 0.3437
Epoch 6029/10000; Iter 51/80; Loss: 0.3639
Epoch 6029/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.054
Epoch 6030/10000; Iter 1/80; Loss: 0.3143
Epoch 6030/10000; Iter 51/80; Loss: 0.4187
Epoch 6030/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.059
Epoch 6031/10000; Iter 1/80; Loss: 0.3857
Epoch 6031/10000; Iter 51/80; Loss: 0.3729
Epoch 6031/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.058
Epoch 6032/10000; Iter 1/80; Loss: 0.3477
Epoch 6032/10000; Iter 51/80; Loss: 0.3529
Epoch 6032/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.05
Epoch 6033/10000; Iter 1/80; Loss: 0.3064
Epoch 6033/10000; Iter 51/80; Loss: 0.3724
Epoch 6033/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.052
Epoch 6034/10000; Iter 1/80; Loss: 0.3890
Epoch 6034/10000; Iter 51/80; Loss: 0.3637
Epoch 6034/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.058
Epoch 6035/10000; Iter 1/80; Loss: 0.3454
Epoch 6035/10000; Iter 51/80; Loss: 0.3445
Epoch 6035/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.053
Epoch 6036/10000; Iter 1/80; Loss: 0.3877
Epoch 6036/10000; Iter 51/80; Loss: 0.3865
Epoch 6036/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.052
Epoch 6037/10000; Iter 1/80; Loss: 0.3338
Epoch 6037/10000; Iter 51/80; Loss: 0.3565
Epoch 6037/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.054
Epoch 6038/10000; Iter 1/80; Loss: 0.3384
Epoch 6038/10000; Iter 51/80; Loss: 0.3918
Epoch 6038/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.051
Epoch 6039/10000; Iter 1/80; Loss: 0.3641
Epoch 6039/10000; Iter 51/80; Loss: 0.3479
Epoch 6039/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.059
Epoch 6040/10000; Iter 1/80; Loss: 0.4140
Epoch 6040/10000; Iter 51/80; Loss: 0.3852
Epoch 6040/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.05
Epoch 6041/10000; Iter 1/80; Loss: 0.3809
Epoch 6041/10000; Iter 51/80; Loss: 0.3824
Epoch 6041/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.056
Epoch 6042/10000; Iter 1/80; Loss: 0.3410
Epoch 6042/10000; Iter 51/80; Loss: 0.3843
Epoch 6042/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.051
Epoch 6043/10000; Iter 1/80; Loss: 0.3710
Epoch 6043/10000; Iter 51/80; Loss: 0.3963
Epoch 6043/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.056
Epoch 6044/10000; Iter 1/80; Loss: 0.3459
Epoch 6044/10000; Iter 51/80; Loss: 0.3427
Epoch 6044/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.049
Epoch 6045/10000; Iter 1/80; Loss: 0.3411
Epoch 6045/10000; Iter 51/80; Loss: 0.3396
Epoch 6045/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.052
Epoch 6046/10000; Iter 1/80; Loss: 0.3631
Epoch 6046/10000; Iter 51/80; Loss: 0.3342
Epoch 6046/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.059
Epoch 6047/10000; Iter 1/80; Loss: 0.3409
Epoch 6047/10000; Iter 51/80; Loss: 0.3237
Epoch 6047/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.062
Epoch 6048/10000; Iter 1/80; Loss: 0.4030
Epoch 6048/10000; Iter 51/80; Loss: 0.3796
Epoch 6048/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.055
Epoch 6049/10000; Iter 1/80; Loss: 0.3564
Epoch 6049/10000; Iter 51/80; Loss: 0.3485
Epoch 6049/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.052
Epoch 6050/10000; Iter 1/80; Loss: 0.3483
Epoch 6050/10000; Iter 51/80; Loss: 0.3683
Epoch 6050/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.059
Epoch 6051/10000; Iter 1/80; Loss: 0.3543
Epoch 6051/10000; Iter 51/80; Loss: 0.4298
Epoch 6051/10000; Iter 80/80; Training Loss: 0.3670, Test Loss: 0.055
Epoch 6052/10000; Iter 1/80; Loss: 0.3862
Epoch 6052/10000; Iter 51/80; Loss: 0.4056
Epoch 6052/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.054
Epoch 6053/10000; Iter 1/80; Loss: 0.3761
Epoch 6053/10000; Iter 51/80; Loss: 0.3566
Epoch 6053/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.06
Epoch 6054/10000; Iter 1/80; Loss: 0.4042
Epoch 6054/10000; Iter 51/80; Loss: 0.3112
Epoch 6054/10000; Iter 80/80; Training Loss: 0.3690, Test Loss: 0.059
Epoch 6055/10000; Iter 1/80; Loss: 0.4129
Epoch 6055/10000; Iter 51/80; Loss: 0.3753
Epoch 6055/10000; Iter 80/80; Training Loss: 0.3710, Test Loss: 0.065
Epoch 6056/10000; Iter 1/80; Loss: 0.3725
Epoch 6056/10000; Iter 51/80; Loss: 0.3591
Epoch 6056/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.055
Epoch 6057/10000; Iter 1/80; Loss: 0.3435
Epoch 6057/10000; Iter 51/80; Loss: 0.3683
Epoch 6057/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.058
Epoch 6058/10000; Iter 1/80; Loss: 0.3780
Epoch 6058/10000; Iter 51/80; Loss: 0.3857
Epoch 6058/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.054
Epoch 6059/10000; Iter 1/80; Loss: 0.3811
Epoch 6059/10000; Iter 51/80; Loss: 0.3608
Epoch 6059/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.053
Epoch 6060/10000; Iter 1/80; Loss: 0.3321
Epoch 6060/10000; Iter 51/80; Loss: 0.3029
Epoch 6060/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.059
Epoch 6061/10000; Iter 1/80; Loss: 0.3966
Epoch 6061/10000; Iter 51/80; Loss: 0.3672
Epoch 6061/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.052
Epoch 6062/10000; Iter 1/80; Loss: 0.3676
Epoch 6062/10000; Iter 51/80; Loss: 0.4246
Epoch 6062/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.054
Epoch 6063/10000; Iter 1/80; Loss: 0.4016
Epoch 6063/10000; Iter 51/80; Loss: 0.3819
Epoch 6063/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.06
Epoch 6064/10000; Iter 1/80; Loss: 0.3330
Epoch 6064/10000; Iter 51/80; Loss: 0.3575
Epoch 6064/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.054
Epoch 6065/10000; Iter 1/80; Loss: 0.3601
Epoch 6065/10000; Iter 51/80; Loss: 0.3697
Epoch 6065/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.061
Epoch 6066/10000; Iter 1/80; Loss: 0.3535
Epoch 6066/10000; Iter 51/80; Loss: 0.3772
Epoch 6066/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.053
Epoch 6067/10000; Iter 1/80; Loss: 0.3633
Epoch 6067/10000; Iter 51/80; Loss: 0.3721
Epoch 6067/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.063
Epoch 6068/10000; Iter 1/80; Loss: 0.3447
Epoch 6068/10000; Iter 51/80; Loss: 0.3533
Epoch 6068/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.059
Epoch 6069/10000; Iter 1/80; Loss: 0.3368
Epoch 6069/10000; Iter 51/80; Loss: 0.3230
Epoch 6069/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.052
Epoch 6070/10000; Iter 1/80; Loss: 0.3634
Epoch 6070/10000; Iter 51/80; Loss: 0.3699
Epoch 6070/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.055
Epoch 6071/10000; Iter 1/80; Loss: 0.3406
Epoch 6071/10000; Iter 51/80; Loss: 0.4176
Epoch 6071/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.061
Epoch 6072/10000; Iter 1/80; Loss: 0.3160
Epoch 6072/10000; Iter 51/80; Loss: 0.3886
Epoch 6072/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.056
Epoch 6073/10000; Iter 1/80; Loss: 0.3892
Epoch 6073/10000; Iter 51/80; Loss: 0.4201
Epoch 6073/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.059
Epoch 6074/10000; Iter 1/80; Loss: 0.3198
Epoch 6074/10000; Iter 51/80; Loss: 0.3299
Epoch 6074/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.056
Epoch 6075/10000; Iter 1/80; Loss: 0.3617
Epoch 6075/10000; Iter 51/80; Loss: 0.4088
Epoch 6075/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.061
Epoch 6076/10000; Iter 1/80; Loss: 0.3361
Epoch 6076/10000; Iter 51/80; Loss: 0.3724
Epoch 6076/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.057
Epoch 6077/10000; Iter 1/80; Loss: 0.3404
Epoch 6077/10000; Iter 51/80; Loss: 0.3286
Epoch 6077/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.06
Epoch 6078/10000; Iter 1/80; Loss: 0.3301
Epoch 6078/10000; Iter 51/80; Loss: 0.3754
Epoch 6078/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.06
Epoch 6079/10000; Iter 1/80; Loss: 0.3666
Epoch 6079/10000; Iter 51/80; Loss: 0.3130
Epoch 6079/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.053
Epoch 6080/10000; Iter 1/80; Loss: 0.4782
Epoch 6080/10000; Iter 51/80; Loss: 0.3566
Epoch 6080/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.051
Epoch 6081/10000; Iter 1/80; Loss: 0.3502
Epoch 6081/10000; Iter 51/80; Loss: 0.3351
Epoch 6081/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.055
Epoch 6082/10000; Iter 1/80; Loss: 0.3548
Epoch 6082/10000; Iter 51/80; Loss: 0.4076
Epoch 6082/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.063
Epoch 6083/10000; Iter 1/80; Loss: 0.4056
Epoch 6083/10000; Iter 51/80; Loss: 0.3853
Epoch 6083/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.057
Epoch 6084/10000; Iter 1/80; Loss: 0.3276
Epoch 6084/10000; Iter 51/80; Loss: 0.3460
Epoch 6084/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.056
Epoch 6085/10000; Iter 1/80; Loss: 0.3638
Epoch 6085/10000; Iter 51/80; Loss: 0.3060
Epoch 6085/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.058
Epoch 6086/10000; Iter 1/80; Loss: 0.3426
Epoch 6086/10000; Iter 51/80; Loss: 0.3637
Epoch 6086/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.059
Epoch 6087/10000; Iter 1/80; Loss: 0.3560
Epoch 6087/10000; Iter 51/80; Loss: 0.4540
Epoch 6087/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.058
Epoch 6088/10000; Iter 1/80; Loss: 0.3737
Epoch 6088/10000; Iter 51/80; Loss: 0.3578
Epoch 6088/10000; Iter 80/80; Training Loss: 0.3680, Test Loss: 0.056
Epoch 6089/10000; Iter 1/80; Loss: 0.3201
Epoch 6089/10000; Iter 51/80; Loss: 0.3785
Epoch 6089/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.055
Epoch 6090/10000; Iter 1/80; Loss: 0.3508
Epoch 6090/10000; Iter 51/80; Loss: 0.3287
Epoch 6090/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.055
Epoch 6091/10000; Iter 1/80; Loss: 0.3370
Epoch 6091/10000; Iter 51/80; Loss: 0.3783
Epoch 6091/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.058
Epoch 6092/10000; Iter 1/80; Loss: 0.3347
Epoch 6092/10000; Iter 51/80; Loss: 0.4088
Epoch 6092/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.052
Epoch 6093/10000; Iter 1/80; Loss: 0.3229
Epoch 6093/10000; Iter 51/80; Loss: 0.3612
Epoch 6093/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.057
Epoch 6094/10000; Iter 1/80; Loss: 0.3108
Epoch 6094/10000; Iter 51/80; Loss: 0.3452
Epoch 6094/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.059
Epoch 6095/10000; Iter 1/80; Loss: 0.4145
Epoch 6095/10000; Iter 51/80; Loss: 0.3726
Epoch 6095/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.066
Epoch 6096/10000; Iter 1/80; Loss: 0.3627
Epoch 6096/10000; Iter 51/80; Loss: 0.3357
Epoch 6096/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.055
Epoch 6097/10000; Iter 1/80; Loss: 0.3674
Epoch 6097/10000; Iter 51/80; Loss: 0.3703
Epoch 6097/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.062
Epoch 6098/10000; Iter 1/80; Loss: 0.3730
Epoch 6098/10000; Iter 51/80; Loss: 0.4085
Epoch 6098/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.057
Epoch 6099/10000; Iter 1/80; Loss: 0.4034
Epoch 6099/10000; Iter 51/80; Loss: 0.3780
Epoch 6099/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.057
Epoch 6100/10000; Iter 1/80; Loss: 0.3436
Epoch 6100/10000; Iter 51/80; Loss: 0.3288
Epoch 6100/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.058
Epoch 6101/10000; Iter 1/80; Loss: 0.3435
Epoch 6101/10000; Iter 51/80; Loss: 0.3654
Epoch 6101/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.062
Model saved
Epoch 6102/10000; Iter 1/80; Loss: 0.2983
Epoch 6102/10000; Iter 51/80; Loss: 0.3856
Epoch 6102/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.06
Epoch 6103/10000; Iter 1/80; Loss: 0.3369
Epoch 6103/10000; Iter 51/80; Loss: 0.3393
Epoch 6103/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.062
Epoch 6104/10000; Iter 1/80; Loss: 0.3676
Epoch 6104/10000; Iter 51/80; Loss: 0.4187
Epoch 6104/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.055
Epoch 6105/10000; Iter 1/80; Loss: 0.3360
Epoch 6105/10000; Iter 51/80; Loss: 0.3621
Epoch 6105/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.051
Epoch 6106/10000; Iter 1/80; Loss: 0.3852
Epoch 6106/10000; Iter 51/80; Loss: 0.3350
Epoch 6106/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.056
Epoch 6107/10000; Iter 1/80; Loss: 0.3115
Epoch 6107/10000; Iter 51/80; Loss: 0.2873
Epoch 6107/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.057
Epoch 6108/10000; Iter 1/80; Loss: 0.3482
Epoch 6108/10000; Iter 51/80; Loss: 0.3511
Epoch 6108/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.055
Epoch 6109/10000; Iter 1/80; Loss: 0.3371
Epoch 6109/10000; Iter 51/80; Loss: 0.3398
Epoch 6109/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.058
Epoch 6110/10000; Iter 1/80; Loss: 0.3891
Epoch 6110/10000; Iter 51/80; Loss: 0.3258
Epoch 6110/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.052
Epoch 6111/10000; Iter 1/80; Loss: 0.3957
Epoch 6111/10000; Iter 51/80; Loss: 0.3409
Epoch 6111/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.057
Epoch 6112/10000; Iter 1/80; Loss: 0.3310
Epoch 6112/10000; Iter 51/80; Loss: 0.3536
Epoch 6112/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.054
Epoch 6113/10000; Iter 1/80; Loss: 0.3027
Epoch 6113/10000; Iter 51/80; Loss: 0.3336
Epoch 6113/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.059
Epoch 6114/10000; Iter 1/80; Loss: 0.3566
Epoch 6114/10000; Iter 51/80; Loss: 0.3675
Epoch 6114/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.057
Epoch 6115/10000; Iter 1/80; Loss: 0.2905
Epoch 6115/10000; Iter 51/80; Loss: 0.3411
Epoch 6115/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.056
Epoch 6116/10000; Iter 1/80; Loss: 0.3398
Epoch 6116/10000; Iter 51/80; Loss: 0.3844
Epoch 6116/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.056
Epoch 6117/10000; Iter 1/80; Loss: 0.3368
Epoch 6117/10000; Iter 51/80; Loss: 0.4317
Epoch 6117/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.051
Epoch 6118/10000; Iter 1/80; Loss: 0.3828
Epoch 6118/10000; Iter 51/80; Loss: 0.3438
Epoch 6118/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.06
Epoch 6119/10000; Iter 1/80; Loss: 0.4265
Epoch 6119/10000; Iter 51/80; Loss: 0.4060
Epoch 6119/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.06
Epoch 6120/10000; Iter 1/80; Loss: 0.3373
Epoch 6120/10000; Iter 51/80; Loss: 0.2895
Epoch 6120/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.056
Epoch 6121/10000; Iter 1/80; Loss: 0.3702
Epoch 6121/10000; Iter 51/80; Loss: 0.3728
Epoch 6121/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.065
Epoch 6122/10000; Iter 1/80; Loss: 0.4482
Epoch 6122/10000; Iter 51/80; Loss: 0.2996
Epoch 6122/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.061
Epoch 6123/10000; Iter 1/80; Loss: 0.3244
Epoch 6123/10000; Iter 51/80; Loss: 0.3627
Epoch 6123/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.058
Epoch 6124/10000; Iter 1/80; Loss: 0.3759
Epoch 6124/10000; Iter 51/80; Loss: 0.3810
Epoch 6124/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.059
Epoch 6125/10000; Iter 1/80; Loss: 0.3458
Epoch 6125/10000; Iter 51/80; Loss: 0.3480
Epoch 6125/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.061
Epoch 6126/10000; Iter 1/80; Loss: 0.3963
Epoch 6126/10000; Iter 51/80; Loss: 0.3486
Epoch 6126/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.057
Epoch 6127/10000; Iter 1/80; Loss: 0.3541
Epoch 6127/10000; Iter 51/80; Loss: 0.3442
Epoch 6127/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.054
Epoch 6128/10000; Iter 1/80; Loss: 0.4253
Epoch 6128/10000; Iter 51/80; Loss: 0.4094
Epoch 6128/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.059
Epoch 6129/10000; Iter 1/80; Loss: 0.4068
Epoch 6129/10000; Iter 51/80; Loss: 0.3163
Epoch 6129/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.055
Epoch 6130/10000; Iter 1/80; Loss: 0.3245
Epoch 6130/10000; Iter 51/80; Loss: 0.3683
Epoch 6130/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.049
Epoch 6131/10000; Iter 1/80; Loss: 0.3910
Epoch 6131/10000; Iter 51/80; Loss: 0.2837
Epoch 6131/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.057
Epoch 6132/10000; Iter 1/80; Loss: 0.3028
Epoch 6132/10000; Iter 51/80; Loss: 0.3517
Epoch 6132/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.056
Epoch 6133/10000; Iter 1/80; Loss: 0.3948
Epoch 6133/10000; Iter 51/80; Loss: 0.3737
Epoch 6133/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.063
Epoch 6134/10000; Iter 1/80; Loss: 0.2906
Epoch 6134/10000; Iter 51/80; Loss: 0.3560
Epoch 6134/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.058
Epoch 6135/10000; Iter 1/80; Loss: 0.4052
Epoch 6135/10000; Iter 51/80; Loss: 0.3416
Epoch 6135/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.058
Epoch 6136/10000; Iter 1/80; Loss: 0.3932
Epoch 6136/10000; Iter 51/80; Loss: 0.3084
Epoch 6136/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.055
Epoch 6137/10000; Iter 1/80; Loss: 0.3479
Epoch 6137/10000; Iter 51/80; Loss: 0.4039
Epoch 6137/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.056
Epoch 6138/10000; Iter 1/80; Loss: 0.3354
Epoch 6138/10000; Iter 51/80; Loss: 0.3946
Epoch 6138/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.057
Epoch 6139/10000; Iter 1/80; Loss: 0.3486
Epoch 6139/10000; Iter 51/80; Loss: 0.3637
Epoch 6139/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.062
Epoch 6140/10000; Iter 1/80; Loss: 0.3315
Epoch 6140/10000; Iter 51/80; Loss: 0.3508
Epoch 6140/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.053
Epoch 6141/10000; Iter 1/80; Loss: 0.4017
Epoch 6141/10000; Iter 51/80; Loss: 0.3191
Epoch 6141/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6142/10000; Iter 1/80; Loss: 0.3157
Epoch 6142/10000; Iter 51/80; Loss: 0.3659
Epoch 6142/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.059
Epoch 6143/10000; Iter 1/80; Loss: 0.3766
Epoch 6143/10000; Iter 51/80; Loss: 0.3405
Epoch 6143/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.058
Epoch 6144/10000; Iter 1/80; Loss: 0.3723
Epoch 6144/10000; Iter 51/80; Loss: 0.3624
Epoch 6144/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.064
Epoch 6145/10000; Iter 1/80; Loss: 0.3972
Epoch 6145/10000; Iter 51/80; Loss: 0.4305
Epoch 6145/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.057
Epoch 6146/10000; Iter 1/80; Loss: 0.3381
Epoch 6146/10000; Iter 51/80; Loss: 0.3302
Epoch 6146/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.06
Epoch 6147/10000; Iter 1/80; Loss: 0.4076
Epoch 6147/10000; Iter 51/80; Loss: 0.3815
Epoch 6147/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.061
Epoch 6148/10000; Iter 1/80; Loss: 0.3175
Epoch 6148/10000; Iter 51/80; Loss: 0.3495
Epoch 6148/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.065
Epoch 6149/10000; Iter 1/80; Loss: 0.3673
Epoch 6149/10000; Iter 51/80; Loss: 0.3458
Epoch 6149/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.061
Epoch 6150/10000; Iter 1/80; Loss: 0.4181
Epoch 6150/10000; Iter 51/80; Loss: 0.3534
Epoch 6150/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.059
Epoch 6151/10000; Iter 1/80; Loss: 0.3875
Epoch 6151/10000; Iter 51/80; Loss: 0.3702
Epoch 6151/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.056
Epoch 6152/10000; Iter 1/80; Loss: 0.3700
Epoch 6152/10000; Iter 51/80; Loss: 0.3389
Epoch 6152/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.051
Epoch 6153/10000; Iter 1/80; Loss: 0.3418
Epoch 6153/10000; Iter 51/80; Loss: 0.3578
Epoch 6153/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.055
Epoch 6154/10000; Iter 1/80; Loss: 0.3481
Epoch 6154/10000; Iter 51/80; Loss: 0.3661
Epoch 6154/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.058
Epoch 6155/10000; Iter 1/80; Loss: 0.3820
Epoch 6155/10000; Iter 51/80; Loss: 0.3401
Epoch 6155/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.059
Epoch 6156/10000; Iter 1/80; Loss: 0.4242
Epoch 6156/10000; Iter 51/80; Loss: 0.3557
Epoch 6156/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.06
Epoch 6157/10000; Iter 1/80; Loss: 0.2961
Epoch 6157/10000; Iter 51/80; Loss: 0.3253
Epoch 6157/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.053
Epoch 6158/10000; Iter 1/80; Loss: 0.3246
Epoch 6158/10000; Iter 51/80; Loss: 0.4663
Epoch 6158/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.059
Epoch 6159/10000; Iter 1/80; Loss: 0.3736
Epoch 6159/10000; Iter 51/80; Loss: 0.3572
Epoch 6159/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.053
Epoch 6160/10000; Iter 1/80; Loss: 0.3751
Epoch 6160/10000; Iter 51/80; Loss: 0.3746
Epoch 6160/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.06
Epoch 6161/10000; Iter 1/80; Loss: 0.3574
Epoch 6161/10000; Iter 51/80; Loss: 0.3180
Epoch 6161/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.061
Epoch 6162/10000; Iter 1/80; Loss: 0.3577
Epoch 6162/10000; Iter 51/80; Loss: 0.3580
Epoch 6162/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.062
Epoch 6163/10000; Iter 1/80; Loss: 0.3759
Epoch 6163/10000; Iter 51/80; Loss: 0.3593
Epoch 6163/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.058
Epoch 6164/10000; Iter 1/80; Loss: 0.3295
Epoch 6164/10000; Iter 51/80; Loss: 0.3789
Epoch 6164/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.053
Epoch 6165/10000; Iter 1/80; Loss: 0.3508
Epoch 6165/10000; Iter 51/80; Loss: 0.3322
Epoch 6165/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.062
Epoch 6166/10000; Iter 1/80; Loss: 0.3940
Epoch 6166/10000; Iter 51/80; Loss: 0.3911
Epoch 6166/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.055
Epoch 6167/10000; Iter 1/80; Loss: 0.3964
Epoch 6167/10000; Iter 51/80; Loss: 0.3180
Epoch 6167/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.062
Epoch 6168/10000; Iter 1/80; Loss: 0.3661
Epoch 6168/10000; Iter 51/80; Loss: 0.3450
Epoch 6168/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.057
Epoch 6169/10000; Iter 1/80; Loss: 0.3858
Epoch 6169/10000; Iter 51/80; Loss: 0.3660
Epoch 6169/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.064
Epoch 6170/10000; Iter 1/80; Loss: 0.3577
Epoch 6170/10000; Iter 51/80; Loss: 0.3830
Epoch 6170/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.063
Epoch 6171/10000; Iter 1/80; Loss: 0.3579
Epoch 6171/10000; Iter 51/80; Loss: 0.3550
Epoch 6171/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.064
Epoch 6172/10000; Iter 1/80; Loss: 0.3440
Epoch 6172/10000; Iter 51/80; Loss: 0.3549
Epoch 6172/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.062
Epoch 6173/10000; Iter 1/80; Loss: 0.3462
Epoch 6173/10000; Iter 51/80; Loss: 0.3551
Epoch 6173/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.061
Epoch 6174/10000; Iter 1/80; Loss: 0.3900
Epoch 6174/10000; Iter 51/80; Loss: 0.3494
Epoch 6174/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6175/10000; Iter 1/80; Loss: 0.3455
Epoch 6175/10000; Iter 51/80; Loss: 0.3842
Epoch 6175/10000; Iter 80/80; Training Loss: 0.3640, Test Loss: 0.057
Epoch 6176/10000; Iter 1/80; Loss: 0.3083
Epoch 6176/10000; Iter 51/80; Loss: 0.3219
Epoch 6176/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.067
Epoch 6177/10000; Iter 1/80; Loss: 0.3283
Epoch 6177/10000; Iter 51/80; Loss: 0.3015
Epoch 6177/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.064
Epoch 6178/10000; Iter 1/80; Loss: 0.3541
Epoch 6178/10000; Iter 51/80; Loss: 0.3542
Epoch 6178/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.06
Epoch 6179/10000; Iter 1/80; Loss: 0.4786
Epoch 6179/10000; Iter 51/80; Loss: 0.3646
Epoch 6179/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.069
Epoch 6180/10000; Iter 1/80; Loss: 0.3371
Epoch 6180/10000; Iter 51/80; Loss: 0.3454
Epoch 6180/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.056
Epoch 6181/10000; Iter 1/80; Loss: 0.4198
Epoch 6181/10000; Iter 51/80; Loss: 0.3592
Epoch 6181/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.061
Epoch 6182/10000; Iter 1/80; Loss: 0.3180
Epoch 6182/10000; Iter 51/80; Loss: 0.3068
Epoch 6182/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.066
Epoch 6183/10000; Iter 1/80; Loss: 0.3920
Epoch 6183/10000; Iter 51/80; Loss: 0.3817
Epoch 6183/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.057
Epoch 6184/10000; Iter 1/80; Loss: 0.3410
Epoch 6184/10000; Iter 51/80; Loss: 0.3803
Epoch 6184/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.067
Epoch 6185/10000; Iter 1/80; Loss: 0.3198
Epoch 6185/10000; Iter 51/80; Loss: 0.3529
Epoch 6185/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.062
Epoch 6186/10000; Iter 1/80; Loss: 0.3690
Epoch 6186/10000; Iter 51/80; Loss: 0.2688
Epoch 6186/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.057
Epoch 6187/10000; Iter 1/80; Loss: 0.3129
Epoch 6187/10000; Iter 51/80; Loss: 0.3432
Epoch 6187/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.057
Epoch 6188/10000; Iter 1/80; Loss: 0.3581
Epoch 6188/10000; Iter 51/80; Loss: 0.3055
Epoch 6188/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.06
Epoch 6189/10000; Iter 1/80; Loss: 0.3383
Epoch 6189/10000; Iter 51/80; Loss: 0.3832
Epoch 6189/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.055
Epoch 6190/10000; Iter 1/80; Loss: 0.3436
Epoch 6190/10000; Iter 51/80; Loss: 0.4045
Epoch 6190/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.058
Epoch 6191/10000; Iter 1/80; Loss: 0.4388
Epoch 6191/10000; Iter 51/80; Loss: 0.3409
Epoch 6191/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.063
Epoch 6192/10000; Iter 1/80; Loss: 0.3445
Epoch 6192/10000; Iter 51/80; Loss: 0.3777
Epoch 6192/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.063
Epoch 6193/10000; Iter 1/80; Loss: 0.3041
Epoch 6193/10000; Iter 51/80; Loss: 0.3785
Epoch 6193/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.054
Epoch 6194/10000; Iter 1/80; Loss: 0.3445
Epoch 6194/10000; Iter 51/80; Loss: 0.3676
Epoch 6194/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.064
Epoch 6195/10000; Iter 1/80; Loss: 0.3239
Epoch 6195/10000; Iter 51/80; Loss: 0.3992
Epoch 6195/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.06
Epoch 6196/10000; Iter 1/80; Loss: 0.3427
Epoch 6196/10000; Iter 51/80; Loss: 0.3558
Epoch 6196/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.062
Epoch 6197/10000; Iter 1/80; Loss: 0.3853
Epoch 6197/10000; Iter 51/80; Loss: 0.3408
Epoch 6197/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.064
Epoch 6198/10000; Iter 1/80; Loss: 0.3445
Epoch 6198/10000; Iter 51/80; Loss: 0.3930
Epoch 6198/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.061
Epoch 6199/10000; Iter 1/80; Loss: 0.3411
Epoch 6199/10000; Iter 51/80; Loss: 0.3993
Epoch 6199/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.057
Epoch 6200/10000; Iter 1/80; Loss: 0.3959
Epoch 6200/10000; Iter 51/80; Loss: 0.3316
Epoch 6200/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.066
Epoch 6201/10000; Iter 1/80; Loss: 0.3881
Epoch 6201/10000; Iter 51/80; Loss: 0.4276
Epoch 6201/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.062
Model saved
Epoch 6202/10000; Iter 1/80; Loss: 0.2837
Epoch 6202/10000; Iter 51/80; Loss: 0.3491
Epoch 6202/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.065
Epoch 6203/10000; Iter 1/80; Loss: 0.3335
Epoch 6203/10000; Iter 51/80; Loss: 0.3083
Epoch 6203/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.063
Epoch 6204/10000; Iter 1/80; Loss: 0.3823
Epoch 6204/10000; Iter 51/80; Loss: 0.3568
Epoch 6204/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.056
Epoch 6205/10000; Iter 1/80; Loss: 0.3624
Epoch 6205/10000; Iter 51/80; Loss: 0.3366
Epoch 6205/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6206/10000; Iter 1/80; Loss: 0.3117
Epoch 6206/10000; Iter 51/80; Loss: 0.3323
Epoch 6206/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.055
Epoch 6207/10000; Iter 1/80; Loss: 0.3486
Epoch 6207/10000; Iter 51/80; Loss: 0.3425
Epoch 6207/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6208/10000; Iter 1/80; Loss: 0.4014
Epoch 6208/10000; Iter 51/80; Loss: 0.3813
Epoch 6208/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.052
Epoch 6209/10000; Iter 1/80; Loss: 0.3416
Epoch 6209/10000; Iter 51/80; Loss: 0.3804
Epoch 6209/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.066
Epoch 6210/10000; Iter 1/80; Loss: 0.3416
Epoch 6210/10000; Iter 51/80; Loss: 0.3259
Epoch 6210/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.06
Epoch 6211/10000; Iter 1/80; Loss: 0.3314
Epoch 6211/10000; Iter 51/80; Loss: 0.3492
Epoch 6211/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.057
Epoch 6212/10000; Iter 1/80; Loss: 0.3442
Epoch 6212/10000; Iter 51/80; Loss: 0.3477
Epoch 6212/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.066
Epoch 6213/10000; Iter 1/80; Loss: 0.3768
Epoch 6213/10000; Iter 51/80; Loss: 0.3894
Epoch 6213/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.056
Epoch 6214/10000; Iter 1/80; Loss: 0.3769
Epoch 6214/10000; Iter 51/80; Loss: 0.3332
Epoch 6214/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.056
Epoch 6215/10000; Iter 1/80; Loss: 0.3624
Epoch 6215/10000; Iter 51/80; Loss: 0.3415
Epoch 6215/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.059
Epoch 6216/10000; Iter 1/80; Loss: 0.3654
Epoch 6216/10000; Iter 51/80; Loss: 0.3233
Epoch 6216/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.06
Epoch 6217/10000; Iter 1/80; Loss: 0.4737
Epoch 6217/10000; Iter 51/80; Loss: 0.3481
Epoch 6217/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.061
Epoch 6218/10000; Iter 1/80; Loss: 0.4707
Epoch 6218/10000; Iter 51/80; Loss: 0.2995
Epoch 6218/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.058
Epoch 6219/10000; Iter 1/80; Loss: 0.3755
Epoch 6219/10000; Iter 51/80; Loss: 0.3244
Epoch 6219/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.06
Epoch 6220/10000; Iter 1/80; Loss: 0.3687
Epoch 6220/10000; Iter 51/80; Loss: 0.3535
Epoch 6220/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6221/10000; Iter 1/80; Loss: 0.2999
Epoch 6221/10000; Iter 51/80; Loss: 0.2692
Epoch 6221/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.06
Epoch 6222/10000; Iter 1/80; Loss: 0.3893
Epoch 6222/10000; Iter 51/80; Loss: 0.3226
Epoch 6222/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.06
Epoch 6223/10000; Iter 1/80; Loss: 0.3329
Epoch 6223/10000; Iter 51/80; Loss: 0.3872
Epoch 6223/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.063
Epoch 6224/10000; Iter 1/80; Loss: 0.2968
Epoch 6224/10000; Iter 51/80; Loss: 0.3435
Epoch 6224/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.058
Epoch 6225/10000; Iter 1/80; Loss: 0.3501
Epoch 6225/10000; Iter 51/80; Loss: 0.3456
Epoch 6225/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.061
Epoch 6226/10000; Iter 1/80; Loss: 0.3730
Epoch 6226/10000; Iter 51/80; Loss: 0.3030
Epoch 6226/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.061
Epoch 6227/10000; Iter 1/80; Loss: 0.3512
Epoch 6227/10000; Iter 51/80; Loss: 0.3354
Epoch 6227/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.068
Epoch 6228/10000; Iter 1/80; Loss: 0.3468
Epoch 6228/10000; Iter 51/80; Loss: 0.3535
Epoch 6228/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.057
Epoch 6229/10000; Iter 1/80; Loss: 0.3097
Epoch 6229/10000; Iter 51/80; Loss: 0.3105
Epoch 6229/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.061
Epoch 6230/10000; Iter 1/80; Loss: 0.3432
Epoch 6230/10000; Iter 51/80; Loss: 0.3389
Epoch 6230/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.057
Epoch 6231/10000; Iter 1/80; Loss: 0.3512
Epoch 6231/10000; Iter 51/80; Loss: 0.3839
Epoch 6231/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.069
Epoch 6232/10000; Iter 1/80; Loss: 0.3776
Epoch 6232/10000; Iter 51/80; Loss: 0.3344
Epoch 6232/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.059
Epoch 6233/10000; Iter 1/80; Loss: 0.3939
Epoch 6233/10000; Iter 51/80; Loss: 0.3830
Epoch 6233/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.055
Epoch 6234/10000; Iter 1/80; Loss: 0.3612
Epoch 6234/10000; Iter 51/80; Loss: 0.3380
Epoch 6234/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.062
Epoch 6235/10000; Iter 1/80; Loss: 0.2827
Epoch 6235/10000; Iter 51/80; Loss: 0.3836
Epoch 6235/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.066
Epoch 6236/10000; Iter 1/80; Loss: 0.3576
Epoch 6236/10000; Iter 51/80; Loss: 0.3666
Epoch 6236/10000; Iter 80/80; Training Loss: 0.3650, Test Loss: 0.062
Epoch 6237/10000; Iter 1/80; Loss: 0.3985
Epoch 6237/10000; Iter 51/80; Loss: 0.3666
Epoch 6237/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.057
Epoch 6238/10000; Iter 1/80; Loss: 0.3443
Epoch 6238/10000; Iter 51/80; Loss: 0.3917
Epoch 6238/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6239/10000; Iter 1/80; Loss: 0.3787
Epoch 6239/10000; Iter 51/80; Loss: 0.3746
Epoch 6239/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.059
Epoch 6240/10000; Iter 1/80; Loss: 0.3382
Epoch 6240/10000; Iter 51/80; Loss: 0.2790
Epoch 6240/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.064
Epoch 6241/10000; Iter 1/80; Loss: 0.3386
Epoch 6241/10000; Iter 51/80; Loss: 0.3523
Epoch 6241/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.061
Epoch 6242/10000; Iter 1/80; Loss: 0.3751
Epoch 6242/10000; Iter 51/80; Loss: 0.3763
Epoch 6242/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.059
Epoch 6243/10000; Iter 1/80; Loss: 0.3423
Epoch 6243/10000; Iter 51/80; Loss: 0.3628
Epoch 6243/10000; Iter 80/80; Training Loss: 0.3620, Test Loss: 0.053
Epoch 6244/10000; Iter 1/80; Loss: 0.3834
Epoch 6244/10000; Iter 51/80; Loss: 0.3718
Epoch 6244/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.054
Epoch 6245/10000; Iter 1/80; Loss: 0.3415
Epoch 6245/10000; Iter 51/80; Loss: 0.3218
Epoch 6245/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.065
Epoch 6246/10000; Iter 1/80; Loss: 0.3517
Epoch 6246/10000; Iter 51/80; Loss: 0.4276
Epoch 6246/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6247/10000; Iter 1/80; Loss: 0.3739
Epoch 6247/10000; Iter 51/80; Loss: 0.3814
Epoch 6247/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.063
Epoch 6248/10000; Iter 1/80; Loss: 0.3679
Epoch 6248/10000; Iter 51/80; Loss: 0.3665
Epoch 6248/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6249/10000; Iter 1/80; Loss: 0.3243
Epoch 6249/10000; Iter 51/80; Loss: 0.3649
Epoch 6249/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.059
Epoch 6250/10000; Iter 1/80; Loss: 0.4042
Epoch 6250/10000; Iter 51/80; Loss: 0.3884
Epoch 6250/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.059
Epoch 6251/10000; Iter 1/80; Loss: 0.3764
Epoch 6251/10000; Iter 51/80; Loss: 0.3537
Epoch 6251/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.064
Epoch 6252/10000; Iter 1/80; Loss: 0.3607
Epoch 6252/10000; Iter 51/80; Loss: 0.3146
Epoch 6252/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.061
Epoch 6253/10000; Iter 1/80; Loss: 0.3578
Epoch 6253/10000; Iter 51/80; Loss: 0.3577
Epoch 6253/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.06
Epoch 6254/10000; Iter 1/80; Loss: 0.3498
Epoch 6254/10000; Iter 51/80; Loss: 0.3395
Epoch 6254/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.056
Epoch 6255/10000; Iter 1/80; Loss: 0.3558
Epoch 6255/10000; Iter 51/80; Loss: 0.4734
Epoch 6255/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.062
Epoch 6256/10000; Iter 1/80; Loss: 0.3618
Epoch 6256/10000; Iter 51/80; Loss: 0.3226
Epoch 6256/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.061
Epoch 6257/10000; Iter 1/80; Loss: 0.3415
Epoch 6257/10000; Iter 51/80; Loss: 0.3781
Epoch 6257/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.059
Epoch 6258/10000; Iter 1/80; Loss: 0.3167
Epoch 6258/10000; Iter 51/80; Loss: 0.3474
Epoch 6258/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.057
Epoch 6259/10000; Iter 1/80; Loss: 0.3621
Epoch 6259/10000; Iter 51/80; Loss: 0.2847
Epoch 6259/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.063
Epoch 6260/10000; Iter 1/80; Loss: 0.3818
Epoch 6260/10000; Iter 51/80; Loss: 0.3699
Epoch 6260/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.057
Epoch 6261/10000; Iter 1/80; Loss: 0.3511
Epoch 6261/10000; Iter 51/80; Loss: 0.3631
Epoch 6261/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.064
Epoch 6262/10000; Iter 1/80; Loss: 0.3245
Epoch 6262/10000; Iter 51/80; Loss: 0.3627
Epoch 6262/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.059
Epoch 6263/10000; Iter 1/80; Loss: 0.4127
Epoch 6263/10000; Iter 51/80; Loss: 0.3023
Epoch 6263/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.063
Epoch 6264/10000; Iter 1/80; Loss: 0.3888
Epoch 6264/10000; Iter 51/80; Loss: 0.4418
Epoch 6264/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.06
Epoch 6265/10000; Iter 1/80; Loss: 0.3236
Epoch 6265/10000; Iter 51/80; Loss: 0.3182
Epoch 6265/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.061
Epoch 6266/10000; Iter 1/80; Loss: 0.3431
Epoch 6266/10000; Iter 51/80; Loss: 0.3225
Epoch 6266/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.065
Epoch 6267/10000; Iter 1/80; Loss: 0.3457
Epoch 6267/10000; Iter 51/80; Loss: 0.3848
Epoch 6267/10000; Iter 80/80; Training Loss: 0.3660, Test Loss: 0.059
Epoch 6268/10000; Iter 1/80; Loss: 0.3800
Epoch 6268/10000; Iter 51/80; Loss: 0.3824
Epoch 6268/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.058
Epoch 6269/10000; Iter 1/80; Loss: 0.3241
Epoch 6269/10000; Iter 51/80; Loss: 0.3497
Epoch 6269/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.063
Epoch 6270/10000; Iter 1/80; Loss: 0.3856
Epoch 6270/10000; Iter 51/80; Loss: 0.4099
Epoch 6270/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6271/10000; Iter 1/80; Loss: 0.3565
Epoch 6271/10000; Iter 51/80; Loss: 0.3377
Epoch 6271/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.057
Epoch 6272/10000; Iter 1/80; Loss: 0.3796
Epoch 6272/10000; Iter 51/80; Loss: 0.3832
Epoch 6272/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.058
Epoch 6273/10000; Iter 1/80; Loss: 0.4399
Epoch 6273/10000; Iter 51/80; Loss: 0.2707
Epoch 6273/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.064
Epoch 6274/10000; Iter 1/80; Loss: 0.3812
Epoch 6274/10000; Iter 51/80; Loss: 0.3439
Epoch 6274/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.055
Epoch 6275/10000; Iter 1/80; Loss: 0.3845
Epoch 6275/10000; Iter 51/80; Loss: 0.3053
Epoch 6275/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.057
Epoch 6276/10000; Iter 1/80; Loss: 0.3908
Epoch 6276/10000; Iter 51/80; Loss: 0.3770
Epoch 6276/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.061
Epoch 6277/10000; Iter 1/80; Loss: 0.3413
Epoch 6277/10000; Iter 51/80; Loss: 0.3264
Epoch 6277/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6278/10000; Iter 1/80; Loss: 0.3329
Epoch 6278/10000; Iter 51/80; Loss: 0.4441
Epoch 6278/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.063
Epoch 6279/10000; Iter 1/80; Loss: 0.3787
Epoch 6279/10000; Iter 51/80; Loss: 0.3285
Epoch 6279/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.066
Epoch 6280/10000; Iter 1/80; Loss: 0.4045
Epoch 6280/10000; Iter 51/80; Loss: 0.3813
Epoch 6280/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.064
Epoch 6281/10000; Iter 1/80; Loss: 0.3107
Epoch 6281/10000; Iter 51/80; Loss: 0.3537
Epoch 6281/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.062
Epoch 6282/10000; Iter 1/80; Loss: 0.3470
Epoch 6282/10000; Iter 51/80; Loss: 0.3385
Epoch 6282/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6283/10000; Iter 1/80; Loss: 0.3723
Epoch 6283/10000; Iter 51/80; Loss: 0.3659
Epoch 6283/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.07
Epoch 6284/10000; Iter 1/80; Loss: 0.3365
Epoch 6284/10000; Iter 51/80; Loss: 0.3124
Epoch 6284/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.064
Epoch 6285/10000; Iter 1/80; Loss: 0.3709
Epoch 6285/10000; Iter 51/80; Loss: 0.3341
Epoch 6285/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.061
Epoch 6286/10000; Iter 1/80; Loss: 0.3992
Epoch 6286/10000; Iter 51/80; Loss: 0.4015
Epoch 6286/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.062
Epoch 6287/10000; Iter 1/80; Loss: 0.4317
Epoch 6287/10000; Iter 51/80; Loss: 0.3369
Epoch 6287/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.063
Epoch 6288/10000; Iter 1/80; Loss: 0.3498
Epoch 6288/10000; Iter 51/80; Loss: 0.3549
Epoch 6288/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.063
Epoch 6289/10000; Iter 1/80; Loss: 0.3583
Epoch 6289/10000; Iter 51/80; Loss: 0.3676
Epoch 6289/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.059
Epoch 6290/10000; Iter 1/80; Loss: 0.3845
Epoch 6290/10000; Iter 51/80; Loss: 0.3445
Epoch 6290/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6291/10000; Iter 1/80; Loss: 0.4123
Epoch 6291/10000; Iter 51/80; Loss: 0.3529
Epoch 6291/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.064
Epoch 6292/10000; Iter 1/80; Loss: 0.3623
Epoch 6292/10000; Iter 51/80; Loss: 0.3157
Epoch 6292/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.063
Epoch 6293/10000; Iter 1/80; Loss: 0.3623
Epoch 6293/10000; Iter 51/80; Loss: 0.3655
Epoch 6293/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.059
Epoch 6294/10000; Iter 1/80; Loss: 0.4072
Epoch 6294/10000; Iter 51/80; Loss: 0.3194
Epoch 6294/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.061
Epoch 6295/10000; Iter 1/80; Loss: 0.4039
Epoch 6295/10000; Iter 51/80; Loss: 0.3804
Epoch 6295/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.06
Epoch 6296/10000; Iter 1/80; Loss: 0.3440
Epoch 6296/10000; Iter 51/80; Loss: 0.3657
Epoch 6296/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.065
Epoch 6297/10000; Iter 1/80; Loss: 0.3489
Epoch 6297/10000; Iter 51/80; Loss: 0.3201
Epoch 6297/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.062
Epoch 6298/10000; Iter 1/80; Loss: 0.3563
Epoch 6298/10000; Iter 51/80; Loss: 0.4085
Epoch 6298/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6299/10000; Iter 1/80; Loss: 0.3397
Epoch 6299/10000; Iter 51/80; Loss: 0.3192
Epoch 6299/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.059
Epoch 6300/10000; Iter 1/80; Loss: 0.3566
Epoch 6300/10000; Iter 51/80; Loss: 0.3483
Epoch 6300/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.062
Epoch 6301/10000; Iter 1/80; Loss: 0.3168
Epoch 6301/10000; Iter 51/80; Loss: 0.4058
Epoch 6301/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.063
Model saved
Epoch 6302/10000; Iter 1/80; Loss: 0.3221
Epoch 6302/10000; Iter 51/80; Loss: 0.3459
Epoch 6302/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.061
Epoch 6303/10000; Iter 1/80; Loss: 0.4253
Epoch 6303/10000; Iter 51/80; Loss: 0.3402
Epoch 6303/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.057
Epoch 6304/10000; Iter 1/80; Loss: 0.3158
Epoch 6304/10000; Iter 51/80; Loss: 0.3376
Epoch 6304/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.053
Epoch 6305/10000; Iter 1/80; Loss: 0.3393
Epoch 6305/10000; Iter 51/80; Loss: 0.3314
Epoch 6305/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.056
Epoch 6306/10000; Iter 1/80; Loss: 0.3512
Epoch 6306/10000; Iter 51/80; Loss: 0.3584
Epoch 6306/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.065
Epoch 6307/10000; Iter 1/80; Loss: 0.3468
Epoch 6307/10000; Iter 51/80; Loss: 0.3780
Epoch 6307/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.056
Epoch 6308/10000; Iter 1/80; Loss: 0.3679
Epoch 6308/10000; Iter 51/80; Loss: 0.3382
Epoch 6308/10000; Iter 80/80; Training Loss: 0.3630, Test Loss: 0.053
Epoch 6309/10000; Iter 1/80; Loss: 0.2951
Epoch 6309/10000; Iter 51/80; Loss: 0.3424
Epoch 6309/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.055
Epoch 6310/10000; Iter 1/80; Loss: 0.3747
Epoch 6310/10000; Iter 51/80; Loss: 0.3328
Epoch 6310/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.059
Epoch 6311/10000; Iter 1/80; Loss: 0.3582
Epoch 6311/10000; Iter 51/80; Loss: 0.2942
Epoch 6311/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.06
Epoch 6312/10000; Iter 1/80; Loss: 0.3388
Epoch 6312/10000; Iter 51/80; Loss: 0.3507
Epoch 6312/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.065
Epoch 6313/10000; Iter 1/80; Loss: 0.3590
Epoch 6313/10000; Iter 51/80; Loss: 0.3782
Epoch 6313/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.061
Epoch 6314/10000; Iter 1/80; Loss: 0.3398
Epoch 6314/10000; Iter 51/80; Loss: 0.3398
Epoch 6314/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.064
Epoch 6315/10000; Iter 1/80; Loss: 0.3580
Epoch 6315/10000; Iter 51/80; Loss: 0.3414
Epoch 6315/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.059
Epoch 6316/10000; Iter 1/80; Loss: 0.3130
Epoch 6316/10000; Iter 51/80; Loss: 0.4077
Epoch 6316/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.057
Epoch 6317/10000; Iter 1/80; Loss: 0.3385
Epoch 6317/10000; Iter 51/80; Loss: 0.3406
Epoch 6317/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.07
Epoch 6318/10000; Iter 1/80; Loss: 0.3981
Epoch 6318/10000; Iter 51/80; Loss: 0.3737
Epoch 6318/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.059
Epoch 6319/10000; Iter 1/80; Loss: 0.3213
Epoch 6319/10000; Iter 51/80; Loss: 0.3700
Epoch 6319/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.064
Epoch 6320/10000; Iter 1/80; Loss: 0.3490
Epoch 6320/10000; Iter 51/80; Loss: 0.3656
Epoch 6320/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.062
Epoch 6321/10000; Iter 1/80; Loss: 0.3501
Epoch 6321/10000; Iter 51/80; Loss: 0.3796
Epoch 6321/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.065
Epoch 6322/10000; Iter 1/80; Loss: 0.3174
Epoch 6322/10000; Iter 51/80; Loss: 0.3609
Epoch 6322/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.071
Epoch 6323/10000; Iter 1/80; Loss: 0.3966
Epoch 6323/10000; Iter 51/80; Loss: 0.4009
Epoch 6323/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.061
Epoch 6324/10000; Iter 1/80; Loss: 0.4708
Epoch 6324/10000; Iter 51/80; Loss: 0.3433
Epoch 6324/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.061
Epoch 6325/10000; Iter 1/80; Loss: 0.3952
Epoch 6325/10000; Iter 51/80; Loss: 0.3453
Epoch 6325/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.058
Epoch 6326/10000; Iter 1/80; Loss: 0.3324
Epoch 6326/10000; Iter 51/80; Loss: 0.3679
Epoch 6326/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.068
Epoch 6327/10000; Iter 1/80; Loss: 0.3648
Epoch 6327/10000; Iter 51/80; Loss: 0.3534
Epoch 6327/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.055
Epoch 6328/10000; Iter 1/80; Loss: 0.3235
Epoch 6328/10000; Iter 51/80; Loss: 0.3329
Epoch 6328/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.06
Epoch 6329/10000; Iter 1/80; Loss: 0.3249
Epoch 6329/10000; Iter 51/80; Loss: 0.3502
Epoch 6329/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6330/10000; Iter 1/80; Loss: 0.3628
Epoch 6330/10000; Iter 51/80; Loss: 0.3375
Epoch 6330/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.061
Epoch 6331/10000; Iter 1/80; Loss: 0.3615
Epoch 6331/10000; Iter 51/80; Loss: 0.3970
Epoch 6331/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.065
Epoch 6332/10000; Iter 1/80; Loss: 0.3560
Epoch 6332/10000; Iter 51/80; Loss: 0.3415
Epoch 6332/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6333/10000; Iter 1/80; Loss: 0.3692
Epoch 6333/10000; Iter 51/80; Loss: 0.3575
Epoch 6333/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.062
Epoch 6334/10000; Iter 1/80; Loss: 0.3491
Epoch 6334/10000; Iter 51/80; Loss: 0.4310
Epoch 6334/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.059
Epoch 6335/10000; Iter 1/80; Loss: 0.3225
Epoch 6335/10000; Iter 51/80; Loss: 0.3338
Epoch 6335/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6336/10000; Iter 1/80; Loss: 0.3531
Epoch 6336/10000; Iter 51/80; Loss: 0.3471
Epoch 6336/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.06
Epoch 6337/10000; Iter 1/80; Loss: 0.3541
Epoch 6337/10000; Iter 51/80; Loss: 0.3474
Epoch 6337/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.057
Epoch 6338/10000; Iter 1/80; Loss: 0.2902
Epoch 6338/10000; Iter 51/80; Loss: 0.3938
Epoch 6338/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.064
Epoch 6339/10000; Iter 1/80; Loss: 0.3366
Epoch 6339/10000; Iter 51/80; Loss: 0.3635
Epoch 6339/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.062
Epoch 6340/10000; Iter 1/80; Loss: 0.3384
Epoch 6340/10000; Iter 51/80; Loss: 0.3464
Epoch 6340/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.063
Epoch 6341/10000; Iter 1/80; Loss: 0.3653
Epoch 6341/10000; Iter 51/80; Loss: 0.3813
Epoch 6341/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.063
Epoch 6342/10000; Iter 1/80; Loss: 0.3440
Epoch 6342/10000; Iter 51/80; Loss: 0.3707
Epoch 6342/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.068
Epoch 6343/10000; Iter 1/80; Loss: 0.2551
Epoch 6343/10000; Iter 51/80; Loss: 0.2990
Epoch 6343/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.059
Epoch 6344/10000; Iter 1/80; Loss: 0.3890
Epoch 6344/10000; Iter 51/80; Loss: 0.3328
Epoch 6344/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.065
Epoch 6345/10000; Iter 1/80; Loss: 0.3244
Epoch 6345/10000; Iter 51/80; Loss: 0.3666
Epoch 6345/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.06
Epoch 6346/10000; Iter 1/80; Loss: 0.3195
Epoch 6346/10000; Iter 51/80; Loss: 0.3593
Epoch 6346/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.062
Epoch 6347/10000; Iter 1/80; Loss: 0.3530
Epoch 6347/10000; Iter 51/80; Loss: 0.3577
Epoch 6347/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.068
Epoch 6348/10000; Iter 1/80; Loss: 0.4090
Epoch 6348/10000; Iter 51/80; Loss: 0.3403
Epoch 6348/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6349/10000; Iter 1/80; Loss: 0.2866
Epoch 6349/10000; Iter 51/80; Loss: 0.3748
Epoch 6349/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6350/10000; Iter 1/80; Loss: 0.3079
Epoch 6350/10000; Iter 51/80; Loss: 0.4569
Epoch 6350/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.061
Epoch 6351/10000; Iter 1/80; Loss: 0.3845
Epoch 6351/10000; Iter 51/80; Loss: 0.3074
Epoch 6351/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.062
Epoch 6352/10000; Iter 1/80; Loss: 0.3816
Epoch 6352/10000; Iter 51/80; Loss: 0.3322
Epoch 6352/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.065
Epoch 6353/10000; Iter 1/80; Loss: 0.4034
Epoch 6353/10000; Iter 51/80; Loss: 0.4371
Epoch 6353/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.058
Epoch 6354/10000; Iter 1/80; Loss: 0.3547
Epoch 6354/10000; Iter 51/80; Loss: 0.3285
Epoch 6354/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.062
Epoch 6355/10000; Iter 1/80; Loss: 0.3232
Epoch 6355/10000; Iter 51/80; Loss: 0.3793
Epoch 6355/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6356/10000; Iter 1/80; Loss: 0.3694
Epoch 6356/10000; Iter 51/80; Loss: 0.3390
Epoch 6356/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.062
Epoch 6357/10000; Iter 1/80; Loss: 0.3460
Epoch 6357/10000; Iter 51/80; Loss: 0.3027
Epoch 6357/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.063
Epoch 6358/10000; Iter 1/80; Loss: 0.3077
Epoch 6358/10000; Iter 51/80; Loss: 0.3177
Epoch 6358/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.062
Epoch 6359/10000; Iter 1/80; Loss: 0.3029
Epoch 6359/10000; Iter 51/80; Loss: 0.3135
Epoch 6359/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.068
Epoch 6360/10000; Iter 1/80; Loss: 0.3318
Epoch 6360/10000; Iter 51/80; Loss: 0.3835
Epoch 6360/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.065
Epoch 6361/10000; Iter 1/80; Loss: 0.3656
Epoch 6361/10000; Iter 51/80; Loss: 0.4118
Epoch 6361/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.066
Epoch 6362/10000; Iter 1/80; Loss: 0.3744
Epoch 6362/10000; Iter 51/80; Loss: 0.3670
Epoch 6362/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.058
Epoch 6363/10000; Iter 1/80; Loss: 0.3835
Epoch 6363/10000; Iter 51/80; Loss: 0.4023
Epoch 6363/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.061
Epoch 6364/10000; Iter 1/80; Loss: 0.3268
Epoch 6364/10000; Iter 51/80; Loss: 0.3021
Epoch 6364/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.062
Epoch 6365/10000; Iter 1/80; Loss: 0.2966
Epoch 6365/10000; Iter 51/80; Loss: 0.3769
Epoch 6365/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.054
Epoch 6366/10000; Iter 1/80; Loss: 0.3492
Epoch 6366/10000; Iter 51/80; Loss: 0.3330
Epoch 6366/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.063
Epoch 6367/10000; Iter 1/80; Loss: 0.3399
Epoch 6367/10000; Iter 51/80; Loss: 0.3303
Epoch 6367/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.059
Epoch 6368/10000; Iter 1/80; Loss: 0.3192
Epoch 6368/10000; Iter 51/80; Loss: 0.3726
Epoch 6368/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.057
Epoch 6369/10000; Iter 1/80; Loss: 0.3059
Epoch 6369/10000; Iter 51/80; Loss: 0.3704
Epoch 6369/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.061
Epoch 6370/10000; Iter 1/80; Loss: 0.2999
Epoch 6370/10000; Iter 51/80; Loss: 0.3802
Epoch 6370/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.061
Epoch 6371/10000; Iter 1/80; Loss: 0.3872
Epoch 6371/10000; Iter 51/80; Loss: 0.3286
Epoch 6371/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.072
Epoch 6372/10000; Iter 1/80; Loss: 0.3621
Epoch 6372/10000; Iter 51/80; Loss: 0.4048
Epoch 6372/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.061
Epoch 6373/10000; Iter 1/80; Loss: 0.4460
Epoch 6373/10000; Iter 51/80; Loss: 0.3427
Epoch 6373/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.067
Epoch 6374/10000; Iter 1/80; Loss: 0.3012
Epoch 6374/10000; Iter 51/80; Loss: 0.2943
Epoch 6374/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.061
Epoch 6375/10000; Iter 1/80; Loss: 0.3324
Epoch 6375/10000; Iter 51/80; Loss: 0.3328
Epoch 6375/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.061
Epoch 6376/10000; Iter 1/80; Loss: 0.3072
Epoch 6376/10000; Iter 51/80; Loss: 0.3426
Epoch 6376/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.057
Epoch 6377/10000; Iter 1/80; Loss: 0.3398
Epoch 6377/10000; Iter 51/80; Loss: 0.3519
Epoch 6377/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.06
Epoch 6378/10000; Iter 1/80; Loss: 0.3308
Epoch 6378/10000; Iter 51/80; Loss: 0.3887
Epoch 6378/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.065
Epoch 6379/10000; Iter 1/80; Loss: 0.3790
Epoch 6379/10000; Iter 51/80; Loss: 0.3480
Epoch 6379/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.061
Epoch 6380/10000; Iter 1/80; Loss: 0.3619
Epoch 6380/10000; Iter 51/80; Loss: 0.3291
Epoch 6380/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6381/10000; Iter 1/80; Loss: 0.4118
Epoch 6381/10000; Iter 51/80; Loss: 0.3836
Epoch 6381/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.065
Epoch 6382/10000; Iter 1/80; Loss: 0.3531
Epoch 6382/10000; Iter 51/80; Loss: 0.3454
Epoch 6382/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.064
Epoch 6383/10000; Iter 1/80; Loss: 0.3315
Epoch 6383/10000; Iter 51/80; Loss: 0.3659
Epoch 6383/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.063
Epoch 6384/10000; Iter 1/80; Loss: 0.3808
Epoch 6384/10000; Iter 51/80; Loss: 0.3608
Epoch 6384/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.061
Epoch 6385/10000; Iter 1/80; Loss: 0.3307
Epoch 6385/10000; Iter 51/80; Loss: 0.3093
Epoch 6385/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.063
Epoch 6386/10000; Iter 1/80; Loss: 0.4053
Epoch 6386/10000; Iter 51/80; Loss: 0.3224
Epoch 6386/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.055
Epoch 6387/10000; Iter 1/80; Loss: 0.3598
Epoch 6387/10000; Iter 51/80; Loss: 0.4138
Epoch 6387/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6388/10000; Iter 1/80; Loss: 0.3450
Epoch 6388/10000; Iter 51/80; Loss: 0.3721
Epoch 6388/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.062
Epoch 6389/10000; Iter 1/80; Loss: 0.3470
Epoch 6389/10000; Iter 51/80; Loss: 0.2763
Epoch 6389/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.065
Epoch 6390/10000; Iter 1/80; Loss: 0.4050
Epoch 6390/10000; Iter 51/80; Loss: 0.3794
Epoch 6390/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.055
Epoch 6391/10000; Iter 1/80; Loss: 0.3512
Epoch 6391/10000; Iter 51/80; Loss: 0.3006
Epoch 6391/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6392/10000; Iter 1/80; Loss: 0.3786
Epoch 6392/10000; Iter 51/80; Loss: 0.3279
Epoch 6392/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.068
Epoch 6393/10000; Iter 1/80; Loss: 0.3456
Epoch 6393/10000; Iter 51/80; Loss: 0.4203
Epoch 6393/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.07
Epoch 6394/10000; Iter 1/80; Loss: 0.3083
Epoch 6394/10000; Iter 51/80; Loss: 0.3405
Epoch 6394/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.064
Epoch 6395/10000; Iter 1/80; Loss: 0.3282
Epoch 6395/10000; Iter 51/80; Loss: 0.3430
Epoch 6395/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.064
Epoch 6396/10000; Iter 1/80; Loss: 0.3374
Epoch 6396/10000; Iter 51/80; Loss: 0.3642
Epoch 6396/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.062
Epoch 6397/10000; Iter 1/80; Loss: 0.3226
Epoch 6397/10000; Iter 51/80; Loss: 0.3774
Epoch 6397/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.057
Epoch 6398/10000; Iter 1/80; Loss: 0.3569
Epoch 6398/10000; Iter 51/80; Loss: 0.4063
Epoch 6398/10000; Iter 80/80; Training Loss: 0.3590, Test Loss: 0.061
Epoch 6399/10000; Iter 1/80; Loss: 0.3625
Epoch 6399/10000; Iter 51/80; Loss: 0.3659
Epoch 6399/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.065
Epoch 6400/10000; Iter 1/80; Loss: 0.4015
Epoch 6400/10000; Iter 51/80; Loss: 0.3788
Epoch 6400/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.066
Epoch 6401/10000; Iter 1/80; Loss: 0.3877
Epoch 6401/10000; Iter 51/80; Loss: 0.3291
Epoch 6401/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.061
Model saved
Epoch 6402/10000; Iter 1/80; Loss: 0.3372
Epoch 6402/10000; Iter 51/80; Loss: 0.3036
Epoch 6402/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.063
Epoch 6403/10000; Iter 1/80; Loss: 0.3807
Epoch 6403/10000; Iter 51/80; Loss: 0.2975
Epoch 6403/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.062
Epoch 6404/10000; Iter 1/80; Loss: 0.3659
Epoch 6404/10000; Iter 51/80; Loss: 0.3717
Epoch 6404/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6405/10000; Iter 1/80; Loss: 0.4057
Epoch 6405/10000; Iter 51/80; Loss: 0.3387
Epoch 6405/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.059
Epoch 6406/10000; Iter 1/80; Loss: 0.3777
Epoch 6406/10000; Iter 51/80; Loss: 0.3174
Epoch 6406/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.072
Epoch 6407/10000; Iter 1/80; Loss: 0.3660
Epoch 6407/10000; Iter 51/80; Loss: 0.3688
Epoch 6407/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.066
Epoch 6408/10000; Iter 1/80; Loss: 0.3580
Epoch 6408/10000; Iter 51/80; Loss: 0.3057
Epoch 6408/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.059
Epoch 6409/10000; Iter 1/80; Loss: 0.3869
Epoch 6409/10000; Iter 51/80; Loss: 0.3441
Epoch 6409/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.065
Epoch 6410/10000; Iter 1/80; Loss: 0.3657
Epoch 6410/10000; Iter 51/80; Loss: 0.3709
Epoch 6410/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.063
Epoch 6411/10000; Iter 1/80; Loss: 0.3839
Epoch 6411/10000; Iter 51/80; Loss: 0.3570
Epoch 6411/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.065
Epoch 6412/10000; Iter 1/80; Loss: 0.3359
Epoch 6412/10000; Iter 51/80; Loss: 0.3783
Epoch 6412/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.064
Epoch 6413/10000; Iter 1/80; Loss: 0.3899
Epoch 6413/10000; Iter 51/80; Loss: 0.3971
Epoch 6413/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.062
Epoch 6414/10000; Iter 1/80; Loss: 0.2961
Epoch 6414/10000; Iter 51/80; Loss: 0.3433
Epoch 6414/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.065
Epoch 6415/10000; Iter 1/80; Loss: 0.3677
Epoch 6415/10000; Iter 51/80; Loss: 0.3847
Epoch 6415/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.061
Epoch 6416/10000; Iter 1/80; Loss: 0.3098
Epoch 6416/10000; Iter 51/80; Loss: 0.4371
Epoch 6416/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.062
Epoch 6417/10000; Iter 1/80; Loss: 0.3479
Epoch 6417/10000; Iter 51/80; Loss: 0.3683
Epoch 6417/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.058
Epoch 6418/10000; Iter 1/80; Loss: 0.3298
Epoch 6418/10000; Iter 51/80; Loss: 0.3342
Epoch 6418/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.064
Epoch 6419/10000; Iter 1/80; Loss: 0.3832
Epoch 6419/10000; Iter 51/80; Loss: 0.3789
Epoch 6419/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.065
Epoch 6420/10000; Iter 1/80; Loss: 0.3785
Epoch 6420/10000; Iter 51/80; Loss: 0.3577
Epoch 6420/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.057
Epoch 6421/10000; Iter 1/80; Loss: 0.3429
Epoch 6421/10000; Iter 51/80; Loss: 0.3431
Epoch 6421/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.061
Epoch 6422/10000; Iter 1/80; Loss: 0.4378
Epoch 6422/10000; Iter 51/80; Loss: 0.3306
Epoch 6422/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.067
Epoch 6423/10000; Iter 1/80; Loss: 0.3197
Epoch 6423/10000; Iter 51/80; Loss: 0.4204
Epoch 6423/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6424/10000; Iter 1/80; Loss: 0.3040
Epoch 6424/10000; Iter 51/80; Loss: 0.3684
Epoch 6424/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.063
Epoch 6425/10000; Iter 1/80; Loss: 0.2983
Epoch 6425/10000; Iter 51/80; Loss: 0.3290
Epoch 6425/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.062
Epoch 6426/10000; Iter 1/80; Loss: 0.3301
Epoch 6426/10000; Iter 51/80; Loss: 0.3500
Epoch 6426/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.06
Epoch 6427/10000; Iter 1/80; Loss: 0.3455
Epoch 6427/10000; Iter 51/80; Loss: 0.3852
Epoch 6427/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.059
Epoch 6428/10000; Iter 1/80; Loss: 0.3379
Epoch 6428/10000; Iter 51/80; Loss: 0.3772
Epoch 6428/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.059
Epoch 6429/10000; Iter 1/80; Loss: 0.2877
Epoch 6429/10000; Iter 51/80; Loss: 0.3446
Epoch 6429/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.07
Epoch 6430/10000; Iter 1/80; Loss: 0.4317
Epoch 6430/10000; Iter 51/80; Loss: 0.2948
Epoch 6430/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6431/10000; Iter 1/80; Loss: 0.2688
Epoch 6431/10000; Iter 51/80; Loss: 0.3434
Epoch 6431/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.067
Epoch 6432/10000; Iter 1/80; Loss: 0.2885
Epoch 6432/10000; Iter 51/80; Loss: 0.3113
Epoch 6432/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.058
Epoch 6433/10000; Iter 1/80; Loss: 0.3734
Epoch 6433/10000; Iter 51/80; Loss: 0.4183
Epoch 6433/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.065
Epoch 6434/10000; Iter 1/80; Loss: 0.3278
Epoch 6434/10000; Iter 51/80; Loss: 0.3646
Epoch 6434/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.068
Epoch 6435/10000; Iter 1/80; Loss: 0.3518
Epoch 6435/10000; Iter 51/80; Loss: 0.3900
Epoch 6435/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.066
Epoch 6436/10000; Iter 1/80; Loss: 0.3030
Epoch 6436/10000; Iter 51/80; Loss: 0.4154
Epoch 6436/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.063
Epoch 6437/10000; Iter 1/80; Loss: 0.3561
Epoch 6437/10000; Iter 51/80; Loss: 0.3135
Epoch 6437/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.067
Epoch 6438/10000; Iter 1/80; Loss: 0.3402
Epoch 6438/10000; Iter 51/80; Loss: 0.3175
Epoch 6438/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6439/10000; Iter 1/80; Loss: 0.3997
Epoch 6439/10000; Iter 51/80; Loss: 0.3479
Epoch 6439/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6440/10000; Iter 1/80; Loss: 0.3428
Epoch 6440/10000; Iter 51/80; Loss: 0.4730
Epoch 6440/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.068
Epoch 6441/10000; Iter 1/80; Loss: 0.3124
Epoch 6441/10000; Iter 51/80; Loss: 0.3475
Epoch 6441/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.062
Epoch 6442/10000; Iter 1/80; Loss: 0.2819
Epoch 6442/10000; Iter 51/80; Loss: 0.3479
Epoch 6442/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.064
Epoch 6443/10000; Iter 1/80; Loss: 0.3242
Epoch 6443/10000; Iter 51/80; Loss: 0.3593
Epoch 6443/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.065
Epoch 6444/10000; Iter 1/80; Loss: 0.3482
Epoch 6444/10000; Iter 51/80; Loss: 0.3037
Epoch 6444/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6445/10000; Iter 1/80; Loss: 0.2934
Epoch 6445/10000; Iter 51/80; Loss: 0.3416
Epoch 6445/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.06
Epoch 6446/10000; Iter 1/80; Loss: 0.3340
Epoch 6446/10000; Iter 51/80; Loss: 0.3542
Epoch 6446/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.067
Epoch 6447/10000; Iter 1/80; Loss: 0.3298
Epoch 6447/10000; Iter 51/80; Loss: 0.3320
Epoch 6447/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6448/10000; Iter 1/80; Loss: 0.3760
Epoch 6448/10000; Iter 51/80; Loss: 0.3907
Epoch 6448/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.059
Epoch 6449/10000; Iter 1/80; Loss: 0.3158
Epoch 6449/10000; Iter 51/80; Loss: 0.3504
Epoch 6449/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.064
Epoch 6450/10000; Iter 1/80; Loss: 0.3383
Epoch 6450/10000; Iter 51/80; Loss: 0.3219
Epoch 6450/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.064
Epoch 6451/10000; Iter 1/80; Loss: 0.3377
Epoch 6451/10000; Iter 51/80; Loss: 0.3490
Epoch 6451/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.064
Epoch 6452/10000; Iter 1/80; Loss: 0.3674
Epoch 6452/10000; Iter 51/80; Loss: 0.3631
Epoch 6452/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.068
Epoch 6453/10000; Iter 1/80; Loss: 0.3546
Epoch 6453/10000; Iter 51/80; Loss: 0.3406
Epoch 6453/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.071
Epoch 6454/10000; Iter 1/80; Loss: 0.2936
Epoch 6454/10000; Iter 51/80; Loss: 0.3866
Epoch 6454/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6455/10000; Iter 1/80; Loss: 0.3619
Epoch 6455/10000; Iter 51/80; Loss: 0.3304
Epoch 6455/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.067
Epoch 6456/10000; Iter 1/80; Loss: 0.3476
Epoch 6456/10000; Iter 51/80; Loss: 0.3212
Epoch 6456/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.06
Epoch 6457/10000; Iter 1/80; Loss: 0.3393
Epoch 6457/10000; Iter 51/80; Loss: 0.3420
Epoch 6457/10000; Iter 80/80; Training Loss: 0.3600, Test Loss: 0.07
Epoch 6458/10000; Iter 1/80; Loss: 0.3472
Epoch 6458/10000; Iter 51/80; Loss: 0.3743
Epoch 6458/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6459/10000; Iter 1/80; Loss: 0.3426
Epoch 6459/10000; Iter 51/80; Loss: 0.3402
Epoch 6459/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.069
Epoch 6460/10000; Iter 1/80; Loss: 0.3273
Epoch 6460/10000; Iter 51/80; Loss: 0.3581
Epoch 6460/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.063
Epoch 6461/10000; Iter 1/80; Loss: 0.3643
Epoch 6461/10000; Iter 51/80; Loss: 0.3537
Epoch 6461/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.062
Epoch 6462/10000; Iter 1/80; Loss: 0.3345
Epoch 6462/10000; Iter 51/80; Loss: 0.3858
Epoch 6462/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.067
Epoch 6463/10000; Iter 1/80; Loss: 0.3565
Epoch 6463/10000; Iter 51/80; Loss: 0.3755
Epoch 6463/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6464/10000; Iter 1/80; Loss: 0.3834
Epoch 6464/10000; Iter 51/80; Loss: 0.4072
Epoch 6464/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.058
Epoch 6465/10000; Iter 1/80; Loss: 0.3108
Epoch 6465/10000; Iter 51/80; Loss: 0.4469
Epoch 6465/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.072
Epoch 6466/10000; Iter 1/80; Loss: 0.2971
Epoch 6466/10000; Iter 51/80; Loss: 0.3735
Epoch 6466/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.07
Epoch 6467/10000; Iter 1/80; Loss: 0.3220
Epoch 6467/10000; Iter 51/80; Loss: 0.3812
Epoch 6467/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.069
Epoch 6468/10000; Iter 1/80; Loss: 0.3621
Epoch 6468/10000; Iter 51/80; Loss: 0.3377
Epoch 6468/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.072
Epoch 6469/10000; Iter 1/80; Loss: 0.3756
Epoch 6469/10000; Iter 51/80; Loss: 0.3165
Epoch 6469/10000; Iter 80/80; Training Loss: 0.3570, Test Loss: 0.058
Epoch 6470/10000; Iter 1/80; Loss: 0.3472
Epoch 6470/10000; Iter 51/80; Loss: 0.2941
Epoch 6470/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6471/10000; Iter 1/80; Loss: 0.2993
Epoch 6471/10000; Iter 51/80; Loss: 0.4594
Epoch 6471/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.064
Epoch 6472/10000; Iter 1/80; Loss: 0.4038
Epoch 6472/10000; Iter 51/80; Loss: 0.3241
Epoch 6472/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.064
Epoch 6473/10000; Iter 1/80; Loss: 0.4117
Epoch 6473/10000; Iter 51/80; Loss: 0.3742
Epoch 6473/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6474/10000; Iter 1/80; Loss: 0.3840
Epoch 6474/10000; Iter 51/80; Loss: 0.3053
Epoch 6474/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6475/10000; Iter 1/80; Loss: 0.3905
Epoch 6475/10000; Iter 51/80; Loss: 0.3249
Epoch 6475/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.071
Epoch 6476/10000; Iter 1/80; Loss: 0.3346
Epoch 6476/10000; Iter 51/80; Loss: 0.3488
Epoch 6476/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.059
Epoch 6477/10000; Iter 1/80; Loss: 0.3577
Epoch 6477/10000; Iter 51/80; Loss: 0.3791
Epoch 6477/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.065
Epoch 6478/10000; Iter 1/80; Loss: 0.3351
Epoch 6478/10000; Iter 51/80; Loss: 0.3493
Epoch 6478/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6479/10000; Iter 1/80; Loss: 0.3592
Epoch 6479/10000; Iter 51/80; Loss: 0.3873
Epoch 6479/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.064
Epoch 6480/10000; Iter 1/80; Loss: 0.3506
Epoch 6480/10000; Iter 51/80; Loss: 0.3137
Epoch 6480/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.069
Epoch 6481/10000; Iter 1/80; Loss: 0.3163
Epoch 6481/10000; Iter 51/80; Loss: 0.3581
Epoch 6481/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.07
Epoch 6482/10000; Iter 1/80; Loss: 0.3413
Epoch 6482/10000; Iter 51/80; Loss: 0.3177
Epoch 6482/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.074
Epoch 6483/10000; Iter 1/80; Loss: 0.2925
Epoch 6483/10000; Iter 51/80; Loss: 0.3808
Epoch 6483/10000; Iter 80/80; Training Loss: 0.3610, Test Loss: 0.073
Epoch 6484/10000; Iter 1/80; Loss: 0.3242
Epoch 6484/10000; Iter 51/80; Loss: 0.3214
Epoch 6484/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.058
Epoch 6485/10000; Iter 1/80; Loss: 0.3902
Epoch 6485/10000; Iter 51/80; Loss: 0.3254
Epoch 6485/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.061
Epoch 6486/10000; Iter 1/80; Loss: 0.4121
Epoch 6486/10000; Iter 51/80; Loss: 0.3381
Epoch 6486/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.065
Epoch 6487/10000; Iter 1/80; Loss: 0.3882
Epoch 6487/10000; Iter 51/80; Loss: 0.3662
Epoch 6487/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.071
Epoch 6488/10000; Iter 1/80; Loss: 0.3491
Epoch 6488/10000; Iter 51/80; Loss: 0.3571
Epoch 6488/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.063
Epoch 6489/10000; Iter 1/80; Loss: 0.3782
Epoch 6489/10000; Iter 51/80; Loss: 0.3683
Epoch 6489/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.063
Epoch 6490/10000; Iter 1/80; Loss: 0.3313
Epoch 6490/10000; Iter 51/80; Loss: 0.3335
Epoch 6490/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.064
Epoch 6491/10000; Iter 1/80; Loss: 0.3383
Epoch 6491/10000; Iter 51/80; Loss: 0.3486
Epoch 6491/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.062
Epoch 6492/10000; Iter 1/80; Loss: 0.3464
Epoch 6492/10000; Iter 51/80; Loss: 0.3696
Epoch 6492/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.066
Epoch 6493/10000; Iter 1/80; Loss: 0.3550
Epoch 6493/10000; Iter 51/80; Loss: 0.3744
Epoch 6493/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.066
Epoch 6494/10000; Iter 1/80; Loss: 0.3232
Epoch 6494/10000; Iter 51/80; Loss: 0.3401
Epoch 6494/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.067
Epoch 6495/10000; Iter 1/80; Loss: 0.3185
Epoch 6495/10000; Iter 51/80; Loss: 0.3955
Epoch 6495/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.068
Epoch 6496/10000; Iter 1/80; Loss: 0.3352
Epoch 6496/10000; Iter 51/80; Loss: 0.3185
Epoch 6496/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.065
Epoch 6497/10000; Iter 1/80; Loss: 0.3415
Epoch 6497/10000; Iter 51/80; Loss: 0.3806
Epoch 6497/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.064
Epoch 6498/10000; Iter 1/80; Loss: 0.3620
Epoch 6498/10000; Iter 51/80; Loss: 0.3757
Epoch 6498/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.064
Epoch 6499/10000; Iter 1/80; Loss: 0.3482
Epoch 6499/10000; Iter 51/80; Loss: 0.3504
Epoch 6499/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 6500/10000; Iter 1/80; Loss: 0.3066
Epoch 6500/10000; Iter 51/80; Loss: 0.3651
Epoch 6500/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.069
Epoch 6501/10000; Iter 1/80; Loss: 0.3654
Epoch 6501/10000; Iter 51/80; Loss: 0.4028
Epoch 6501/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.065
Model saved
Epoch 6502/10000; Iter 1/80; Loss: 0.3558
Epoch 6502/10000; Iter 51/80; Loss: 0.3301
Epoch 6502/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.064
Epoch 6503/10000; Iter 1/80; Loss: 0.3566
Epoch 6503/10000; Iter 51/80; Loss: 0.3424
Epoch 6503/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 6504/10000; Iter 1/80; Loss: 0.3027
Epoch 6504/10000; Iter 51/80; Loss: 0.3465
Epoch 6504/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.057
Epoch 6505/10000; Iter 1/80; Loss: 0.3850
Epoch 6505/10000; Iter 51/80; Loss: 0.3295
Epoch 6505/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.066
Epoch 6506/10000; Iter 1/80; Loss: 0.3290
Epoch 6506/10000; Iter 51/80; Loss: 0.3073
Epoch 6506/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 6507/10000; Iter 1/80; Loss: 0.3387
Epoch 6507/10000; Iter 51/80; Loss: 0.3431
Epoch 6507/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.062
Epoch 6508/10000; Iter 1/80; Loss: 0.3219
Epoch 6508/10000; Iter 51/80; Loss: 0.3553
Epoch 6508/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.062
Epoch 6509/10000; Iter 1/80; Loss: 0.3545
Epoch 6509/10000; Iter 51/80; Loss: 0.3570
Epoch 6509/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.07
Epoch 6510/10000; Iter 1/80; Loss: 0.3170
Epoch 6510/10000; Iter 51/80; Loss: 0.3559
Epoch 6510/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.075
Epoch 6511/10000; Iter 1/80; Loss: 0.3618
Epoch 6511/10000; Iter 51/80; Loss: 0.3320
Epoch 6511/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.069
Epoch 6512/10000; Iter 1/80; Loss: 0.3790
Epoch 6512/10000; Iter 51/80; Loss: 0.3340
Epoch 6512/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.068
Epoch 6513/10000; Iter 1/80; Loss: 0.3365
Epoch 6513/10000; Iter 51/80; Loss: 0.3639
Epoch 6513/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.065
Epoch 6514/10000; Iter 1/80; Loss: 0.3370
Epoch 6514/10000; Iter 51/80; Loss: 0.3425
Epoch 6514/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.065
Epoch 6515/10000; Iter 1/80; Loss: 0.3530
Epoch 6515/10000; Iter 51/80; Loss: 0.3403
Epoch 6515/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.073
Epoch 6516/10000; Iter 1/80; Loss: 0.3451
Epoch 6516/10000; Iter 51/80; Loss: 0.2608
Epoch 6516/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.065
Epoch 6517/10000; Iter 1/80; Loss: 0.3206
Epoch 6517/10000; Iter 51/80; Loss: 0.3638
Epoch 6517/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.067
Epoch 6518/10000; Iter 1/80; Loss: 0.3110
Epoch 6518/10000; Iter 51/80; Loss: 0.3555
Epoch 6518/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.066
Epoch 6519/10000; Iter 1/80; Loss: 0.3478
Epoch 6519/10000; Iter 51/80; Loss: 0.3556
Epoch 6519/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.069
Epoch 6520/10000; Iter 1/80; Loss: 0.3812
Epoch 6520/10000; Iter 51/80; Loss: 0.3871
Epoch 6520/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.072
Epoch 6521/10000; Iter 1/80; Loss: 0.3194
Epoch 6521/10000; Iter 51/80; Loss: 0.3117
Epoch 6521/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6522/10000; Iter 1/80; Loss: 0.3321
Epoch 6522/10000; Iter 51/80; Loss: 0.3487
Epoch 6522/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.064
Epoch 6523/10000; Iter 1/80; Loss: 0.3999
Epoch 6523/10000; Iter 51/80; Loss: 0.3301
Epoch 6523/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.065
Epoch 6524/10000; Iter 1/80; Loss: 0.3544
Epoch 6524/10000; Iter 51/80; Loss: 0.3145
Epoch 6524/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.069
Epoch 6525/10000; Iter 1/80; Loss: 0.3486
Epoch 6525/10000; Iter 51/80; Loss: 0.2906
Epoch 6525/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6526/10000; Iter 1/80; Loss: 0.4027
Epoch 6526/10000; Iter 51/80; Loss: 0.2897
Epoch 6526/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.062
Epoch 6527/10000; Iter 1/80; Loss: 0.4015
Epoch 6527/10000; Iter 51/80; Loss: 0.2987
Epoch 6527/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.053
Epoch 6528/10000; Iter 1/80; Loss: 0.3759
Epoch 6528/10000; Iter 51/80; Loss: 0.3172
Epoch 6528/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.064
Epoch 6529/10000; Iter 1/80; Loss: 0.3715
Epoch 6529/10000; Iter 51/80; Loss: 0.3032
Epoch 6529/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.064
Epoch 6530/10000; Iter 1/80; Loss: 0.3350
Epoch 6530/10000; Iter 51/80; Loss: 0.3432
Epoch 6530/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.062
Epoch 6531/10000; Iter 1/80; Loss: 0.3858
Epoch 6531/10000; Iter 51/80; Loss: 0.3109
Epoch 6531/10000; Iter 80/80; Training Loss: 0.3560, Test Loss: 0.065
Epoch 6532/10000; Iter 1/80; Loss: 0.3283
Epoch 6532/10000; Iter 51/80; Loss: 0.3475
Epoch 6532/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6533/10000; Iter 1/80; Loss: 0.3775
Epoch 6533/10000; Iter 51/80; Loss: 0.3199
Epoch 6533/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.072
Epoch 6534/10000; Iter 1/80; Loss: 0.3377
Epoch 6534/10000; Iter 51/80; Loss: 0.3134
Epoch 6534/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.065
Epoch 6535/10000; Iter 1/80; Loss: 0.3336
Epoch 6535/10000; Iter 51/80; Loss: 0.3306
Epoch 6535/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.063
Epoch 6536/10000; Iter 1/80; Loss: 0.3452
Epoch 6536/10000; Iter 51/80; Loss: 0.3604
Epoch 6536/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.071
Epoch 6537/10000; Iter 1/80; Loss: 0.3336
Epoch 6537/10000; Iter 51/80; Loss: 0.3757
Epoch 6537/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.066
Epoch 6538/10000; Iter 1/80; Loss: 0.3756
Epoch 6538/10000; Iter 51/80; Loss: 0.3876
Epoch 6538/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.065
Epoch 6539/10000; Iter 1/80; Loss: 0.2988
Epoch 6539/10000; Iter 51/80; Loss: 0.3463
Epoch 6539/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.068
Epoch 6540/10000; Iter 1/80; Loss: 0.4152
Epoch 6540/10000; Iter 51/80; Loss: 0.3436
Epoch 6540/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.068
Epoch 6541/10000; Iter 1/80; Loss: 0.3821
Epoch 6541/10000; Iter 51/80; Loss: 0.3296
Epoch 6541/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6542/10000; Iter 1/80; Loss: 0.3625
Epoch 6542/10000; Iter 51/80; Loss: 0.3600
Epoch 6542/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.076
Epoch 6543/10000; Iter 1/80; Loss: 0.4139
Epoch 6543/10000; Iter 51/80; Loss: 0.3117
Epoch 6543/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.071
Epoch 6544/10000; Iter 1/80; Loss: 0.3215
Epoch 6544/10000; Iter 51/80; Loss: 0.3080
Epoch 6544/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.063
Epoch 6545/10000; Iter 1/80; Loss: 0.3319
Epoch 6545/10000; Iter 51/80; Loss: 0.3175
Epoch 6545/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.062
Epoch 6546/10000; Iter 1/80; Loss: 0.3640
Epoch 6546/10000; Iter 51/80; Loss: 0.3388
Epoch 6546/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.066
Epoch 6547/10000; Iter 1/80; Loss: 0.3395
Epoch 6547/10000; Iter 51/80; Loss: 0.3436
Epoch 6547/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.067
Epoch 6548/10000; Iter 1/80; Loss: 0.3788
Epoch 6548/10000; Iter 51/80; Loss: 0.3253
Epoch 6548/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.062
Epoch 6549/10000; Iter 1/80; Loss: 0.3374
Epoch 6549/10000; Iter 51/80; Loss: 0.3242
Epoch 6549/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.063
Epoch 6550/10000; Iter 1/80; Loss: 0.3955
Epoch 6550/10000; Iter 51/80; Loss: 0.3410
Epoch 6550/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.059
Epoch 6551/10000; Iter 1/80; Loss: 0.3663
Epoch 6551/10000; Iter 51/80; Loss: 0.2967
Epoch 6551/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.06
Epoch 6552/10000; Iter 1/80; Loss: 0.3140
Epoch 6552/10000; Iter 51/80; Loss: 0.3340
Epoch 6552/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.069
Epoch 6553/10000; Iter 1/80; Loss: 0.3198
Epoch 6553/10000; Iter 51/80; Loss: 0.3503
Epoch 6553/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.065
Epoch 6554/10000; Iter 1/80; Loss: 0.3389
Epoch 6554/10000; Iter 51/80; Loss: 0.3617
Epoch 6554/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.062
Epoch 6555/10000; Iter 1/80; Loss: 0.4000
Epoch 6555/10000; Iter 51/80; Loss: 0.3351
Epoch 6555/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.065
Epoch 6556/10000; Iter 1/80; Loss: 0.3073
Epoch 6556/10000; Iter 51/80; Loss: 0.4256
Epoch 6556/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.065
Epoch 6557/10000; Iter 1/80; Loss: 0.3096
Epoch 6557/10000; Iter 51/80; Loss: 0.3219
Epoch 6557/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.065
Epoch 6558/10000; Iter 1/80; Loss: 0.3258
Epoch 6558/10000; Iter 51/80; Loss: 0.4063
Epoch 6558/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.063
Epoch 6559/10000; Iter 1/80; Loss: 0.3244
Epoch 6559/10000; Iter 51/80; Loss: 0.3422
Epoch 6559/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.059
Epoch 6560/10000; Iter 1/80; Loss: 0.3338
Epoch 6560/10000; Iter 51/80; Loss: 0.3318
Epoch 6560/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 6561/10000; Iter 1/80; Loss: 0.2876
Epoch 6561/10000; Iter 51/80; Loss: 0.3781
Epoch 6561/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.067
Epoch 6562/10000; Iter 1/80; Loss: 0.3063
Epoch 6562/10000; Iter 51/80; Loss: 0.3497
Epoch 6562/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.062
Epoch 6563/10000; Iter 1/80; Loss: 0.3773
Epoch 6563/10000; Iter 51/80; Loss: 0.3042
Epoch 6563/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.068
Epoch 6564/10000; Iter 1/80; Loss: 0.2861
Epoch 6564/10000; Iter 51/80; Loss: 0.3553
Epoch 6564/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.065
Epoch 6565/10000; Iter 1/80; Loss: 0.3451
Epoch 6565/10000; Iter 51/80; Loss: 0.3894
Epoch 6565/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6566/10000; Iter 1/80; Loss: 0.4202
Epoch 6566/10000; Iter 51/80; Loss: 0.3343
Epoch 6566/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6567/10000; Iter 1/80; Loss: 0.3998
Epoch 6567/10000; Iter 51/80; Loss: 0.3489
Epoch 6567/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6568/10000; Iter 1/80; Loss: 0.3739
Epoch 6568/10000; Iter 51/80; Loss: 0.3484
Epoch 6568/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.069
Epoch 6569/10000; Iter 1/80; Loss: 0.3436
Epoch 6569/10000; Iter 51/80; Loss: 0.3299
Epoch 6569/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6570/10000; Iter 1/80; Loss: 0.3322
Epoch 6570/10000; Iter 51/80; Loss: 0.3082
Epoch 6570/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.071
Epoch 6571/10000; Iter 1/80; Loss: 0.3897
Epoch 6571/10000; Iter 51/80; Loss: 0.3291
Epoch 6571/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.071
Epoch 6572/10000; Iter 1/80; Loss: 0.3804
Epoch 6572/10000; Iter 51/80; Loss: 0.3531
Epoch 6572/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6573/10000; Iter 1/80; Loss: 0.4181
Epoch 6573/10000; Iter 51/80; Loss: 0.3245
Epoch 6573/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.065
Epoch 6574/10000; Iter 1/80; Loss: 0.3371
Epoch 6574/10000; Iter 51/80; Loss: 0.3604
Epoch 6574/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.068
Epoch 6575/10000; Iter 1/80; Loss: 0.3275
Epoch 6575/10000; Iter 51/80; Loss: 0.3663
Epoch 6575/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.065
Epoch 6576/10000; Iter 1/80; Loss: 0.3874
Epoch 6576/10000; Iter 51/80; Loss: 0.3298
Epoch 6576/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.071
Epoch 6577/10000; Iter 1/80; Loss: 0.3988
Epoch 6577/10000; Iter 51/80; Loss: 0.4320
Epoch 6577/10000; Iter 80/80; Training Loss: 0.3540, Test Loss: 0.057
Epoch 6578/10000; Iter 1/80; Loss: 0.4268
Epoch 6578/10000; Iter 51/80; Loss: 0.3284
Epoch 6578/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.072
Epoch 6579/10000; Iter 1/80; Loss: 0.3529
Epoch 6579/10000; Iter 51/80; Loss: 0.3365
Epoch 6579/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.06
Epoch 6580/10000; Iter 1/80; Loss: 0.3443
Epoch 6580/10000; Iter 51/80; Loss: 0.3542
Epoch 6580/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6581/10000; Iter 1/80; Loss: 0.3340
Epoch 6581/10000; Iter 51/80; Loss: 0.4166
Epoch 6581/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.066
Epoch 6582/10000; Iter 1/80; Loss: 0.3332
Epoch 6582/10000; Iter 51/80; Loss: 0.3390
Epoch 6582/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.059
Epoch 6583/10000; Iter 1/80; Loss: 0.3234
Epoch 6583/10000; Iter 51/80; Loss: 0.3611
Epoch 6583/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.059
Epoch 6584/10000; Iter 1/80; Loss: 0.3558
Epoch 6584/10000; Iter 51/80; Loss: 0.3676
Epoch 6584/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.063
Epoch 6585/10000; Iter 1/80; Loss: 0.3509
Epoch 6585/10000; Iter 51/80; Loss: 0.3585
Epoch 6585/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.064
Epoch 6586/10000; Iter 1/80; Loss: 0.3355
Epoch 6586/10000; Iter 51/80; Loss: 0.3204
Epoch 6586/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.064
Epoch 6587/10000; Iter 1/80; Loss: 0.3084
Epoch 6587/10000; Iter 51/80; Loss: 0.3417
Epoch 6587/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.063
Epoch 6588/10000; Iter 1/80; Loss: 0.3380
Epoch 6588/10000; Iter 51/80; Loss: 0.3542
Epoch 6588/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.06
Epoch 6589/10000; Iter 1/80; Loss: 0.2902
Epoch 6589/10000; Iter 51/80; Loss: 0.3331
Epoch 6589/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.063
Epoch 6590/10000; Iter 1/80; Loss: 0.3317
Epoch 6590/10000; Iter 51/80; Loss: 0.3474
Epoch 6590/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.067
Epoch 6591/10000; Iter 1/80; Loss: 0.3112
Epoch 6591/10000; Iter 51/80; Loss: 0.3610
Epoch 6591/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.072
Epoch 6592/10000; Iter 1/80; Loss: 0.3539
Epoch 6592/10000; Iter 51/80; Loss: 0.4044
Epoch 6592/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.067
Epoch 6593/10000; Iter 1/80; Loss: 0.3222
Epoch 6593/10000; Iter 51/80; Loss: 0.3384
Epoch 6593/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6594/10000; Iter 1/80; Loss: 0.3629
Epoch 6594/10000; Iter 51/80; Loss: 0.3800
Epoch 6594/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.066
Epoch 6595/10000; Iter 1/80; Loss: 0.3481
Epoch 6595/10000; Iter 51/80; Loss: 0.3290
Epoch 6595/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.06
Epoch 6596/10000; Iter 1/80; Loss: 0.3248
Epoch 6596/10000; Iter 51/80; Loss: 0.3161
Epoch 6596/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.063
Epoch 6597/10000; Iter 1/80; Loss: 0.4582
Epoch 6597/10000; Iter 51/80; Loss: 0.3882
Epoch 6597/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.071
Epoch 6598/10000; Iter 1/80; Loss: 0.3884
Epoch 6598/10000; Iter 51/80; Loss: 0.3549
Epoch 6598/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.066
Epoch 6599/10000; Iter 1/80; Loss: 0.3430
Epoch 6599/10000; Iter 51/80; Loss: 0.3339
Epoch 6599/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6600/10000; Iter 1/80; Loss: 0.3733
Epoch 6600/10000; Iter 51/80; Loss: 0.2782
Epoch 6600/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.061
Epoch 6601/10000; Iter 1/80; Loss: 0.3594
Epoch 6601/10000; Iter 51/80; Loss: 0.3382
Epoch 6601/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.068
Model saved
Epoch 6602/10000; Iter 1/80; Loss: 0.3589
Epoch 6602/10000; Iter 51/80; Loss: 0.3585
Epoch 6602/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 6603/10000; Iter 1/80; Loss: 0.3003
Epoch 6603/10000; Iter 51/80; Loss: 0.3267
Epoch 6603/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6604/10000; Iter 1/80; Loss: 0.3446
Epoch 6604/10000; Iter 51/80; Loss: 0.3551
Epoch 6604/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.06
Epoch 6605/10000; Iter 1/80; Loss: 0.2957
Epoch 6605/10000; Iter 51/80; Loss: 0.3444
Epoch 6605/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.068
Epoch 6606/10000; Iter 1/80; Loss: 0.3621
Epoch 6606/10000; Iter 51/80; Loss: 0.3971
Epoch 6606/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.073
Epoch 6607/10000; Iter 1/80; Loss: 0.3117
Epoch 6607/10000; Iter 51/80; Loss: 0.3537
Epoch 6607/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.068
Epoch 6608/10000; Iter 1/80; Loss: 0.3027
Epoch 6608/10000; Iter 51/80; Loss: 0.3342
Epoch 6608/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.063
Epoch 6609/10000; Iter 1/80; Loss: 0.3954
Epoch 6609/10000; Iter 51/80; Loss: 0.4032
Epoch 6609/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6610/10000; Iter 1/80; Loss: 0.3666
Epoch 6610/10000; Iter 51/80; Loss: 0.2987
Epoch 6610/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.059
Epoch 6611/10000; Iter 1/80; Loss: 0.3327
Epoch 6611/10000; Iter 51/80; Loss: 0.3213
Epoch 6611/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6612/10000; Iter 1/80; Loss: 0.3002
Epoch 6612/10000; Iter 51/80; Loss: 0.3572
Epoch 6612/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.073
Epoch 6613/10000; Iter 1/80; Loss: 0.3333
Epoch 6613/10000; Iter 51/80; Loss: 0.3817
Epoch 6613/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.063
Epoch 6614/10000; Iter 1/80; Loss: 0.3761
Epoch 6614/10000; Iter 51/80; Loss: 0.3992
Epoch 6614/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.062
Epoch 6615/10000; Iter 1/80; Loss: 0.3159
Epoch 6615/10000; Iter 51/80; Loss: 0.3209
Epoch 6615/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6616/10000; Iter 1/80; Loss: 0.3483
Epoch 6616/10000; Iter 51/80; Loss: 0.3168
Epoch 6616/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 6617/10000; Iter 1/80; Loss: 0.3523
Epoch 6617/10000; Iter 51/80; Loss: 0.3512
Epoch 6617/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 6618/10000; Iter 1/80; Loss: 0.3118
Epoch 6618/10000; Iter 51/80; Loss: 0.3435
Epoch 6618/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6619/10000; Iter 1/80; Loss: 0.3381
Epoch 6619/10000; Iter 51/80; Loss: 0.3374
Epoch 6619/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.063
Epoch 6620/10000; Iter 1/80; Loss: 0.3649
Epoch 6620/10000; Iter 51/80; Loss: 0.3264
Epoch 6620/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.066
Epoch 6621/10000; Iter 1/80; Loss: 0.3912
Epoch 6621/10000; Iter 51/80; Loss: 0.3301
Epoch 6621/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.076
Epoch 6622/10000; Iter 1/80; Loss: 0.3566
Epoch 6622/10000; Iter 51/80; Loss: 0.3869
Epoch 6622/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.077
Epoch 6623/10000; Iter 1/80; Loss: 0.3188
Epoch 6623/10000; Iter 51/80; Loss: 0.3553
Epoch 6623/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.067
Epoch 6624/10000; Iter 1/80; Loss: 0.3092
Epoch 6624/10000; Iter 51/80; Loss: 0.3580
Epoch 6624/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.067
Epoch 6625/10000; Iter 1/80; Loss: 0.3558
Epoch 6625/10000; Iter 51/80; Loss: 0.3058
Epoch 6625/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.063
Epoch 6626/10000; Iter 1/80; Loss: 0.3337
Epoch 6626/10000; Iter 51/80; Loss: 0.3618
Epoch 6626/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6627/10000; Iter 1/80; Loss: 0.3806
Epoch 6627/10000; Iter 51/80; Loss: 0.3533
Epoch 6627/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.067
Epoch 6628/10000; Iter 1/80; Loss: 0.3511
Epoch 6628/10000; Iter 51/80; Loss: 0.3190
Epoch 6628/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.061
Epoch 6629/10000; Iter 1/80; Loss: 0.3638
Epoch 6629/10000; Iter 51/80; Loss: 0.3444
Epoch 6629/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.07
Epoch 6630/10000; Iter 1/80; Loss: 0.3459
Epoch 6630/10000; Iter 51/80; Loss: 0.3311
Epoch 6630/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.067
Epoch 6631/10000; Iter 1/80; Loss: 0.3247
Epoch 6631/10000; Iter 51/80; Loss: 0.3599
Epoch 6631/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.065
Epoch 6632/10000; Iter 1/80; Loss: 0.3080
Epoch 6632/10000; Iter 51/80; Loss: 0.4146
Epoch 6632/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.062
Epoch 6633/10000; Iter 1/80; Loss: 0.3553
Epoch 6633/10000; Iter 51/80; Loss: 0.3302
Epoch 6633/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6634/10000; Iter 1/80; Loss: 0.3076
Epoch 6634/10000; Iter 51/80; Loss: 0.3416
Epoch 6634/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.063
Epoch 6635/10000; Iter 1/80; Loss: 0.3159
Epoch 6635/10000; Iter 51/80; Loss: 0.3258
Epoch 6635/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.07
Epoch 6636/10000; Iter 1/80; Loss: 0.3604
Epoch 6636/10000; Iter 51/80; Loss: 0.3513
Epoch 6636/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.069
Epoch 6637/10000; Iter 1/80; Loss: 0.3747
Epoch 6637/10000; Iter 51/80; Loss: 0.3091
Epoch 6637/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.06
Epoch 6638/10000; Iter 1/80; Loss: 0.3503
Epoch 6638/10000; Iter 51/80; Loss: 0.3777
Epoch 6638/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.065
Epoch 6639/10000; Iter 1/80; Loss: 0.3167
Epoch 6639/10000; Iter 51/80; Loss: 0.3477
Epoch 6639/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.068
Epoch 6640/10000; Iter 1/80; Loss: 0.3221
Epoch 6640/10000; Iter 51/80; Loss: 0.3144
Epoch 6640/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.064
Epoch 6641/10000; Iter 1/80; Loss: 0.3775
Epoch 6641/10000; Iter 51/80; Loss: 0.3361
Epoch 6641/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.071
Epoch 6642/10000; Iter 1/80; Loss: 0.3942
Epoch 6642/10000; Iter 51/80; Loss: 0.3687
Epoch 6642/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 6643/10000; Iter 1/80; Loss: 0.3253
Epoch 6643/10000; Iter 51/80; Loss: 0.3683
Epoch 6643/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.068
Epoch 6644/10000; Iter 1/80; Loss: 0.3419
Epoch 6644/10000; Iter 51/80; Loss: 0.3512
Epoch 6644/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.066
Epoch 6645/10000; Iter 1/80; Loss: 0.3355
Epoch 6645/10000; Iter 51/80; Loss: 0.3845
Epoch 6645/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.069
Epoch 6646/10000; Iter 1/80; Loss: 0.3453
Epoch 6646/10000; Iter 51/80; Loss: 0.3712
Epoch 6646/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.065
Epoch 6647/10000; Iter 1/80; Loss: 0.3099
Epoch 6647/10000; Iter 51/80; Loss: 0.3440
Epoch 6647/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.058
Epoch 6648/10000; Iter 1/80; Loss: 0.3244
Epoch 6648/10000; Iter 51/80; Loss: 0.3537
Epoch 6648/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.062
Epoch 6649/10000; Iter 1/80; Loss: 0.3384
Epoch 6649/10000; Iter 51/80; Loss: 0.3863
Epoch 6649/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.066
Epoch 6650/10000; Iter 1/80; Loss: 0.3251
Epoch 6650/10000; Iter 51/80; Loss: 0.3512
Epoch 6650/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.074
Epoch 6651/10000; Iter 1/80; Loss: 0.3879
Epoch 6651/10000; Iter 51/80; Loss: 0.3425
Epoch 6651/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6652/10000; Iter 1/80; Loss: 0.3282
Epoch 6652/10000; Iter 51/80; Loss: 0.2906
Epoch 6652/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.062
Epoch 6653/10000; Iter 1/80; Loss: 0.3599
Epoch 6653/10000; Iter 51/80; Loss: 0.3759
Epoch 6653/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.069
Epoch 6654/10000; Iter 1/80; Loss: 0.3223
Epoch 6654/10000; Iter 51/80; Loss: 0.3996
Epoch 6654/10000; Iter 80/80; Training Loss: 0.3580, Test Loss: 0.071
Epoch 6655/10000; Iter 1/80; Loss: 0.3752
Epoch 6655/10000; Iter 51/80; Loss: 0.3255
Epoch 6655/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 6656/10000; Iter 1/80; Loss: 0.3581
Epoch 6656/10000; Iter 51/80; Loss: 0.2959
Epoch 6656/10000; Iter 80/80; Training Loss: 0.3550, Test Loss: 0.076
Epoch 6657/10000; Iter 1/80; Loss: 0.3897
Epoch 6657/10000; Iter 51/80; Loss: 0.3955
Epoch 6657/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.067
Epoch 6658/10000; Iter 1/80; Loss: 0.4376
Epoch 6658/10000; Iter 51/80; Loss: 0.3692
Epoch 6658/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.062
Epoch 6659/10000; Iter 1/80; Loss: 0.3168
Epoch 6659/10000; Iter 51/80; Loss: 0.3610
Epoch 6659/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6660/10000; Iter 1/80; Loss: 0.3519
Epoch 6660/10000; Iter 51/80; Loss: 0.3676
Epoch 6660/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.063
Epoch 6661/10000; Iter 1/80; Loss: 0.3617
Epoch 6661/10000; Iter 51/80; Loss: 0.3657
Epoch 6661/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.076
Epoch 6662/10000; Iter 1/80; Loss: 0.3754
Epoch 6662/10000; Iter 51/80; Loss: 0.3400
Epoch 6662/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.065
Epoch 6663/10000; Iter 1/80; Loss: 0.4000
Epoch 6663/10000; Iter 51/80; Loss: 0.4326
Epoch 6663/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6664/10000; Iter 1/80; Loss: 0.3727
Epoch 6664/10000; Iter 51/80; Loss: 0.3072
Epoch 6664/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.064
Epoch 6665/10000; Iter 1/80; Loss: 0.3608
Epoch 6665/10000; Iter 51/80; Loss: 0.3996
Epoch 6665/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.065
Epoch 6666/10000; Iter 1/80; Loss: 0.3457
Epoch 6666/10000; Iter 51/80; Loss: 0.3716
Epoch 6666/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.071
Epoch 6667/10000; Iter 1/80; Loss: 0.3201
Epoch 6667/10000; Iter 51/80; Loss: 0.3358
Epoch 6667/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 6668/10000; Iter 1/80; Loss: 0.3032
Epoch 6668/10000; Iter 51/80; Loss: 0.3255
Epoch 6668/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.076
Epoch 6669/10000; Iter 1/80; Loss: 0.3411
Epoch 6669/10000; Iter 51/80; Loss: 0.3828
Epoch 6669/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 6670/10000; Iter 1/80; Loss: 0.3772
Epoch 6670/10000; Iter 51/80; Loss: 0.3499
Epoch 6670/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 6671/10000; Iter 1/80; Loss: 0.3322
Epoch 6671/10000; Iter 51/80; Loss: 0.4073
Epoch 6671/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.073
Epoch 6672/10000; Iter 1/80; Loss: 0.3722
Epoch 6672/10000; Iter 51/80; Loss: 0.3531
Epoch 6672/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 6673/10000; Iter 1/80; Loss: 0.3209
Epoch 6673/10000; Iter 51/80; Loss: 0.3695
Epoch 6673/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.065
Epoch 6674/10000; Iter 1/80; Loss: 0.3584
Epoch 6674/10000; Iter 51/80; Loss: 0.3912
Epoch 6674/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.056
Epoch 6675/10000; Iter 1/80; Loss: 0.3326
Epoch 6675/10000; Iter 51/80; Loss: 0.4144
Epoch 6675/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6676/10000; Iter 1/80; Loss: 0.3947
Epoch 6676/10000; Iter 51/80; Loss: 0.3975
Epoch 6676/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.067
Epoch 6677/10000; Iter 1/80; Loss: 0.3390
Epoch 6677/10000; Iter 51/80; Loss: 0.4103
Epoch 6677/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.069
Epoch 6678/10000; Iter 1/80; Loss: 0.3639
Epoch 6678/10000; Iter 51/80; Loss: 0.3588
Epoch 6678/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.067
Epoch 6679/10000; Iter 1/80; Loss: 0.3287
Epoch 6679/10000; Iter 51/80; Loss: 0.3631
Epoch 6679/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.065
Epoch 6680/10000; Iter 1/80; Loss: 0.3635
Epoch 6680/10000; Iter 51/80; Loss: 0.3950
Epoch 6680/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.065
Epoch 6681/10000; Iter 1/80; Loss: 0.3465
Epoch 6681/10000; Iter 51/80; Loss: 0.3434
Epoch 6681/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6682/10000; Iter 1/80; Loss: 0.3319
Epoch 6682/10000; Iter 51/80; Loss: 0.3941
Epoch 6682/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.067
Epoch 6683/10000; Iter 1/80; Loss: 0.3546
Epoch 6683/10000; Iter 51/80; Loss: 0.3348
Epoch 6683/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.066
Epoch 6684/10000; Iter 1/80; Loss: 0.3707
Epoch 6684/10000; Iter 51/80; Loss: 0.3490
Epoch 6684/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6685/10000; Iter 1/80; Loss: 0.4222
Epoch 6685/10000; Iter 51/80; Loss: 0.3172
Epoch 6685/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.063
Epoch 6686/10000; Iter 1/80; Loss: 0.3067
Epoch 6686/10000; Iter 51/80; Loss: 0.3304
Epoch 6686/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6687/10000; Iter 1/80; Loss: 0.3063
Epoch 6687/10000; Iter 51/80; Loss: 0.3863
Epoch 6687/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.065
Epoch 6688/10000; Iter 1/80; Loss: 0.4157
Epoch 6688/10000; Iter 51/80; Loss: 0.3453
Epoch 6688/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.063
Epoch 6689/10000; Iter 1/80; Loss: 0.3407
Epoch 6689/10000; Iter 51/80; Loss: 0.3537
Epoch 6689/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.066
Epoch 6690/10000; Iter 1/80; Loss: 0.3173
Epoch 6690/10000; Iter 51/80; Loss: 0.3448
Epoch 6690/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.07
Epoch 6691/10000; Iter 1/80; Loss: 0.4184
Epoch 6691/10000; Iter 51/80; Loss: 0.3234
Epoch 6691/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.07
Epoch 6692/10000; Iter 1/80; Loss: 0.3298
Epoch 6692/10000; Iter 51/80; Loss: 0.3122
Epoch 6692/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.063
Epoch 6693/10000; Iter 1/80; Loss: 0.3719
Epoch 6693/10000; Iter 51/80; Loss: 0.3127
Epoch 6693/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6694/10000; Iter 1/80; Loss: 0.3662
Epoch 6694/10000; Iter 51/80; Loss: 0.3454
Epoch 6694/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 6695/10000; Iter 1/80; Loss: 0.3516
Epoch 6695/10000; Iter 51/80; Loss: 0.3512
Epoch 6695/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.06
Epoch 6696/10000; Iter 1/80; Loss: 0.3892
Epoch 6696/10000; Iter 51/80; Loss: 0.3799
Epoch 6696/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6697/10000; Iter 1/80; Loss: 0.3290
Epoch 6697/10000; Iter 51/80; Loss: 0.2983
Epoch 6697/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.059
Epoch 6698/10000; Iter 1/80; Loss: 0.3178
Epoch 6698/10000; Iter 51/80; Loss: 0.3268
Epoch 6698/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.062
Epoch 6699/10000; Iter 1/80; Loss: 0.3267
Epoch 6699/10000; Iter 51/80; Loss: 0.3366
Epoch 6699/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 6700/10000; Iter 1/80; Loss: 0.3320
Epoch 6700/10000; Iter 51/80; Loss: 0.3618
Epoch 6700/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.069
Epoch 6701/10000; Iter 1/80; Loss: 0.3611
Epoch 6701/10000; Iter 51/80; Loss: 0.3359
Epoch 6701/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Model saved
Epoch 6702/10000; Iter 1/80; Loss: 0.3407
Epoch 6702/10000; Iter 51/80; Loss: 0.3089
Epoch 6702/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.067
Epoch 6703/10000; Iter 1/80; Loss: 0.3692
Epoch 6703/10000; Iter 51/80; Loss: 0.3310
Epoch 6703/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 6704/10000; Iter 1/80; Loss: 0.3263
Epoch 6704/10000; Iter 51/80; Loss: 0.3109
Epoch 6704/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.069
Epoch 6705/10000; Iter 1/80; Loss: 0.3180
Epoch 6705/10000; Iter 51/80; Loss: 0.3390
Epoch 6705/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6706/10000; Iter 1/80; Loss: 0.4597
Epoch 6706/10000; Iter 51/80; Loss: 0.3547
Epoch 6706/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.063
Epoch 6707/10000; Iter 1/80; Loss: 0.3956
Epoch 6707/10000; Iter 51/80; Loss: 0.3762
Epoch 6707/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.06
Epoch 6708/10000; Iter 1/80; Loss: 0.3374
Epoch 6708/10000; Iter 51/80; Loss: 0.3479
Epoch 6708/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 6709/10000; Iter 1/80; Loss: 0.4140
Epoch 6709/10000; Iter 51/80; Loss: 0.3171
Epoch 6709/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6710/10000; Iter 1/80; Loss: 0.3339
Epoch 6710/10000; Iter 51/80; Loss: 0.3590
Epoch 6710/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.067
Epoch 6711/10000; Iter 1/80; Loss: 0.3740
Epoch 6711/10000; Iter 51/80; Loss: 0.3147
Epoch 6711/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 6712/10000; Iter 1/80; Loss: 0.3381
Epoch 6712/10000; Iter 51/80; Loss: 0.3405
Epoch 6712/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 6713/10000; Iter 1/80; Loss: 0.3235
Epoch 6713/10000; Iter 51/80; Loss: 0.3047
Epoch 6713/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.075
Epoch 6714/10000; Iter 1/80; Loss: 0.3279
Epoch 6714/10000; Iter 51/80; Loss: 0.3445
Epoch 6714/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.074
Epoch 6715/10000; Iter 1/80; Loss: 0.3589
Epoch 6715/10000; Iter 51/80; Loss: 0.3302
Epoch 6715/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.068
Epoch 6716/10000; Iter 1/80; Loss: 0.3585
Epoch 6716/10000; Iter 51/80; Loss: 0.3009
Epoch 6716/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 6717/10000; Iter 1/80; Loss: 0.3769
Epoch 6717/10000; Iter 51/80; Loss: 0.3887
Epoch 6717/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.068
Epoch 6718/10000; Iter 1/80; Loss: 0.3352
Epoch 6718/10000; Iter 51/80; Loss: 0.3315
Epoch 6718/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 6719/10000; Iter 1/80; Loss: 0.3561
Epoch 6719/10000; Iter 51/80; Loss: 0.3483
Epoch 6719/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6720/10000; Iter 1/80; Loss: 0.3503
Epoch 6720/10000; Iter 51/80; Loss: 0.3514
Epoch 6720/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.062
Epoch 6721/10000; Iter 1/80; Loss: 0.3101
Epoch 6721/10000; Iter 51/80; Loss: 0.3072
Epoch 6721/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.062
Epoch 6722/10000; Iter 1/80; Loss: 0.4579
Epoch 6722/10000; Iter 51/80; Loss: 0.3602
Epoch 6722/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6723/10000; Iter 1/80; Loss: 0.2981
Epoch 6723/10000; Iter 51/80; Loss: 0.3467
Epoch 6723/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.071
Epoch 6724/10000; Iter 1/80; Loss: 0.3205
Epoch 6724/10000; Iter 51/80; Loss: 0.3416
Epoch 6724/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 6725/10000; Iter 1/80; Loss: 0.3096
Epoch 6725/10000; Iter 51/80; Loss: 0.3029
Epoch 6725/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.071
Epoch 6726/10000; Iter 1/80; Loss: 0.3638
Epoch 6726/10000; Iter 51/80; Loss: 0.3643
Epoch 6726/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.065
Epoch 6727/10000; Iter 1/80; Loss: 0.2893
Epoch 6727/10000; Iter 51/80; Loss: 0.3220
Epoch 6727/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.065
Epoch 6728/10000; Iter 1/80; Loss: 0.3416
Epoch 6728/10000; Iter 51/80; Loss: 0.4014
Epoch 6728/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.065
Epoch 6729/10000; Iter 1/80; Loss: 0.3519
Epoch 6729/10000; Iter 51/80; Loss: 0.3861
Epoch 6729/10000; Iter 80/80; Training Loss: 0.3530, Test Loss: 0.067
Epoch 6730/10000; Iter 1/80; Loss: 0.3296
Epoch 6730/10000; Iter 51/80; Loss: 0.3072
Epoch 6730/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 6731/10000; Iter 1/80; Loss: 0.3881
Epoch 6731/10000; Iter 51/80; Loss: 0.4001
Epoch 6731/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 6732/10000; Iter 1/80; Loss: 0.3396
Epoch 6732/10000; Iter 51/80; Loss: 0.3519
Epoch 6732/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.072
Epoch 6733/10000; Iter 1/80; Loss: 0.3530
Epoch 6733/10000; Iter 51/80; Loss: 0.2939
Epoch 6733/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.073
Epoch 6734/10000; Iter 1/80; Loss: 0.3203
Epoch 6734/10000; Iter 51/80; Loss: 0.3367
Epoch 6734/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6735/10000; Iter 1/80; Loss: 0.3602
Epoch 6735/10000; Iter 51/80; Loss: 0.3751
Epoch 6735/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6736/10000; Iter 1/80; Loss: 0.3237
Epoch 6736/10000; Iter 51/80; Loss: 0.3531
Epoch 6736/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.074
Epoch 6737/10000; Iter 1/80; Loss: 0.3159
Epoch 6737/10000; Iter 51/80; Loss: 0.2650
Epoch 6737/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 6738/10000; Iter 1/80; Loss: 0.3184
Epoch 6738/10000; Iter 51/80; Loss: 0.3229
Epoch 6738/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 6739/10000; Iter 1/80; Loss: 0.3208
Epoch 6739/10000; Iter 51/80; Loss: 0.2859
Epoch 6739/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6740/10000; Iter 1/80; Loss: 0.3377
Epoch 6740/10000; Iter 51/80; Loss: 0.3411
Epoch 6740/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.074
Epoch 6741/10000; Iter 1/80; Loss: 0.3111
Epoch 6741/10000; Iter 51/80; Loss: 0.2827
Epoch 6741/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 6742/10000; Iter 1/80; Loss: 0.3955
Epoch 6742/10000; Iter 51/80; Loss: 0.4135
Epoch 6742/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.062
Epoch 6743/10000; Iter 1/80; Loss: 0.3965
Epoch 6743/10000; Iter 51/80; Loss: 0.3442
Epoch 6743/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.066
Epoch 6744/10000; Iter 1/80; Loss: 0.3681
Epoch 6744/10000; Iter 51/80; Loss: 0.3321
Epoch 6744/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 6745/10000; Iter 1/80; Loss: 0.3765
Epoch 6745/10000; Iter 51/80; Loss: 0.3168
Epoch 6745/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 6746/10000; Iter 1/80; Loss: 0.3201
Epoch 6746/10000; Iter 51/80; Loss: 0.3390
Epoch 6746/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 6747/10000; Iter 1/80; Loss: 0.3299
Epoch 6747/10000; Iter 51/80; Loss: 0.3228
Epoch 6747/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 6748/10000; Iter 1/80; Loss: 0.3394
Epoch 6748/10000; Iter 51/80; Loss: 0.3661
Epoch 6748/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 6749/10000; Iter 1/80; Loss: 0.3626
Epoch 6749/10000; Iter 51/80; Loss: 0.3384
Epoch 6749/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.066
Epoch 6750/10000; Iter 1/80; Loss: 0.3317
Epoch 6750/10000; Iter 51/80; Loss: 0.3193
Epoch 6750/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.068
Epoch 6751/10000; Iter 1/80; Loss: 0.2844
Epoch 6751/10000; Iter 51/80; Loss: 0.2994
Epoch 6751/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.063
Epoch 6752/10000; Iter 1/80; Loss: 0.2916
Epoch 6752/10000; Iter 51/80; Loss: 0.3633
Epoch 6752/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 6753/10000; Iter 1/80; Loss: 0.3487
Epoch 6753/10000; Iter 51/80; Loss: 0.3432
Epoch 6753/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.071
Epoch 6754/10000; Iter 1/80; Loss: 0.3887
Epoch 6754/10000; Iter 51/80; Loss: 0.3727
Epoch 6754/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6755/10000; Iter 1/80; Loss: 0.3046
Epoch 6755/10000; Iter 51/80; Loss: 0.3570
Epoch 6755/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 6756/10000; Iter 1/80; Loss: 0.3145
Epoch 6756/10000; Iter 51/80; Loss: 0.3430
Epoch 6756/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.067
Epoch 6757/10000; Iter 1/80; Loss: 0.3048
Epoch 6757/10000; Iter 51/80; Loss: 0.3961
Epoch 6757/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.064
Epoch 6758/10000; Iter 1/80; Loss: 0.3384
Epoch 6758/10000; Iter 51/80; Loss: 0.3525
Epoch 6758/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6759/10000; Iter 1/80; Loss: 0.3424
Epoch 6759/10000; Iter 51/80; Loss: 0.3021
Epoch 6759/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 6760/10000; Iter 1/80; Loss: 0.3249
Epoch 6760/10000; Iter 51/80; Loss: 0.3268
Epoch 6760/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.074
Epoch 6761/10000; Iter 1/80; Loss: 0.3514
Epoch 6761/10000; Iter 51/80; Loss: 0.3096
Epoch 6761/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.068
Epoch 6762/10000; Iter 1/80; Loss: 0.3350
Epoch 6762/10000; Iter 51/80; Loss: 0.3507
Epoch 6762/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.073
Epoch 6763/10000; Iter 1/80; Loss: 0.4282
Epoch 6763/10000; Iter 51/80; Loss: 0.3763
Epoch 6763/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.07
Epoch 6764/10000; Iter 1/80; Loss: 0.4035
Epoch 6764/10000; Iter 51/80; Loss: 0.3954
Epoch 6764/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.075
Epoch 6765/10000; Iter 1/80; Loss: 0.3124
Epoch 6765/10000; Iter 51/80; Loss: 0.4134
Epoch 6765/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6766/10000; Iter 1/80; Loss: 0.3275
Epoch 6766/10000; Iter 51/80; Loss: 0.3620
Epoch 6766/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.072
Epoch 6767/10000; Iter 1/80; Loss: 0.3699
Epoch 6767/10000; Iter 51/80; Loss: 0.3409
Epoch 6767/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.063
Epoch 6768/10000; Iter 1/80; Loss: 0.4054
Epoch 6768/10000; Iter 51/80; Loss: 0.3246
Epoch 6768/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.074
Epoch 6769/10000; Iter 1/80; Loss: 0.3916
Epoch 6769/10000; Iter 51/80; Loss: 0.3698
Epoch 6769/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6770/10000; Iter 1/80; Loss: 0.3669
Epoch 6770/10000; Iter 51/80; Loss: 0.3485
Epoch 6770/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.069
Epoch 6771/10000; Iter 1/80; Loss: 0.4080
Epoch 6771/10000; Iter 51/80; Loss: 0.3247
Epoch 6771/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.073
Epoch 6772/10000; Iter 1/80; Loss: 0.2689
Epoch 6772/10000; Iter 51/80; Loss: 0.3439
Epoch 6772/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.068
Epoch 6773/10000; Iter 1/80; Loss: 0.3038
Epoch 6773/10000; Iter 51/80; Loss: 0.3625
Epoch 6773/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.063
Epoch 6774/10000; Iter 1/80; Loss: 0.3573
Epoch 6774/10000; Iter 51/80; Loss: 0.3369
Epoch 6774/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6775/10000; Iter 1/80; Loss: 0.3157
Epoch 6775/10000; Iter 51/80; Loss: 0.3679
Epoch 6775/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.073
Epoch 6776/10000; Iter 1/80; Loss: 0.3051
Epoch 6776/10000; Iter 51/80; Loss: 0.3469
Epoch 6776/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.072
Epoch 6777/10000; Iter 1/80; Loss: 0.3309
Epoch 6777/10000; Iter 51/80; Loss: 0.3532
Epoch 6777/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6778/10000; Iter 1/80; Loss: 0.3086
Epoch 6778/10000; Iter 51/80; Loss: 0.3943
Epoch 6778/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.063
Epoch 6779/10000; Iter 1/80; Loss: 0.3639
Epoch 6779/10000; Iter 51/80; Loss: 0.3847
Epoch 6779/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6780/10000; Iter 1/80; Loss: 0.3591
Epoch 6780/10000; Iter 51/80; Loss: 0.3104
Epoch 6780/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 6781/10000; Iter 1/80; Loss: 0.3398
Epoch 6781/10000; Iter 51/80; Loss: 0.3241
Epoch 6781/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.064
Epoch 6782/10000; Iter 1/80; Loss: 0.3299
Epoch 6782/10000; Iter 51/80; Loss: 0.3997
Epoch 6782/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 6783/10000; Iter 1/80; Loss: 0.3553
Epoch 6783/10000; Iter 51/80; Loss: 0.3253
Epoch 6783/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.071
Epoch 6784/10000; Iter 1/80; Loss: 0.3456
Epoch 6784/10000; Iter 51/80; Loss: 0.2601
Epoch 6784/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.066
Epoch 6785/10000; Iter 1/80; Loss: 0.3437
Epoch 6785/10000; Iter 51/80; Loss: 0.3607
Epoch 6785/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.064
Epoch 6786/10000; Iter 1/80; Loss: 0.3418
Epoch 6786/10000; Iter 51/80; Loss: 0.3171
Epoch 6786/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.072
Epoch 6787/10000; Iter 1/80; Loss: 0.3573
Epoch 6787/10000; Iter 51/80; Loss: 0.3690
Epoch 6787/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.058
Epoch 6788/10000; Iter 1/80; Loss: 0.2724
Epoch 6788/10000; Iter 51/80; Loss: 0.3338
Epoch 6788/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.06
Epoch 6789/10000; Iter 1/80; Loss: 0.3289
Epoch 6789/10000; Iter 51/80; Loss: 0.3812
Epoch 6789/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.069
Epoch 6790/10000; Iter 1/80; Loss: 0.3881
Epoch 6790/10000; Iter 51/80; Loss: 0.2829
Epoch 6790/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.07
Epoch 6791/10000; Iter 1/80; Loss: 0.3018
Epoch 6791/10000; Iter 51/80; Loss: 0.3312
Epoch 6791/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 6792/10000; Iter 1/80; Loss: 0.3288
Epoch 6792/10000; Iter 51/80; Loss: 0.3215
Epoch 6792/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.061
Epoch 6793/10000; Iter 1/80; Loss: 0.2968
Epoch 6793/10000; Iter 51/80; Loss: 0.3232
Epoch 6793/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 6794/10000; Iter 1/80; Loss: 0.3167
Epoch 6794/10000; Iter 51/80; Loss: 0.3353
Epoch 6794/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.067
Epoch 6795/10000; Iter 1/80; Loss: 0.3415
Epoch 6795/10000; Iter 51/80; Loss: 0.3348
Epoch 6795/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.07
Epoch 6796/10000; Iter 1/80; Loss: 0.3519
Epoch 6796/10000; Iter 51/80; Loss: 0.3770
Epoch 6796/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 6797/10000; Iter 1/80; Loss: 0.3591
Epoch 6797/10000; Iter 51/80; Loss: 0.3488
Epoch 6797/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 6798/10000; Iter 1/80; Loss: 0.3304
Epoch 6798/10000; Iter 51/80; Loss: 0.3723
Epoch 6798/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.071
Epoch 6799/10000; Iter 1/80; Loss: 0.3042
Epoch 6799/10000; Iter 51/80; Loss: 0.3056
Epoch 6799/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.068
Epoch 6800/10000; Iter 1/80; Loss: 0.3292
Epoch 6800/10000; Iter 51/80; Loss: 0.3403
Epoch 6800/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 6801/10000; Iter 1/80; Loss: 0.3782
Epoch 6801/10000; Iter 51/80; Loss: 0.4114
Epoch 6801/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.065
Model saved
Epoch 6802/10000; Iter 1/80; Loss: 0.3341
Epoch 6802/10000; Iter 51/80; Loss: 0.3254
Epoch 6802/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 6803/10000; Iter 1/80; Loss: 0.3852
Epoch 6803/10000; Iter 51/80; Loss: 0.3595
Epoch 6803/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.069
Epoch 6804/10000; Iter 1/80; Loss: 0.3826
Epoch 6804/10000; Iter 51/80; Loss: 0.2997
Epoch 6804/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.075
Epoch 6805/10000; Iter 1/80; Loss: 0.3146
Epoch 6805/10000; Iter 51/80; Loss: 0.3189
Epoch 6805/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6806/10000; Iter 1/80; Loss: 0.3570
Epoch 6806/10000; Iter 51/80; Loss: 0.3598
Epoch 6806/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.063
Epoch 6807/10000; Iter 1/80; Loss: 0.3290
Epoch 6807/10000; Iter 51/80; Loss: 0.3361
Epoch 6807/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6808/10000; Iter 1/80; Loss: 0.3585
Epoch 6808/10000; Iter 51/80; Loss: 0.3538
Epoch 6808/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.063
Epoch 6809/10000; Iter 1/80; Loss: 0.3019
Epoch 6809/10000; Iter 51/80; Loss: 0.3481
Epoch 6809/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.065
Epoch 6810/10000; Iter 1/80; Loss: 0.3015
Epoch 6810/10000; Iter 51/80; Loss: 0.3828
Epoch 6810/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.069
Epoch 6811/10000; Iter 1/80; Loss: 0.3548
Epoch 6811/10000; Iter 51/80; Loss: 0.4258
Epoch 6811/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6812/10000; Iter 1/80; Loss: 0.3350
Epoch 6812/10000; Iter 51/80; Loss: 0.3645
Epoch 6812/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 6813/10000; Iter 1/80; Loss: 0.3232
Epoch 6813/10000; Iter 51/80; Loss: 0.3808
Epoch 6813/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.065
Epoch 6814/10000; Iter 1/80; Loss: 0.3130
Epoch 6814/10000; Iter 51/80; Loss: 0.3070
Epoch 6814/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.072
Epoch 6815/10000; Iter 1/80; Loss: 0.3214
Epoch 6815/10000; Iter 51/80; Loss: 0.3066
Epoch 6815/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.065
Epoch 6816/10000; Iter 1/80; Loss: 0.2933
Epoch 6816/10000; Iter 51/80; Loss: 0.3078
Epoch 6816/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.061
Epoch 6817/10000; Iter 1/80; Loss: 0.3878
Epoch 6817/10000; Iter 51/80; Loss: 0.3718
Epoch 6817/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6818/10000; Iter 1/80; Loss: 0.3716
Epoch 6818/10000; Iter 51/80; Loss: 0.3371
Epoch 6818/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.068
Epoch 6819/10000; Iter 1/80; Loss: 0.4061
Epoch 6819/10000; Iter 51/80; Loss: 0.3445
Epoch 6819/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.067
Epoch 6820/10000; Iter 1/80; Loss: 0.3396
Epoch 6820/10000; Iter 51/80; Loss: 0.3416
Epoch 6820/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 6821/10000; Iter 1/80; Loss: 0.3372
Epoch 6821/10000; Iter 51/80; Loss: 0.4047
Epoch 6821/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 6822/10000; Iter 1/80; Loss: 0.3733
Epoch 6822/10000; Iter 51/80; Loss: 0.3647
Epoch 6822/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 6823/10000; Iter 1/80; Loss: 0.3128
Epoch 6823/10000; Iter 51/80; Loss: 0.3564
Epoch 6823/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 6824/10000; Iter 1/80; Loss: 0.4130
Epoch 6824/10000; Iter 51/80; Loss: 0.3280
Epoch 6824/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.072
Epoch 6825/10000; Iter 1/80; Loss: 0.3830
Epoch 6825/10000; Iter 51/80; Loss: 0.4050
Epoch 6825/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.063
Epoch 6826/10000; Iter 1/80; Loss: 0.2595
Epoch 6826/10000; Iter 51/80; Loss: 0.3858
Epoch 6826/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.066
Epoch 6827/10000; Iter 1/80; Loss: 0.3293
Epoch 6827/10000; Iter 51/80; Loss: 0.3444
Epoch 6827/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6828/10000; Iter 1/80; Loss: 0.3410
Epoch 6828/10000; Iter 51/80; Loss: 0.3805
Epoch 6828/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 6829/10000; Iter 1/80; Loss: 0.3534
Epoch 6829/10000; Iter 51/80; Loss: 0.3577
Epoch 6829/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.076
Epoch 6830/10000; Iter 1/80; Loss: 0.2933
Epoch 6830/10000; Iter 51/80; Loss: 0.2972
Epoch 6830/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.069
Epoch 6831/10000; Iter 1/80; Loss: 0.2934
Epoch 6831/10000; Iter 51/80; Loss: 0.3338
Epoch 6831/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 6832/10000; Iter 1/80; Loss: 0.3333
Epoch 6832/10000; Iter 51/80; Loss: 0.4067
Epoch 6832/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.062
Epoch 6833/10000; Iter 1/80; Loss: 0.2869
Epoch 6833/10000; Iter 51/80; Loss: 0.3592
Epoch 6833/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 6834/10000; Iter 1/80; Loss: 0.3001
Epoch 6834/10000; Iter 51/80; Loss: 0.3777
Epoch 6834/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.077
Epoch 6835/10000; Iter 1/80; Loss: 0.3595
Epoch 6835/10000; Iter 51/80; Loss: 0.3642
Epoch 6835/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.062
Epoch 6836/10000; Iter 1/80; Loss: 0.3561
Epoch 6836/10000; Iter 51/80; Loss: 0.4079
Epoch 6836/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.072
Epoch 6837/10000; Iter 1/80; Loss: 0.3334
Epoch 6837/10000; Iter 51/80; Loss: 0.3384
Epoch 6837/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 6838/10000; Iter 1/80; Loss: 0.3461
Epoch 6838/10000; Iter 51/80; Loss: 0.3214
Epoch 6838/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.077
Epoch 6839/10000; Iter 1/80; Loss: 0.3768
Epoch 6839/10000; Iter 51/80; Loss: 0.3904
Epoch 6839/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.061
Epoch 6840/10000; Iter 1/80; Loss: 0.3453
Epoch 6840/10000; Iter 51/80; Loss: 0.4036
Epoch 6840/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.069
Epoch 6841/10000; Iter 1/80; Loss: 0.2796
Epoch 6841/10000; Iter 51/80; Loss: 0.3572
Epoch 6841/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.072
Epoch 6842/10000; Iter 1/80; Loss: 0.3715
Epoch 6842/10000; Iter 51/80; Loss: 0.3435
Epoch 6842/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.065
Epoch 6843/10000; Iter 1/80; Loss: 0.3661
Epoch 6843/10000; Iter 51/80; Loss: 0.3345
Epoch 6843/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6844/10000; Iter 1/80; Loss: 0.3183
Epoch 6844/10000; Iter 51/80; Loss: 0.3410
Epoch 6844/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6845/10000; Iter 1/80; Loss: 0.3822
Epoch 6845/10000; Iter 51/80; Loss: 0.3600
Epoch 6845/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.059
Epoch 6846/10000; Iter 1/80; Loss: 0.4254
Epoch 6846/10000; Iter 51/80; Loss: 0.3078
Epoch 6846/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6847/10000; Iter 1/80; Loss: 0.3173
Epoch 6847/10000; Iter 51/80; Loss: 0.3003
Epoch 6847/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.074
Epoch 6848/10000; Iter 1/80; Loss: 0.3331
Epoch 6848/10000; Iter 51/80; Loss: 0.3831
Epoch 6848/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.069
Epoch 6849/10000; Iter 1/80; Loss: 0.2793
Epoch 6849/10000; Iter 51/80; Loss: 0.3565
Epoch 6849/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 6850/10000; Iter 1/80; Loss: 0.3049
Epoch 6850/10000; Iter 51/80; Loss: 0.3212
Epoch 6850/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.064
Epoch 6851/10000; Iter 1/80; Loss: 0.3115
Epoch 6851/10000; Iter 51/80; Loss: 0.3252
Epoch 6851/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 6852/10000; Iter 1/80; Loss: 0.3860
Epoch 6852/10000; Iter 51/80; Loss: 0.3791
Epoch 6852/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 6853/10000; Iter 1/80; Loss: 0.4079
Epoch 6853/10000; Iter 51/80; Loss: 0.3424
Epoch 6853/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.077
Epoch 6854/10000; Iter 1/80; Loss: 0.3306
Epoch 6854/10000; Iter 51/80; Loss: 0.3257
Epoch 6854/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.067
Epoch 6855/10000; Iter 1/80; Loss: 0.3681
Epoch 6855/10000; Iter 51/80; Loss: 0.3728
Epoch 6855/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.07
Epoch 6856/10000; Iter 1/80; Loss: 0.3747
Epoch 6856/10000; Iter 51/80; Loss: 0.3080
Epoch 6856/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.071
Epoch 6857/10000; Iter 1/80; Loss: 0.4313
Epoch 6857/10000; Iter 51/80; Loss: 0.3645
Epoch 6857/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.063
Epoch 6858/10000; Iter 1/80; Loss: 0.3301
Epoch 6858/10000; Iter 51/80; Loss: 0.3372
Epoch 6858/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.074
Epoch 6859/10000; Iter 1/80; Loss: 0.3388
Epoch 6859/10000; Iter 51/80; Loss: 0.3676
Epoch 6859/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.068
Epoch 6860/10000; Iter 1/80; Loss: 0.3269
Epoch 6860/10000; Iter 51/80; Loss: 0.3707
Epoch 6860/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6861/10000; Iter 1/80; Loss: 0.3616
Epoch 6861/10000; Iter 51/80; Loss: 0.2838
Epoch 6861/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 6862/10000; Iter 1/80; Loss: 0.3633
Epoch 6862/10000; Iter 51/80; Loss: 0.3449
Epoch 6862/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6863/10000; Iter 1/80; Loss: 0.3354
Epoch 6863/10000; Iter 51/80; Loss: 0.3535
Epoch 6863/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6864/10000; Iter 1/80; Loss: 0.2937
Epoch 6864/10000; Iter 51/80; Loss: 0.3695
Epoch 6864/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.068
Epoch 6865/10000; Iter 1/80; Loss: 0.4111
Epoch 6865/10000; Iter 51/80; Loss: 0.2965
Epoch 6865/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 6866/10000; Iter 1/80; Loss: 0.3177
Epoch 6866/10000; Iter 51/80; Loss: 0.3597
Epoch 6866/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.063
Epoch 6867/10000; Iter 1/80; Loss: 0.3347
Epoch 6867/10000; Iter 51/80; Loss: 0.3485
Epoch 6867/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.064
Epoch 6868/10000; Iter 1/80; Loss: 0.4029
Epoch 6868/10000; Iter 51/80; Loss: 0.3986
Epoch 6868/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.066
Epoch 6869/10000; Iter 1/80; Loss: 0.3832
Epoch 6869/10000; Iter 51/80; Loss: 0.3400
Epoch 6869/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.066
Epoch 6870/10000; Iter 1/80; Loss: 0.3074
Epoch 6870/10000; Iter 51/80; Loss: 0.3443
Epoch 6870/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6871/10000; Iter 1/80; Loss: 0.3867
Epoch 6871/10000; Iter 51/80; Loss: 0.3318
Epoch 6871/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.064
Epoch 6872/10000; Iter 1/80; Loss: 0.3380
Epoch 6872/10000; Iter 51/80; Loss: 0.3903
Epoch 6872/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 6873/10000; Iter 1/80; Loss: 0.3335
Epoch 6873/10000; Iter 51/80; Loss: 0.3580
Epoch 6873/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.064
Epoch 6874/10000; Iter 1/80; Loss: 0.3474
Epoch 6874/10000; Iter 51/80; Loss: 0.2860
Epoch 6874/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 6875/10000; Iter 1/80; Loss: 0.3387
Epoch 6875/10000; Iter 51/80; Loss: 0.3715
Epoch 6875/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 6876/10000; Iter 1/80; Loss: 0.3301
Epoch 6876/10000; Iter 51/80; Loss: 0.2657
Epoch 6876/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.061
Epoch 6877/10000; Iter 1/80; Loss: 0.3484
Epoch 6877/10000; Iter 51/80; Loss: 0.3466
Epoch 6877/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 6878/10000; Iter 1/80; Loss: 0.3663
Epoch 6878/10000; Iter 51/80; Loss: 0.3034
Epoch 6878/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 6879/10000; Iter 1/80; Loss: 0.3878
Epoch 6879/10000; Iter 51/80; Loss: 0.3305
Epoch 6879/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.069
Epoch 6880/10000; Iter 1/80; Loss: 0.3915
Epoch 6880/10000; Iter 51/80; Loss: 0.3622
Epoch 6880/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.065
Epoch 6881/10000; Iter 1/80; Loss: 0.3777
Epoch 6881/10000; Iter 51/80; Loss: 0.3604
Epoch 6881/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.069
Epoch 6882/10000; Iter 1/80; Loss: 0.3747
Epoch 6882/10000; Iter 51/80; Loss: 0.3476
Epoch 6882/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.072
Epoch 6883/10000; Iter 1/80; Loss: 0.3212
Epoch 6883/10000; Iter 51/80; Loss: 0.3668
Epoch 6883/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 6884/10000; Iter 1/80; Loss: 0.3808
Epoch 6884/10000; Iter 51/80; Loss: 0.3532
Epoch 6884/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 6885/10000; Iter 1/80; Loss: 0.3794
Epoch 6885/10000; Iter 51/80; Loss: 0.3644
Epoch 6885/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.067
Epoch 6886/10000; Iter 1/80; Loss: 0.3792
Epoch 6886/10000; Iter 51/80; Loss: 0.3250
Epoch 6886/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.071
Epoch 6887/10000; Iter 1/80; Loss: 0.3431
Epoch 6887/10000; Iter 51/80; Loss: 0.3559
Epoch 6887/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.066
Epoch 6888/10000; Iter 1/80; Loss: 0.3407
Epoch 6888/10000; Iter 51/80; Loss: 0.2895
Epoch 6888/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 6889/10000; Iter 1/80; Loss: 0.3287
Epoch 6889/10000; Iter 51/80; Loss: 0.3641
Epoch 6889/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6890/10000; Iter 1/80; Loss: 0.3330
Epoch 6890/10000; Iter 51/80; Loss: 0.3110
Epoch 6890/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.067
Epoch 6891/10000; Iter 1/80; Loss: 0.3206
Epoch 6891/10000; Iter 51/80; Loss: 0.4127
Epoch 6891/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 6892/10000; Iter 1/80; Loss: 0.3650
Epoch 6892/10000; Iter 51/80; Loss: 0.3253
Epoch 6892/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 6893/10000; Iter 1/80; Loss: 0.3477
Epoch 6893/10000; Iter 51/80; Loss: 0.3140
Epoch 6893/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.076
Epoch 6894/10000; Iter 1/80; Loss: 0.3233
Epoch 6894/10000; Iter 51/80; Loss: 0.3468
Epoch 6894/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.073
Epoch 6895/10000; Iter 1/80; Loss: 0.2861
Epoch 6895/10000; Iter 51/80; Loss: 0.3187
Epoch 6895/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 6896/10000; Iter 1/80; Loss: 0.3173
Epoch 6896/10000; Iter 51/80; Loss: 0.3552
Epoch 6896/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.067
Epoch 6897/10000; Iter 1/80; Loss: 0.3534
Epoch 6897/10000; Iter 51/80; Loss: 0.3287
Epoch 6897/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.071
Epoch 6898/10000; Iter 1/80; Loss: 0.4021
Epoch 6898/10000; Iter 51/80; Loss: 0.3551
Epoch 6898/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.062
Epoch 6899/10000; Iter 1/80; Loss: 0.3314
Epoch 6899/10000; Iter 51/80; Loss: 0.4144
Epoch 6899/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.074
Epoch 6900/10000; Iter 1/80; Loss: 0.3512
Epoch 6900/10000; Iter 51/80; Loss: 0.3831
Epoch 6900/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6901/10000; Iter 1/80; Loss: 0.2752
Epoch 6901/10000; Iter 51/80; Loss: 0.3491
Epoch 6901/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Model saved
Epoch 6902/10000; Iter 1/80; Loss: 0.3832
Epoch 6902/10000; Iter 51/80; Loss: 0.3267
Epoch 6902/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.065
Epoch 6903/10000; Iter 1/80; Loss: 0.4008
Epoch 6903/10000; Iter 51/80; Loss: 0.4153
Epoch 6903/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 6904/10000; Iter 1/80; Loss: 0.3619
Epoch 6904/10000; Iter 51/80; Loss: 0.3149
Epoch 6904/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.075
Epoch 6905/10000; Iter 1/80; Loss: 0.3741
Epoch 6905/10000; Iter 51/80; Loss: 0.3943
Epoch 6905/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.062
Epoch 6906/10000; Iter 1/80; Loss: 0.3764
Epoch 6906/10000; Iter 51/80; Loss: 0.3372
Epoch 6906/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.062
Epoch 6907/10000; Iter 1/80; Loss: 0.3452
Epoch 6907/10000; Iter 51/80; Loss: 0.3437
Epoch 6907/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6908/10000; Iter 1/80; Loss: 0.3182
Epoch 6908/10000; Iter 51/80; Loss: 0.3642
Epoch 6908/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 6909/10000; Iter 1/80; Loss: 0.3486
Epoch 6909/10000; Iter 51/80; Loss: 0.4184
Epoch 6909/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.07
Epoch 6910/10000; Iter 1/80; Loss: 0.3528
Epoch 6910/10000; Iter 51/80; Loss: 0.3638
Epoch 6910/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.075
Epoch 6911/10000; Iter 1/80; Loss: 0.3531
Epoch 6911/10000; Iter 51/80; Loss: 0.4124
Epoch 6911/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 6912/10000; Iter 1/80; Loss: 0.3250
Epoch 6912/10000; Iter 51/80; Loss: 0.3535
Epoch 6912/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 6913/10000; Iter 1/80; Loss: 0.3427
Epoch 6913/10000; Iter 51/80; Loss: 0.3321
Epoch 6913/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.063
Epoch 6914/10000; Iter 1/80; Loss: 0.3058
Epoch 6914/10000; Iter 51/80; Loss: 0.3399
Epoch 6914/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 6915/10000; Iter 1/80; Loss: 0.3245
Epoch 6915/10000; Iter 51/80; Loss: 0.3136
Epoch 6915/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.074
Epoch 6916/10000; Iter 1/80; Loss: 0.3242
Epoch 6916/10000; Iter 51/80; Loss: 0.3407
Epoch 6916/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 6917/10000; Iter 1/80; Loss: 0.3465
Epoch 6917/10000; Iter 51/80; Loss: 0.2845
Epoch 6917/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.068
Epoch 6918/10000; Iter 1/80; Loss: 0.3821
Epoch 6918/10000; Iter 51/80; Loss: 0.3236
Epoch 6918/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.069
Epoch 6919/10000; Iter 1/80; Loss: 0.3377
Epoch 6919/10000; Iter 51/80; Loss: 0.3279
Epoch 6919/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.068
Epoch 6920/10000; Iter 1/80; Loss: 0.3760
Epoch 6920/10000; Iter 51/80; Loss: 0.3340
Epoch 6920/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 6921/10000; Iter 1/80; Loss: 0.3339
Epoch 6921/10000; Iter 51/80; Loss: 0.3080
Epoch 6921/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.066
Epoch 6922/10000; Iter 1/80; Loss: 0.3221
Epoch 6922/10000; Iter 51/80; Loss: 0.3506
Epoch 6922/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6923/10000; Iter 1/80; Loss: 0.3221
Epoch 6923/10000; Iter 51/80; Loss: 0.3081
Epoch 6923/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.068
Epoch 6924/10000; Iter 1/80; Loss: 0.2968
Epoch 6924/10000; Iter 51/80; Loss: 0.3414
Epoch 6924/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.066
Epoch 6925/10000; Iter 1/80; Loss: 0.3619
Epoch 6925/10000; Iter 51/80; Loss: 0.3895
Epoch 6925/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.073
Epoch 6926/10000; Iter 1/80; Loss: 0.3581
Epoch 6926/10000; Iter 51/80; Loss: 0.3792
Epoch 6926/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.061
Epoch 6927/10000; Iter 1/80; Loss: 0.3078
Epoch 6927/10000; Iter 51/80; Loss: 0.3731
Epoch 6927/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 6928/10000; Iter 1/80; Loss: 0.3441
Epoch 6928/10000; Iter 51/80; Loss: 0.3083
Epoch 6928/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.071
Epoch 6929/10000; Iter 1/80; Loss: 0.3544
Epoch 6929/10000; Iter 51/80; Loss: 0.3596
Epoch 6929/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.069
Epoch 6930/10000; Iter 1/80; Loss: 0.3215
Epoch 6930/10000; Iter 51/80; Loss: 0.3446
Epoch 6930/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.062
Epoch 6931/10000; Iter 1/80; Loss: 0.3596
Epoch 6931/10000; Iter 51/80; Loss: 0.3241
Epoch 6931/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.065
Epoch 6932/10000; Iter 1/80; Loss: 0.3028
Epoch 6932/10000; Iter 51/80; Loss: 0.3090
Epoch 6932/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.079
Epoch 6933/10000; Iter 1/80; Loss: 0.3340
Epoch 6933/10000; Iter 51/80; Loss: 0.3457
Epoch 6933/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.063
Epoch 6934/10000; Iter 1/80; Loss: 0.3087
Epoch 6934/10000; Iter 51/80; Loss: 0.2810
Epoch 6934/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.072
Epoch 6935/10000; Iter 1/80; Loss: 0.3459
Epoch 6935/10000; Iter 51/80; Loss: 0.3429
Epoch 6935/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 6936/10000; Iter 1/80; Loss: 0.3139
Epoch 6936/10000; Iter 51/80; Loss: 0.3308
Epoch 6936/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6937/10000; Iter 1/80; Loss: 0.3250
Epoch 6937/10000; Iter 51/80; Loss: 0.3277
Epoch 6937/10000; Iter 80/80; Training Loss: 0.3510, Test Loss: 0.076
Epoch 6938/10000; Iter 1/80; Loss: 0.3068
Epoch 6938/10000; Iter 51/80; Loss: 0.3029
Epoch 6938/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.066
Epoch 6939/10000; Iter 1/80; Loss: 0.3823
Epoch 6939/10000; Iter 51/80; Loss: 0.4423
Epoch 6939/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6940/10000; Iter 1/80; Loss: 0.3493
Epoch 6940/10000; Iter 51/80; Loss: 0.3218
Epoch 6940/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.067
Epoch 6941/10000; Iter 1/80; Loss: 0.3176
Epoch 6941/10000; Iter 51/80; Loss: 0.3578
Epoch 6941/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6942/10000; Iter 1/80; Loss: 0.3201
Epoch 6942/10000; Iter 51/80; Loss: 0.2979
Epoch 6942/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 6943/10000; Iter 1/80; Loss: 0.3392
Epoch 6943/10000; Iter 51/80; Loss: 0.3772
Epoch 6943/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6944/10000; Iter 1/80; Loss: 0.3474
Epoch 6944/10000; Iter 51/80; Loss: 0.2700
Epoch 6944/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 6945/10000; Iter 1/80; Loss: 0.3527
Epoch 6945/10000; Iter 51/80; Loss: 0.3471
Epoch 6945/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.069
Epoch 6946/10000; Iter 1/80; Loss: 0.3577
Epoch 6946/10000; Iter 51/80; Loss: 0.3078
Epoch 6946/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.069
Epoch 6947/10000; Iter 1/80; Loss: 0.4024
Epoch 6947/10000; Iter 51/80; Loss: 0.3686
Epoch 6947/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.066
Epoch 6948/10000; Iter 1/80; Loss: 0.3252
Epoch 6948/10000; Iter 51/80; Loss: 0.3222
Epoch 6948/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.068
Epoch 6949/10000; Iter 1/80; Loss: 0.3575
Epoch 6949/10000; Iter 51/80; Loss: 0.3512
Epoch 6949/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.076
Epoch 6950/10000; Iter 1/80; Loss: 0.3836
Epoch 6950/10000; Iter 51/80; Loss: 0.3502
Epoch 6950/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 6951/10000; Iter 1/80; Loss: 0.2945
Epoch 6951/10000; Iter 51/80; Loss: 0.3458
Epoch 6951/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6952/10000; Iter 1/80; Loss: 0.3476
Epoch 6952/10000; Iter 51/80; Loss: 0.3537
Epoch 6952/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.061
Epoch 6953/10000; Iter 1/80; Loss: 0.3487
Epoch 6953/10000; Iter 51/80; Loss: 0.3105
Epoch 6953/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 6954/10000; Iter 1/80; Loss: 0.3157
Epoch 6954/10000; Iter 51/80; Loss: 0.3890
Epoch 6954/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 6955/10000; Iter 1/80; Loss: 0.3466
Epoch 6955/10000; Iter 51/80; Loss: 0.3465
Epoch 6955/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.07
Epoch 6956/10000; Iter 1/80; Loss: 0.3668
Epoch 6956/10000; Iter 51/80; Loss: 0.3263
Epoch 6956/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.066
Epoch 6957/10000; Iter 1/80; Loss: 0.3217
Epoch 6957/10000; Iter 51/80; Loss: 0.3096
Epoch 6957/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 6958/10000; Iter 1/80; Loss: 0.3070
Epoch 6958/10000; Iter 51/80; Loss: 0.3556
Epoch 6958/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.063
Epoch 6959/10000; Iter 1/80; Loss: 0.4273
Epoch 6959/10000; Iter 51/80; Loss: 0.3456
Epoch 6959/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.073
Epoch 6960/10000; Iter 1/80; Loss: 0.3335
Epoch 6960/10000; Iter 51/80; Loss: 0.2997
Epoch 6960/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.071
Epoch 6961/10000; Iter 1/80; Loss: 0.3370
Epoch 6961/10000; Iter 51/80; Loss: 0.3203
Epoch 6961/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.077
Epoch 6962/10000; Iter 1/80; Loss: 0.3737
Epoch 6962/10000; Iter 51/80; Loss: 0.3518
Epoch 6962/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 6963/10000; Iter 1/80; Loss: 0.3723
Epoch 6963/10000; Iter 51/80; Loss: 0.3371
Epoch 6963/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.065
Epoch 6964/10000; Iter 1/80; Loss: 0.3227
Epoch 6964/10000; Iter 51/80; Loss: 0.3431
Epoch 6964/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.07
Epoch 6965/10000; Iter 1/80; Loss: 0.3786
Epoch 6965/10000; Iter 51/80; Loss: 0.3301
Epoch 6965/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.063
Epoch 6966/10000; Iter 1/80; Loss: 0.3398
Epoch 6966/10000; Iter 51/80; Loss: 0.3543
Epoch 6966/10000; Iter 80/80; Training Loss: 0.3500, Test Loss: 0.067
Epoch 6967/10000; Iter 1/80; Loss: 0.3262
Epoch 6967/10000; Iter 51/80; Loss: 0.3508
Epoch 6967/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6968/10000; Iter 1/80; Loss: 0.3316
Epoch 6968/10000; Iter 51/80; Loss: 0.3781
Epoch 6968/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 6969/10000; Iter 1/80; Loss: 0.3630
Epoch 6969/10000; Iter 51/80; Loss: 0.4077
Epoch 6969/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6970/10000; Iter 1/80; Loss: 0.4102
Epoch 6970/10000; Iter 51/80; Loss: 0.3332
Epoch 6970/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.079
Epoch 6971/10000; Iter 1/80; Loss: 0.3508
Epoch 6971/10000; Iter 51/80; Loss: 0.3338
Epoch 6971/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 6972/10000; Iter 1/80; Loss: 0.3442
Epoch 6972/10000; Iter 51/80; Loss: 0.3471
Epoch 6972/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 6973/10000; Iter 1/80; Loss: 0.3028
Epoch 6973/10000; Iter 51/80; Loss: 0.3648
Epoch 6973/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 6974/10000; Iter 1/80; Loss: 0.3347
Epoch 6974/10000; Iter 51/80; Loss: 0.3426
Epoch 6974/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.066
Epoch 6975/10000; Iter 1/80; Loss: 0.3354
Epoch 6975/10000; Iter 51/80; Loss: 0.3657
Epoch 6975/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 6976/10000; Iter 1/80; Loss: 0.4190
Epoch 6976/10000; Iter 51/80; Loss: 0.3513
Epoch 6976/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 6977/10000; Iter 1/80; Loss: 0.3620
Epoch 6977/10000; Iter 51/80; Loss: 0.3859
Epoch 6977/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 6978/10000; Iter 1/80; Loss: 0.3368
Epoch 6978/10000; Iter 51/80; Loss: 0.3676
Epoch 6978/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6979/10000; Iter 1/80; Loss: 0.3001
Epoch 6979/10000; Iter 51/80; Loss: 0.3862
Epoch 6979/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 6980/10000; Iter 1/80; Loss: 0.3922
Epoch 6980/10000; Iter 51/80; Loss: 0.3630
Epoch 6980/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.08
Epoch 6981/10000; Iter 1/80; Loss: 0.3414
Epoch 6981/10000; Iter 51/80; Loss: 0.3048
Epoch 6981/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 6982/10000; Iter 1/80; Loss: 0.3256
Epoch 6982/10000; Iter 51/80; Loss: 0.3783
Epoch 6982/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6983/10000; Iter 1/80; Loss: 0.3397
Epoch 6983/10000; Iter 51/80; Loss: 0.3385
Epoch 6983/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 6984/10000; Iter 1/80; Loss: 0.3650
Epoch 6984/10000; Iter 51/80; Loss: 0.3736
Epoch 6984/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 6985/10000; Iter 1/80; Loss: 0.3195
Epoch 6985/10000; Iter 51/80; Loss: 0.3692
Epoch 6985/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.079
Epoch 6986/10000; Iter 1/80; Loss: 0.3347
Epoch 6986/10000; Iter 51/80; Loss: 0.3865
Epoch 6986/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.071
Epoch 6987/10000; Iter 1/80; Loss: 0.3346
Epoch 6987/10000; Iter 51/80; Loss: 0.3618
Epoch 6987/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 6988/10000; Iter 1/80; Loss: 0.3128
Epoch 6988/10000; Iter 51/80; Loss: 0.2994
Epoch 6988/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 6989/10000; Iter 1/80; Loss: 0.3155
Epoch 6989/10000; Iter 51/80; Loss: 0.2945
Epoch 6989/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 6990/10000; Iter 1/80; Loss: 0.3591
Epoch 6990/10000; Iter 51/80; Loss: 0.3190
Epoch 6990/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 6991/10000; Iter 1/80; Loss: 0.3074
Epoch 6991/10000; Iter 51/80; Loss: 0.3590
Epoch 6991/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 6992/10000; Iter 1/80; Loss: 0.3712
Epoch 6992/10000; Iter 51/80; Loss: 0.3438
Epoch 6992/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 6993/10000; Iter 1/80; Loss: 0.2797
Epoch 6993/10000; Iter 51/80; Loss: 0.3340
Epoch 6993/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 6994/10000; Iter 1/80; Loss: 0.3312
Epoch 6994/10000; Iter 51/80; Loss: 0.3461
Epoch 6994/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 6995/10000; Iter 1/80; Loss: 0.3788
Epoch 6995/10000; Iter 51/80; Loss: 0.3486
Epoch 6995/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.066
Epoch 6996/10000; Iter 1/80; Loss: 0.3412
Epoch 6996/10000; Iter 51/80; Loss: 0.3841
Epoch 6996/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 6997/10000; Iter 1/80; Loss: 0.2951
Epoch 6997/10000; Iter 51/80; Loss: 0.3038
Epoch 6997/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.063
Epoch 6998/10000; Iter 1/80; Loss: 0.2956
Epoch 6998/10000; Iter 51/80; Loss: 0.3504
Epoch 6998/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.073
Epoch 6999/10000; Iter 1/80; Loss: 0.3978
Epoch 6999/10000; Iter 51/80; Loss: 0.3314
Epoch 6999/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 7000/10000; Iter 1/80; Loss: 0.3323
Epoch 7000/10000; Iter 51/80; Loss: 0.3583
Epoch 7000/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.069
Epoch 7001/10000; Iter 1/80; Loss: 0.3751
Epoch 7001/10000; Iter 51/80; Loss: 0.3618
Epoch 7001/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.071
Model saved
Epoch 7002/10000; Iter 1/80; Loss: 0.3349
Epoch 7002/10000; Iter 51/80; Loss: 0.3285
Epoch 7002/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 7003/10000; Iter 1/80; Loss: 0.4129
Epoch 7003/10000; Iter 51/80; Loss: 0.3431
Epoch 7003/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 7004/10000; Iter 1/80; Loss: 0.3810
Epoch 7004/10000; Iter 51/80; Loss: 0.3188
Epoch 7004/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 7005/10000; Iter 1/80; Loss: 0.4368
Epoch 7005/10000; Iter 51/80; Loss: 0.3675
Epoch 7005/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.062
Epoch 7006/10000; Iter 1/80; Loss: 0.3039
Epoch 7006/10000; Iter 51/80; Loss: 0.3694
Epoch 7006/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 7007/10000; Iter 1/80; Loss: 0.3179
Epoch 7007/10000; Iter 51/80; Loss: 0.3445
Epoch 7007/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 7008/10000; Iter 1/80; Loss: 0.3117
Epoch 7008/10000; Iter 51/80; Loss: 0.3070
Epoch 7008/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.065
Epoch 7009/10000; Iter 1/80; Loss: 0.3667
Epoch 7009/10000; Iter 51/80; Loss: 0.2949
Epoch 7009/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.074
Epoch 7010/10000; Iter 1/80; Loss: 0.3322
Epoch 7010/10000; Iter 51/80; Loss: 0.3238
Epoch 7010/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 7011/10000; Iter 1/80; Loss: 0.3187
Epoch 7011/10000; Iter 51/80; Loss: 0.3111
Epoch 7011/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.065
Epoch 7012/10000; Iter 1/80; Loss: 0.3194
Epoch 7012/10000; Iter 51/80; Loss: 0.3440
Epoch 7012/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.07
Epoch 7013/10000; Iter 1/80; Loss: 0.3201
Epoch 7013/10000; Iter 51/80; Loss: 0.3701
Epoch 7013/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 7014/10000; Iter 1/80; Loss: 0.3555
Epoch 7014/10000; Iter 51/80; Loss: 0.3073
Epoch 7014/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 7015/10000; Iter 1/80; Loss: 0.3362
Epoch 7015/10000; Iter 51/80; Loss: 0.3148
Epoch 7015/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 7016/10000; Iter 1/80; Loss: 0.3939
Epoch 7016/10000; Iter 51/80; Loss: 0.3375
Epoch 7016/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.072
Epoch 7017/10000; Iter 1/80; Loss: 0.3226
Epoch 7017/10000; Iter 51/80; Loss: 0.3108
Epoch 7017/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.072
Epoch 7018/10000; Iter 1/80; Loss: 0.3146
Epoch 7018/10000; Iter 51/80; Loss: 0.3587
Epoch 7018/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.075
Epoch 7019/10000; Iter 1/80; Loss: 0.3535
Epoch 7019/10000; Iter 51/80; Loss: 0.3772
Epoch 7019/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.067
Epoch 7020/10000; Iter 1/80; Loss: 0.3704
Epoch 7020/10000; Iter 51/80; Loss: 0.3412
Epoch 7020/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7021/10000; Iter 1/80; Loss: 0.3169
Epoch 7021/10000; Iter 51/80; Loss: 0.3856
Epoch 7021/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.071
Epoch 7022/10000; Iter 1/80; Loss: 0.3254
Epoch 7022/10000; Iter 51/80; Loss: 0.2998
Epoch 7022/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 7023/10000; Iter 1/80; Loss: 0.3212
Epoch 7023/10000; Iter 51/80; Loss: 0.3202
Epoch 7023/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 7024/10000; Iter 1/80; Loss: 0.3345
Epoch 7024/10000; Iter 51/80; Loss: 0.3242
Epoch 7024/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.07
Epoch 7025/10000; Iter 1/80; Loss: 0.3529
Epoch 7025/10000; Iter 51/80; Loss: 0.3535
Epoch 7025/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.057
Epoch 7026/10000; Iter 1/80; Loss: 0.3257
Epoch 7026/10000; Iter 51/80; Loss: 0.3156
Epoch 7026/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 7027/10000; Iter 1/80; Loss: 0.4069
Epoch 7027/10000; Iter 51/80; Loss: 0.3396
Epoch 7027/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.064
Epoch 7028/10000; Iter 1/80; Loss: 0.3272
Epoch 7028/10000; Iter 51/80; Loss: 0.3925
Epoch 7028/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.069
Epoch 7029/10000; Iter 1/80; Loss: 0.3978
Epoch 7029/10000; Iter 51/80; Loss: 0.3713
Epoch 7029/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.067
Epoch 7030/10000; Iter 1/80; Loss: 0.3271
Epoch 7030/10000; Iter 51/80; Loss: 0.3674
Epoch 7030/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.063
Epoch 7031/10000; Iter 1/80; Loss: 0.3333
Epoch 7031/10000; Iter 51/80; Loss: 0.3241
Epoch 7031/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.065
Epoch 7032/10000; Iter 1/80; Loss: 0.3571
Epoch 7032/10000; Iter 51/80; Loss: 0.3404
Epoch 7032/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7033/10000; Iter 1/80; Loss: 0.3425
Epoch 7033/10000; Iter 51/80; Loss: 0.3385
Epoch 7033/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 7034/10000; Iter 1/80; Loss: 0.3560
Epoch 7034/10000; Iter 51/80; Loss: 0.3547
Epoch 7034/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7035/10000; Iter 1/80; Loss: 0.3361
Epoch 7035/10000; Iter 51/80; Loss: 0.3364
Epoch 7035/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 7036/10000; Iter 1/80; Loss: 0.3319
Epoch 7036/10000; Iter 51/80; Loss: 0.3836
Epoch 7036/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.074
Epoch 7037/10000; Iter 1/80; Loss: 0.3042
Epoch 7037/10000; Iter 51/80; Loss: 0.3249
Epoch 7037/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.077
Epoch 7038/10000; Iter 1/80; Loss: 0.3988
Epoch 7038/10000; Iter 51/80; Loss: 0.3048
Epoch 7038/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7039/10000; Iter 1/80; Loss: 0.3574
Epoch 7039/10000; Iter 51/80; Loss: 0.3663
Epoch 7039/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.064
Epoch 7040/10000; Iter 1/80; Loss: 0.4491
Epoch 7040/10000; Iter 51/80; Loss: 0.3676
Epoch 7040/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 7041/10000; Iter 1/80; Loss: 0.3467
Epoch 7041/10000; Iter 51/80; Loss: 0.3242
Epoch 7041/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.072
Epoch 7042/10000; Iter 1/80; Loss: 0.4063
Epoch 7042/10000; Iter 51/80; Loss: 0.4233
Epoch 7042/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.067
Epoch 7043/10000; Iter 1/80; Loss: 0.3301
Epoch 7043/10000; Iter 51/80; Loss: 0.3263
Epoch 7043/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.072
Epoch 7044/10000; Iter 1/80; Loss: 0.4149
Epoch 7044/10000; Iter 51/80; Loss: 0.3256
Epoch 7044/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 7045/10000; Iter 1/80; Loss: 0.3398
Epoch 7045/10000; Iter 51/80; Loss: 0.3267
Epoch 7045/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7046/10000; Iter 1/80; Loss: 0.3511
Epoch 7046/10000; Iter 51/80; Loss: 0.2942
Epoch 7046/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 7047/10000; Iter 1/80; Loss: 0.3065
Epoch 7047/10000; Iter 51/80; Loss: 0.3312
Epoch 7047/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.075
Epoch 7048/10000; Iter 1/80; Loss: 0.3504
Epoch 7048/10000; Iter 51/80; Loss: 0.3392
Epoch 7048/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7049/10000; Iter 1/80; Loss: 0.3369
Epoch 7049/10000; Iter 51/80; Loss: 0.3347
Epoch 7049/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7050/10000; Iter 1/80; Loss: 0.4160
Epoch 7050/10000; Iter 51/80; Loss: 0.3522
Epoch 7050/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7051/10000; Iter 1/80; Loss: 0.3501
Epoch 7051/10000; Iter 51/80; Loss: 0.3240
Epoch 7051/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7052/10000; Iter 1/80; Loss: 0.3632
Epoch 7052/10000; Iter 51/80; Loss: 0.2662
Epoch 7052/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.064
Epoch 7053/10000; Iter 1/80; Loss: 0.3085
Epoch 7053/10000; Iter 51/80; Loss: 0.3286
Epoch 7053/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 7054/10000; Iter 1/80; Loss: 0.3787
Epoch 7054/10000; Iter 51/80; Loss: 0.3355
Epoch 7054/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7055/10000; Iter 1/80; Loss: 0.3069
Epoch 7055/10000; Iter 51/80; Loss: 0.3755
Epoch 7055/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7056/10000; Iter 1/80; Loss: 0.3364
Epoch 7056/10000; Iter 51/80; Loss: 0.3303
Epoch 7056/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 7057/10000; Iter 1/80; Loss: 0.3441
Epoch 7057/10000; Iter 51/80; Loss: 0.3662
Epoch 7057/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.075
Epoch 7058/10000; Iter 1/80; Loss: 0.3648
Epoch 7058/10000; Iter 51/80; Loss: 0.3154
Epoch 7058/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.065
Epoch 7059/10000; Iter 1/80; Loss: 0.3964
Epoch 7059/10000; Iter 51/80; Loss: 0.3261
Epoch 7059/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.071
Epoch 7060/10000; Iter 1/80; Loss: 0.3534
Epoch 7060/10000; Iter 51/80; Loss: 0.2762
Epoch 7060/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 7061/10000; Iter 1/80; Loss: 0.3753
Epoch 7061/10000; Iter 51/80; Loss: 0.3770
Epoch 7061/10000; Iter 80/80; Training Loss: 0.3490, Test Loss: 0.073
Epoch 7062/10000; Iter 1/80; Loss: 0.3164
Epoch 7062/10000; Iter 51/80; Loss: 0.3499
Epoch 7062/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 7063/10000; Iter 1/80; Loss: 0.3123
Epoch 7063/10000; Iter 51/80; Loss: 0.3528
Epoch 7063/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.068
Epoch 7064/10000; Iter 1/80; Loss: 0.3817
Epoch 7064/10000; Iter 51/80; Loss: 0.3311
Epoch 7064/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.073
Epoch 7065/10000; Iter 1/80; Loss: 0.2812
Epoch 7065/10000; Iter 51/80; Loss: 0.3127
Epoch 7065/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.065
Epoch 7066/10000; Iter 1/80; Loss: 0.3271
Epoch 7066/10000; Iter 51/80; Loss: 0.3311
Epoch 7066/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.062
Epoch 7067/10000; Iter 1/80; Loss: 0.3328
Epoch 7067/10000; Iter 51/80; Loss: 0.3581
Epoch 7067/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.076
Epoch 7068/10000; Iter 1/80; Loss: 0.3235
Epoch 7068/10000; Iter 51/80; Loss: 0.3162
Epoch 7068/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 7069/10000; Iter 1/80; Loss: 0.3087
Epoch 7069/10000; Iter 51/80; Loss: 0.3431
Epoch 7069/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 7070/10000; Iter 1/80; Loss: 0.3365
Epoch 7070/10000; Iter 51/80; Loss: 0.3003
Epoch 7070/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.061
Epoch 7071/10000; Iter 1/80; Loss: 0.3474
Epoch 7071/10000; Iter 51/80; Loss: 0.3364
Epoch 7071/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.078
Epoch 7072/10000; Iter 1/80; Loss: 0.3415
Epoch 7072/10000; Iter 51/80; Loss: 0.2904
Epoch 7072/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.073
Epoch 7073/10000; Iter 1/80; Loss: 0.3300
Epoch 7073/10000; Iter 51/80; Loss: 0.3503
Epoch 7073/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7074/10000; Iter 1/80; Loss: 0.3564
Epoch 7074/10000; Iter 51/80; Loss: 0.3380
Epoch 7074/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 7075/10000; Iter 1/80; Loss: 0.3377
Epoch 7075/10000; Iter 51/80; Loss: 0.3096
Epoch 7075/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7076/10000; Iter 1/80; Loss: 0.3186
Epoch 7076/10000; Iter 51/80; Loss: 0.3614
Epoch 7076/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.068
Epoch 7077/10000; Iter 1/80; Loss: 0.3334
Epoch 7077/10000; Iter 51/80; Loss: 0.3569
Epoch 7077/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 7078/10000; Iter 1/80; Loss: 0.3587
Epoch 7078/10000; Iter 51/80; Loss: 0.3334
Epoch 7078/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7079/10000; Iter 1/80; Loss: 0.3541
Epoch 7079/10000; Iter 51/80; Loss: 0.3502
Epoch 7079/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.072
Epoch 7080/10000; Iter 1/80; Loss: 0.2999
Epoch 7080/10000; Iter 51/80; Loss: 0.3578
Epoch 7080/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7081/10000; Iter 1/80; Loss: 0.3390
Epoch 7081/10000; Iter 51/80; Loss: 0.3553
Epoch 7081/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.068
Epoch 7082/10000; Iter 1/80; Loss: 0.3027
Epoch 7082/10000; Iter 51/80; Loss: 0.3279
Epoch 7082/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7083/10000; Iter 1/80; Loss: 0.3482
Epoch 7083/10000; Iter 51/80; Loss: 0.3186
Epoch 7083/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.071
Epoch 7084/10000; Iter 1/80; Loss: 0.3078
Epoch 7084/10000; Iter 51/80; Loss: 0.3460
Epoch 7084/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.075
Epoch 7085/10000; Iter 1/80; Loss: 0.3182
Epoch 7085/10000; Iter 51/80; Loss: 0.3317
Epoch 7085/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.077
Epoch 7086/10000; Iter 1/80; Loss: 0.3097
Epoch 7086/10000; Iter 51/80; Loss: 0.3166
Epoch 7086/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.072
Epoch 7087/10000; Iter 1/80; Loss: 0.3356
Epoch 7087/10000; Iter 51/80; Loss: 0.3171
Epoch 7087/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.066
Epoch 7088/10000; Iter 1/80; Loss: 0.3065
Epoch 7088/10000; Iter 51/80; Loss: 0.3899
Epoch 7088/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 7089/10000; Iter 1/80; Loss: 0.2826
Epoch 7089/10000; Iter 51/80; Loss: 0.3156
Epoch 7089/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 7090/10000; Iter 1/80; Loss: 0.3471
Epoch 7090/10000; Iter 51/80; Loss: 0.3301
Epoch 7090/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.071
Epoch 7091/10000; Iter 1/80; Loss: 0.3414
Epoch 7091/10000; Iter 51/80; Loss: 0.3971
Epoch 7091/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 7092/10000; Iter 1/80; Loss: 0.3249
Epoch 7092/10000; Iter 51/80; Loss: 0.3092
Epoch 7092/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 7093/10000; Iter 1/80; Loss: 0.4098
Epoch 7093/10000; Iter 51/80; Loss: 0.3180
Epoch 7093/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7094/10000; Iter 1/80; Loss: 0.3357
Epoch 7094/10000; Iter 51/80; Loss: 0.2785
Epoch 7094/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 7095/10000; Iter 1/80; Loss: 0.3201
Epoch 7095/10000; Iter 51/80; Loss: 0.3804
Epoch 7095/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7096/10000; Iter 1/80; Loss: 0.3090
Epoch 7096/10000; Iter 51/80; Loss: 0.3286
Epoch 7096/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 7097/10000; Iter 1/80; Loss: 0.3199
Epoch 7097/10000; Iter 51/80; Loss: 0.3618
Epoch 7097/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7098/10000; Iter 1/80; Loss: 0.3900
Epoch 7098/10000; Iter 51/80; Loss: 0.3850
Epoch 7098/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.078
Epoch 7099/10000; Iter 1/80; Loss: 0.3650
Epoch 7099/10000; Iter 51/80; Loss: 0.3765
Epoch 7099/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.071
Epoch 7100/10000; Iter 1/80; Loss: 0.3845
Epoch 7100/10000; Iter 51/80; Loss: 0.3447
Epoch 7100/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 7101/10000; Iter 1/80; Loss: 0.3400
Epoch 7101/10000; Iter 51/80; Loss: 0.3217
Epoch 7101/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.062
Model saved
Epoch 7102/10000; Iter 1/80; Loss: 0.2868
Epoch 7102/10000; Iter 51/80; Loss: 0.3356
Epoch 7102/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7103/10000; Iter 1/80; Loss: 0.3798
Epoch 7103/10000; Iter 51/80; Loss: 0.3064
Epoch 7103/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.067
Epoch 7104/10000; Iter 1/80; Loss: 0.3823
Epoch 7104/10000; Iter 51/80; Loss: 0.3584
Epoch 7104/10000; Iter 80/80; Training Loss: 0.3520, Test Loss: 0.076
Epoch 7105/10000; Iter 1/80; Loss: 0.3359
Epoch 7105/10000; Iter 51/80; Loss: 0.3175
Epoch 7105/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7106/10000; Iter 1/80; Loss: 0.3330
Epoch 7106/10000; Iter 51/80; Loss: 0.3807
Epoch 7106/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.074
Epoch 7107/10000; Iter 1/80; Loss: 0.3109
Epoch 7107/10000; Iter 51/80; Loss: 0.3301
Epoch 7107/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.075
Epoch 7108/10000; Iter 1/80; Loss: 0.4359
Epoch 7108/10000; Iter 51/80; Loss: 0.3892
Epoch 7108/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 7109/10000; Iter 1/80; Loss: 0.3581
Epoch 7109/10000; Iter 51/80; Loss: 0.3310
Epoch 7109/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 7110/10000; Iter 1/80; Loss: 0.2933
Epoch 7110/10000; Iter 51/80; Loss: 0.3848
Epoch 7110/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7111/10000; Iter 1/80; Loss: 0.3267
Epoch 7111/10000; Iter 51/80; Loss: 0.3630
Epoch 7111/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7112/10000; Iter 1/80; Loss: 0.3259
Epoch 7112/10000; Iter 51/80; Loss: 0.4119
Epoch 7112/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7113/10000; Iter 1/80; Loss: 0.3932
Epoch 7113/10000; Iter 51/80; Loss: 0.2919
Epoch 7113/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.078
Epoch 7114/10000; Iter 1/80; Loss: 0.3359
Epoch 7114/10000; Iter 51/80; Loss: 0.3514
Epoch 7114/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7115/10000; Iter 1/80; Loss: 0.3465
Epoch 7115/10000; Iter 51/80; Loss: 0.3713
Epoch 7115/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.077
Epoch 7116/10000; Iter 1/80; Loss: 0.3610
Epoch 7116/10000; Iter 51/80; Loss: 0.3537
Epoch 7116/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7117/10000; Iter 1/80; Loss: 0.3104
Epoch 7117/10000; Iter 51/80; Loss: 0.3455
Epoch 7117/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.061
Epoch 7118/10000; Iter 1/80; Loss: 0.3133
Epoch 7118/10000; Iter 51/80; Loss: 0.3728
Epoch 7118/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7119/10000; Iter 1/80; Loss: 0.3483
Epoch 7119/10000; Iter 51/80; Loss: 0.4140
Epoch 7119/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.076
Epoch 7120/10000; Iter 1/80; Loss: 0.3343
Epoch 7120/10000; Iter 51/80; Loss: 0.3156
Epoch 7120/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.069
Epoch 7121/10000; Iter 1/80; Loss: 0.2955
Epoch 7121/10000; Iter 51/80; Loss: 0.3527
Epoch 7121/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.065
Epoch 7122/10000; Iter 1/80; Loss: 0.3308
Epoch 7122/10000; Iter 51/80; Loss: 0.3698
Epoch 7122/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 7123/10000; Iter 1/80; Loss: 0.3570
Epoch 7123/10000; Iter 51/80; Loss: 0.3378
Epoch 7123/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.079
Epoch 7124/10000; Iter 1/80; Loss: 0.4148
Epoch 7124/10000; Iter 51/80; Loss: 0.2963
Epoch 7124/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7125/10000; Iter 1/80; Loss: 0.4041
Epoch 7125/10000; Iter 51/80; Loss: 0.4154
Epoch 7125/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 7126/10000; Iter 1/80; Loss: 0.3963
Epoch 7126/10000; Iter 51/80; Loss: 0.3504
Epoch 7126/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 7127/10000; Iter 1/80; Loss: 0.3372
Epoch 7127/10000; Iter 51/80; Loss: 0.3253
Epoch 7127/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 7128/10000; Iter 1/80; Loss: 0.3062
Epoch 7128/10000; Iter 51/80; Loss: 0.3088
Epoch 7128/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7129/10000; Iter 1/80; Loss: 0.3222
Epoch 7129/10000; Iter 51/80; Loss: 0.3793
Epoch 7129/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.069
Epoch 7130/10000; Iter 1/80; Loss: 0.3041
Epoch 7130/10000; Iter 51/80; Loss: 0.3716
Epoch 7130/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.075
Epoch 7131/10000; Iter 1/80; Loss: 0.3156
Epoch 7131/10000; Iter 51/80; Loss: 0.3614
Epoch 7131/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7132/10000; Iter 1/80; Loss: 0.4732
Epoch 7132/10000; Iter 51/80; Loss: 0.2751
Epoch 7132/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 7133/10000; Iter 1/80; Loss: 0.3128
Epoch 7133/10000; Iter 51/80; Loss: 0.3581
Epoch 7133/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 7134/10000; Iter 1/80; Loss: 0.2875
Epoch 7134/10000; Iter 51/80; Loss: 0.3862
Epoch 7134/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.072
Epoch 7135/10000; Iter 1/80; Loss: 0.3194
Epoch 7135/10000; Iter 51/80; Loss: 0.2918
Epoch 7135/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.074
Epoch 7136/10000; Iter 1/80; Loss: 0.3443
Epoch 7136/10000; Iter 51/80; Loss: 0.3523
Epoch 7136/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7137/10000; Iter 1/80; Loss: 0.3949
Epoch 7137/10000; Iter 51/80; Loss: 0.3754
Epoch 7137/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.066
Epoch 7138/10000; Iter 1/80; Loss: 0.3437
Epoch 7138/10000; Iter 51/80; Loss: 0.3552
Epoch 7138/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.075
Epoch 7139/10000; Iter 1/80; Loss: 0.3474
Epoch 7139/10000; Iter 51/80; Loss: 0.3796
Epoch 7139/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.068
Epoch 7140/10000; Iter 1/80; Loss: 0.2999
Epoch 7140/10000; Iter 51/80; Loss: 0.3162
Epoch 7140/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.072
Epoch 7141/10000; Iter 1/80; Loss: 0.3339
Epoch 7141/10000; Iter 51/80; Loss: 0.3216
Epoch 7141/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7142/10000; Iter 1/80; Loss: 0.3430
Epoch 7142/10000; Iter 51/80; Loss: 0.3944
Epoch 7142/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.066
Epoch 7143/10000; Iter 1/80; Loss: 0.3407
Epoch 7143/10000; Iter 51/80; Loss: 0.3545
Epoch 7143/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7144/10000; Iter 1/80; Loss: 0.2961
Epoch 7144/10000; Iter 51/80; Loss: 0.3298
Epoch 7144/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 7145/10000; Iter 1/80; Loss: 0.3487
Epoch 7145/10000; Iter 51/80; Loss: 0.3491
Epoch 7145/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 7146/10000; Iter 1/80; Loss: 0.3673
Epoch 7146/10000; Iter 51/80; Loss: 0.3804
Epoch 7146/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7147/10000; Iter 1/80; Loss: 0.3614
Epoch 7147/10000; Iter 51/80; Loss: 0.3293
Epoch 7147/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 7148/10000; Iter 1/80; Loss: 0.3023
Epoch 7148/10000; Iter 51/80; Loss: 0.3460
Epoch 7148/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7149/10000; Iter 1/80; Loss: 0.3029
Epoch 7149/10000; Iter 51/80; Loss: 0.3476
Epoch 7149/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.075
Epoch 7150/10000; Iter 1/80; Loss: 0.3363
Epoch 7150/10000; Iter 51/80; Loss: 0.3013
Epoch 7150/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7151/10000; Iter 1/80; Loss: 0.3270
Epoch 7151/10000; Iter 51/80; Loss: 0.3243
Epoch 7151/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.07
Epoch 7152/10000; Iter 1/80; Loss: 0.3267
Epoch 7152/10000; Iter 51/80; Loss: 0.3380
Epoch 7152/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.072
Epoch 7153/10000; Iter 1/80; Loss: 0.3840
Epoch 7153/10000; Iter 51/80; Loss: 0.3494
Epoch 7153/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.069
Epoch 7154/10000; Iter 1/80; Loss: 0.2800
Epoch 7154/10000; Iter 51/80; Loss: 0.3816
Epoch 7154/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7155/10000; Iter 1/80; Loss: 0.3208
Epoch 7155/10000; Iter 51/80; Loss: 0.3401
Epoch 7155/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.06
Epoch 7156/10000; Iter 1/80; Loss: 0.3274
Epoch 7156/10000; Iter 51/80; Loss: 0.3347
Epoch 7156/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7157/10000; Iter 1/80; Loss: 0.3018
Epoch 7157/10000; Iter 51/80; Loss: 0.2985
Epoch 7157/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7158/10000; Iter 1/80; Loss: 0.3269
Epoch 7158/10000; Iter 51/80; Loss: 0.3421
Epoch 7158/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7159/10000; Iter 1/80; Loss: 0.3380
Epoch 7159/10000; Iter 51/80; Loss: 0.3330
Epoch 7159/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.063
Epoch 7160/10000; Iter 1/80; Loss: 0.3317
Epoch 7160/10000; Iter 51/80; Loss: 0.3118
Epoch 7160/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.082
Epoch 7161/10000; Iter 1/80; Loss: 0.3114
Epoch 7161/10000; Iter 51/80; Loss: 0.3268
Epoch 7161/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.078
Epoch 7162/10000; Iter 1/80; Loss: 0.3581
Epoch 7162/10000; Iter 51/80; Loss: 0.3206
Epoch 7162/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.071
Epoch 7163/10000; Iter 1/80; Loss: 0.3300
Epoch 7163/10000; Iter 51/80; Loss: 0.3659
Epoch 7163/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.064
Epoch 7164/10000; Iter 1/80; Loss: 0.3679
Epoch 7164/10000; Iter 51/80; Loss: 0.3396
Epoch 7164/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.074
Epoch 7165/10000; Iter 1/80; Loss: 0.3436
Epoch 7165/10000; Iter 51/80; Loss: 0.4010
Epoch 7165/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7166/10000; Iter 1/80; Loss: 0.3060
Epoch 7166/10000; Iter 51/80; Loss: 0.3403
Epoch 7166/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.065
Epoch 7167/10000; Iter 1/80; Loss: 0.2791
Epoch 7167/10000; Iter 51/80; Loss: 0.3003
Epoch 7167/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7168/10000; Iter 1/80; Loss: 0.2972
Epoch 7168/10000; Iter 51/80; Loss: 0.3065
Epoch 7168/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.068
Epoch 7169/10000; Iter 1/80; Loss: 0.3147
Epoch 7169/10000; Iter 51/80; Loss: 0.3649
Epoch 7169/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7170/10000; Iter 1/80; Loss: 0.3266
Epoch 7170/10000; Iter 51/80; Loss: 0.3737
Epoch 7170/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7171/10000; Iter 1/80; Loss: 0.3169
Epoch 7171/10000; Iter 51/80; Loss: 0.3671
Epoch 7171/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7172/10000; Iter 1/80; Loss: 0.3268
Epoch 7172/10000; Iter 51/80; Loss: 0.3948
Epoch 7172/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7173/10000; Iter 1/80; Loss: 0.3247
Epoch 7173/10000; Iter 51/80; Loss: 0.3668
Epoch 7173/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7174/10000; Iter 1/80; Loss: 0.3520
Epoch 7174/10000; Iter 51/80; Loss: 0.3898
Epoch 7174/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.075
Epoch 7175/10000; Iter 1/80; Loss: 0.3492
Epoch 7175/10000; Iter 51/80; Loss: 0.3645
Epoch 7175/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 7176/10000; Iter 1/80; Loss: 0.3673
Epoch 7176/10000; Iter 51/80; Loss: 0.3400
Epoch 7176/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.066
Epoch 7177/10000; Iter 1/80; Loss: 0.3090
Epoch 7177/10000; Iter 51/80; Loss: 0.3796
Epoch 7177/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.063
Epoch 7178/10000; Iter 1/80; Loss: 0.3181
Epoch 7178/10000; Iter 51/80; Loss: 0.3239
Epoch 7178/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7179/10000; Iter 1/80; Loss: 0.3324
Epoch 7179/10000; Iter 51/80; Loss: 0.3114
Epoch 7179/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.064
Epoch 7180/10000; Iter 1/80; Loss: 0.3392
Epoch 7180/10000; Iter 51/80; Loss: 0.3787
Epoch 7180/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7181/10000; Iter 1/80; Loss: 0.3575
Epoch 7181/10000; Iter 51/80; Loss: 0.3399
Epoch 7181/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7182/10000; Iter 1/80; Loss: 0.3346
Epoch 7182/10000; Iter 51/80; Loss: 0.3394
Epoch 7182/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 7183/10000; Iter 1/80; Loss: 0.3846
Epoch 7183/10000; Iter 51/80; Loss: 0.2706
Epoch 7183/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.073
Epoch 7184/10000; Iter 1/80; Loss: 0.3302
Epoch 7184/10000; Iter 51/80; Loss: 0.3350
Epoch 7184/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 7185/10000; Iter 1/80; Loss: 0.3484
Epoch 7185/10000; Iter 51/80; Loss: 0.3407
Epoch 7185/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.064
Epoch 7186/10000; Iter 1/80; Loss: 0.3523
Epoch 7186/10000; Iter 51/80; Loss: 0.2938
Epoch 7186/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 7187/10000; Iter 1/80; Loss: 0.3644
Epoch 7187/10000; Iter 51/80; Loss: 0.3055
Epoch 7187/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.071
Epoch 7188/10000; Iter 1/80; Loss: 0.3355
Epoch 7188/10000; Iter 51/80; Loss: 0.3620
Epoch 7188/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.071
Epoch 7189/10000; Iter 1/80; Loss: 0.3043
Epoch 7189/10000; Iter 51/80; Loss: 0.3583
Epoch 7189/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.071
Epoch 7190/10000; Iter 1/80; Loss: 0.3565
Epoch 7190/10000; Iter 51/80; Loss: 0.3631
Epoch 7190/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7191/10000; Iter 1/80; Loss: 0.3853
Epoch 7191/10000; Iter 51/80; Loss: 0.3183
Epoch 7191/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 7192/10000; Iter 1/80; Loss: 0.3441
Epoch 7192/10000; Iter 51/80; Loss: 0.3428
Epoch 7192/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.078
Epoch 7193/10000; Iter 1/80; Loss: 0.3060
Epoch 7193/10000; Iter 51/80; Loss: 0.3031
Epoch 7193/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.069
Epoch 7194/10000; Iter 1/80; Loss: 0.3754
Epoch 7194/10000; Iter 51/80; Loss: 0.3063
Epoch 7194/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 7195/10000; Iter 1/80; Loss: 0.3245
Epoch 7195/10000; Iter 51/80; Loss: 0.3602
Epoch 7195/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 7196/10000; Iter 1/80; Loss: 0.2523
Epoch 7196/10000; Iter 51/80; Loss: 0.3780
Epoch 7196/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 7197/10000; Iter 1/80; Loss: 0.3216
Epoch 7197/10000; Iter 51/80; Loss: 0.3140
Epoch 7197/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7198/10000; Iter 1/80; Loss: 0.3205
Epoch 7198/10000; Iter 51/80; Loss: 0.3577
Epoch 7198/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 7199/10000; Iter 1/80; Loss: 0.3085
Epoch 7199/10000; Iter 51/80; Loss: 0.3695
Epoch 7199/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 7200/10000; Iter 1/80; Loss: 0.3453
Epoch 7200/10000; Iter 51/80; Loss: 0.3570
Epoch 7200/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7201/10000; Iter 1/80; Loss: 0.3410
Epoch 7201/10000; Iter 51/80; Loss: 0.3303
Epoch 7201/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Model saved
Epoch 7202/10000; Iter 1/80; Loss: 0.3825
Epoch 7202/10000; Iter 51/80; Loss: 0.3463
Epoch 7202/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.065
Epoch 7203/10000; Iter 1/80; Loss: 0.2995
Epoch 7203/10000; Iter 51/80; Loss: 0.4004
Epoch 7203/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.068
Epoch 7204/10000; Iter 1/80; Loss: 0.3936
Epoch 7204/10000; Iter 51/80; Loss: 0.3219
Epoch 7204/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.076
Epoch 7205/10000; Iter 1/80; Loss: 0.3596
Epoch 7205/10000; Iter 51/80; Loss: 0.3366
Epoch 7205/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.075
Epoch 7206/10000; Iter 1/80; Loss: 0.3313
Epoch 7206/10000; Iter 51/80; Loss: 0.3319
Epoch 7206/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7207/10000; Iter 1/80; Loss: 0.3130
Epoch 7207/10000; Iter 51/80; Loss: 0.3566
Epoch 7207/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.067
Epoch 7208/10000; Iter 1/80; Loss: 0.3717
Epoch 7208/10000; Iter 51/80; Loss: 0.3356
Epoch 7208/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.076
Epoch 7209/10000; Iter 1/80; Loss: 0.2847
Epoch 7209/10000; Iter 51/80; Loss: 0.3785
Epoch 7209/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.072
Epoch 7210/10000; Iter 1/80; Loss: 0.3303
Epoch 7210/10000; Iter 51/80; Loss: 0.3603
Epoch 7210/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7211/10000; Iter 1/80; Loss: 0.3910
Epoch 7211/10000; Iter 51/80; Loss: 0.3698
Epoch 7211/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7212/10000; Iter 1/80; Loss: 0.2919
Epoch 7212/10000; Iter 51/80; Loss: 0.2884
Epoch 7212/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7213/10000; Iter 1/80; Loss: 0.3602
Epoch 7213/10000; Iter 51/80; Loss: 0.3389
Epoch 7213/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 7214/10000; Iter 1/80; Loss: 0.3147
Epoch 7214/10000; Iter 51/80; Loss: 0.3646
Epoch 7214/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7215/10000; Iter 1/80; Loss: 0.3392
Epoch 7215/10000; Iter 51/80; Loss: 0.3358
Epoch 7215/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.066
Epoch 7216/10000; Iter 1/80; Loss: 0.3634
Epoch 7216/10000; Iter 51/80; Loss: 0.3846
Epoch 7216/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 7217/10000; Iter 1/80; Loss: 0.3982
Epoch 7217/10000; Iter 51/80; Loss: 0.4310
Epoch 7217/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 7218/10000; Iter 1/80; Loss: 0.2932
Epoch 7218/10000; Iter 51/80; Loss: 0.3070
Epoch 7218/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.066
Epoch 7219/10000; Iter 1/80; Loss: 0.3577
Epoch 7219/10000; Iter 51/80; Loss: 0.3043
Epoch 7219/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7220/10000; Iter 1/80; Loss: 0.3731
Epoch 7220/10000; Iter 51/80; Loss: 0.3679
Epoch 7220/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 7221/10000; Iter 1/80; Loss: 0.3118
Epoch 7221/10000; Iter 51/80; Loss: 0.3261
Epoch 7221/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7222/10000; Iter 1/80; Loss: 0.3174
Epoch 7222/10000; Iter 51/80; Loss: 0.3876
Epoch 7222/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7223/10000; Iter 1/80; Loss: 0.3280
Epoch 7223/10000; Iter 51/80; Loss: 0.3532
Epoch 7223/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.076
Epoch 7224/10000; Iter 1/80; Loss: 0.3572
Epoch 7224/10000; Iter 51/80; Loss: 0.3219
Epoch 7224/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.072
Epoch 7225/10000; Iter 1/80; Loss: 0.3760
Epoch 7225/10000; Iter 51/80; Loss: 0.2866
Epoch 7225/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.067
Epoch 7226/10000; Iter 1/80; Loss: 0.3459
Epoch 7226/10000; Iter 51/80; Loss: 0.3516
Epoch 7226/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7227/10000; Iter 1/80; Loss: 0.3522
Epoch 7227/10000; Iter 51/80; Loss: 0.3333
Epoch 7227/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.072
Epoch 7228/10000; Iter 1/80; Loss: 0.2910
Epoch 7228/10000; Iter 51/80; Loss: 0.3118
Epoch 7228/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 7229/10000; Iter 1/80; Loss: 0.3429
Epoch 7229/10000; Iter 51/80; Loss: 0.2816
Epoch 7229/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.061
Epoch 7230/10000; Iter 1/80; Loss: 0.3041
Epoch 7230/10000; Iter 51/80; Loss: 0.3586
Epoch 7230/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.076
Epoch 7231/10000; Iter 1/80; Loss: 0.3482
Epoch 7231/10000; Iter 51/80; Loss: 0.3140
Epoch 7231/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.074
Epoch 7232/10000; Iter 1/80; Loss: 0.3348
Epoch 7232/10000; Iter 51/80; Loss: 0.3202
Epoch 7232/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7233/10000; Iter 1/80; Loss: 0.3687
Epoch 7233/10000; Iter 51/80; Loss: 0.3301
Epoch 7233/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 7234/10000; Iter 1/80; Loss: 0.3869
Epoch 7234/10000; Iter 51/80; Loss: 0.3030
Epoch 7234/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 7235/10000; Iter 1/80; Loss: 0.2987
Epoch 7235/10000; Iter 51/80; Loss: 0.3895
Epoch 7235/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.062
Epoch 7236/10000; Iter 1/80; Loss: 0.3340
Epoch 7236/10000; Iter 51/80; Loss: 0.3719
Epoch 7236/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.074
Epoch 7237/10000; Iter 1/80; Loss: 0.3388
Epoch 7237/10000; Iter 51/80; Loss: 0.3169
Epoch 7237/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.066
Epoch 7238/10000; Iter 1/80; Loss: 0.3337
Epoch 7238/10000; Iter 51/80; Loss: 0.3325
Epoch 7238/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.066
Epoch 7239/10000; Iter 1/80; Loss: 0.3300
Epoch 7239/10000; Iter 51/80; Loss: 0.3049
Epoch 7239/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7240/10000; Iter 1/80; Loss: 0.3791
Epoch 7240/10000; Iter 51/80; Loss: 0.3133
Epoch 7240/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 7241/10000; Iter 1/80; Loss: 0.3581
Epoch 7241/10000; Iter 51/80; Loss: 0.3396
Epoch 7241/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.063
Epoch 7242/10000; Iter 1/80; Loss: 0.3503
Epoch 7242/10000; Iter 51/80; Loss: 0.3025
Epoch 7242/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7243/10000; Iter 1/80; Loss: 0.3613
Epoch 7243/10000; Iter 51/80; Loss: 0.3479
Epoch 7243/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7244/10000; Iter 1/80; Loss: 0.3338
Epoch 7244/10000; Iter 51/80; Loss: 0.3501
Epoch 7244/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 7245/10000; Iter 1/80; Loss: 0.3846
Epoch 7245/10000; Iter 51/80; Loss: 0.3413
Epoch 7245/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 7246/10000; Iter 1/80; Loss: 0.2686
Epoch 7246/10000; Iter 51/80; Loss: 0.3344
Epoch 7246/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7247/10000; Iter 1/80; Loss: 0.2695
Epoch 7247/10000; Iter 51/80; Loss: 0.3164
Epoch 7247/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.068
Epoch 7248/10000; Iter 1/80; Loss: 0.3074
Epoch 7248/10000; Iter 51/80; Loss: 0.3699
Epoch 7248/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7249/10000; Iter 1/80; Loss: 0.3320
Epoch 7249/10000; Iter 51/80; Loss: 0.3024
Epoch 7249/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.073
Epoch 7250/10000; Iter 1/80; Loss: 0.3258
Epoch 7250/10000; Iter 51/80; Loss: 0.3440
Epoch 7250/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 7251/10000; Iter 1/80; Loss: 0.3206
Epoch 7251/10000; Iter 51/80; Loss: 0.3973
Epoch 7251/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.076
Epoch 7252/10000; Iter 1/80; Loss: 0.3484
Epoch 7252/10000; Iter 51/80; Loss: 0.3005
Epoch 7252/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7253/10000; Iter 1/80; Loss: 0.3276
Epoch 7253/10000; Iter 51/80; Loss: 0.3518
Epoch 7253/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7254/10000; Iter 1/80; Loss: 0.3322
Epoch 7254/10000; Iter 51/80; Loss: 0.3316
Epoch 7254/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 7255/10000; Iter 1/80; Loss: 0.3435
Epoch 7255/10000; Iter 51/80; Loss: 0.2817
Epoch 7255/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7256/10000; Iter 1/80; Loss: 0.3277
Epoch 7256/10000; Iter 51/80; Loss: 0.2925
Epoch 7256/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 7257/10000; Iter 1/80; Loss: 0.2772
Epoch 7257/10000; Iter 51/80; Loss: 0.3096
Epoch 7257/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7258/10000; Iter 1/80; Loss: 0.3299
Epoch 7258/10000; Iter 51/80; Loss: 0.3216
Epoch 7258/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7259/10000; Iter 1/80; Loss: 0.3431
Epoch 7259/10000; Iter 51/80; Loss: 0.3056
Epoch 7259/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7260/10000; Iter 1/80; Loss: 0.2885
Epoch 7260/10000; Iter 51/80; Loss: 0.3746
Epoch 7260/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.066
Epoch 7261/10000; Iter 1/80; Loss: 0.3133
Epoch 7261/10000; Iter 51/80; Loss: 0.3782
Epoch 7261/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 7262/10000; Iter 1/80; Loss: 0.3421
Epoch 7262/10000; Iter 51/80; Loss: 0.3225
Epoch 7262/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.064
Epoch 7263/10000; Iter 1/80; Loss: 0.2927
Epoch 7263/10000; Iter 51/80; Loss: 0.3555
Epoch 7263/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7264/10000; Iter 1/80; Loss: 0.3222
Epoch 7264/10000; Iter 51/80; Loss: 0.3060
Epoch 7264/10000; Iter 80/80; Training Loss: 0.3480, Test Loss: 0.067
Epoch 7265/10000; Iter 1/80; Loss: 0.3283
Epoch 7265/10000; Iter 51/80; Loss: 0.3373
Epoch 7265/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.065
Epoch 7266/10000; Iter 1/80; Loss: 0.3841
Epoch 7266/10000; Iter 51/80; Loss: 0.3511
Epoch 7266/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7267/10000; Iter 1/80; Loss: 0.3393
Epoch 7267/10000; Iter 51/80; Loss: 0.3627
Epoch 7267/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.072
Epoch 7268/10000; Iter 1/80; Loss: 0.4024
Epoch 7268/10000; Iter 51/80; Loss: 0.3327
Epoch 7268/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.07
Epoch 7269/10000; Iter 1/80; Loss: 0.3062
Epoch 7269/10000; Iter 51/80; Loss: 0.3089
Epoch 7269/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 7270/10000; Iter 1/80; Loss: 0.3643
Epoch 7270/10000; Iter 51/80; Loss: 0.3707
Epoch 7270/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.072
Epoch 7271/10000; Iter 1/80; Loss: 0.3691
Epoch 7271/10000; Iter 51/80; Loss: 0.3842
Epoch 7271/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.076
Epoch 7272/10000; Iter 1/80; Loss: 0.3332
Epoch 7272/10000; Iter 51/80; Loss: 0.3659
Epoch 7272/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.078
Epoch 7273/10000; Iter 1/80; Loss: 0.3433
Epoch 7273/10000; Iter 51/80; Loss: 0.3520
Epoch 7273/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7274/10000; Iter 1/80; Loss: 0.3392
Epoch 7274/10000; Iter 51/80; Loss: 0.3350
Epoch 7274/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 7275/10000; Iter 1/80; Loss: 0.3494
Epoch 7275/10000; Iter 51/80; Loss: 0.3405
Epoch 7275/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7276/10000; Iter 1/80; Loss: 0.3709
Epoch 7276/10000; Iter 51/80; Loss: 0.3213
Epoch 7276/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.066
Epoch 7277/10000; Iter 1/80; Loss: 0.3157
Epoch 7277/10000; Iter 51/80; Loss: 0.3575
Epoch 7277/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.061
Epoch 7278/10000; Iter 1/80; Loss: 0.3075
Epoch 7278/10000; Iter 51/80; Loss: 0.3186
Epoch 7278/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 7279/10000; Iter 1/80; Loss: 0.3812
Epoch 7279/10000; Iter 51/80; Loss: 0.3160
Epoch 7279/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7280/10000; Iter 1/80; Loss: 0.3853
Epoch 7280/10000; Iter 51/80; Loss: 0.4540
Epoch 7280/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7281/10000; Iter 1/80; Loss: 0.3405
Epoch 7281/10000; Iter 51/80; Loss: 0.3479
Epoch 7281/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 7282/10000; Iter 1/80; Loss: 0.3410
Epoch 7282/10000; Iter 51/80; Loss: 0.3614
Epoch 7282/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 7283/10000; Iter 1/80; Loss: 0.3206
Epoch 7283/10000; Iter 51/80; Loss: 0.3612
Epoch 7283/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 7284/10000; Iter 1/80; Loss: 0.3580
Epoch 7284/10000; Iter 51/80; Loss: 0.2895
Epoch 7284/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7285/10000; Iter 1/80; Loss: 0.3702
Epoch 7285/10000; Iter 51/80; Loss: 0.3607
Epoch 7285/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 7286/10000; Iter 1/80; Loss: 0.4190
Epoch 7286/10000; Iter 51/80; Loss: 0.2855
Epoch 7286/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7287/10000; Iter 1/80; Loss: 0.3468
Epoch 7287/10000; Iter 51/80; Loss: 0.3491
Epoch 7287/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7288/10000; Iter 1/80; Loss: 0.3633
Epoch 7288/10000; Iter 51/80; Loss: 0.3662
Epoch 7288/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.07
Epoch 7289/10000; Iter 1/80; Loss: 0.3044
Epoch 7289/10000; Iter 51/80; Loss: 0.3747
Epoch 7289/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7290/10000; Iter 1/80; Loss: 0.3274
Epoch 7290/10000; Iter 51/80; Loss: 0.3173
Epoch 7290/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.074
Epoch 7291/10000; Iter 1/80; Loss: 0.3538
Epoch 7291/10000; Iter 51/80; Loss: 0.3259
Epoch 7291/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 7292/10000; Iter 1/80; Loss: 0.3275
Epoch 7292/10000; Iter 51/80; Loss: 0.3191
Epoch 7292/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7293/10000; Iter 1/80; Loss: 0.3525
Epoch 7293/10000; Iter 51/80; Loss: 0.2977
Epoch 7293/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 7294/10000; Iter 1/80; Loss: 0.3256
Epoch 7294/10000; Iter 51/80; Loss: 0.3290
Epoch 7294/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7295/10000; Iter 1/80; Loss: 0.2706
Epoch 7295/10000; Iter 51/80; Loss: 0.3660
Epoch 7295/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 7296/10000; Iter 1/80; Loss: 0.2912
Epoch 7296/10000; Iter 51/80; Loss: 0.3183
Epoch 7296/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.061
Epoch 7297/10000; Iter 1/80; Loss: 0.2997
Epoch 7297/10000; Iter 51/80; Loss: 0.3312
Epoch 7297/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.065
Epoch 7298/10000; Iter 1/80; Loss: 0.3604
Epoch 7298/10000; Iter 51/80; Loss: 0.3649
Epoch 7298/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7299/10000; Iter 1/80; Loss: 0.3054
Epoch 7299/10000; Iter 51/80; Loss: 0.3053
Epoch 7299/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7300/10000; Iter 1/80; Loss: 0.3805
Epoch 7300/10000; Iter 51/80; Loss: 0.3192
Epoch 7300/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7301/10000; Iter 1/80; Loss: 0.3484
Epoch 7301/10000; Iter 51/80; Loss: 0.2958
Epoch 7301/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.067
Model saved
Epoch 7302/10000; Iter 1/80; Loss: 0.3717
Epoch 7302/10000; Iter 51/80; Loss: 0.3638
Epoch 7302/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7303/10000; Iter 1/80; Loss: 0.3794
Epoch 7303/10000; Iter 51/80; Loss: 0.3998
Epoch 7303/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 7304/10000; Iter 1/80; Loss: 0.3566
Epoch 7304/10000; Iter 51/80; Loss: 0.4479
Epoch 7304/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 7305/10000; Iter 1/80; Loss: 0.3914
Epoch 7305/10000; Iter 51/80; Loss: 0.2950
Epoch 7305/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7306/10000; Iter 1/80; Loss: 0.3128
Epoch 7306/10000; Iter 51/80; Loss: 0.3223
Epoch 7306/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.066
Epoch 7307/10000; Iter 1/80; Loss: 0.3288
Epoch 7307/10000; Iter 51/80; Loss: 0.3489
Epoch 7307/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7308/10000; Iter 1/80; Loss: 0.3203
Epoch 7308/10000; Iter 51/80; Loss: 0.2942
Epoch 7308/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.063
Epoch 7309/10000; Iter 1/80; Loss: 0.3656
Epoch 7309/10000; Iter 51/80; Loss: 0.3678
Epoch 7309/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7310/10000; Iter 1/80; Loss: 0.3241
Epoch 7310/10000; Iter 51/80; Loss: 0.3248
Epoch 7310/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 7311/10000; Iter 1/80; Loss: 0.3856
Epoch 7311/10000; Iter 51/80; Loss: 0.3424
Epoch 7311/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.074
Epoch 7312/10000; Iter 1/80; Loss: 0.3335
Epoch 7312/10000; Iter 51/80; Loss: 0.3398
Epoch 7312/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 7313/10000; Iter 1/80; Loss: 0.3655
Epoch 7313/10000; Iter 51/80; Loss: 0.3059
Epoch 7313/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 7314/10000; Iter 1/80; Loss: 0.3436
Epoch 7314/10000; Iter 51/80; Loss: 0.3611
Epoch 7314/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 7315/10000; Iter 1/80; Loss: 0.3105
Epoch 7315/10000; Iter 51/80; Loss: 0.3325
Epoch 7315/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 7316/10000; Iter 1/80; Loss: 0.3728
Epoch 7316/10000; Iter 51/80; Loss: 0.3900
Epoch 7316/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.077
Epoch 7317/10000; Iter 1/80; Loss: 0.3835
Epoch 7317/10000; Iter 51/80; Loss: 0.3722
Epoch 7317/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 7318/10000; Iter 1/80; Loss: 0.3113
Epoch 7318/10000; Iter 51/80; Loss: 0.3668
Epoch 7318/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.066
Epoch 7319/10000; Iter 1/80; Loss: 0.3186
Epoch 7319/10000; Iter 51/80; Loss: 0.3598
Epoch 7319/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.068
Epoch 7320/10000; Iter 1/80; Loss: 0.3180
Epoch 7320/10000; Iter 51/80; Loss: 0.3180
Epoch 7320/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 7321/10000; Iter 1/80; Loss: 0.3443
Epoch 7321/10000; Iter 51/80; Loss: 0.3257
Epoch 7321/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7322/10000; Iter 1/80; Loss: 0.3463
Epoch 7322/10000; Iter 51/80; Loss: 0.3359
Epoch 7322/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7323/10000; Iter 1/80; Loss: 0.3146
Epoch 7323/10000; Iter 51/80; Loss: 0.3429
Epoch 7323/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.073
Epoch 7324/10000; Iter 1/80; Loss: 0.3752
Epoch 7324/10000; Iter 51/80; Loss: 0.3784
Epoch 7324/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.065
Epoch 7325/10000; Iter 1/80; Loss: 0.2904
Epoch 7325/10000; Iter 51/80; Loss: 0.2966
Epoch 7325/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.067
Epoch 7326/10000; Iter 1/80; Loss: 0.3096
Epoch 7326/10000; Iter 51/80; Loss: 0.3514
Epoch 7326/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.067
Epoch 7327/10000; Iter 1/80; Loss: 0.3291
Epoch 7327/10000; Iter 51/80; Loss: 0.3681
Epoch 7327/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7328/10000; Iter 1/80; Loss: 0.3030
Epoch 7328/10000; Iter 51/80; Loss: 0.3820
Epoch 7328/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7329/10000; Iter 1/80; Loss: 0.2728
Epoch 7329/10000; Iter 51/80; Loss: 0.3387
Epoch 7329/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.074
Epoch 7330/10000; Iter 1/80; Loss: 0.4121
Epoch 7330/10000; Iter 51/80; Loss: 0.3506
Epoch 7330/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.065
Epoch 7331/10000; Iter 1/80; Loss: 0.2709
Epoch 7331/10000; Iter 51/80; Loss: 0.3040
Epoch 7331/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 7332/10000; Iter 1/80; Loss: 0.3880
Epoch 7332/10000; Iter 51/80; Loss: 0.3828
Epoch 7332/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7333/10000; Iter 1/80; Loss: 0.3001
Epoch 7333/10000; Iter 51/80; Loss: 0.3377
Epoch 7333/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7334/10000; Iter 1/80; Loss: 0.3506
Epoch 7334/10000; Iter 51/80; Loss: 0.3181
Epoch 7334/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.076
Epoch 7335/10000; Iter 1/80; Loss: 0.3879
Epoch 7335/10000; Iter 51/80; Loss: 0.2580
Epoch 7335/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7336/10000; Iter 1/80; Loss: 0.3077
Epoch 7336/10000; Iter 51/80; Loss: 0.3895
Epoch 7336/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.072
Epoch 7337/10000; Iter 1/80; Loss: 0.2906
Epoch 7337/10000; Iter 51/80; Loss: 0.3329
Epoch 7337/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 7338/10000; Iter 1/80; Loss: 0.3626
Epoch 7338/10000; Iter 51/80; Loss: 0.3228
Epoch 7338/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 7339/10000; Iter 1/80; Loss: 0.3211
Epoch 7339/10000; Iter 51/80; Loss: 0.3622
Epoch 7339/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.074
Epoch 7340/10000; Iter 1/80; Loss: 0.3756
Epoch 7340/10000; Iter 51/80; Loss: 0.3922
Epoch 7340/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7341/10000; Iter 1/80; Loss: 0.2774
Epoch 7341/10000; Iter 51/80; Loss: 0.3417
Epoch 7341/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7342/10000; Iter 1/80; Loss: 0.3629
Epoch 7342/10000; Iter 51/80; Loss: 0.3641
Epoch 7342/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.064
Epoch 7343/10000; Iter 1/80; Loss: 0.3041
Epoch 7343/10000; Iter 51/80; Loss: 0.3789
Epoch 7343/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7344/10000; Iter 1/80; Loss: 0.2774
Epoch 7344/10000; Iter 51/80; Loss: 0.3317
Epoch 7344/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7345/10000; Iter 1/80; Loss: 0.3181
Epoch 7345/10000; Iter 51/80; Loss: 0.2896
Epoch 7345/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 7346/10000; Iter 1/80; Loss: 0.3593
Epoch 7346/10000; Iter 51/80; Loss: 0.3562
Epoch 7346/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7347/10000; Iter 1/80; Loss: 0.3303
Epoch 7347/10000; Iter 51/80; Loss: 0.3635
Epoch 7347/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 7348/10000; Iter 1/80; Loss: 0.3361
Epoch 7348/10000; Iter 51/80; Loss: 0.3108
Epoch 7348/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 7349/10000; Iter 1/80; Loss: 0.3351
Epoch 7349/10000; Iter 51/80; Loss: 0.3681
Epoch 7349/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 7350/10000; Iter 1/80; Loss: 0.2870
Epoch 7350/10000; Iter 51/80; Loss: 0.3426
Epoch 7350/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.075
Epoch 7351/10000; Iter 1/80; Loss: 0.3995
Epoch 7351/10000; Iter 51/80; Loss: 0.3832
Epoch 7351/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7352/10000; Iter 1/80; Loss: 0.3127
Epoch 7352/10000; Iter 51/80; Loss: 0.3039
Epoch 7352/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 7353/10000; Iter 1/80; Loss: 0.3632
Epoch 7353/10000; Iter 51/80; Loss: 0.3353
Epoch 7353/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7354/10000; Iter 1/80; Loss: 0.3478
Epoch 7354/10000; Iter 51/80; Loss: 0.3165
Epoch 7354/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 7355/10000; Iter 1/80; Loss: 0.3584
Epoch 7355/10000; Iter 51/80; Loss: 0.3378
Epoch 7355/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7356/10000; Iter 1/80; Loss: 0.2849
Epoch 7356/10000; Iter 51/80; Loss: 0.3286
Epoch 7356/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 7357/10000; Iter 1/80; Loss: 0.2835
Epoch 7357/10000; Iter 51/80; Loss: 0.3616
Epoch 7357/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.063
Epoch 7358/10000; Iter 1/80; Loss: 0.3573
Epoch 7358/10000; Iter 51/80; Loss: 0.3055
Epoch 7358/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.071
Epoch 7359/10000; Iter 1/80; Loss: 0.2995
Epoch 7359/10000; Iter 51/80; Loss: 0.3301
Epoch 7359/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7360/10000; Iter 1/80; Loss: 0.3118
Epoch 7360/10000; Iter 51/80; Loss: 0.3765
Epoch 7360/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7361/10000; Iter 1/80; Loss: 0.2822
Epoch 7361/10000; Iter 51/80; Loss: 0.3454
Epoch 7361/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7362/10000; Iter 1/80; Loss: 0.3566
Epoch 7362/10000; Iter 51/80; Loss: 0.3246
Epoch 7362/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.067
Epoch 7363/10000; Iter 1/80; Loss: 0.3024
Epoch 7363/10000; Iter 51/80; Loss: 0.3451
Epoch 7363/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7364/10000; Iter 1/80; Loss: 0.3799
Epoch 7364/10000; Iter 51/80; Loss: 0.3426
Epoch 7364/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 7365/10000; Iter 1/80; Loss: 0.3536
Epoch 7365/10000; Iter 51/80; Loss: 0.3069
Epoch 7365/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 7366/10000; Iter 1/80; Loss: 0.3394
Epoch 7366/10000; Iter 51/80; Loss: 0.3155
Epoch 7366/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.065
Epoch 7367/10000; Iter 1/80; Loss: 0.3232
Epoch 7367/10000; Iter 51/80; Loss: 0.3291
Epoch 7367/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.073
Epoch 7368/10000; Iter 1/80; Loss: 0.3356
Epoch 7368/10000; Iter 51/80; Loss: 0.3934
Epoch 7368/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.067
Epoch 7369/10000; Iter 1/80; Loss: 0.2976
Epoch 7369/10000; Iter 51/80; Loss: 0.3070
Epoch 7369/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 7370/10000; Iter 1/80; Loss: 0.3071
Epoch 7370/10000; Iter 51/80; Loss: 0.2896
Epoch 7370/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 7371/10000; Iter 1/80; Loss: 0.3133
Epoch 7371/10000; Iter 51/80; Loss: 0.3171
Epoch 7371/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7372/10000; Iter 1/80; Loss: 0.3560
Epoch 7372/10000; Iter 51/80; Loss: 0.3207
Epoch 7372/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 7373/10000; Iter 1/80; Loss: 0.3962
Epoch 7373/10000; Iter 51/80; Loss: 0.3078
Epoch 7373/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7374/10000; Iter 1/80; Loss: 0.3457
Epoch 7374/10000; Iter 51/80; Loss: 0.3369
Epoch 7374/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 7375/10000; Iter 1/80; Loss: 0.3084
Epoch 7375/10000; Iter 51/80; Loss: 0.3665
Epoch 7375/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7376/10000; Iter 1/80; Loss: 0.3434
Epoch 7376/10000; Iter 51/80; Loss: 0.3657
Epoch 7376/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7377/10000; Iter 1/80; Loss: 0.3510
Epoch 7377/10000; Iter 51/80; Loss: 0.3528
Epoch 7377/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.078
Epoch 7378/10000; Iter 1/80; Loss: 0.3559
Epoch 7378/10000; Iter 51/80; Loss: 0.3114
Epoch 7378/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 7379/10000; Iter 1/80; Loss: 0.3791
Epoch 7379/10000; Iter 51/80; Loss: 0.3172
Epoch 7379/10000; Iter 80/80; Training Loss: 0.3450, Test Loss: 0.07
Epoch 7380/10000; Iter 1/80; Loss: 0.3513
Epoch 7380/10000; Iter 51/80; Loss: 0.3262
Epoch 7380/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7381/10000; Iter 1/80; Loss: 0.3319
Epoch 7381/10000; Iter 51/80; Loss: 0.3204
Epoch 7381/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.077
Epoch 7382/10000; Iter 1/80; Loss: 0.3635
Epoch 7382/10000; Iter 51/80; Loss: 0.3026
Epoch 7382/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 7383/10000; Iter 1/80; Loss: 0.3122
Epoch 7383/10000; Iter 51/80; Loss: 0.3531
Epoch 7383/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.065
Epoch 7384/10000; Iter 1/80; Loss: 0.3771
Epoch 7384/10000; Iter 51/80; Loss: 0.3801
Epoch 7384/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7385/10000; Iter 1/80; Loss: 0.3634
Epoch 7385/10000; Iter 51/80; Loss: 0.3498
Epoch 7385/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.064
Epoch 7386/10000; Iter 1/80; Loss: 0.3310
Epoch 7386/10000; Iter 51/80; Loss: 0.3433
Epoch 7386/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.063
Epoch 7387/10000; Iter 1/80; Loss: 0.3542
Epoch 7387/10000; Iter 51/80; Loss: 0.3098
Epoch 7387/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.078
Epoch 7388/10000; Iter 1/80; Loss: 0.3520
Epoch 7388/10000; Iter 51/80; Loss: 0.3407
Epoch 7388/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7389/10000; Iter 1/80; Loss: 0.3127
Epoch 7389/10000; Iter 51/80; Loss: 0.3520
Epoch 7389/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.072
Epoch 7390/10000; Iter 1/80; Loss: 0.3148
Epoch 7390/10000; Iter 51/80; Loss: 0.2902
Epoch 7390/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 7391/10000; Iter 1/80; Loss: 0.2933
Epoch 7391/10000; Iter 51/80; Loss: 0.3304
Epoch 7391/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.062
Epoch 7392/10000; Iter 1/80; Loss: 0.3247
Epoch 7392/10000; Iter 51/80; Loss: 0.3958
Epoch 7392/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7393/10000; Iter 1/80; Loss: 0.3685
Epoch 7393/10000; Iter 51/80; Loss: 0.3507
Epoch 7393/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7394/10000; Iter 1/80; Loss: 0.3376
Epoch 7394/10000; Iter 51/80; Loss: 0.2902
Epoch 7394/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 7395/10000; Iter 1/80; Loss: 0.3286
Epoch 7395/10000; Iter 51/80; Loss: 0.3896
Epoch 7395/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.063
Epoch 7396/10000; Iter 1/80; Loss: 0.3273
Epoch 7396/10000; Iter 51/80; Loss: 0.3962
Epoch 7396/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.066
Epoch 7397/10000; Iter 1/80; Loss: 0.3733
Epoch 7397/10000; Iter 51/80; Loss: 0.3116
Epoch 7397/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.064
Epoch 7398/10000; Iter 1/80; Loss: 0.3668
Epoch 7398/10000; Iter 51/80; Loss: 0.3405
Epoch 7398/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 7399/10000; Iter 1/80; Loss: 0.3400
Epoch 7399/10000; Iter 51/80; Loss: 0.3265
Epoch 7399/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.078
Epoch 7400/10000; Iter 1/80; Loss: 0.3875
Epoch 7400/10000; Iter 51/80; Loss: 0.3630
Epoch 7400/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 7401/10000; Iter 1/80; Loss: 0.3278
Epoch 7401/10000; Iter 51/80; Loss: 0.3285
Epoch 7401/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Model saved
Epoch 7402/10000; Iter 1/80; Loss: 0.3565
Epoch 7402/10000; Iter 51/80; Loss: 0.3152
Epoch 7402/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7403/10000; Iter 1/80; Loss: 0.3031
Epoch 7403/10000; Iter 51/80; Loss: 0.3531
Epoch 7403/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 7404/10000; Iter 1/80; Loss: 0.3346
Epoch 7404/10000; Iter 51/80; Loss: 0.2976
Epoch 7404/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 7405/10000; Iter 1/80; Loss: 0.3890
Epoch 7405/10000; Iter 51/80; Loss: 0.3597
Epoch 7405/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7406/10000; Iter 1/80; Loss: 0.3787
Epoch 7406/10000; Iter 51/80; Loss: 0.3143
Epoch 7406/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.072
Epoch 7407/10000; Iter 1/80; Loss: 0.2929
Epoch 7407/10000; Iter 51/80; Loss: 0.3884
Epoch 7407/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.065
Epoch 7408/10000; Iter 1/80; Loss: 0.3299
Epoch 7408/10000; Iter 51/80; Loss: 0.3234
Epoch 7408/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7409/10000; Iter 1/80; Loss: 0.3907
Epoch 7409/10000; Iter 51/80; Loss: 0.2938
Epoch 7409/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7410/10000; Iter 1/80; Loss: 0.3179
Epoch 7410/10000; Iter 51/80; Loss: 0.3735
Epoch 7410/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7411/10000; Iter 1/80; Loss: 0.3417
Epoch 7411/10000; Iter 51/80; Loss: 0.3252
Epoch 7411/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.064
Epoch 7412/10000; Iter 1/80; Loss: 0.3320
Epoch 7412/10000; Iter 51/80; Loss: 0.3551
Epoch 7412/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 7413/10000; Iter 1/80; Loss: 0.3550
Epoch 7413/10000; Iter 51/80; Loss: 0.3747
Epoch 7413/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7414/10000; Iter 1/80; Loss: 0.3625
Epoch 7414/10000; Iter 51/80; Loss: 0.3409
Epoch 7414/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7415/10000; Iter 1/80; Loss: 0.2948
Epoch 7415/10000; Iter 51/80; Loss: 0.3552
Epoch 7415/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 7416/10000; Iter 1/80; Loss: 0.3342
Epoch 7416/10000; Iter 51/80; Loss: 0.3268
Epoch 7416/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.063
Epoch 7417/10000; Iter 1/80; Loss: 0.3620
Epoch 7417/10000; Iter 51/80; Loss: 0.3076
Epoch 7417/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.069
Epoch 7418/10000; Iter 1/80; Loss: 0.3573
Epoch 7418/10000; Iter 51/80; Loss: 0.3588
Epoch 7418/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7419/10000; Iter 1/80; Loss: 0.3346
Epoch 7419/10000; Iter 51/80; Loss: 0.3290
Epoch 7419/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.077
Epoch 7420/10000; Iter 1/80; Loss: 0.3749
Epoch 7420/10000; Iter 51/80; Loss: 0.3494
Epoch 7420/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 7421/10000; Iter 1/80; Loss: 0.2988
Epoch 7421/10000; Iter 51/80; Loss: 0.4009
Epoch 7421/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 7422/10000; Iter 1/80; Loss: 0.2879
Epoch 7422/10000; Iter 51/80; Loss: 0.3909
Epoch 7422/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7423/10000; Iter 1/80; Loss: 0.3935
Epoch 7423/10000; Iter 51/80; Loss: 0.3889
Epoch 7423/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.061
Epoch 7424/10000; Iter 1/80; Loss: 0.2985
Epoch 7424/10000; Iter 51/80; Loss: 0.3851
Epoch 7424/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7425/10000; Iter 1/80; Loss: 0.3535
Epoch 7425/10000; Iter 51/80; Loss: 0.3145
Epoch 7425/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.073
Epoch 7426/10000; Iter 1/80; Loss: 0.3586
Epoch 7426/10000; Iter 51/80; Loss: 0.3595
Epoch 7426/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 7427/10000; Iter 1/80; Loss: 0.3774
Epoch 7427/10000; Iter 51/80; Loss: 0.3306
Epoch 7427/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.071
Epoch 7428/10000; Iter 1/80; Loss: 0.3654
Epoch 7428/10000; Iter 51/80; Loss: 0.3473
Epoch 7428/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7429/10000; Iter 1/80; Loss: 0.3312
Epoch 7429/10000; Iter 51/80; Loss: 0.2803
Epoch 7429/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 7430/10000; Iter 1/80; Loss: 0.3318
Epoch 7430/10000; Iter 51/80; Loss: 0.3447
Epoch 7430/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.067
Epoch 7431/10000; Iter 1/80; Loss: 0.3192
Epoch 7431/10000; Iter 51/80; Loss: 0.3367
Epoch 7431/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7432/10000; Iter 1/80; Loss: 0.3219
Epoch 7432/10000; Iter 51/80; Loss: 0.3922
Epoch 7432/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7433/10000; Iter 1/80; Loss: 0.2714
Epoch 7433/10000; Iter 51/80; Loss: 0.3190
Epoch 7433/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7434/10000; Iter 1/80; Loss: 0.3083
Epoch 7434/10000; Iter 51/80; Loss: 0.3225
Epoch 7434/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.062
Epoch 7435/10000; Iter 1/80; Loss: 0.3681
Epoch 7435/10000; Iter 51/80; Loss: 0.3533
Epoch 7435/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.07
Epoch 7436/10000; Iter 1/80; Loss: 0.3015
Epoch 7436/10000; Iter 51/80; Loss: 0.3407
Epoch 7436/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.068
Epoch 7437/10000; Iter 1/80; Loss: 0.3280
Epoch 7437/10000; Iter 51/80; Loss: 0.3704
Epoch 7437/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 7438/10000; Iter 1/80; Loss: 0.2813
Epoch 7438/10000; Iter 51/80; Loss: 0.3261
Epoch 7438/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 7439/10000; Iter 1/80; Loss: 0.3291
Epoch 7439/10000; Iter 51/80; Loss: 0.3413
Epoch 7439/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7440/10000; Iter 1/80; Loss: 0.3931
Epoch 7440/10000; Iter 51/80; Loss: 0.3799
Epoch 7440/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.071
Epoch 7441/10000; Iter 1/80; Loss: 0.3561
Epoch 7441/10000; Iter 51/80; Loss: 0.4056
Epoch 7441/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7442/10000; Iter 1/80; Loss: 0.3534
Epoch 7442/10000; Iter 51/80; Loss: 0.3503
Epoch 7442/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7443/10000; Iter 1/80; Loss: 0.2945
Epoch 7443/10000; Iter 51/80; Loss: 0.3264
Epoch 7443/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.064
Epoch 7444/10000; Iter 1/80; Loss: 0.3069
Epoch 7444/10000; Iter 51/80; Loss: 0.2883
Epoch 7444/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.076
Epoch 7445/10000; Iter 1/80; Loss: 0.3508
Epoch 7445/10000; Iter 51/80; Loss: 0.2762
Epoch 7445/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.066
Epoch 7446/10000; Iter 1/80; Loss: 0.4180
Epoch 7446/10000; Iter 51/80; Loss: 0.3312
Epoch 7446/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.065
Epoch 7447/10000; Iter 1/80; Loss: 0.2760
Epoch 7447/10000; Iter 51/80; Loss: 0.3405
Epoch 7447/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.068
Epoch 7448/10000; Iter 1/80; Loss: 0.2835
Epoch 7448/10000; Iter 51/80; Loss: 0.3007
Epoch 7448/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.076
Epoch 7449/10000; Iter 1/80; Loss: 0.4221
Epoch 7449/10000; Iter 51/80; Loss: 0.3715
Epoch 7449/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.064
Epoch 7450/10000; Iter 1/80; Loss: 0.3480
Epoch 7450/10000; Iter 51/80; Loss: 0.2885
Epoch 7450/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7451/10000; Iter 1/80; Loss: 0.3439
Epoch 7451/10000; Iter 51/80; Loss: 0.3194
Epoch 7451/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7452/10000; Iter 1/80; Loss: 0.3182
Epoch 7452/10000; Iter 51/80; Loss: 0.3383
Epoch 7452/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7453/10000; Iter 1/80; Loss: 0.3472
Epoch 7453/10000; Iter 51/80; Loss: 0.3513
Epoch 7453/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7454/10000; Iter 1/80; Loss: 0.3612
Epoch 7454/10000; Iter 51/80; Loss: 0.3445
Epoch 7454/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.074
Epoch 7455/10000; Iter 1/80; Loss: 0.3511
Epoch 7455/10000; Iter 51/80; Loss: 0.3484
Epoch 7455/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.076
Epoch 7456/10000; Iter 1/80; Loss: 0.3004
Epoch 7456/10000; Iter 51/80; Loss: 0.3428
Epoch 7456/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.065
Epoch 7457/10000; Iter 1/80; Loss: 0.3257
Epoch 7457/10000; Iter 51/80; Loss: 0.3226
Epoch 7457/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 7458/10000; Iter 1/80; Loss: 0.3383
Epoch 7458/10000; Iter 51/80; Loss: 0.3293
Epoch 7458/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 7459/10000; Iter 1/80; Loss: 0.3110
Epoch 7459/10000; Iter 51/80; Loss: 0.2996
Epoch 7459/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 7460/10000; Iter 1/80; Loss: 0.3704
Epoch 7460/10000; Iter 51/80; Loss: 0.3367
Epoch 7460/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7461/10000; Iter 1/80; Loss: 0.3521
Epoch 7461/10000; Iter 51/80; Loss: 0.3304
Epoch 7461/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7462/10000; Iter 1/80; Loss: 0.4083
Epoch 7462/10000; Iter 51/80; Loss: 0.3623
Epoch 7462/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.073
Epoch 7463/10000; Iter 1/80; Loss: 0.3647
Epoch 7463/10000; Iter 51/80; Loss: 0.3386
Epoch 7463/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7464/10000; Iter 1/80; Loss: 0.3720
Epoch 7464/10000; Iter 51/80; Loss: 0.3040
Epoch 7464/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.078
Epoch 7465/10000; Iter 1/80; Loss: 0.3162
Epoch 7465/10000; Iter 51/80; Loss: 0.3135
Epoch 7465/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7466/10000; Iter 1/80; Loss: 0.2852
Epoch 7466/10000; Iter 51/80; Loss: 0.3361
Epoch 7466/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7467/10000; Iter 1/80; Loss: 0.3678
Epoch 7467/10000; Iter 51/80; Loss: 0.3136
Epoch 7467/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.066
Epoch 7468/10000; Iter 1/80; Loss: 0.3445
Epoch 7468/10000; Iter 51/80; Loss: 0.3277
Epoch 7468/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7469/10000; Iter 1/80; Loss: 0.3654
Epoch 7469/10000; Iter 51/80; Loss: 0.3399
Epoch 7469/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 7470/10000; Iter 1/80; Loss: 0.3316
Epoch 7470/10000; Iter 51/80; Loss: 0.3841
Epoch 7470/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.068
Epoch 7471/10000; Iter 1/80; Loss: 0.3707
Epoch 7471/10000; Iter 51/80; Loss: 0.3202
Epoch 7471/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 7472/10000; Iter 1/80; Loss: 0.3222
Epoch 7472/10000; Iter 51/80; Loss: 0.3536
Epoch 7472/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.066
Epoch 7473/10000; Iter 1/80; Loss: 0.3638
Epoch 7473/10000; Iter 51/80; Loss: 0.3243
Epoch 7473/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.076
Epoch 7474/10000; Iter 1/80; Loss: 0.2770
Epoch 7474/10000; Iter 51/80; Loss: 0.3209
Epoch 7474/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 7475/10000; Iter 1/80; Loss: 0.3021
Epoch 7475/10000; Iter 51/80; Loss: 0.3508
Epoch 7475/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.066
Epoch 7476/10000; Iter 1/80; Loss: 0.3261
Epoch 7476/10000; Iter 51/80; Loss: 0.3734
Epoch 7476/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.066
Epoch 7477/10000; Iter 1/80; Loss: 0.2926
Epoch 7477/10000; Iter 51/80; Loss: 0.3400
Epoch 7477/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 7478/10000; Iter 1/80; Loss: 0.3397
Epoch 7478/10000; Iter 51/80; Loss: 0.3544
Epoch 7478/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 7479/10000; Iter 1/80; Loss: 0.3280
Epoch 7479/10000; Iter 51/80; Loss: 0.3531
Epoch 7479/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 7480/10000; Iter 1/80; Loss: 0.3025
Epoch 7480/10000; Iter 51/80; Loss: 0.3539
Epoch 7480/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7481/10000; Iter 1/80; Loss: 0.3077
Epoch 7481/10000; Iter 51/80; Loss: 0.4265
Epoch 7481/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7482/10000; Iter 1/80; Loss: 0.4155
Epoch 7482/10000; Iter 51/80; Loss: 0.3375
Epoch 7482/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7483/10000; Iter 1/80; Loss: 0.3118
Epoch 7483/10000; Iter 51/80; Loss: 0.3208
Epoch 7483/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.078
Epoch 7484/10000; Iter 1/80; Loss: 0.3215
Epoch 7484/10000; Iter 51/80; Loss: 0.3212
Epoch 7484/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.074
Epoch 7485/10000; Iter 1/80; Loss: 0.3618
Epoch 7485/10000; Iter 51/80; Loss: 0.3515
Epoch 7485/10000; Iter 80/80; Training Loss: 0.3470, Test Loss: 0.068
Epoch 7486/10000; Iter 1/80; Loss: 0.3039
Epoch 7486/10000; Iter 51/80; Loss: 0.2908
Epoch 7486/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.067
Epoch 7487/10000; Iter 1/80; Loss: 0.4150
Epoch 7487/10000; Iter 51/80; Loss: 0.3871
Epoch 7487/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7488/10000; Iter 1/80; Loss: 0.3227
Epoch 7488/10000; Iter 51/80; Loss: 0.3129
Epoch 7488/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7489/10000; Iter 1/80; Loss: 0.2927
Epoch 7489/10000; Iter 51/80; Loss: 0.3095
Epoch 7489/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7490/10000; Iter 1/80; Loss: 0.3833
Epoch 7490/10000; Iter 51/80; Loss: 0.3801
Epoch 7490/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 7491/10000; Iter 1/80; Loss: 0.3233
Epoch 7491/10000; Iter 51/80; Loss: 0.3135
Epoch 7491/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7492/10000; Iter 1/80; Loss: 0.2946
Epoch 7492/10000; Iter 51/80; Loss: 0.3244
Epoch 7492/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 7493/10000; Iter 1/80; Loss: 0.3953
Epoch 7493/10000; Iter 51/80; Loss: 0.3113
Epoch 7493/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.063
Epoch 7494/10000; Iter 1/80; Loss: 0.2987
Epoch 7494/10000; Iter 51/80; Loss: 0.3248
Epoch 7494/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7495/10000; Iter 1/80; Loss: 0.3280
Epoch 7495/10000; Iter 51/80; Loss: 0.3003
Epoch 7495/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7496/10000; Iter 1/80; Loss: 0.3486
Epoch 7496/10000; Iter 51/80; Loss: 0.3271
Epoch 7496/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7497/10000; Iter 1/80; Loss: 0.3452
Epoch 7497/10000; Iter 51/80; Loss: 0.3009
Epoch 7497/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.064
Epoch 7498/10000; Iter 1/80; Loss: 0.3281
Epoch 7498/10000; Iter 51/80; Loss: 0.3822
Epoch 7498/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7499/10000; Iter 1/80; Loss: 0.3245
Epoch 7499/10000; Iter 51/80; Loss: 0.3788
Epoch 7499/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.069
Epoch 7500/10000; Iter 1/80; Loss: 0.3116
Epoch 7500/10000; Iter 51/80; Loss: 0.3325
Epoch 7500/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 7501/10000; Iter 1/80; Loss: 0.3917
Epoch 7501/10000; Iter 51/80; Loss: 0.3191
Epoch 7501/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Model saved
Epoch 7502/10000; Iter 1/80; Loss: 0.3174
Epoch 7502/10000; Iter 51/80; Loss: 0.3915
Epoch 7502/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.078
Epoch 7503/10000; Iter 1/80; Loss: 0.3088
Epoch 7503/10000; Iter 51/80; Loss: 0.3165
Epoch 7503/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 7504/10000; Iter 1/80; Loss: 0.3467
Epoch 7504/10000; Iter 51/80; Loss: 0.3223
Epoch 7504/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.064
Epoch 7505/10000; Iter 1/80; Loss: 0.3333
Epoch 7505/10000; Iter 51/80; Loss: 0.3280
Epoch 7505/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 7506/10000; Iter 1/80; Loss: 0.2815
Epoch 7506/10000; Iter 51/80; Loss: 0.3337
Epoch 7506/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7507/10000; Iter 1/80; Loss: 0.3241
Epoch 7507/10000; Iter 51/80; Loss: 0.3520
Epoch 7507/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.076
Epoch 7508/10000; Iter 1/80; Loss: 0.3963
Epoch 7508/10000; Iter 51/80; Loss: 0.3449
Epoch 7508/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.075
Epoch 7509/10000; Iter 1/80; Loss: 0.3565
Epoch 7509/10000; Iter 51/80; Loss: 0.4054
Epoch 7509/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7510/10000; Iter 1/80; Loss: 0.4020
Epoch 7510/10000; Iter 51/80; Loss: 0.4411
Epoch 7510/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7511/10000; Iter 1/80; Loss: 0.3003
Epoch 7511/10000; Iter 51/80; Loss: 0.3404
Epoch 7511/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7512/10000; Iter 1/80; Loss: 0.2603
Epoch 7512/10000; Iter 51/80; Loss: 0.3279
Epoch 7512/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7513/10000; Iter 1/80; Loss: 0.3222
Epoch 7513/10000; Iter 51/80; Loss: 0.3148
Epoch 7513/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7514/10000; Iter 1/80; Loss: 0.3854
Epoch 7514/10000; Iter 51/80; Loss: 0.3225
Epoch 7514/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.071
Epoch 7515/10000; Iter 1/80; Loss: 0.3516
Epoch 7515/10000; Iter 51/80; Loss: 0.3689
Epoch 7515/10000; Iter 80/80; Training Loss: 0.3440, Test Loss: 0.063
Epoch 7516/10000; Iter 1/80; Loss: 0.3197
Epoch 7516/10000; Iter 51/80; Loss: 0.2844
Epoch 7516/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7517/10000; Iter 1/80; Loss: 0.3219
Epoch 7517/10000; Iter 51/80; Loss: 0.3777
Epoch 7517/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.077
Epoch 7518/10000; Iter 1/80; Loss: 0.3018
Epoch 7518/10000; Iter 51/80; Loss: 0.3619
Epoch 7518/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.082
Epoch 7519/10000; Iter 1/80; Loss: 0.3212
Epoch 7519/10000; Iter 51/80; Loss: 0.3369
Epoch 7519/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7520/10000; Iter 1/80; Loss: 0.4464
Epoch 7520/10000; Iter 51/80; Loss: 0.3283
Epoch 7520/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.069
Epoch 7521/10000; Iter 1/80; Loss: 0.3282
Epoch 7521/10000; Iter 51/80; Loss: 0.3268
Epoch 7521/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.067
Epoch 7522/10000; Iter 1/80; Loss: 0.2974
Epoch 7522/10000; Iter 51/80; Loss: 0.3397
Epoch 7522/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7523/10000; Iter 1/80; Loss: 0.3473
Epoch 7523/10000; Iter 51/80; Loss: 0.3661
Epoch 7523/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.078
Epoch 7524/10000; Iter 1/80; Loss: 0.3245
Epoch 7524/10000; Iter 51/80; Loss: 0.4143
Epoch 7524/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7525/10000; Iter 1/80; Loss: 0.3908
Epoch 7525/10000; Iter 51/80; Loss: 0.3602
Epoch 7525/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7526/10000; Iter 1/80; Loss: 0.3649
Epoch 7526/10000; Iter 51/80; Loss: 0.3305
Epoch 7526/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7527/10000; Iter 1/80; Loss: 0.3715
Epoch 7527/10000; Iter 51/80; Loss: 0.3036
Epoch 7527/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 7528/10000; Iter 1/80; Loss: 0.4190
Epoch 7528/10000; Iter 51/80; Loss: 0.3747
Epoch 7528/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 7529/10000; Iter 1/80; Loss: 0.2981
Epoch 7529/10000; Iter 51/80; Loss: 0.3395
Epoch 7529/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 7530/10000; Iter 1/80; Loss: 0.2873
Epoch 7530/10000; Iter 51/80; Loss: 0.3938
Epoch 7530/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7531/10000; Iter 1/80; Loss: 0.4349
Epoch 7531/10000; Iter 51/80; Loss: 0.4023
Epoch 7531/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.072
Epoch 7532/10000; Iter 1/80; Loss: 0.4150
Epoch 7532/10000; Iter 51/80; Loss: 0.3457
Epoch 7532/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7533/10000; Iter 1/80; Loss: 0.2877
Epoch 7533/10000; Iter 51/80; Loss: 0.3432
Epoch 7533/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7534/10000; Iter 1/80; Loss: 0.3724
Epoch 7534/10000; Iter 51/80; Loss: 0.3000
Epoch 7534/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 7535/10000; Iter 1/80; Loss: 0.3293
Epoch 7535/10000; Iter 51/80; Loss: 0.3341
Epoch 7535/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7536/10000; Iter 1/80; Loss: 0.3879
Epoch 7536/10000; Iter 51/80; Loss: 0.3668
Epoch 7536/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7537/10000; Iter 1/80; Loss: 0.3442
Epoch 7537/10000; Iter 51/80; Loss: 0.3020
Epoch 7537/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.066
Epoch 7538/10000; Iter 1/80; Loss: 0.3659
Epoch 7538/10000; Iter 51/80; Loss: 0.3150
Epoch 7538/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7539/10000; Iter 1/80; Loss: 0.3703
Epoch 7539/10000; Iter 51/80; Loss: 0.3428
Epoch 7539/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 7540/10000; Iter 1/80; Loss: 0.3253
Epoch 7540/10000; Iter 51/80; Loss: 0.3472
Epoch 7540/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.071
Epoch 7541/10000; Iter 1/80; Loss: 0.3877
Epoch 7541/10000; Iter 51/80; Loss: 0.3396
Epoch 7541/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.076
Epoch 7542/10000; Iter 1/80; Loss: 0.3207
Epoch 7542/10000; Iter 51/80; Loss: 0.3169
Epoch 7542/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.071
Epoch 7543/10000; Iter 1/80; Loss: 0.3470
Epoch 7543/10000; Iter 51/80; Loss: 0.3059
Epoch 7543/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.075
Epoch 7544/10000; Iter 1/80; Loss: 0.3623
Epoch 7544/10000; Iter 51/80; Loss: 0.3489
Epoch 7544/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.073
Epoch 7545/10000; Iter 1/80; Loss: 0.3083
Epoch 7545/10000; Iter 51/80; Loss: 0.3382
Epoch 7545/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 7546/10000; Iter 1/80; Loss: 0.3538
Epoch 7546/10000; Iter 51/80; Loss: 0.3486
Epoch 7546/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7547/10000; Iter 1/80; Loss: 0.3517
Epoch 7547/10000; Iter 51/80; Loss: 0.3777
Epoch 7547/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 7548/10000; Iter 1/80; Loss: 0.3355
Epoch 7548/10000; Iter 51/80; Loss: 0.3325
Epoch 7548/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.077
Epoch 7549/10000; Iter 1/80; Loss: 0.3390
Epoch 7549/10000; Iter 51/80; Loss: 0.3185
Epoch 7549/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.072
Epoch 7550/10000; Iter 1/80; Loss: 0.3019
Epoch 7550/10000; Iter 51/80; Loss: 0.3144
Epoch 7550/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7551/10000; Iter 1/80; Loss: 0.3660
Epoch 7551/10000; Iter 51/80; Loss: 0.3127
Epoch 7551/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 7552/10000; Iter 1/80; Loss: 0.3919
Epoch 7552/10000; Iter 51/80; Loss: 0.3402
Epoch 7552/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 7553/10000; Iter 1/80; Loss: 0.3547
Epoch 7553/10000; Iter 51/80; Loss: 0.3841
Epoch 7553/10000; Iter 80/80; Training Loss: 0.3460, Test Loss: 0.074
Epoch 7554/10000; Iter 1/80; Loss: 0.3546
Epoch 7554/10000; Iter 51/80; Loss: 0.3481
Epoch 7554/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7555/10000; Iter 1/80; Loss: 0.3257
Epoch 7555/10000; Iter 51/80; Loss: 0.3547
Epoch 7555/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 7556/10000; Iter 1/80; Loss: 0.2940
Epoch 7556/10000; Iter 51/80; Loss: 0.3554
Epoch 7556/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.069
Epoch 7557/10000; Iter 1/80; Loss: 0.3190
Epoch 7557/10000; Iter 51/80; Loss: 0.3445
Epoch 7557/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 7558/10000; Iter 1/80; Loss: 0.3065
Epoch 7558/10000; Iter 51/80; Loss: 0.3181
Epoch 7558/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.076
Epoch 7559/10000; Iter 1/80; Loss: 0.3833
Epoch 7559/10000; Iter 51/80; Loss: 0.4157
Epoch 7559/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.067
Epoch 7560/10000; Iter 1/80; Loss: 0.3373
Epoch 7560/10000; Iter 51/80; Loss: 0.3946
Epoch 7560/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.069
Epoch 7561/10000; Iter 1/80; Loss: 0.2913
Epoch 7561/10000; Iter 51/80; Loss: 0.3693
Epoch 7561/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7562/10000; Iter 1/80; Loss: 0.3165
Epoch 7562/10000; Iter 51/80; Loss: 0.3559
Epoch 7562/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.073
Epoch 7563/10000; Iter 1/80; Loss: 0.3809
Epoch 7563/10000; Iter 51/80; Loss: 0.3447
Epoch 7563/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.077
Epoch 7564/10000; Iter 1/80; Loss: 0.3539
Epoch 7564/10000; Iter 51/80; Loss: 0.3197
Epoch 7564/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.069
Epoch 7565/10000; Iter 1/80; Loss: 0.3319
Epoch 7565/10000; Iter 51/80; Loss: 0.3260
Epoch 7565/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.079
Epoch 7566/10000; Iter 1/80; Loss: 0.3663
Epoch 7566/10000; Iter 51/80; Loss: 0.3073
Epoch 7566/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7567/10000; Iter 1/80; Loss: 0.3262
Epoch 7567/10000; Iter 51/80; Loss: 0.3658
Epoch 7567/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7568/10000; Iter 1/80; Loss: 0.3111
Epoch 7568/10000; Iter 51/80; Loss: 0.3686
Epoch 7568/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7569/10000; Iter 1/80; Loss: 0.3712
Epoch 7569/10000; Iter 51/80; Loss: 0.2877
Epoch 7569/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7570/10000; Iter 1/80; Loss: 0.3485
Epoch 7570/10000; Iter 51/80; Loss: 0.3323
Epoch 7570/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.072
Epoch 7571/10000; Iter 1/80; Loss: 0.3084
Epoch 7571/10000; Iter 51/80; Loss: 0.3577
Epoch 7571/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 7572/10000; Iter 1/80; Loss: 0.3008
Epoch 7572/10000; Iter 51/80; Loss: 0.2989
Epoch 7572/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.066
Epoch 7573/10000; Iter 1/80; Loss: 0.3555
Epoch 7573/10000; Iter 51/80; Loss: 0.3189
Epoch 7573/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7574/10000; Iter 1/80; Loss: 0.3888
Epoch 7574/10000; Iter 51/80; Loss: 0.3416
Epoch 7574/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.078
Epoch 7575/10000; Iter 1/80; Loss: 0.3294
Epoch 7575/10000; Iter 51/80; Loss: 0.2985
Epoch 7575/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7576/10000; Iter 1/80; Loss: 0.4226
Epoch 7576/10000; Iter 51/80; Loss: 0.3298
Epoch 7576/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 7577/10000; Iter 1/80; Loss: 0.2875
Epoch 7577/10000; Iter 51/80; Loss: 0.3487
Epoch 7577/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7578/10000; Iter 1/80; Loss: 0.3597
Epoch 7578/10000; Iter 51/80; Loss: 0.4061
Epoch 7578/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.075
Epoch 7579/10000; Iter 1/80; Loss: 0.3247
Epoch 7579/10000; Iter 51/80; Loss: 0.3062
Epoch 7579/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.074
Epoch 7580/10000; Iter 1/80; Loss: 0.3920
Epoch 7580/10000; Iter 51/80; Loss: 0.2947
Epoch 7580/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 7581/10000; Iter 1/80; Loss: 0.3343
Epoch 7581/10000; Iter 51/80; Loss: 0.3004
Epoch 7581/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7582/10000; Iter 1/80; Loss: 0.3141
Epoch 7582/10000; Iter 51/80; Loss: 0.3586
Epoch 7582/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7583/10000; Iter 1/80; Loss: 0.3473
Epoch 7583/10000; Iter 51/80; Loss: 0.3701
Epoch 7583/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 7584/10000; Iter 1/80; Loss: 0.3599
Epoch 7584/10000; Iter 51/80; Loss: 0.3159
Epoch 7584/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7585/10000; Iter 1/80; Loss: 0.3445
Epoch 7585/10000; Iter 51/80; Loss: 0.3058
Epoch 7585/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.078
Epoch 7586/10000; Iter 1/80; Loss: 0.3608
Epoch 7586/10000; Iter 51/80; Loss: 0.3713
Epoch 7586/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7587/10000; Iter 1/80; Loss: 0.3809
Epoch 7587/10000; Iter 51/80; Loss: 0.3753
Epoch 7587/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7588/10000; Iter 1/80; Loss: 0.2890
Epoch 7588/10000; Iter 51/80; Loss: 0.3216
Epoch 7588/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7589/10000; Iter 1/80; Loss: 0.3346
Epoch 7589/10000; Iter 51/80; Loss: 0.2977
Epoch 7589/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.075
Epoch 7590/10000; Iter 1/80; Loss: 0.3972
Epoch 7590/10000; Iter 51/80; Loss: 0.3162
Epoch 7590/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7591/10000; Iter 1/80; Loss: 0.3692
Epoch 7591/10000; Iter 51/80; Loss: 0.3101
Epoch 7591/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.067
Epoch 7592/10000; Iter 1/80; Loss: 0.3728
Epoch 7592/10000; Iter 51/80; Loss: 0.3099
Epoch 7592/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.066
Epoch 7593/10000; Iter 1/80; Loss: 0.3116
Epoch 7593/10000; Iter 51/80; Loss: 0.3599
Epoch 7593/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7594/10000; Iter 1/80; Loss: 0.3072
Epoch 7594/10000; Iter 51/80; Loss: 0.3318
Epoch 7594/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 7595/10000; Iter 1/80; Loss: 0.3343
Epoch 7595/10000; Iter 51/80; Loss: 0.3133
Epoch 7595/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7596/10000; Iter 1/80; Loss: 0.3169
Epoch 7596/10000; Iter 51/80; Loss: 0.3410
Epoch 7596/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7597/10000; Iter 1/80; Loss: 0.3307
Epoch 7597/10000; Iter 51/80; Loss: 0.3589
Epoch 7597/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7598/10000; Iter 1/80; Loss: 0.3389
Epoch 7598/10000; Iter 51/80; Loss: 0.2997
Epoch 7598/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.066
Epoch 7599/10000; Iter 1/80; Loss: 0.2886
Epoch 7599/10000; Iter 51/80; Loss: 0.3433
Epoch 7599/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 7600/10000; Iter 1/80; Loss: 0.3608
Epoch 7600/10000; Iter 51/80; Loss: 0.3479
Epoch 7600/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.068
Epoch 7601/10000; Iter 1/80; Loss: 0.3470
Epoch 7601/10000; Iter 51/80; Loss: 0.3667
Epoch 7601/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Model saved
Epoch 7602/10000; Iter 1/80; Loss: 0.3053
Epoch 7602/10000; Iter 51/80; Loss: 0.3567
Epoch 7602/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7603/10000; Iter 1/80; Loss: 0.2840
Epoch 7603/10000; Iter 51/80; Loss: 0.3110
Epoch 7603/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.063
Epoch 7604/10000; Iter 1/80; Loss: 0.3258
Epoch 7604/10000; Iter 51/80; Loss: 0.2732
Epoch 7604/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.062
Epoch 7605/10000; Iter 1/80; Loss: 0.3244
Epoch 7605/10000; Iter 51/80; Loss: 0.3575
Epoch 7605/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.07
Epoch 7606/10000; Iter 1/80; Loss: 0.3454
Epoch 7606/10000; Iter 51/80; Loss: 0.3303
Epoch 7606/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7607/10000; Iter 1/80; Loss: 0.3061
Epoch 7607/10000; Iter 51/80; Loss: 0.3190
Epoch 7607/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 7608/10000; Iter 1/80; Loss: 0.2691
Epoch 7608/10000; Iter 51/80; Loss: 0.3541
Epoch 7608/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.078
Epoch 7609/10000; Iter 1/80; Loss: 0.3498
Epoch 7609/10000; Iter 51/80; Loss: 0.3437
Epoch 7609/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 7610/10000; Iter 1/80; Loss: 0.3709
Epoch 7610/10000; Iter 51/80; Loss: 0.3072
Epoch 7610/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.063
Epoch 7611/10000; Iter 1/80; Loss: 0.2926
Epoch 7611/10000; Iter 51/80; Loss: 0.3256
Epoch 7611/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 7612/10000; Iter 1/80; Loss: 0.3196
Epoch 7612/10000; Iter 51/80; Loss: 0.3063
Epoch 7612/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7613/10000; Iter 1/80; Loss: 0.3010
Epoch 7613/10000; Iter 51/80; Loss: 0.3179
Epoch 7613/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.062
Epoch 7614/10000; Iter 1/80; Loss: 0.2851
Epoch 7614/10000; Iter 51/80; Loss: 0.3730
Epoch 7614/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7615/10000; Iter 1/80; Loss: 0.3068
Epoch 7615/10000; Iter 51/80; Loss: 0.3175
Epoch 7615/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7616/10000; Iter 1/80; Loss: 0.3407
Epoch 7616/10000; Iter 51/80; Loss: 0.3145
Epoch 7616/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7617/10000; Iter 1/80; Loss: 0.2877
Epoch 7617/10000; Iter 51/80; Loss: 0.3315
Epoch 7617/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 7618/10000; Iter 1/80; Loss: 0.3296
Epoch 7618/10000; Iter 51/80; Loss: 0.3556
Epoch 7618/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.073
Epoch 7619/10000; Iter 1/80; Loss: 0.3119
Epoch 7619/10000; Iter 51/80; Loss: 0.3971
Epoch 7619/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7620/10000; Iter 1/80; Loss: 0.3133
Epoch 7620/10000; Iter 51/80; Loss: 0.3431
Epoch 7620/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7621/10000; Iter 1/80; Loss: 0.3478
Epoch 7621/10000; Iter 51/80; Loss: 0.2966
Epoch 7621/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7622/10000; Iter 1/80; Loss: 0.2866
Epoch 7622/10000; Iter 51/80; Loss: 0.3192
Epoch 7622/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7623/10000; Iter 1/80; Loss: 0.3685
Epoch 7623/10000; Iter 51/80; Loss: 0.3485
Epoch 7623/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.062
Epoch 7624/10000; Iter 1/80; Loss: 0.3186
Epoch 7624/10000; Iter 51/80; Loss: 0.3332
Epoch 7624/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.067
Epoch 7625/10000; Iter 1/80; Loss: 0.3224
Epoch 7625/10000; Iter 51/80; Loss: 0.3145
Epoch 7625/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7626/10000; Iter 1/80; Loss: 0.4042
Epoch 7626/10000; Iter 51/80; Loss: 0.3053
Epoch 7626/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.064
Epoch 7627/10000; Iter 1/80; Loss: 0.3180
Epoch 7627/10000; Iter 51/80; Loss: 0.3313
Epoch 7627/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 7628/10000; Iter 1/80; Loss: 0.3473
Epoch 7628/10000; Iter 51/80; Loss: 0.3063
Epoch 7628/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 7629/10000; Iter 1/80; Loss: 0.3976
Epoch 7629/10000; Iter 51/80; Loss: 0.3918
Epoch 7629/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7630/10000; Iter 1/80; Loss: 0.3287
Epoch 7630/10000; Iter 51/80; Loss: 0.3420
Epoch 7630/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 7631/10000; Iter 1/80; Loss: 0.3303
Epoch 7631/10000; Iter 51/80; Loss: 0.3098
Epoch 7631/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7632/10000; Iter 1/80; Loss: 0.3909
Epoch 7632/10000; Iter 51/80; Loss: 0.4306
Epoch 7632/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7633/10000; Iter 1/80; Loss: 0.3860
Epoch 7633/10000; Iter 51/80; Loss: 0.3425
Epoch 7633/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7634/10000; Iter 1/80; Loss: 0.3573
Epoch 7634/10000; Iter 51/80; Loss: 0.3145
Epoch 7634/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7635/10000; Iter 1/80; Loss: 0.2786
Epoch 7635/10000; Iter 51/80; Loss: 0.3508
Epoch 7635/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7636/10000; Iter 1/80; Loss: 0.3884
Epoch 7636/10000; Iter 51/80; Loss: 0.3537
Epoch 7636/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.081
Epoch 7637/10000; Iter 1/80; Loss: 0.2919
Epoch 7637/10000; Iter 51/80; Loss: 0.3024
Epoch 7637/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 7638/10000; Iter 1/80; Loss: 0.3581
Epoch 7638/10000; Iter 51/80; Loss: 0.3369
Epoch 7638/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 7639/10000; Iter 1/80; Loss: 0.3317
Epoch 7639/10000; Iter 51/80; Loss: 0.3555
Epoch 7639/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7640/10000; Iter 1/80; Loss: 0.3351
Epoch 7640/10000; Iter 51/80; Loss: 0.2868
Epoch 7640/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 7641/10000; Iter 1/80; Loss: 0.3704
Epoch 7641/10000; Iter 51/80; Loss: 0.3257
Epoch 7641/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.066
Epoch 7642/10000; Iter 1/80; Loss: 0.3109
Epoch 7642/10000; Iter 51/80; Loss: 0.3364
Epoch 7642/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.064
Epoch 7643/10000; Iter 1/80; Loss: 0.3492
Epoch 7643/10000; Iter 51/80; Loss: 0.2968
Epoch 7643/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.076
Epoch 7644/10000; Iter 1/80; Loss: 0.3728
Epoch 7644/10000; Iter 51/80; Loss: 0.3304
Epoch 7644/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.068
Epoch 7645/10000; Iter 1/80; Loss: 0.3557
Epoch 7645/10000; Iter 51/80; Loss: 0.3047
Epoch 7645/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7646/10000; Iter 1/80; Loss: 0.2919
Epoch 7646/10000; Iter 51/80; Loss: 0.3684
Epoch 7646/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.065
Epoch 7647/10000; Iter 1/80; Loss: 0.3377
Epoch 7647/10000; Iter 51/80; Loss: 0.3962
Epoch 7647/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 7648/10000; Iter 1/80; Loss: 0.3111
Epoch 7648/10000; Iter 51/80; Loss: 0.3334
Epoch 7648/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 7649/10000; Iter 1/80; Loss: 0.3155
Epoch 7649/10000; Iter 51/80; Loss: 0.3413
Epoch 7649/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.067
Epoch 7650/10000; Iter 1/80; Loss: 0.3727
Epoch 7650/10000; Iter 51/80; Loss: 0.3519
Epoch 7650/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 7651/10000; Iter 1/80; Loss: 0.3352
Epoch 7651/10000; Iter 51/80; Loss: 0.3231
Epoch 7651/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 7652/10000; Iter 1/80; Loss: 0.3076
Epoch 7652/10000; Iter 51/80; Loss: 0.3427
Epoch 7652/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7653/10000; Iter 1/80; Loss: 0.3276
Epoch 7653/10000; Iter 51/80; Loss: 0.3098
Epoch 7653/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7654/10000; Iter 1/80; Loss: 0.3115
Epoch 7654/10000; Iter 51/80; Loss: 0.3041
Epoch 7654/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 7655/10000; Iter 1/80; Loss: 0.3682
Epoch 7655/10000; Iter 51/80; Loss: 0.3707
Epoch 7655/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 7656/10000; Iter 1/80; Loss: 0.2866
Epoch 7656/10000; Iter 51/80; Loss: 0.3006
Epoch 7656/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7657/10000; Iter 1/80; Loss: 0.2978
Epoch 7657/10000; Iter 51/80; Loss: 0.3819
Epoch 7657/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.07
Epoch 7658/10000; Iter 1/80; Loss: 0.3528
Epoch 7658/10000; Iter 51/80; Loss: 0.3281
Epoch 7658/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.066
Epoch 7659/10000; Iter 1/80; Loss: 0.3322
Epoch 7659/10000; Iter 51/80; Loss: 0.3221
Epoch 7659/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.072
Epoch 7660/10000; Iter 1/80; Loss: 0.2971
Epoch 7660/10000; Iter 51/80; Loss: 0.3625
Epoch 7660/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7661/10000; Iter 1/80; Loss: 0.2809
Epoch 7661/10000; Iter 51/80; Loss: 0.3284
Epoch 7661/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7662/10000; Iter 1/80; Loss: 0.2825
Epoch 7662/10000; Iter 51/80; Loss: 0.3171
Epoch 7662/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7663/10000; Iter 1/80; Loss: 0.3425
Epoch 7663/10000; Iter 51/80; Loss: 0.3568
Epoch 7663/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.068
Epoch 7664/10000; Iter 1/80; Loss: 0.3147
Epoch 7664/10000; Iter 51/80; Loss: 0.3621
Epoch 7664/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.072
Epoch 7665/10000; Iter 1/80; Loss: 0.2859
Epoch 7665/10000; Iter 51/80; Loss: 0.3575
Epoch 7665/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7666/10000; Iter 1/80; Loss: 0.2587
Epoch 7666/10000; Iter 51/80; Loss: 0.3356
Epoch 7666/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 7667/10000; Iter 1/80; Loss: 0.3548
Epoch 7667/10000; Iter 51/80; Loss: 0.3530
Epoch 7667/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.078
Epoch 7668/10000; Iter 1/80; Loss: 0.3546
Epoch 7668/10000; Iter 51/80; Loss: 0.3592
Epoch 7668/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.073
Epoch 7669/10000; Iter 1/80; Loss: 0.2947
Epoch 7669/10000; Iter 51/80; Loss: 0.3148
Epoch 7669/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 7670/10000; Iter 1/80; Loss: 0.3499
Epoch 7670/10000; Iter 51/80; Loss: 0.2934
Epoch 7670/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7671/10000; Iter 1/80; Loss: 0.3699
Epoch 7671/10000; Iter 51/80; Loss: 0.3154
Epoch 7671/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7672/10000; Iter 1/80; Loss: 0.3463
Epoch 7672/10000; Iter 51/80; Loss: 0.2940
Epoch 7672/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 7673/10000; Iter 1/80; Loss: 0.4244
Epoch 7673/10000; Iter 51/80; Loss: 0.3277
Epoch 7673/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 7674/10000; Iter 1/80; Loss: 0.2952
Epoch 7674/10000; Iter 51/80; Loss: 0.4075
Epoch 7674/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 7675/10000; Iter 1/80; Loss: 0.3169
Epoch 7675/10000; Iter 51/80; Loss: 0.3528
Epoch 7675/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7676/10000; Iter 1/80; Loss: 0.3190
Epoch 7676/10000; Iter 51/80; Loss: 0.3482
Epoch 7676/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7677/10000; Iter 1/80; Loss: 0.3979
Epoch 7677/10000; Iter 51/80; Loss: 0.3643
Epoch 7677/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.075
Epoch 7678/10000; Iter 1/80; Loss: 0.3105
Epoch 7678/10000; Iter 51/80; Loss: 0.3242
Epoch 7678/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7679/10000; Iter 1/80; Loss: 0.3207
Epoch 7679/10000; Iter 51/80; Loss: 0.2885
Epoch 7679/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7680/10000; Iter 1/80; Loss: 0.3375
Epoch 7680/10000; Iter 51/80; Loss: 0.3516
Epoch 7680/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.079
Epoch 7681/10000; Iter 1/80; Loss: 0.3081
Epoch 7681/10000; Iter 51/80; Loss: 0.3047
Epoch 7681/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7682/10000; Iter 1/80; Loss: 0.3980
Epoch 7682/10000; Iter 51/80; Loss: 0.3509
Epoch 7682/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7683/10000; Iter 1/80; Loss: 0.3428
Epoch 7683/10000; Iter 51/80; Loss: 0.2850
Epoch 7683/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7684/10000; Iter 1/80; Loss: 0.4210
Epoch 7684/10000; Iter 51/80; Loss: 0.2693
Epoch 7684/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 7685/10000; Iter 1/80; Loss: 0.3566
Epoch 7685/10000; Iter 51/80; Loss: 0.3028
Epoch 7685/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 7686/10000; Iter 1/80; Loss: 0.3744
Epoch 7686/10000; Iter 51/80; Loss: 0.3256
Epoch 7686/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.07
Epoch 7687/10000; Iter 1/80; Loss: 0.3405
Epoch 7687/10000; Iter 51/80; Loss: 0.3671
Epoch 7687/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 7688/10000; Iter 1/80; Loss: 0.2864
Epoch 7688/10000; Iter 51/80; Loss: 0.3634
Epoch 7688/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7689/10000; Iter 1/80; Loss: 0.3567
Epoch 7689/10000; Iter 51/80; Loss: 0.3096
Epoch 7689/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.075
Epoch 7690/10000; Iter 1/80; Loss: 0.3523
Epoch 7690/10000; Iter 51/80; Loss: 0.3536
Epoch 7690/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7691/10000; Iter 1/80; Loss: 0.3187
Epoch 7691/10000; Iter 51/80; Loss: 0.3261
Epoch 7691/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 7692/10000; Iter 1/80; Loss: 0.3312
Epoch 7692/10000; Iter 51/80; Loss: 0.3027
Epoch 7692/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 7693/10000; Iter 1/80; Loss: 0.3096
Epoch 7693/10000; Iter 51/80; Loss: 0.2948
Epoch 7693/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7694/10000; Iter 1/80; Loss: 0.3401
Epoch 7694/10000; Iter 51/80; Loss: 0.3135
Epoch 7694/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7695/10000; Iter 1/80; Loss: 0.2806
Epoch 7695/10000; Iter 51/80; Loss: 0.3285
Epoch 7695/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7696/10000; Iter 1/80; Loss: 0.4636
Epoch 7696/10000; Iter 51/80; Loss: 0.3214
Epoch 7696/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.07
Epoch 7697/10000; Iter 1/80; Loss: 0.3085
Epoch 7697/10000; Iter 51/80; Loss: 0.3631
Epoch 7697/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7698/10000; Iter 1/80; Loss: 0.3732
Epoch 7698/10000; Iter 51/80; Loss: 0.3371
Epoch 7698/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7699/10000; Iter 1/80; Loss: 0.3058
Epoch 7699/10000; Iter 51/80; Loss: 0.3711
Epoch 7699/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.071
Epoch 7700/10000; Iter 1/80; Loss: 0.3169
Epoch 7700/10000; Iter 51/80; Loss: 0.2935
Epoch 7700/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.073
Epoch 7701/10000; Iter 1/80; Loss: 0.3142
Epoch 7701/10000; Iter 51/80; Loss: 0.3140
Epoch 7701/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.079
Model saved
Epoch 7702/10000; Iter 1/80; Loss: 0.3510
Epoch 7702/10000; Iter 51/80; Loss: 0.3299
Epoch 7702/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.067
Epoch 7703/10000; Iter 1/80; Loss: 0.3396
Epoch 7703/10000; Iter 51/80; Loss: 0.2961
Epoch 7703/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.082
Epoch 7704/10000; Iter 1/80; Loss: 0.3619
Epoch 7704/10000; Iter 51/80; Loss: 0.3444
Epoch 7704/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.063
Epoch 7705/10000; Iter 1/80; Loss: 0.3223
Epoch 7705/10000; Iter 51/80; Loss: 0.3154
Epoch 7705/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.067
Epoch 7706/10000; Iter 1/80; Loss: 0.3289
Epoch 7706/10000; Iter 51/80; Loss: 0.3795
Epoch 7706/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.078
Epoch 7707/10000; Iter 1/80; Loss: 0.3793
Epoch 7707/10000; Iter 51/80; Loss: 0.3699
Epoch 7707/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7708/10000; Iter 1/80; Loss: 0.3121
Epoch 7708/10000; Iter 51/80; Loss: 0.2750
Epoch 7708/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 7709/10000; Iter 1/80; Loss: 0.3513
Epoch 7709/10000; Iter 51/80; Loss: 0.3700
Epoch 7709/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.074
Epoch 7710/10000; Iter 1/80; Loss: 0.2543
Epoch 7710/10000; Iter 51/80; Loss: 0.3292
Epoch 7710/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 7711/10000; Iter 1/80; Loss: 0.3114
Epoch 7711/10000; Iter 51/80; Loss: 0.3327
Epoch 7711/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 7712/10000; Iter 1/80; Loss: 0.3417
Epoch 7712/10000; Iter 51/80; Loss: 0.2962
Epoch 7712/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 7713/10000; Iter 1/80; Loss: 0.3099
Epoch 7713/10000; Iter 51/80; Loss: 0.3247
Epoch 7713/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.064
Epoch 7714/10000; Iter 1/80; Loss: 0.3645
Epoch 7714/10000; Iter 51/80; Loss: 0.3505
Epoch 7714/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 7715/10000; Iter 1/80; Loss: 0.3431
Epoch 7715/10000; Iter 51/80; Loss: 0.3144
Epoch 7715/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7716/10000; Iter 1/80; Loss: 0.3195
Epoch 7716/10000; Iter 51/80; Loss: 0.3068
Epoch 7716/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 7717/10000; Iter 1/80; Loss: 0.3265
Epoch 7717/10000; Iter 51/80; Loss: 0.3217
Epoch 7717/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 7718/10000; Iter 1/80; Loss: 0.3249
Epoch 7718/10000; Iter 51/80; Loss: 0.3090
Epoch 7718/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.075
Epoch 7719/10000; Iter 1/80; Loss: 0.3390
Epoch 7719/10000; Iter 51/80; Loss: 0.3257
Epoch 7719/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.074
Epoch 7720/10000; Iter 1/80; Loss: 0.3109
Epoch 7720/10000; Iter 51/80; Loss: 0.3102
Epoch 7720/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.073
Epoch 7721/10000; Iter 1/80; Loss: 0.3911
Epoch 7721/10000; Iter 51/80; Loss: 0.3514
Epoch 7721/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7722/10000; Iter 1/80; Loss: 0.2839
Epoch 7722/10000; Iter 51/80; Loss: 0.3214
Epoch 7722/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7723/10000; Iter 1/80; Loss: 0.3768
Epoch 7723/10000; Iter 51/80; Loss: 0.3038
Epoch 7723/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 7724/10000; Iter 1/80; Loss: 0.3995
Epoch 7724/10000; Iter 51/80; Loss: 0.3644
Epoch 7724/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.071
Epoch 7725/10000; Iter 1/80; Loss: 0.3415
Epoch 7725/10000; Iter 51/80; Loss: 0.3653
Epoch 7725/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7726/10000; Iter 1/80; Loss: 0.3123
Epoch 7726/10000; Iter 51/80; Loss: 0.4028
Epoch 7726/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.067
Epoch 7727/10000; Iter 1/80; Loss: 0.3139
Epoch 7727/10000; Iter 51/80; Loss: 0.2629
Epoch 7727/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.077
Epoch 7728/10000; Iter 1/80; Loss: 0.3218
Epoch 7728/10000; Iter 51/80; Loss: 0.3557
Epoch 7728/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 7729/10000; Iter 1/80; Loss: 0.3243
Epoch 7729/10000; Iter 51/80; Loss: 0.3212
Epoch 7729/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.068
Epoch 7730/10000; Iter 1/80; Loss: 0.3409
Epoch 7730/10000; Iter 51/80; Loss: 0.3703
Epoch 7730/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.077
Epoch 7731/10000; Iter 1/80; Loss: 0.3655
Epoch 7731/10000; Iter 51/80; Loss: 0.3252
Epoch 7731/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 7732/10000; Iter 1/80; Loss: 0.3380
Epoch 7732/10000; Iter 51/80; Loss: 0.3195
Epoch 7732/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7733/10000; Iter 1/80; Loss: 0.3397
Epoch 7733/10000; Iter 51/80; Loss: 0.2877
Epoch 7733/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.068
Epoch 7734/10000; Iter 1/80; Loss: 0.3122
Epoch 7734/10000; Iter 51/80; Loss: 0.3786
Epoch 7734/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 7735/10000; Iter 1/80; Loss: 0.3102
Epoch 7735/10000; Iter 51/80; Loss: 0.3253
Epoch 7735/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.068
Epoch 7736/10000; Iter 1/80; Loss: 0.3086
Epoch 7736/10000; Iter 51/80; Loss: 0.3151
Epoch 7736/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.077
Epoch 7737/10000; Iter 1/80; Loss: 0.2910
Epoch 7737/10000; Iter 51/80; Loss: 0.3582
Epoch 7737/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7738/10000; Iter 1/80; Loss: 0.3039
Epoch 7738/10000; Iter 51/80; Loss: 0.3265
Epoch 7738/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 7739/10000; Iter 1/80; Loss: 0.3752
Epoch 7739/10000; Iter 51/80; Loss: 0.2965
Epoch 7739/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7740/10000; Iter 1/80; Loss: 0.3273
Epoch 7740/10000; Iter 51/80; Loss: 0.3101
Epoch 7740/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 7741/10000; Iter 1/80; Loss: 0.3853
Epoch 7741/10000; Iter 51/80; Loss: 0.3367
Epoch 7741/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7742/10000; Iter 1/80; Loss: 0.2851
Epoch 7742/10000; Iter 51/80; Loss: 0.3515
Epoch 7742/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 7743/10000; Iter 1/80; Loss: 0.2913
Epoch 7743/10000; Iter 51/80; Loss: 0.3823
Epoch 7743/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7744/10000; Iter 1/80; Loss: 0.2912
Epoch 7744/10000; Iter 51/80; Loss: 0.3409
Epoch 7744/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 7745/10000; Iter 1/80; Loss: 0.3145
Epoch 7745/10000; Iter 51/80; Loss: 0.3326
Epoch 7745/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7746/10000; Iter 1/80; Loss: 0.2855
Epoch 7746/10000; Iter 51/80; Loss: 0.3532
Epoch 7746/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.068
Epoch 7747/10000; Iter 1/80; Loss: 0.2987
Epoch 7747/10000; Iter 51/80; Loss: 0.3127
Epoch 7747/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 7748/10000; Iter 1/80; Loss: 0.2925
Epoch 7748/10000; Iter 51/80; Loss: 0.3874
Epoch 7748/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 7749/10000; Iter 1/80; Loss: 0.3563
Epoch 7749/10000; Iter 51/80; Loss: 0.3958
Epoch 7749/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.074
Epoch 7750/10000; Iter 1/80; Loss: 0.2984
Epoch 7750/10000; Iter 51/80; Loss: 0.3571
Epoch 7750/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 7751/10000; Iter 1/80; Loss: 0.3500
Epoch 7751/10000; Iter 51/80; Loss: 0.3123
Epoch 7751/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7752/10000; Iter 1/80; Loss: 0.3115
Epoch 7752/10000; Iter 51/80; Loss: 0.3327
Epoch 7752/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.069
Epoch 7753/10000; Iter 1/80; Loss: 0.3887
Epoch 7753/10000; Iter 51/80; Loss: 0.3552
Epoch 7753/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7754/10000; Iter 1/80; Loss: 0.2863
Epoch 7754/10000; Iter 51/80; Loss: 0.3639
Epoch 7754/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.081
Epoch 7755/10000; Iter 1/80; Loss: 0.3562
Epoch 7755/10000; Iter 51/80; Loss: 0.3422
Epoch 7755/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 7756/10000; Iter 1/80; Loss: 0.3325
Epoch 7756/10000; Iter 51/80; Loss: 0.3165
Epoch 7756/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 7757/10000; Iter 1/80; Loss: 0.3387
Epoch 7757/10000; Iter 51/80; Loss: 0.3105
Epoch 7757/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.066
Epoch 7758/10000; Iter 1/80; Loss: 0.3809
Epoch 7758/10000; Iter 51/80; Loss: 0.3366
Epoch 7758/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 7759/10000; Iter 1/80; Loss: 0.3039
Epoch 7759/10000; Iter 51/80; Loss: 0.3189
Epoch 7759/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 7760/10000; Iter 1/80; Loss: 0.3064
Epoch 7760/10000; Iter 51/80; Loss: 0.3287
Epoch 7760/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.069
Epoch 7761/10000; Iter 1/80; Loss: 0.3600
Epoch 7761/10000; Iter 51/80; Loss: 0.3162
Epoch 7761/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7762/10000; Iter 1/80; Loss: 0.2903
Epoch 7762/10000; Iter 51/80; Loss: 0.3809
Epoch 7762/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 7763/10000; Iter 1/80; Loss: 0.3162
Epoch 7763/10000; Iter 51/80; Loss: 0.4206
Epoch 7763/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7764/10000; Iter 1/80; Loss: 0.3025
Epoch 7764/10000; Iter 51/80; Loss: 0.2976
Epoch 7764/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.061
Epoch 7765/10000; Iter 1/80; Loss: 0.3181
Epoch 7765/10000; Iter 51/80; Loss: 0.3063
Epoch 7765/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.072
Epoch 7766/10000; Iter 1/80; Loss: 0.4050
Epoch 7766/10000; Iter 51/80; Loss: 0.2786
Epoch 7766/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 7767/10000; Iter 1/80; Loss: 0.3194
Epoch 7767/10000; Iter 51/80; Loss: 0.3488
Epoch 7767/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 7768/10000; Iter 1/80; Loss: 0.3483
Epoch 7768/10000; Iter 51/80; Loss: 0.3375
Epoch 7768/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 7769/10000; Iter 1/80; Loss: 0.2842
Epoch 7769/10000; Iter 51/80; Loss: 0.3804
Epoch 7769/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.065
Epoch 7770/10000; Iter 1/80; Loss: 0.3286
Epoch 7770/10000; Iter 51/80; Loss: 0.2941
Epoch 7770/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 7771/10000; Iter 1/80; Loss: 0.3843
Epoch 7771/10000; Iter 51/80; Loss: 0.3498
Epoch 7771/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7772/10000; Iter 1/80; Loss: 0.2951
Epoch 7772/10000; Iter 51/80; Loss: 0.2999
Epoch 7772/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 7773/10000; Iter 1/80; Loss: 0.3305
Epoch 7773/10000; Iter 51/80; Loss: 0.3484
Epoch 7773/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 7774/10000; Iter 1/80; Loss: 0.3028
Epoch 7774/10000; Iter 51/80; Loss: 0.3645
Epoch 7774/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.069
Epoch 7775/10000; Iter 1/80; Loss: 0.3097
Epoch 7775/10000; Iter 51/80; Loss: 0.3387
Epoch 7775/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 7776/10000; Iter 1/80; Loss: 0.3587
Epoch 7776/10000; Iter 51/80; Loss: 0.3182
Epoch 7776/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7777/10000; Iter 1/80; Loss: 0.3660
Epoch 7777/10000; Iter 51/80; Loss: 0.3071
Epoch 7777/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.068
Epoch 7778/10000; Iter 1/80; Loss: 0.3228
Epoch 7778/10000; Iter 51/80; Loss: 0.3898
Epoch 7778/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.076
Epoch 7779/10000; Iter 1/80; Loss: 0.3221
Epoch 7779/10000; Iter 51/80; Loss: 0.2993
Epoch 7779/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.076
Epoch 7780/10000; Iter 1/80; Loss: 0.3353
Epoch 7780/10000; Iter 51/80; Loss: 0.3546
Epoch 7780/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7781/10000; Iter 1/80; Loss: 0.3301
Epoch 7781/10000; Iter 51/80; Loss: 0.3383
Epoch 7781/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 7782/10000; Iter 1/80; Loss: 0.3823
Epoch 7782/10000; Iter 51/80; Loss: 0.2870
Epoch 7782/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.065
Epoch 7783/10000; Iter 1/80; Loss: 0.3293
Epoch 7783/10000; Iter 51/80; Loss: 0.3537
Epoch 7783/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7784/10000; Iter 1/80; Loss: 0.3582
Epoch 7784/10000; Iter 51/80; Loss: 0.3151
Epoch 7784/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.066
Epoch 7785/10000; Iter 1/80; Loss: 0.3573
Epoch 7785/10000; Iter 51/80; Loss: 0.3467
Epoch 7785/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.072
Epoch 7786/10000; Iter 1/80; Loss: 0.3316
Epoch 7786/10000; Iter 51/80; Loss: 0.3407
Epoch 7786/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.072
Epoch 7787/10000; Iter 1/80; Loss: 0.3323
Epoch 7787/10000; Iter 51/80; Loss: 0.3568
Epoch 7787/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 7788/10000; Iter 1/80; Loss: 0.2998
Epoch 7788/10000; Iter 51/80; Loss: 0.3252
Epoch 7788/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.065
Epoch 7789/10000; Iter 1/80; Loss: 0.3661
Epoch 7789/10000; Iter 51/80; Loss: 0.3412
Epoch 7789/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7790/10000; Iter 1/80; Loss: 0.3199
Epoch 7790/10000; Iter 51/80; Loss: 0.3398
Epoch 7790/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.065
Epoch 7791/10000; Iter 1/80; Loss: 0.3335
Epoch 7791/10000; Iter 51/80; Loss: 0.2822
Epoch 7791/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 7792/10000; Iter 1/80; Loss: 0.2988
Epoch 7792/10000; Iter 51/80; Loss: 0.3098
Epoch 7792/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 7793/10000; Iter 1/80; Loss: 0.3179
Epoch 7793/10000; Iter 51/80; Loss: 0.3842
Epoch 7793/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7794/10000; Iter 1/80; Loss: 0.3737
Epoch 7794/10000; Iter 51/80; Loss: 0.3513
Epoch 7794/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 7795/10000; Iter 1/80; Loss: 0.2944
Epoch 7795/10000; Iter 51/80; Loss: 0.3140
Epoch 7795/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 7796/10000; Iter 1/80; Loss: 0.3358
Epoch 7796/10000; Iter 51/80; Loss: 0.3411
Epoch 7796/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 7797/10000; Iter 1/80; Loss: 0.3694
Epoch 7797/10000; Iter 51/80; Loss: 0.3545
Epoch 7797/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 7798/10000; Iter 1/80; Loss: 0.3434
Epoch 7798/10000; Iter 51/80; Loss: 0.3443
Epoch 7798/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.065
Epoch 7799/10000; Iter 1/80; Loss: 0.3459
Epoch 7799/10000; Iter 51/80; Loss: 0.3320
Epoch 7799/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 7800/10000; Iter 1/80; Loss: 0.3094
Epoch 7800/10000; Iter 51/80; Loss: 0.4003
Epoch 7800/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 7801/10000; Iter 1/80; Loss: 0.3180
Epoch 7801/10000; Iter 51/80; Loss: 0.4292
Epoch 7801/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.067
Model saved
Epoch 7802/10000; Iter 1/80; Loss: 0.3637
Epoch 7802/10000; Iter 51/80; Loss: 0.3501
Epoch 7802/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.067
Epoch 7803/10000; Iter 1/80; Loss: 0.3064
Epoch 7803/10000; Iter 51/80; Loss: 0.3480
Epoch 7803/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.078
Epoch 7804/10000; Iter 1/80; Loss: 0.3596
Epoch 7804/10000; Iter 51/80; Loss: 0.3307
Epoch 7804/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.063
Epoch 7805/10000; Iter 1/80; Loss: 0.3517
Epoch 7805/10000; Iter 51/80; Loss: 0.3526
Epoch 7805/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7806/10000; Iter 1/80; Loss: 0.3133
Epoch 7806/10000; Iter 51/80; Loss: 0.3092
Epoch 7806/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 7807/10000; Iter 1/80; Loss: 0.3266
Epoch 7807/10000; Iter 51/80; Loss: 0.3867
Epoch 7807/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 7808/10000; Iter 1/80; Loss: 0.3423
Epoch 7808/10000; Iter 51/80; Loss: 0.3711
Epoch 7808/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 7809/10000; Iter 1/80; Loss: 0.3044
Epoch 7809/10000; Iter 51/80; Loss: 0.3554
Epoch 7809/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.081
Epoch 7810/10000; Iter 1/80; Loss: 0.3175
Epoch 7810/10000; Iter 51/80; Loss: 0.3491
Epoch 7810/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 7811/10000; Iter 1/80; Loss: 0.3548
Epoch 7811/10000; Iter 51/80; Loss: 0.3421
Epoch 7811/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.071
Epoch 7812/10000; Iter 1/80; Loss: 0.2901
Epoch 7812/10000; Iter 51/80; Loss: 0.3171
Epoch 7812/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7813/10000; Iter 1/80; Loss: 0.3213
Epoch 7813/10000; Iter 51/80; Loss: 0.2811
Epoch 7813/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.076
Epoch 7814/10000; Iter 1/80; Loss: 0.3185
Epoch 7814/10000; Iter 51/80; Loss: 0.3322
Epoch 7814/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.078
Epoch 7815/10000; Iter 1/80; Loss: 0.3139
Epoch 7815/10000; Iter 51/80; Loss: 0.3499
Epoch 7815/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7816/10000; Iter 1/80; Loss: 0.3146
Epoch 7816/10000; Iter 51/80; Loss: 0.3045
Epoch 7816/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 7817/10000; Iter 1/80; Loss: 0.3597
Epoch 7817/10000; Iter 51/80; Loss: 0.3891
Epoch 7817/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.072
Epoch 7818/10000; Iter 1/80; Loss: 0.3613
Epoch 7818/10000; Iter 51/80; Loss: 0.3473
Epoch 7818/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.07
Epoch 7819/10000; Iter 1/80; Loss: 0.3000
Epoch 7819/10000; Iter 51/80; Loss: 0.3210
Epoch 7819/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7820/10000; Iter 1/80; Loss: 0.3245
Epoch 7820/10000; Iter 51/80; Loss: 0.3378
Epoch 7820/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.063
Epoch 7821/10000; Iter 1/80; Loss: 0.3425
Epoch 7821/10000; Iter 51/80; Loss: 0.3876
Epoch 7821/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 7822/10000; Iter 1/80; Loss: 0.3314
Epoch 7822/10000; Iter 51/80; Loss: 0.3396
Epoch 7822/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 7823/10000; Iter 1/80; Loss: 0.2811
Epoch 7823/10000; Iter 51/80; Loss: 0.2815
Epoch 7823/10000; Iter 80/80; Training Loss: 0.3420, Test Loss: 0.07
Epoch 7824/10000; Iter 1/80; Loss: 0.3389
Epoch 7824/10000; Iter 51/80; Loss: 0.3166
Epoch 7824/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.07
Epoch 7825/10000; Iter 1/80; Loss: 0.3623
Epoch 7825/10000; Iter 51/80; Loss: 0.3194
Epoch 7825/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.064
Epoch 7826/10000; Iter 1/80; Loss: 0.3421
Epoch 7826/10000; Iter 51/80; Loss: 0.3238
Epoch 7826/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 7827/10000; Iter 1/80; Loss: 0.3232
Epoch 7827/10000; Iter 51/80; Loss: 0.3835
Epoch 7827/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 7828/10000; Iter 1/80; Loss: 0.3000
Epoch 7828/10000; Iter 51/80; Loss: 0.2705
Epoch 7828/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.071
Epoch 7829/10000; Iter 1/80; Loss: 0.4144
Epoch 7829/10000; Iter 51/80; Loss: 0.3366
Epoch 7829/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 7830/10000; Iter 1/80; Loss: 0.3404
Epoch 7830/10000; Iter 51/80; Loss: 0.3187
Epoch 7830/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7831/10000; Iter 1/80; Loss: 0.2814
Epoch 7831/10000; Iter 51/80; Loss: 0.3433
Epoch 7831/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 7832/10000; Iter 1/80; Loss: 0.3503
Epoch 7832/10000; Iter 51/80; Loss: 0.2840
Epoch 7832/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 7833/10000; Iter 1/80; Loss: 0.3459
Epoch 7833/10000; Iter 51/80; Loss: 0.4012
Epoch 7833/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.075
Epoch 7834/10000; Iter 1/80; Loss: 0.3146
Epoch 7834/10000; Iter 51/80; Loss: 0.3151
Epoch 7834/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 7835/10000; Iter 1/80; Loss: 0.3086
Epoch 7835/10000; Iter 51/80; Loss: 0.3405
Epoch 7835/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.08
Epoch 7836/10000; Iter 1/80; Loss: 0.3500
Epoch 7836/10000; Iter 51/80; Loss: 0.3258
Epoch 7836/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.08
Epoch 7837/10000; Iter 1/80; Loss: 0.3554
Epoch 7837/10000; Iter 51/80; Loss: 0.3154
Epoch 7837/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 7838/10000; Iter 1/80; Loss: 0.3321
Epoch 7838/10000; Iter 51/80; Loss: 0.3426
Epoch 7838/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7839/10000; Iter 1/80; Loss: 0.3736
Epoch 7839/10000; Iter 51/80; Loss: 0.3748
Epoch 7839/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.064
Epoch 7840/10000; Iter 1/80; Loss: 0.3177
Epoch 7840/10000; Iter 51/80; Loss: 0.3119
Epoch 7840/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 7841/10000; Iter 1/80; Loss: 0.3359
Epoch 7841/10000; Iter 51/80; Loss: 0.3487
Epoch 7841/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.074
Epoch 7842/10000; Iter 1/80; Loss: 0.3295
Epoch 7842/10000; Iter 51/80; Loss: 0.3759
Epoch 7842/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7843/10000; Iter 1/80; Loss: 0.3107
Epoch 7843/10000; Iter 51/80; Loss: 0.3282
Epoch 7843/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7844/10000; Iter 1/80; Loss: 0.3542
Epoch 7844/10000; Iter 51/80; Loss: 0.2953
Epoch 7844/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 7845/10000; Iter 1/80; Loss: 0.3736
Epoch 7845/10000; Iter 51/80; Loss: 0.3570
Epoch 7845/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7846/10000; Iter 1/80; Loss: 0.3378
Epoch 7846/10000; Iter 51/80; Loss: 0.3053
Epoch 7846/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.08
Epoch 7847/10000; Iter 1/80; Loss: 0.3584
Epoch 7847/10000; Iter 51/80; Loss: 0.3534
Epoch 7847/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 7848/10000; Iter 1/80; Loss: 0.3125
Epoch 7848/10000; Iter 51/80; Loss: 0.3419
Epoch 7848/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.078
Epoch 7849/10000; Iter 1/80; Loss: 0.2961
Epoch 7849/10000; Iter 51/80; Loss: 0.3566
Epoch 7849/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7850/10000; Iter 1/80; Loss: 0.2742
Epoch 7850/10000; Iter 51/80; Loss: 0.3505
Epoch 7850/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 7851/10000; Iter 1/80; Loss: 0.3733
Epoch 7851/10000; Iter 51/80; Loss: 0.3442
Epoch 7851/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7852/10000; Iter 1/80; Loss: 0.3701
Epoch 7852/10000; Iter 51/80; Loss: 0.3113
Epoch 7852/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.067
Epoch 7853/10000; Iter 1/80; Loss: 0.2715
Epoch 7853/10000; Iter 51/80; Loss: 0.3091
Epoch 7853/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7854/10000; Iter 1/80; Loss: 0.3782
Epoch 7854/10000; Iter 51/80; Loss: 0.3495
Epoch 7854/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.074
Epoch 7855/10000; Iter 1/80; Loss: 0.3906
Epoch 7855/10000; Iter 51/80; Loss: 0.3179
Epoch 7855/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.079
Epoch 7856/10000; Iter 1/80; Loss: 0.3435
Epoch 7856/10000; Iter 51/80; Loss: 0.3363
Epoch 7856/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 7857/10000; Iter 1/80; Loss: 0.3290
Epoch 7857/10000; Iter 51/80; Loss: 0.3590
Epoch 7857/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.067
Epoch 7858/10000; Iter 1/80; Loss: 0.2991
Epoch 7858/10000; Iter 51/80; Loss: 0.3496
Epoch 7858/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.077
Epoch 7859/10000; Iter 1/80; Loss: 0.3256
Epoch 7859/10000; Iter 51/80; Loss: 0.3224
Epoch 7859/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.076
Epoch 7860/10000; Iter 1/80; Loss: 0.3094
Epoch 7860/10000; Iter 51/80; Loss: 0.3020
Epoch 7860/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.071
Epoch 7861/10000; Iter 1/80; Loss: 0.3374
Epoch 7861/10000; Iter 51/80; Loss: 0.3266
Epoch 7861/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.072
Epoch 7862/10000; Iter 1/80; Loss: 0.3749
Epoch 7862/10000; Iter 51/80; Loss: 0.3330
Epoch 7862/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.075
Epoch 7863/10000; Iter 1/80; Loss: 0.3082
Epoch 7863/10000; Iter 51/80; Loss: 0.3157
Epoch 7863/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.067
Epoch 7864/10000; Iter 1/80; Loss: 0.3621
Epoch 7864/10000; Iter 51/80; Loss: 0.3598
Epoch 7864/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.067
Epoch 7865/10000; Iter 1/80; Loss: 0.3700
Epoch 7865/10000; Iter 51/80; Loss: 0.2867
Epoch 7865/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.067
Epoch 7866/10000; Iter 1/80; Loss: 0.3515
Epoch 7866/10000; Iter 51/80; Loss: 0.2987
Epoch 7866/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.081
Epoch 7867/10000; Iter 1/80; Loss: 0.3682
Epoch 7867/10000; Iter 51/80; Loss: 0.3444
Epoch 7867/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 7868/10000; Iter 1/80; Loss: 0.3619
Epoch 7868/10000; Iter 51/80; Loss: 0.3627
Epoch 7868/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.07
Epoch 7869/10000; Iter 1/80; Loss: 0.3920
Epoch 7869/10000; Iter 51/80; Loss: 0.3180
Epoch 7869/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7870/10000; Iter 1/80; Loss: 0.4188
Epoch 7870/10000; Iter 51/80; Loss: 0.3027
Epoch 7870/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.067
Epoch 7871/10000; Iter 1/80; Loss: 0.3195
Epoch 7871/10000; Iter 51/80; Loss: 0.3244
Epoch 7871/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7872/10000; Iter 1/80; Loss: 0.3047
Epoch 7872/10000; Iter 51/80; Loss: 0.3539
Epoch 7872/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 7873/10000; Iter 1/80; Loss: 0.3407
Epoch 7873/10000; Iter 51/80; Loss: 0.3603
Epoch 7873/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 7874/10000; Iter 1/80; Loss: 0.2879
Epoch 7874/10000; Iter 51/80; Loss: 0.3030
Epoch 7874/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 7875/10000; Iter 1/80; Loss: 0.3469
Epoch 7875/10000; Iter 51/80; Loss: 0.3306
Epoch 7875/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.076
Epoch 7876/10000; Iter 1/80; Loss: 0.2933
Epoch 7876/10000; Iter 51/80; Loss: 0.3779
Epoch 7876/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7877/10000; Iter 1/80; Loss: 0.2813
Epoch 7877/10000; Iter 51/80; Loss: 0.3217
Epoch 7877/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 7878/10000; Iter 1/80; Loss: 0.2987
Epoch 7878/10000; Iter 51/80; Loss: 0.3453
Epoch 7878/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.077
Epoch 7879/10000; Iter 1/80; Loss: 0.3926
Epoch 7879/10000; Iter 51/80; Loss: 0.3428
Epoch 7879/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.064
Epoch 7880/10000; Iter 1/80; Loss: 0.3879
Epoch 7880/10000; Iter 51/80; Loss: 0.3257
Epoch 7880/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7881/10000; Iter 1/80; Loss: 0.3233
Epoch 7881/10000; Iter 51/80; Loss: 0.3665
Epoch 7881/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 7882/10000; Iter 1/80; Loss: 0.3496
Epoch 7882/10000; Iter 51/80; Loss: 0.3293
Epoch 7882/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 7883/10000; Iter 1/80; Loss: 0.3261
Epoch 7883/10000; Iter 51/80; Loss: 0.2973
Epoch 7883/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.066
Epoch 7884/10000; Iter 1/80; Loss: 0.3148
Epoch 7884/10000; Iter 51/80; Loss: 0.3555
Epoch 7884/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.071
Epoch 7885/10000; Iter 1/80; Loss: 0.3405
Epoch 7885/10000; Iter 51/80; Loss: 0.3138
Epoch 7885/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 7886/10000; Iter 1/80; Loss: 0.3982
Epoch 7886/10000; Iter 51/80; Loss: 0.3182
Epoch 7886/10000; Iter 80/80; Training Loss: 0.3430, Test Loss: 0.072
Epoch 7887/10000; Iter 1/80; Loss: 0.2836
Epoch 7887/10000; Iter 51/80; Loss: 0.2859
Epoch 7887/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.069
Epoch 7888/10000; Iter 1/80; Loss: 0.2752
Epoch 7888/10000; Iter 51/80; Loss: 0.3027
Epoch 7888/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.082
Epoch 7889/10000; Iter 1/80; Loss: 0.2846
Epoch 7889/10000; Iter 51/80; Loss: 0.3315
Epoch 7889/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7890/10000; Iter 1/80; Loss: 0.3126
Epoch 7890/10000; Iter 51/80; Loss: 0.3062
Epoch 7890/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 7891/10000; Iter 1/80; Loss: 0.3321
Epoch 7891/10000; Iter 51/80; Loss: 0.3485
Epoch 7891/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 7892/10000; Iter 1/80; Loss: 0.3259
Epoch 7892/10000; Iter 51/80; Loss: 0.3063
Epoch 7892/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 7893/10000; Iter 1/80; Loss: 0.4104
Epoch 7893/10000; Iter 51/80; Loss: 0.3234
Epoch 7893/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7894/10000; Iter 1/80; Loss: 0.3314
Epoch 7894/10000; Iter 51/80; Loss: 0.2911
Epoch 7894/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 7895/10000; Iter 1/80; Loss: 0.3265
Epoch 7895/10000; Iter 51/80; Loss: 0.3037
Epoch 7895/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.071
Epoch 7896/10000; Iter 1/80; Loss: 0.3524
Epoch 7896/10000; Iter 51/80; Loss: 0.3015
Epoch 7896/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 7897/10000; Iter 1/80; Loss: 0.2944
Epoch 7897/10000; Iter 51/80; Loss: 0.3509
Epoch 7897/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 7898/10000; Iter 1/80; Loss: 0.3535
Epoch 7898/10000; Iter 51/80; Loss: 0.3356
Epoch 7898/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.063
Epoch 7899/10000; Iter 1/80; Loss: 0.2696
Epoch 7899/10000; Iter 51/80; Loss: 0.3090
Epoch 7899/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.068
Epoch 7900/10000; Iter 1/80; Loss: 0.3407
Epoch 7900/10000; Iter 51/80; Loss: 0.3193
Epoch 7900/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 7901/10000; Iter 1/80; Loss: 0.2871
Epoch 7901/10000; Iter 51/80; Loss: 0.2994
Epoch 7901/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Model saved
Epoch 7902/10000; Iter 1/80; Loss: 0.3416
Epoch 7902/10000; Iter 51/80; Loss: 0.3269
Epoch 7902/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.077
Epoch 7903/10000; Iter 1/80; Loss: 0.3679
Epoch 7903/10000; Iter 51/80; Loss: 0.3310
Epoch 7903/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 7904/10000; Iter 1/80; Loss: 0.4015
Epoch 7904/10000; Iter 51/80; Loss: 0.3287
Epoch 7904/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 7905/10000; Iter 1/80; Loss: 0.3709
Epoch 7905/10000; Iter 51/80; Loss: 0.4201
Epoch 7905/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 7906/10000; Iter 1/80; Loss: 0.3312
Epoch 7906/10000; Iter 51/80; Loss: 0.3189
Epoch 7906/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 7907/10000; Iter 1/80; Loss: 0.3832
Epoch 7907/10000; Iter 51/80; Loss: 0.3532
Epoch 7907/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 7908/10000; Iter 1/80; Loss: 0.3778
Epoch 7908/10000; Iter 51/80; Loss: 0.3518
Epoch 7908/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.069
Epoch 7909/10000; Iter 1/80; Loss: 0.3397
Epoch 7909/10000; Iter 51/80; Loss: 0.3838
Epoch 7909/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 7910/10000; Iter 1/80; Loss: 0.2813
Epoch 7910/10000; Iter 51/80; Loss: 0.3434
Epoch 7910/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.08
Epoch 7911/10000; Iter 1/80; Loss: 0.3882
Epoch 7911/10000; Iter 51/80; Loss: 0.3640
Epoch 7911/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 7912/10000; Iter 1/80; Loss: 0.4381
Epoch 7912/10000; Iter 51/80; Loss: 0.3155
Epoch 7912/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.073
Epoch 7913/10000; Iter 1/80; Loss: 0.3252
Epoch 7913/10000; Iter 51/80; Loss: 0.3141
Epoch 7913/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.072
Epoch 7914/10000; Iter 1/80; Loss: 0.2795
Epoch 7914/10000; Iter 51/80; Loss: 0.2947
Epoch 7914/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 7915/10000; Iter 1/80; Loss: 0.4119
Epoch 7915/10000; Iter 51/80; Loss: 0.2743
Epoch 7915/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 7916/10000; Iter 1/80; Loss: 0.3431
Epoch 7916/10000; Iter 51/80; Loss: 0.3187
Epoch 7916/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 7917/10000; Iter 1/80; Loss: 0.3662
Epoch 7917/10000; Iter 51/80; Loss: 0.3484
Epoch 7917/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 7918/10000; Iter 1/80; Loss: 0.3155
Epoch 7918/10000; Iter 51/80; Loss: 0.3168
Epoch 7918/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.065
Epoch 7919/10000; Iter 1/80; Loss: 0.3259
Epoch 7919/10000; Iter 51/80; Loss: 0.3729
Epoch 7919/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 7920/10000; Iter 1/80; Loss: 0.3332
Epoch 7920/10000; Iter 51/80; Loss: 0.3455
Epoch 7920/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 7921/10000; Iter 1/80; Loss: 0.3013
Epoch 7921/10000; Iter 51/80; Loss: 0.3269
Epoch 7921/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7922/10000; Iter 1/80; Loss: 0.3117
Epoch 7922/10000; Iter 51/80; Loss: 0.3003
Epoch 7922/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 7923/10000; Iter 1/80; Loss: 0.2898
Epoch 7923/10000; Iter 51/80; Loss: 0.3248
Epoch 7923/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 7924/10000; Iter 1/80; Loss: 0.4117
Epoch 7924/10000; Iter 51/80; Loss: 0.3081
Epoch 7924/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 7925/10000; Iter 1/80; Loss: 0.3977
Epoch 7925/10000; Iter 51/80; Loss: 0.3822
Epoch 7925/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7926/10000; Iter 1/80; Loss: 0.3929
Epoch 7926/10000; Iter 51/80; Loss: 0.3592
Epoch 7926/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.072
Epoch 7927/10000; Iter 1/80; Loss: 0.3966
Epoch 7927/10000; Iter 51/80; Loss: 0.3079
Epoch 7927/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.077
Epoch 7928/10000; Iter 1/80; Loss: 0.2998
Epoch 7928/10000; Iter 51/80; Loss: 0.3315
Epoch 7928/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 7929/10000; Iter 1/80; Loss: 0.3323
Epoch 7929/10000; Iter 51/80; Loss: 0.3297
Epoch 7929/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.07
Epoch 7930/10000; Iter 1/80; Loss: 0.3498
Epoch 7930/10000; Iter 51/80; Loss: 0.3363
Epoch 7930/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 7931/10000; Iter 1/80; Loss: 0.3360
Epoch 7931/10000; Iter 51/80; Loss: 0.3863
Epoch 7931/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.068
Epoch 7932/10000; Iter 1/80; Loss: 0.3274
Epoch 7932/10000; Iter 51/80; Loss: 0.3499
Epoch 7932/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 7933/10000; Iter 1/80; Loss: 0.3205
Epoch 7933/10000; Iter 51/80; Loss: 0.3505
Epoch 7933/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7934/10000; Iter 1/80; Loss: 0.3282
Epoch 7934/10000; Iter 51/80; Loss: 0.3104
Epoch 7934/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 7935/10000; Iter 1/80; Loss: 0.2865
Epoch 7935/10000; Iter 51/80; Loss: 0.3433
Epoch 7935/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 7936/10000; Iter 1/80; Loss: 0.3409
Epoch 7936/10000; Iter 51/80; Loss: 0.3518
Epoch 7936/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.066
Epoch 7937/10000; Iter 1/80; Loss: 0.3011
Epoch 7937/10000; Iter 51/80; Loss: 0.3948
Epoch 7937/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 7938/10000; Iter 1/80; Loss: 0.3100
Epoch 7938/10000; Iter 51/80; Loss: 0.2899
Epoch 7938/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 7939/10000; Iter 1/80; Loss: 0.3552
Epoch 7939/10000; Iter 51/80; Loss: 0.3230
Epoch 7939/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 7940/10000; Iter 1/80; Loss: 0.3155
Epoch 7940/10000; Iter 51/80; Loss: 0.3215
Epoch 7940/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 7941/10000; Iter 1/80; Loss: 0.3139
Epoch 7941/10000; Iter 51/80; Loss: 0.3513
Epoch 7941/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.066
Epoch 7942/10000; Iter 1/80; Loss: 0.3296
Epoch 7942/10000; Iter 51/80; Loss: 0.3546
Epoch 7942/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 7943/10000; Iter 1/80; Loss: 0.3591
Epoch 7943/10000; Iter 51/80; Loss: 0.2873
Epoch 7943/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.065
Epoch 7944/10000; Iter 1/80; Loss: 0.3354
Epoch 7944/10000; Iter 51/80; Loss: 0.3776
Epoch 7944/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 7945/10000; Iter 1/80; Loss: 0.2936
Epoch 7945/10000; Iter 51/80; Loss: 0.3827
Epoch 7945/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 7946/10000; Iter 1/80; Loss: 0.3176
Epoch 7946/10000; Iter 51/80; Loss: 0.3066
Epoch 7946/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7947/10000; Iter 1/80; Loss: 0.3278
Epoch 7947/10000; Iter 51/80; Loss: 0.3613
Epoch 7947/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.071
Epoch 7948/10000; Iter 1/80; Loss: 0.2876
Epoch 7948/10000; Iter 51/80; Loss: 0.3573
Epoch 7948/10000; Iter 80/80; Training Loss: 0.3410, Test Loss: 0.074
Epoch 7949/10000; Iter 1/80; Loss: 0.3167
Epoch 7949/10000; Iter 51/80; Loss: 0.3140
Epoch 7949/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.076
Epoch 7950/10000; Iter 1/80; Loss: 0.3232
Epoch 7950/10000; Iter 51/80; Loss: 0.4227
Epoch 7950/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7951/10000; Iter 1/80; Loss: 0.3852
Epoch 7951/10000; Iter 51/80; Loss: 0.3215
Epoch 7951/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 7952/10000; Iter 1/80; Loss: 0.2884
Epoch 7952/10000; Iter 51/80; Loss: 0.2961
Epoch 7952/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 7953/10000; Iter 1/80; Loss: 0.3318
Epoch 7953/10000; Iter 51/80; Loss: 0.3430
Epoch 7953/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.077
Epoch 7954/10000; Iter 1/80; Loss: 0.2966
Epoch 7954/10000; Iter 51/80; Loss: 0.3018
Epoch 7954/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 7955/10000; Iter 1/80; Loss: 0.2915
Epoch 7955/10000; Iter 51/80; Loss: 0.3520
Epoch 7955/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 7956/10000; Iter 1/80; Loss: 0.3106
Epoch 7956/10000; Iter 51/80; Loss: 0.3249
Epoch 7956/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.072
Epoch 7957/10000; Iter 1/80; Loss: 0.3044
Epoch 7957/10000; Iter 51/80; Loss: 0.3509
Epoch 7957/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 7958/10000; Iter 1/80; Loss: 0.2959
Epoch 7958/10000; Iter 51/80; Loss: 0.3227
Epoch 7958/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 7959/10000; Iter 1/80; Loss: 0.3518
Epoch 7959/10000; Iter 51/80; Loss: 0.3663
Epoch 7959/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7960/10000; Iter 1/80; Loss: 0.3904
Epoch 7960/10000; Iter 51/80; Loss: 0.3409
Epoch 7960/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.078
Epoch 7961/10000; Iter 1/80; Loss: 0.3082
Epoch 7961/10000; Iter 51/80; Loss: 0.3154
Epoch 7961/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 7962/10000; Iter 1/80; Loss: 0.3203
Epoch 7962/10000; Iter 51/80; Loss: 0.3128
Epoch 7962/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 7963/10000; Iter 1/80; Loss: 0.3237
Epoch 7963/10000; Iter 51/80; Loss: 0.3039
Epoch 7963/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 7964/10000; Iter 1/80; Loss: 0.3303
Epoch 7964/10000; Iter 51/80; Loss: 0.3199
Epoch 7964/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 7965/10000; Iter 1/80; Loss: 0.3174
Epoch 7965/10000; Iter 51/80; Loss: 0.3529
Epoch 7965/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.075
Epoch 7966/10000; Iter 1/80; Loss: 0.3568
Epoch 7966/10000; Iter 51/80; Loss: 0.3732
Epoch 7966/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 7967/10000; Iter 1/80; Loss: 0.3359
Epoch 7967/10000; Iter 51/80; Loss: 0.3329
Epoch 7967/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 7968/10000; Iter 1/80; Loss: 0.3220
Epoch 7968/10000; Iter 51/80; Loss: 0.3777
Epoch 7968/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 7969/10000; Iter 1/80; Loss: 0.3189
Epoch 7969/10000; Iter 51/80; Loss: 0.3238
Epoch 7969/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 7970/10000; Iter 1/80; Loss: 0.3404
Epoch 7970/10000; Iter 51/80; Loss: 0.3143
Epoch 7970/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 7971/10000; Iter 1/80; Loss: 0.3613
Epoch 7971/10000; Iter 51/80; Loss: 0.2974
Epoch 7971/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 7972/10000; Iter 1/80; Loss: 0.3953
Epoch 7972/10000; Iter 51/80; Loss: 0.3106
Epoch 7972/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 7973/10000; Iter 1/80; Loss: 0.2924
Epoch 7973/10000; Iter 51/80; Loss: 0.3234
Epoch 7973/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 7974/10000; Iter 1/80; Loss: 0.3188
Epoch 7974/10000; Iter 51/80; Loss: 0.2912
Epoch 7974/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 7975/10000; Iter 1/80; Loss: 0.3482
Epoch 7975/10000; Iter 51/80; Loss: 0.2679
Epoch 7975/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.074
Epoch 7976/10000; Iter 1/80; Loss: 0.3450
Epoch 7976/10000; Iter 51/80; Loss: 0.3155
Epoch 7976/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.076
Epoch 7977/10000; Iter 1/80; Loss: 0.3230
Epoch 7977/10000; Iter 51/80; Loss: 0.3782
Epoch 7977/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.082
Epoch 7978/10000; Iter 1/80; Loss: 0.3235
Epoch 7978/10000; Iter 51/80; Loss: 0.2962
Epoch 7978/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 7979/10000; Iter 1/80; Loss: 0.3210
Epoch 7979/10000; Iter 51/80; Loss: 0.3751
Epoch 7979/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 7980/10000; Iter 1/80; Loss: 0.3319
Epoch 7980/10000; Iter 51/80; Loss: 0.3573
Epoch 7980/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.067
Epoch 7981/10000; Iter 1/80; Loss: 0.3218
Epoch 7981/10000; Iter 51/80; Loss: 0.3796
Epoch 7981/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.072
Epoch 7982/10000; Iter 1/80; Loss: 0.3806
Epoch 7982/10000; Iter 51/80; Loss: 0.3777
Epoch 7982/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 7983/10000; Iter 1/80; Loss: 0.3770
Epoch 7983/10000; Iter 51/80; Loss: 0.3238
Epoch 7983/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 7984/10000; Iter 1/80; Loss: 0.3277
Epoch 7984/10000; Iter 51/80; Loss: 0.3307
Epoch 7984/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 7985/10000; Iter 1/80; Loss: 0.3269
Epoch 7985/10000; Iter 51/80; Loss: 0.2903
Epoch 7985/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 7986/10000; Iter 1/80; Loss: 0.3644
Epoch 7986/10000; Iter 51/80; Loss: 0.3097
Epoch 7986/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 7987/10000; Iter 1/80; Loss: 0.2739
Epoch 7987/10000; Iter 51/80; Loss: 0.2887
Epoch 7987/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 7988/10000; Iter 1/80; Loss: 0.3412
Epoch 7988/10000; Iter 51/80; Loss: 0.3409
Epoch 7988/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 7989/10000; Iter 1/80; Loss: 0.3396
Epoch 7989/10000; Iter 51/80; Loss: 0.3557
Epoch 7989/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.069
Epoch 7990/10000; Iter 1/80; Loss: 0.2827
Epoch 7990/10000; Iter 51/80; Loss: 0.3285
Epoch 7990/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 7991/10000; Iter 1/80; Loss: 0.3570
Epoch 7991/10000; Iter 51/80; Loss: 0.3724
Epoch 7991/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.073
Epoch 7992/10000; Iter 1/80; Loss: 0.3198
Epoch 7992/10000; Iter 51/80; Loss: 0.3325
Epoch 7992/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.066
Epoch 7993/10000; Iter 1/80; Loss: 0.3207
Epoch 7993/10000; Iter 51/80; Loss: 0.3888
Epoch 7993/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.075
Epoch 7994/10000; Iter 1/80; Loss: 0.3217
Epoch 7994/10000; Iter 51/80; Loss: 0.3007
Epoch 7994/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.08
Epoch 7995/10000; Iter 1/80; Loss: 0.3565
Epoch 7995/10000; Iter 51/80; Loss: 0.3575
Epoch 7995/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 7996/10000; Iter 1/80; Loss: 0.2937
Epoch 7996/10000; Iter 51/80; Loss: 0.3440
Epoch 7996/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 7997/10000; Iter 1/80; Loss: 0.3829
Epoch 7997/10000; Iter 51/80; Loss: 0.2993
Epoch 7997/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 7998/10000; Iter 1/80; Loss: 0.3285
Epoch 7998/10000; Iter 51/80; Loss: 0.3441
Epoch 7998/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.067
Epoch 7999/10000; Iter 1/80; Loss: 0.3436
Epoch 7999/10000; Iter 51/80; Loss: 0.3529
Epoch 7999/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 8000/10000; Iter 1/80; Loss: 0.3218
Epoch 8000/10000; Iter 51/80; Loss: 0.2931
Epoch 8000/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 8001/10000; Iter 1/80; Loss: 0.3299
Epoch 8001/10000; Iter 51/80; Loss: 0.3399
Epoch 8001/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.069
Model saved
Epoch 8002/10000; Iter 1/80; Loss: 0.2813
Epoch 8002/10000; Iter 51/80; Loss: 0.3305
Epoch 8002/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.074
Epoch 8003/10000; Iter 1/80; Loss: 0.2894
Epoch 8003/10000; Iter 51/80; Loss: 0.3379
Epoch 8003/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.073
Epoch 8004/10000; Iter 1/80; Loss: 0.3267
Epoch 8004/10000; Iter 51/80; Loss: 0.3556
Epoch 8004/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 8005/10000; Iter 1/80; Loss: 0.3870
Epoch 8005/10000; Iter 51/80; Loss: 0.3355
Epoch 8005/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.078
Epoch 8006/10000; Iter 1/80; Loss: 0.3244
Epoch 8006/10000; Iter 51/80; Loss: 0.3586
Epoch 8006/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8007/10000; Iter 1/80; Loss: 0.3064
Epoch 8007/10000; Iter 51/80; Loss: 0.3999
Epoch 8007/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.076
Epoch 8008/10000; Iter 1/80; Loss: 0.3031
Epoch 8008/10000; Iter 51/80; Loss: 0.3443
Epoch 8008/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8009/10000; Iter 1/80; Loss: 0.3760
Epoch 8009/10000; Iter 51/80; Loss: 0.3355
Epoch 8009/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8010/10000; Iter 1/80; Loss: 0.3137
Epoch 8010/10000; Iter 51/80; Loss: 0.3478
Epoch 8010/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8011/10000; Iter 1/80; Loss: 0.3146
Epoch 8011/10000; Iter 51/80; Loss: 0.3215
Epoch 8011/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.067
Epoch 8012/10000; Iter 1/80; Loss: 0.3563
Epoch 8012/10000; Iter 51/80; Loss: 0.2982
Epoch 8012/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8013/10000; Iter 1/80; Loss: 0.3066
Epoch 8013/10000; Iter 51/80; Loss: 0.3462
Epoch 8013/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 8014/10000; Iter 1/80; Loss: 0.3205
Epoch 8014/10000; Iter 51/80; Loss: 0.3361
Epoch 8014/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8015/10000; Iter 1/80; Loss: 0.2888
Epoch 8015/10000; Iter 51/80; Loss: 0.2820
Epoch 8015/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.077
Epoch 8016/10000; Iter 1/80; Loss: 0.3079
Epoch 8016/10000; Iter 51/80; Loss: 0.3579
Epoch 8016/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8017/10000; Iter 1/80; Loss: 0.3388
Epoch 8017/10000; Iter 51/80; Loss: 0.3259
Epoch 8017/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 8018/10000; Iter 1/80; Loss: 0.2979
Epoch 8018/10000; Iter 51/80; Loss: 0.3051
Epoch 8018/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8019/10000; Iter 1/80; Loss: 0.3149
Epoch 8019/10000; Iter 51/80; Loss: 0.3398
Epoch 8019/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.071
Epoch 8020/10000; Iter 1/80; Loss: 0.3381
Epoch 8020/10000; Iter 51/80; Loss: 0.3424
Epoch 8020/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.078
Epoch 8021/10000; Iter 1/80; Loss: 0.3339
Epoch 8021/10000; Iter 51/80; Loss: 0.2792
Epoch 8021/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 8022/10000; Iter 1/80; Loss: 0.3582
Epoch 8022/10000; Iter 51/80; Loss: 0.3994
Epoch 8022/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 8023/10000; Iter 1/80; Loss: 0.3467
Epoch 8023/10000; Iter 51/80; Loss: 0.3679
Epoch 8023/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.067
Epoch 8024/10000; Iter 1/80; Loss: 0.3473
Epoch 8024/10000; Iter 51/80; Loss: 0.2769
Epoch 8024/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 8025/10000; Iter 1/80; Loss: 0.3428
Epoch 8025/10000; Iter 51/80; Loss: 0.3497
Epoch 8025/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.083
Epoch 8026/10000; Iter 1/80; Loss: 0.3435
Epoch 8026/10000; Iter 51/80; Loss: 0.3105
Epoch 8026/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.074
Epoch 8027/10000; Iter 1/80; Loss: 0.3180
Epoch 8027/10000; Iter 51/80; Loss: 0.3308
Epoch 8027/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 8028/10000; Iter 1/80; Loss: 0.3250
Epoch 8028/10000; Iter 51/80; Loss: 0.2514
Epoch 8028/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8029/10000; Iter 1/80; Loss: 0.3039
Epoch 8029/10000; Iter 51/80; Loss: 0.3279
Epoch 8029/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 8030/10000; Iter 1/80; Loss: 0.3282
Epoch 8030/10000; Iter 51/80; Loss: 0.3154
Epoch 8030/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8031/10000; Iter 1/80; Loss: 0.3216
Epoch 8031/10000; Iter 51/80; Loss: 0.3782
Epoch 8031/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.067
Epoch 8032/10000; Iter 1/80; Loss: 0.2904
Epoch 8032/10000; Iter 51/80; Loss: 0.3070
Epoch 8032/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8033/10000; Iter 1/80; Loss: 0.3768
Epoch 8033/10000; Iter 51/80; Loss: 0.2865
Epoch 8033/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8034/10000; Iter 1/80; Loss: 0.4355
Epoch 8034/10000; Iter 51/80; Loss: 0.3205
Epoch 8034/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 8035/10000; Iter 1/80; Loss: 0.3315
Epoch 8035/10000; Iter 51/80; Loss: 0.3114
Epoch 8035/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 8036/10000; Iter 1/80; Loss: 0.3597
Epoch 8036/10000; Iter 51/80; Loss: 0.3077
Epoch 8036/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8037/10000; Iter 1/80; Loss: 0.3376
Epoch 8037/10000; Iter 51/80; Loss: 0.3128
Epoch 8037/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 8038/10000; Iter 1/80; Loss: 0.3191
Epoch 8038/10000; Iter 51/80; Loss: 0.3647
Epoch 8038/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8039/10000; Iter 1/80; Loss: 0.3188
Epoch 8039/10000; Iter 51/80; Loss: 0.3099
Epoch 8039/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.067
Epoch 8040/10000; Iter 1/80; Loss: 0.2857
Epoch 8040/10000; Iter 51/80; Loss: 0.3080
Epoch 8040/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.069
Epoch 8041/10000; Iter 1/80; Loss: 0.3143
Epoch 8041/10000; Iter 51/80; Loss: 0.3112
Epoch 8041/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.066
Epoch 8042/10000; Iter 1/80; Loss: 0.3447
Epoch 8042/10000; Iter 51/80; Loss: 0.3161
Epoch 8042/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 8043/10000; Iter 1/80; Loss: 0.2809
Epoch 8043/10000; Iter 51/80; Loss: 0.2921
Epoch 8043/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.066
Epoch 8044/10000; Iter 1/80; Loss: 0.2936
Epoch 8044/10000; Iter 51/80; Loss: 0.3073
Epoch 8044/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 8045/10000; Iter 1/80; Loss: 0.3267
Epoch 8045/10000; Iter 51/80; Loss: 0.3057
Epoch 8045/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 8046/10000; Iter 1/80; Loss: 0.2985
Epoch 8046/10000; Iter 51/80; Loss: 0.2699
Epoch 8046/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 8047/10000; Iter 1/80; Loss: 0.3302
Epoch 8047/10000; Iter 51/80; Loss: 0.3320
Epoch 8047/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 8048/10000; Iter 1/80; Loss: 0.3417
Epoch 8048/10000; Iter 51/80; Loss: 0.3279
Epoch 8048/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 8049/10000; Iter 1/80; Loss: 0.3487
Epoch 8049/10000; Iter 51/80; Loss: 0.3076
Epoch 8049/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8050/10000; Iter 1/80; Loss: 0.3659
Epoch 8050/10000; Iter 51/80; Loss: 0.3462
Epoch 8050/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8051/10000; Iter 1/80; Loss: 0.3223
Epoch 8051/10000; Iter 51/80; Loss: 0.3176
Epoch 8051/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 8052/10000; Iter 1/80; Loss: 0.3227
Epoch 8052/10000; Iter 51/80; Loss: 0.3463
Epoch 8052/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8053/10000; Iter 1/80; Loss: 0.3118
Epoch 8053/10000; Iter 51/80; Loss: 0.2878
Epoch 8053/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 8054/10000; Iter 1/80; Loss: 0.3256
Epoch 8054/10000; Iter 51/80; Loss: 0.3060
Epoch 8054/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8055/10000; Iter 1/80; Loss: 0.2818
Epoch 8055/10000; Iter 51/80; Loss: 0.2900
Epoch 8055/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 8056/10000; Iter 1/80; Loss: 0.3528
Epoch 8056/10000; Iter 51/80; Loss: 0.3144
Epoch 8056/10000; Iter 80/80; Training Loss: 0.3400, Test Loss: 0.064
Epoch 8057/10000; Iter 1/80; Loss: 0.3672
Epoch 8057/10000; Iter 51/80; Loss: 0.3618
Epoch 8057/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.078
Epoch 8058/10000; Iter 1/80; Loss: 0.3614
Epoch 8058/10000; Iter 51/80; Loss: 0.3493
Epoch 8058/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.076
Epoch 8059/10000; Iter 1/80; Loss: 0.3144
Epoch 8059/10000; Iter 51/80; Loss: 0.3242
Epoch 8059/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8060/10000; Iter 1/80; Loss: 0.3414
Epoch 8060/10000; Iter 51/80; Loss: 0.3038
Epoch 8060/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.079
Epoch 8061/10000; Iter 1/80; Loss: 0.3456
Epoch 8061/10000; Iter 51/80; Loss: 0.3466
Epoch 8061/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.073
Epoch 8062/10000; Iter 1/80; Loss: 0.3651
Epoch 8062/10000; Iter 51/80; Loss: 0.3470
Epoch 8062/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.082
Epoch 8063/10000; Iter 1/80; Loss: 0.3282
Epoch 8063/10000; Iter 51/80; Loss: 0.3284
Epoch 8063/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 8064/10000; Iter 1/80; Loss: 0.3418
Epoch 8064/10000; Iter 51/80; Loss: 0.3215
Epoch 8064/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 8065/10000; Iter 1/80; Loss: 0.3282
Epoch 8065/10000; Iter 51/80; Loss: 0.3510
Epoch 8065/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 8066/10000; Iter 1/80; Loss: 0.3452
Epoch 8066/10000; Iter 51/80; Loss: 0.4011
Epoch 8066/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.076
Epoch 8067/10000; Iter 1/80; Loss: 0.3879
Epoch 8067/10000; Iter 51/80; Loss: 0.3168
Epoch 8067/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.063
Epoch 8068/10000; Iter 1/80; Loss: 0.4313
Epoch 8068/10000; Iter 51/80; Loss: 0.3604
Epoch 8068/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.066
Epoch 8069/10000; Iter 1/80; Loss: 0.3361
Epoch 8069/10000; Iter 51/80; Loss: 0.2825
Epoch 8069/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 8070/10000; Iter 1/80; Loss: 0.3322
Epoch 8070/10000; Iter 51/80; Loss: 0.2894
Epoch 8070/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.066
Epoch 8071/10000; Iter 1/80; Loss: 0.2993
Epoch 8071/10000; Iter 51/80; Loss: 0.3253
Epoch 8071/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.08
Epoch 8072/10000; Iter 1/80; Loss: 0.2898
Epoch 8072/10000; Iter 51/80; Loss: 0.3502
Epoch 8072/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.077
Epoch 8073/10000; Iter 1/80; Loss: 0.2960
Epoch 8073/10000; Iter 51/80; Loss: 0.3548
Epoch 8073/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 8074/10000; Iter 1/80; Loss: 0.2676
Epoch 8074/10000; Iter 51/80; Loss: 0.2924
Epoch 8074/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8075/10000; Iter 1/80; Loss: 0.3240
Epoch 8075/10000; Iter 51/80; Loss: 0.3367
Epoch 8075/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 8076/10000; Iter 1/80; Loss: 0.3155
Epoch 8076/10000; Iter 51/80; Loss: 0.3043
Epoch 8076/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8077/10000; Iter 1/80; Loss: 0.3484
Epoch 8077/10000; Iter 51/80; Loss: 0.3517
Epoch 8077/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 8078/10000; Iter 1/80; Loss: 0.3719
Epoch 8078/10000; Iter 51/80; Loss: 0.3982
Epoch 8078/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8079/10000; Iter 1/80; Loss: 0.3107
Epoch 8079/10000; Iter 51/80; Loss: 0.3094
Epoch 8079/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8080/10000; Iter 1/80; Loss: 0.3246
Epoch 8080/10000; Iter 51/80; Loss: 0.3739
Epoch 8080/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 8081/10000; Iter 1/80; Loss: 0.2716
Epoch 8081/10000; Iter 51/80; Loss: 0.3300
Epoch 8081/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 8082/10000; Iter 1/80; Loss: 0.3309
Epoch 8082/10000; Iter 51/80; Loss: 0.3067
Epoch 8082/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 8083/10000; Iter 1/80; Loss: 0.3580
Epoch 8083/10000; Iter 51/80; Loss: 0.3319
Epoch 8083/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8084/10000; Iter 1/80; Loss: 0.3590
Epoch 8084/10000; Iter 51/80; Loss: 0.3642
Epoch 8084/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 8085/10000; Iter 1/80; Loss: 0.3483
Epoch 8085/10000; Iter 51/80; Loss: 0.3484
Epoch 8085/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 8086/10000; Iter 1/80; Loss: 0.3288
Epoch 8086/10000; Iter 51/80; Loss: 0.3683
Epoch 8086/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.085
Epoch 8087/10000; Iter 1/80; Loss: 0.3537
Epoch 8087/10000; Iter 51/80; Loss: 0.3865
Epoch 8087/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.065
Epoch 8088/10000; Iter 1/80; Loss: 0.2706
Epoch 8088/10000; Iter 51/80; Loss: 0.3160
Epoch 8088/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.079
Epoch 8089/10000; Iter 1/80; Loss: 0.3535
Epoch 8089/10000; Iter 51/80; Loss: 0.3582
Epoch 8089/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 8090/10000; Iter 1/80; Loss: 0.2857
Epoch 8090/10000; Iter 51/80; Loss: 0.3226
Epoch 8090/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 8091/10000; Iter 1/80; Loss: 0.3259
Epoch 8091/10000; Iter 51/80; Loss: 0.3514
Epoch 8091/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.067
Epoch 8092/10000; Iter 1/80; Loss: 0.3597
Epoch 8092/10000; Iter 51/80; Loss: 0.3204
Epoch 8092/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 8093/10000; Iter 1/80; Loss: 0.3276
Epoch 8093/10000; Iter 51/80; Loss: 0.3329
Epoch 8093/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 8094/10000; Iter 1/80; Loss: 0.3385
Epoch 8094/10000; Iter 51/80; Loss: 0.3433
Epoch 8094/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 8095/10000; Iter 1/80; Loss: 0.2970
Epoch 8095/10000; Iter 51/80; Loss: 0.3524
Epoch 8095/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8096/10000; Iter 1/80; Loss: 0.3253
Epoch 8096/10000; Iter 51/80; Loss: 0.3164
Epoch 8096/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 8097/10000; Iter 1/80; Loss: 0.3617
Epoch 8097/10000; Iter 51/80; Loss: 0.2971
Epoch 8097/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.073
Epoch 8098/10000; Iter 1/80; Loss: 0.3208
Epoch 8098/10000; Iter 51/80; Loss: 0.3059
Epoch 8098/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8099/10000; Iter 1/80; Loss: 0.3191
Epoch 8099/10000; Iter 51/80; Loss: 0.3403
Epoch 8099/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 8100/10000; Iter 1/80; Loss: 0.3409
Epoch 8100/10000; Iter 51/80; Loss: 0.3194
Epoch 8100/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.069
Epoch 8101/10000; Iter 1/80; Loss: 0.2939
Epoch 8101/10000; Iter 51/80; Loss: 0.3093
Epoch 8101/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Model saved
Epoch 8102/10000; Iter 1/80; Loss: 0.2958
Epoch 8102/10000; Iter 51/80; Loss: 0.3423
Epoch 8102/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 8103/10000; Iter 1/80; Loss: 0.2999
Epoch 8103/10000; Iter 51/80; Loss: 0.2851
Epoch 8103/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 8104/10000; Iter 1/80; Loss: 0.3815
Epoch 8104/10000; Iter 51/80; Loss: 0.3405
Epoch 8104/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.081
Epoch 8105/10000; Iter 1/80; Loss: 0.2888
Epoch 8105/10000; Iter 51/80; Loss: 0.2861
Epoch 8105/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8106/10000; Iter 1/80; Loss: 0.3255
Epoch 8106/10000; Iter 51/80; Loss: 0.3362
Epoch 8106/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.083
Epoch 8107/10000; Iter 1/80; Loss: 0.3558
Epoch 8107/10000; Iter 51/80; Loss: 0.3215
Epoch 8107/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 8108/10000; Iter 1/80; Loss: 0.3186
Epoch 8108/10000; Iter 51/80; Loss: 0.3364
Epoch 8108/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.08
Epoch 8109/10000; Iter 1/80; Loss: 0.3409
Epoch 8109/10000; Iter 51/80; Loss: 0.2910
Epoch 8109/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.065
Epoch 8110/10000; Iter 1/80; Loss: 0.3580
Epoch 8110/10000; Iter 51/80; Loss: 0.3284
Epoch 8110/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8111/10000; Iter 1/80; Loss: 0.2601
Epoch 8111/10000; Iter 51/80; Loss: 0.3425
Epoch 8111/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 8112/10000; Iter 1/80; Loss: 0.3624
Epoch 8112/10000; Iter 51/80; Loss: 0.2606
Epoch 8112/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 8113/10000; Iter 1/80; Loss: 0.3221
Epoch 8113/10000; Iter 51/80; Loss: 0.3523
Epoch 8113/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 8114/10000; Iter 1/80; Loss: 0.3266
Epoch 8114/10000; Iter 51/80; Loss: 0.3173
Epoch 8114/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 8115/10000; Iter 1/80; Loss: 0.3600
Epoch 8115/10000; Iter 51/80; Loss: 0.3673
Epoch 8115/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.07
Epoch 8116/10000; Iter 1/80; Loss: 0.3131
Epoch 8116/10000; Iter 51/80; Loss: 0.3271
Epoch 8116/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.077
Epoch 8117/10000; Iter 1/80; Loss: 0.4083
Epoch 8117/10000; Iter 51/80; Loss: 0.3349
Epoch 8117/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.077
Epoch 8118/10000; Iter 1/80; Loss: 0.3054
Epoch 8118/10000; Iter 51/80; Loss: 0.3381
Epoch 8118/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8119/10000; Iter 1/80; Loss: 0.3108
Epoch 8119/10000; Iter 51/80; Loss: 0.2703
Epoch 8119/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 8120/10000; Iter 1/80; Loss: 0.3294
Epoch 8120/10000; Iter 51/80; Loss: 0.3412
Epoch 8120/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 8121/10000; Iter 1/80; Loss: 0.2916
Epoch 8121/10000; Iter 51/80; Loss: 0.2916
Epoch 8121/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8122/10000; Iter 1/80; Loss: 0.3216
Epoch 8122/10000; Iter 51/80; Loss: 0.3513
Epoch 8122/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 8123/10000; Iter 1/80; Loss: 0.2824
Epoch 8123/10000; Iter 51/80; Loss: 0.3166
Epoch 8123/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.07
Epoch 8124/10000; Iter 1/80; Loss: 0.3654
Epoch 8124/10000; Iter 51/80; Loss: 0.3178
Epoch 8124/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.066
Epoch 8125/10000; Iter 1/80; Loss: 0.2887
Epoch 8125/10000; Iter 51/80; Loss: 0.3629
Epoch 8125/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.066
Epoch 8126/10000; Iter 1/80; Loss: 0.3653
Epoch 8126/10000; Iter 51/80; Loss: 0.3259
Epoch 8126/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.07
Epoch 8127/10000; Iter 1/80; Loss: 0.2991
Epoch 8127/10000; Iter 51/80; Loss: 0.4214
Epoch 8127/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.074
Epoch 8128/10000; Iter 1/80; Loss: 0.3145
Epoch 8128/10000; Iter 51/80; Loss: 0.3605
Epoch 8128/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8129/10000; Iter 1/80; Loss: 0.3226
Epoch 8129/10000; Iter 51/80; Loss: 0.3162
Epoch 8129/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 8130/10000; Iter 1/80; Loss: 0.3537
Epoch 8130/10000; Iter 51/80; Loss: 0.2739
Epoch 8130/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8131/10000; Iter 1/80; Loss: 0.3655
Epoch 8131/10000; Iter 51/80; Loss: 0.2996
Epoch 8131/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8132/10000; Iter 1/80; Loss: 0.3704
Epoch 8132/10000; Iter 51/80; Loss: 0.3822
Epoch 8132/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 8133/10000; Iter 1/80; Loss: 0.3311
Epoch 8133/10000; Iter 51/80; Loss: 0.3268
Epoch 8133/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 8134/10000; Iter 1/80; Loss: 0.3498
Epoch 8134/10000; Iter 51/80; Loss: 0.3533
Epoch 8134/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8135/10000; Iter 1/80; Loss: 0.3240
Epoch 8135/10000; Iter 51/80; Loss: 0.3725
Epoch 8135/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 8136/10000; Iter 1/80; Loss: 0.2933
Epoch 8136/10000; Iter 51/80; Loss: 0.3208
Epoch 8136/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 8137/10000; Iter 1/80; Loss: 0.3469
Epoch 8137/10000; Iter 51/80; Loss: 0.2990
Epoch 8137/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.064
Epoch 8138/10000; Iter 1/80; Loss: 0.3550
Epoch 8138/10000; Iter 51/80; Loss: 0.3735
Epoch 8138/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 8139/10000; Iter 1/80; Loss: 0.4901
Epoch 8139/10000; Iter 51/80; Loss: 0.3173
Epoch 8139/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.065
Epoch 8140/10000; Iter 1/80; Loss: 0.3345
Epoch 8140/10000; Iter 51/80; Loss: 0.3369
Epoch 8140/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.084
Epoch 8141/10000; Iter 1/80; Loss: 0.3093
Epoch 8141/10000; Iter 51/80; Loss: 0.3760
Epoch 8141/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8142/10000; Iter 1/80; Loss: 0.3128
Epoch 8142/10000; Iter 51/80; Loss: 0.3599
Epoch 8142/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.068
Epoch 8143/10000; Iter 1/80; Loss: 0.3279
Epoch 8143/10000; Iter 51/80; Loss: 0.4306
Epoch 8143/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 8144/10000; Iter 1/80; Loss: 0.3187
Epoch 8144/10000; Iter 51/80; Loss: 0.3444
Epoch 8144/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 8145/10000; Iter 1/80; Loss: 0.3236
Epoch 8145/10000; Iter 51/80; Loss: 0.2972
Epoch 8145/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8146/10000; Iter 1/80; Loss: 0.3056
Epoch 8146/10000; Iter 51/80; Loss: 0.3324
Epoch 8146/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.069
Epoch 8147/10000; Iter 1/80; Loss: 0.2948
Epoch 8147/10000; Iter 51/80; Loss: 0.4029
Epoch 8147/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8148/10000; Iter 1/80; Loss: 0.3384
Epoch 8148/10000; Iter 51/80; Loss: 0.3393
Epoch 8148/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8149/10000; Iter 1/80; Loss: 0.3460
Epoch 8149/10000; Iter 51/80; Loss: 0.3984
Epoch 8149/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.089
Epoch 8150/10000; Iter 1/80; Loss: 0.3503
Epoch 8150/10000; Iter 51/80; Loss: 0.3071
Epoch 8150/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8151/10000; Iter 1/80; Loss: 0.2798
Epoch 8151/10000; Iter 51/80; Loss: 0.3564
Epoch 8151/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.067
Epoch 8152/10000; Iter 1/80; Loss: 0.3282
Epoch 8152/10000; Iter 51/80; Loss: 0.3060
Epoch 8152/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.077
Epoch 8153/10000; Iter 1/80; Loss: 0.3844
Epoch 8153/10000; Iter 51/80; Loss: 0.3033
Epoch 8153/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 8154/10000; Iter 1/80; Loss: 0.3362
Epoch 8154/10000; Iter 51/80; Loss: 0.3705
Epoch 8154/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.077
Epoch 8155/10000; Iter 1/80; Loss: 0.3547
Epoch 8155/10000; Iter 51/80; Loss: 0.3335
Epoch 8155/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8156/10000; Iter 1/80; Loss: 0.3103
Epoch 8156/10000; Iter 51/80; Loss: 0.3369
Epoch 8156/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8157/10000; Iter 1/80; Loss: 0.2991
Epoch 8157/10000; Iter 51/80; Loss: 0.2661
Epoch 8157/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8158/10000; Iter 1/80; Loss: 0.3353
Epoch 8158/10000; Iter 51/80; Loss: 0.3455
Epoch 8158/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 8159/10000; Iter 1/80; Loss: 0.3576
Epoch 8159/10000; Iter 51/80; Loss: 0.3109
Epoch 8159/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 8160/10000; Iter 1/80; Loss: 0.3428
Epoch 8160/10000; Iter 51/80; Loss: 0.3012
Epoch 8160/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 8161/10000; Iter 1/80; Loss: 0.3198
Epoch 8161/10000; Iter 51/80; Loss: 0.2922
Epoch 8161/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 8162/10000; Iter 1/80; Loss: 0.3200
Epoch 8162/10000; Iter 51/80; Loss: 0.3902
Epoch 8162/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.07
Epoch 8163/10000; Iter 1/80; Loss: 0.3643
Epoch 8163/10000; Iter 51/80; Loss: 0.3819
Epoch 8163/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8164/10000; Iter 1/80; Loss: 0.3288
Epoch 8164/10000; Iter 51/80; Loss: 0.3069
Epoch 8164/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8165/10000; Iter 1/80; Loss: 0.3315
Epoch 8165/10000; Iter 51/80; Loss: 0.3132
Epoch 8165/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.079
Epoch 8166/10000; Iter 1/80; Loss: 0.3027
Epoch 8166/10000; Iter 51/80; Loss: 0.2802
Epoch 8166/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8167/10000; Iter 1/80; Loss: 0.3608
Epoch 8167/10000; Iter 51/80; Loss: 0.3562
Epoch 8167/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8168/10000; Iter 1/80; Loss: 0.3382
Epoch 8168/10000; Iter 51/80; Loss: 0.2595
Epoch 8168/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 8169/10000; Iter 1/80; Loss: 0.3310
Epoch 8169/10000; Iter 51/80; Loss: 0.3465
Epoch 8169/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.078
Epoch 8170/10000; Iter 1/80; Loss: 0.3288
Epoch 8170/10000; Iter 51/80; Loss: 0.3044
Epoch 8170/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 8171/10000; Iter 1/80; Loss: 0.3437
Epoch 8171/10000; Iter 51/80; Loss: 0.3010
Epoch 8171/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.065
Epoch 8172/10000; Iter 1/80; Loss: 0.2940
Epoch 8172/10000; Iter 51/80; Loss: 0.3470
Epoch 8172/10000; Iter 80/80; Training Loss: 0.3390, Test Loss: 0.073
Epoch 8173/10000; Iter 1/80; Loss: 0.3043
Epoch 8173/10000; Iter 51/80; Loss: 0.3055
Epoch 8173/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 8174/10000; Iter 1/80; Loss: 0.3756
Epoch 8174/10000; Iter 51/80; Loss: 0.3664
Epoch 8174/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8175/10000; Iter 1/80; Loss: 0.3715
Epoch 8175/10000; Iter 51/80; Loss: 0.3126
Epoch 8175/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.072
Epoch 8176/10000; Iter 1/80; Loss: 0.3389
Epoch 8176/10000; Iter 51/80; Loss: 0.3113
Epoch 8176/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8177/10000; Iter 1/80; Loss: 0.4110
Epoch 8177/10000; Iter 51/80; Loss: 0.3286
Epoch 8177/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.072
Epoch 8178/10000; Iter 1/80; Loss: 0.3183
Epoch 8178/10000; Iter 51/80; Loss: 0.2870
Epoch 8178/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 8179/10000; Iter 1/80; Loss: 0.3365
Epoch 8179/10000; Iter 51/80; Loss: 0.2952
Epoch 8179/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8180/10000; Iter 1/80; Loss: 0.3418
Epoch 8180/10000; Iter 51/80; Loss: 0.3477
Epoch 8180/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.079
Epoch 8181/10000; Iter 1/80; Loss: 0.2661
Epoch 8181/10000; Iter 51/80; Loss: 0.2921
Epoch 8181/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 8182/10000; Iter 1/80; Loss: 0.3757
Epoch 8182/10000; Iter 51/80; Loss: 0.3605
Epoch 8182/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 8183/10000; Iter 1/80; Loss: 0.3514
Epoch 8183/10000; Iter 51/80; Loss: 0.3492
Epoch 8183/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 8184/10000; Iter 1/80; Loss: 0.3711
Epoch 8184/10000; Iter 51/80; Loss: 0.3901
Epoch 8184/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 8185/10000; Iter 1/80; Loss: 0.2915
Epoch 8185/10000; Iter 51/80; Loss: 0.3536
Epoch 8185/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8186/10000; Iter 1/80; Loss: 0.3534
Epoch 8186/10000; Iter 51/80; Loss: 0.3316
Epoch 8186/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 8187/10000; Iter 1/80; Loss: 0.2898
Epoch 8187/10000; Iter 51/80; Loss: 0.3877
Epoch 8187/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8188/10000; Iter 1/80; Loss: 0.3536
Epoch 8188/10000; Iter 51/80; Loss: 0.3330
Epoch 8188/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 8189/10000; Iter 1/80; Loss: 0.3771
Epoch 8189/10000; Iter 51/80; Loss: 0.3231
Epoch 8189/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 8190/10000; Iter 1/80; Loss: 0.3257
Epoch 8190/10000; Iter 51/80; Loss: 0.2973
Epoch 8190/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8191/10000; Iter 1/80; Loss: 0.2964
Epoch 8191/10000; Iter 51/80; Loss: 0.3202
Epoch 8191/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8192/10000; Iter 1/80; Loss: 0.3573
Epoch 8192/10000; Iter 51/80; Loss: 0.2851
Epoch 8192/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8193/10000; Iter 1/80; Loss: 0.3552
Epoch 8193/10000; Iter 51/80; Loss: 0.3126
Epoch 8193/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 8194/10000; Iter 1/80; Loss: 0.3642
Epoch 8194/10000; Iter 51/80; Loss: 0.3150
Epoch 8194/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.087
Epoch 8195/10000; Iter 1/80; Loss: 0.2836
Epoch 8195/10000; Iter 51/80; Loss: 0.3423
Epoch 8195/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8196/10000; Iter 1/80; Loss: 0.3477
Epoch 8196/10000; Iter 51/80; Loss: 0.3630
Epoch 8196/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.058
Epoch 8197/10000; Iter 1/80; Loss: 0.3105
Epoch 8197/10000; Iter 51/80; Loss: 0.3623
Epoch 8197/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8198/10000; Iter 1/80; Loss: 0.3424
Epoch 8198/10000; Iter 51/80; Loss: 0.3558
Epoch 8198/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8199/10000; Iter 1/80; Loss: 0.3047
Epoch 8199/10000; Iter 51/80; Loss: 0.3252
Epoch 8199/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.078
Epoch 8200/10000; Iter 1/80; Loss: 0.3367
Epoch 8200/10000; Iter 51/80; Loss: 0.3599
Epoch 8200/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.077
Epoch 8201/10000; Iter 1/80; Loss: 0.3060
Epoch 8201/10000; Iter 51/80; Loss: 0.3495
Epoch 8201/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Model saved
Epoch 8202/10000; Iter 1/80; Loss: 0.2974
Epoch 8202/10000; Iter 51/80; Loss: 0.2981
Epoch 8202/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.064
Epoch 8203/10000; Iter 1/80; Loss: 0.3301
Epoch 8203/10000; Iter 51/80; Loss: 0.2981
Epoch 8203/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8204/10000; Iter 1/80; Loss: 0.3049
Epoch 8204/10000; Iter 51/80; Loss: 0.3734
Epoch 8204/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 8205/10000; Iter 1/80; Loss: 0.3646
Epoch 8205/10000; Iter 51/80; Loss: 0.3251
Epoch 8205/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.068
Epoch 8206/10000; Iter 1/80; Loss: 0.3606
Epoch 8206/10000; Iter 51/80; Loss: 0.3482
Epoch 8206/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.082
Epoch 8207/10000; Iter 1/80; Loss: 0.3392
Epoch 8207/10000; Iter 51/80; Loss: 0.3868
Epoch 8207/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 8208/10000; Iter 1/80; Loss: 0.3545
Epoch 8208/10000; Iter 51/80; Loss: 0.3528
Epoch 8208/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.067
Epoch 8209/10000; Iter 1/80; Loss: 0.3660
Epoch 8209/10000; Iter 51/80; Loss: 0.3757
Epoch 8209/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 8210/10000; Iter 1/80; Loss: 0.3327
Epoch 8210/10000; Iter 51/80; Loss: 0.3169
Epoch 8210/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8211/10000; Iter 1/80; Loss: 0.3364
Epoch 8211/10000; Iter 51/80; Loss: 0.3741
Epoch 8211/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8212/10000; Iter 1/80; Loss: 0.3366
Epoch 8212/10000; Iter 51/80; Loss: 0.3322
Epoch 8212/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8213/10000; Iter 1/80; Loss: 0.3374
Epoch 8213/10000; Iter 51/80; Loss: 0.3302
Epoch 8213/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 8214/10000; Iter 1/80; Loss: 0.3592
Epoch 8214/10000; Iter 51/80; Loss: 0.2604
Epoch 8214/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8215/10000; Iter 1/80; Loss: 0.2961
Epoch 8215/10000; Iter 51/80; Loss: 0.3191
Epoch 8215/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8216/10000; Iter 1/80; Loss: 0.3077
Epoch 8216/10000; Iter 51/80; Loss: 0.3008
Epoch 8216/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 8217/10000; Iter 1/80; Loss: 0.3297
Epoch 8217/10000; Iter 51/80; Loss: 0.3927
Epoch 8217/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 8218/10000; Iter 1/80; Loss: 0.3781
Epoch 8218/10000; Iter 51/80; Loss: 0.3599
Epoch 8218/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.067
Epoch 8219/10000; Iter 1/80; Loss: 0.3354
Epoch 8219/10000; Iter 51/80; Loss: 0.3018
Epoch 8219/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8220/10000; Iter 1/80; Loss: 0.2820
Epoch 8220/10000; Iter 51/80; Loss: 0.3118
Epoch 8220/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 8221/10000; Iter 1/80; Loss: 0.3069
Epoch 8221/10000; Iter 51/80; Loss: 0.3574
Epoch 8221/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8222/10000; Iter 1/80; Loss: 0.3519
Epoch 8222/10000; Iter 51/80; Loss: 0.3382
Epoch 8222/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8223/10000; Iter 1/80; Loss: 0.3254
Epoch 8223/10000; Iter 51/80; Loss: 0.3571
Epoch 8223/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 8224/10000; Iter 1/80; Loss: 0.3521
Epoch 8224/10000; Iter 51/80; Loss: 0.3884
Epoch 8224/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 8225/10000; Iter 1/80; Loss: 0.2936
Epoch 8225/10000; Iter 51/80; Loss: 0.3030
Epoch 8225/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.08
Epoch 8226/10000; Iter 1/80; Loss: 0.3328
Epoch 8226/10000; Iter 51/80; Loss: 0.3294
Epoch 8226/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.065
Epoch 8227/10000; Iter 1/80; Loss: 0.3436
Epoch 8227/10000; Iter 51/80; Loss: 0.3544
Epoch 8227/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.069
Epoch 8228/10000; Iter 1/80; Loss: 0.2846
Epoch 8228/10000; Iter 51/80; Loss: 0.2894
Epoch 8228/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8229/10000; Iter 1/80; Loss: 0.3229
Epoch 8229/10000; Iter 51/80; Loss: 0.2743
Epoch 8229/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8230/10000; Iter 1/80; Loss: 0.3213
Epoch 8230/10000; Iter 51/80; Loss: 0.2945
Epoch 8230/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8231/10000; Iter 1/80; Loss: 0.2962
Epoch 8231/10000; Iter 51/80; Loss: 0.3363
Epoch 8231/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8232/10000; Iter 1/80; Loss: 0.3409
Epoch 8232/10000; Iter 51/80; Loss: 0.3418
Epoch 8232/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.073
Epoch 8233/10000; Iter 1/80; Loss: 0.2995
Epoch 8233/10000; Iter 51/80; Loss: 0.3443
Epoch 8233/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.069
Epoch 8234/10000; Iter 1/80; Loss: 0.3674
Epoch 8234/10000; Iter 51/80; Loss: 0.3183
Epoch 8234/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.086
Epoch 8235/10000; Iter 1/80; Loss: 0.3385
Epoch 8235/10000; Iter 51/80; Loss: 0.3061
Epoch 8235/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.068
Epoch 8236/10000; Iter 1/80; Loss: 0.3286
Epoch 8236/10000; Iter 51/80; Loss: 0.4100
Epoch 8236/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.067
Epoch 8237/10000; Iter 1/80; Loss: 0.3443
Epoch 8237/10000; Iter 51/80; Loss: 0.4202
Epoch 8237/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 8238/10000; Iter 1/80; Loss: 0.3227
Epoch 8238/10000; Iter 51/80; Loss: 0.3627
Epoch 8238/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 8239/10000; Iter 1/80; Loss: 0.2972
Epoch 8239/10000; Iter 51/80; Loss: 0.2949
Epoch 8239/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8240/10000; Iter 1/80; Loss: 0.3279
Epoch 8240/10000; Iter 51/80; Loss: 0.3409
Epoch 8240/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 8241/10000; Iter 1/80; Loss: 0.3464
Epoch 8241/10000; Iter 51/80; Loss: 0.2955
Epoch 8241/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8242/10000; Iter 1/80; Loss: 0.3295
Epoch 8242/10000; Iter 51/80; Loss: 0.3375
Epoch 8242/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8243/10000; Iter 1/80; Loss: 0.2752
Epoch 8243/10000; Iter 51/80; Loss: 0.2975
Epoch 8243/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.081
Epoch 8244/10000; Iter 1/80; Loss: 0.3633
Epoch 8244/10000; Iter 51/80; Loss: 0.3461
Epoch 8244/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 8245/10000; Iter 1/80; Loss: 0.3302
Epoch 8245/10000; Iter 51/80; Loss: 0.3740
Epoch 8245/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.065
Epoch 8246/10000; Iter 1/80; Loss: 0.3193
Epoch 8246/10000; Iter 51/80; Loss: 0.3369
Epoch 8246/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.074
Epoch 8247/10000; Iter 1/80; Loss: 0.3298
Epoch 8247/10000; Iter 51/80; Loss: 0.3307
Epoch 8247/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.073
Epoch 8248/10000; Iter 1/80; Loss: 0.3440
Epoch 8248/10000; Iter 51/80; Loss: 0.4052
Epoch 8248/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 8249/10000; Iter 1/80; Loss: 0.2987
Epoch 8249/10000; Iter 51/80; Loss: 0.3041
Epoch 8249/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.07
Epoch 8250/10000; Iter 1/80; Loss: 0.3243
Epoch 8250/10000; Iter 51/80; Loss: 0.3568
Epoch 8250/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8251/10000; Iter 1/80; Loss: 0.3593
Epoch 8251/10000; Iter 51/80; Loss: 0.2973
Epoch 8251/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.065
Epoch 8252/10000; Iter 1/80; Loss: 0.3438
Epoch 8252/10000; Iter 51/80; Loss: 0.3983
Epoch 8252/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.066
Epoch 8253/10000; Iter 1/80; Loss: 0.3564
Epoch 8253/10000; Iter 51/80; Loss: 0.2896
Epoch 8253/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.067
Epoch 8254/10000; Iter 1/80; Loss: 0.3518
Epoch 8254/10000; Iter 51/80; Loss: 0.3219
Epoch 8254/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8255/10000; Iter 1/80; Loss: 0.3174
Epoch 8255/10000; Iter 51/80; Loss: 0.3328
Epoch 8255/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.069
Epoch 8256/10000; Iter 1/80; Loss: 0.3558
Epoch 8256/10000; Iter 51/80; Loss: 0.4074
Epoch 8256/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 8257/10000; Iter 1/80; Loss: 0.3197
Epoch 8257/10000; Iter 51/80; Loss: 0.3531
Epoch 8257/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8258/10000; Iter 1/80; Loss: 0.3758
Epoch 8258/10000; Iter 51/80; Loss: 0.3429
Epoch 8258/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.081
Epoch 8259/10000; Iter 1/80; Loss: 0.3541
Epoch 8259/10000; Iter 51/80; Loss: 0.3771
Epoch 8259/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8260/10000; Iter 1/80; Loss: 0.3148
Epoch 8260/10000; Iter 51/80; Loss: 0.3403
Epoch 8260/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Epoch 8261/10000; Iter 1/80; Loss: 0.3900
Epoch 8261/10000; Iter 51/80; Loss: 0.4133
Epoch 8261/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 8262/10000; Iter 1/80; Loss: 0.3199
Epoch 8262/10000; Iter 51/80; Loss: 0.3739
Epoch 8262/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8263/10000; Iter 1/80; Loss: 0.2931
Epoch 8263/10000; Iter 51/80; Loss: 0.3301
Epoch 8263/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8264/10000; Iter 1/80; Loss: 0.4013
Epoch 8264/10000; Iter 51/80; Loss: 0.3028
Epoch 8264/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 8265/10000; Iter 1/80; Loss: 0.4215
Epoch 8265/10000; Iter 51/80; Loss: 0.3268
Epoch 8265/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.08
Epoch 8266/10000; Iter 1/80; Loss: 0.3259
Epoch 8266/10000; Iter 51/80; Loss: 0.3023
Epoch 8266/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8267/10000; Iter 1/80; Loss: 0.2628
Epoch 8267/10000; Iter 51/80; Loss: 0.3942
Epoch 8267/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8268/10000; Iter 1/80; Loss: 0.3724
Epoch 8268/10000; Iter 51/80; Loss: 0.3526
Epoch 8268/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.077
Epoch 8269/10000; Iter 1/80; Loss: 0.2840
Epoch 8269/10000; Iter 51/80; Loss: 0.3131
Epoch 8269/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 8270/10000; Iter 1/80; Loss: 0.3077
Epoch 8270/10000; Iter 51/80; Loss: 0.3376
Epoch 8270/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.087
Epoch 8271/10000; Iter 1/80; Loss: 0.3398
Epoch 8271/10000; Iter 51/80; Loss: 0.2962
Epoch 8271/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 8272/10000; Iter 1/80; Loss: 0.3292
Epoch 8272/10000; Iter 51/80; Loss: 0.3623
Epoch 8272/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8273/10000; Iter 1/80; Loss: 0.3054
Epoch 8273/10000; Iter 51/80; Loss: 0.3122
Epoch 8273/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.074
Epoch 8274/10000; Iter 1/80; Loss: 0.3882
Epoch 8274/10000; Iter 51/80; Loss: 0.3352
Epoch 8274/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.069
Epoch 8275/10000; Iter 1/80; Loss: 0.3189
Epoch 8275/10000; Iter 51/80; Loss: 0.3353
Epoch 8275/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.08
Epoch 8276/10000; Iter 1/80; Loss: 0.3575
Epoch 8276/10000; Iter 51/80; Loss: 0.3239
Epoch 8276/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 8277/10000; Iter 1/80; Loss: 0.3378
Epoch 8277/10000; Iter 51/80; Loss: 0.3632
Epoch 8277/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.069
Epoch 8278/10000; Iter 1/80; Loss: 0.3063
Epoch 8278/10000; Iter 51/80; Loss: 0.3023
Epoch 8278/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 8279/10000; Iter 1/80; Loss: 0.3409
Epoch 8279/10000; Iter 51/80; Loss: 0.3191
Epoch 8279/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8280/10000; Iter 1/80; Loss: 0.4054
Epoch 8280/10000; Iter 51/80; Loss: 0.3042
Epoch 8280/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.067
Epoch 8281/10000; Iter 1/80; Loss: 0.3360
Epoch 8281/10000; Iter 51/80; Loss: 0.3152
Epoch 8281/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 8282/10000; Iter 1/80; Loss: 0.3509
Epoch 8282/10000; Iter 51/80; Loss: 0.3499
Epoch 8282/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.064
Epoch 8283/10000; Iter 1/80; Loss: 0.3055
Epoch 8283/10000; Iter 51/80; Loss: 0.2953
Epoch 8283/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 8284/10000; Iter 1/80; Loss: 0.3525
Epoch 8284/10000; Iter 51/80; Loss: 0.3074
Epoch 8284/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.081
Epoch 8285/10000; Iter 1/80; Loss: 0.2920
Epoch 8285/10000; Iter 51/80; Loss: 0.3406
Epoch 8285/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.083
Epoch 8286/10000; Iter 1/80; Loss: 0.2905
Epoch 8286/10000; Iter 51/80; Loss: 0.3212
Epoch 8286/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 8287/10000; Iter 1/80; Loss: 0.3004
Epoch 8287/10000; Iter 51/80; Loss: 0.3333
Epoch 8287/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 8288/10000; Iter 1/80; Loss: 0.3290
Epoch 8288/10000; Iter 51/80; Loss: 0.3170
Epoch 8288/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8289/10000; Iter 1/80; Loss: 0.3234
Epoch 8289/10000; Iter 51/80; Loss: 0.3295
Epoch 8289/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8290/10000; Iter 1/80; Loss: 0.3243
Epoch 8290/10000; Iter 51/80; Loss: 0.3069
Epoch 8290/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 8291/10000; Iter 1/80; Loss: 0.3652
Epoch 8291/10000; Iter 51/80; Loss: 0.2983
Epoch 8291/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.069
Epoch 8292/10000; Iter 1/80; Loss: 0.3148
Epoch 8292/10000; Iter 51/80; Loss: 0.2983
Epoch 8292/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 8293/10000; Iter 1/80; Loss: 0.3356
Epoch 8293/10000; Iter 51/80; Loss: 0.3285
Epoch 8293/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 8294/10000; Iter 1/80; Loss: 0.3088
Epoch 8294/10000; Iter 51/80; Loss: 0.2752
Epoch 8294/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 8295/10000; Iter 1/80; Loss: 0.3471
Epoch 8295/10000; Iter 51/80; Loss: 0.2983
Epoch 8295/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8296/10000; Iter 1/80; Loss: 0.2928
Epoch 8296/10000; Iter 51/80; Loss: 0.3562
Epoch 8296/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8297/10000; Iter 1/80; Loss: 0.3556
Epoch 8297/10000; Iter 51/80; Loss: 0.3270
Epoch 8297/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8298/10000; Iter 1/80; Loss: 0.2972
Epoch 8298/10000; Iter 51/80; Loss: 0.3684
Epoch 8298/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 8299/10000; Iter 1/80; Loss: 0.3357
Epoch 8299/10000; Iter 51/80; Loss: 0.3847
Epoch 8299/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8300/10000; Iter 1/80; Loss: 0.3165
Epoch 8300/10000; Iter 51/80; Loss: 0.2771
Epoch 8300/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.077
Epoch 8301/10000; Iter 1/80; Loss: 0.3112
Epoch 8301/10000; Iter 51/80; Loss: 0.3210
Epoch 8301/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Model saved
Epoch 8302/10000; Iter 1/80; Loss: 0.2521
Epoch 8302/10000; Iter 51/80; Loss: 0.2885
Epoch 8302/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8303/10000; Iter 1/80; Loss: 0.2996
Epoch 8303/10000; Iter 51/80; Loss: 0.3338
Epoch 8303/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8304/10000; Iter 1/80; Loss: 0.3168
Epoch 8304/10000; Iter 51/80; Loss: 0.3027
Epoch 8304/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 8305/10000; Iter 1/80; Loss: 0.3393
Epoch 8305/10000; Iter 51/80; Loss: 0.2969
Epoch 8305/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 8306/10000; Iter 1/80; Loss: 0.4024
Epoch 8306/10000; Iter 51/80; Loss: 0.2720
Epoch 8306/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 8307/10000; Iter 1/80; Loss: 0.3190
Epoch 8307/10000; Iter 51/80; Loss: 0.3546
Epoch 8307/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 8308/10000; Iter 1/80; Loss: 0.3161
Epoch 8308/10000; Iter 51/80; Loss: 0.3486
Epoch 8308/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 8309/10000; Iter 1/80; Loss: 0.2888
Epoch 8309/10000; Iter 51/80; Loss: 0.2896
Epoch 8309/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8310/10000; Iter 1/80; Loss: 0.2885
Epoch 8310/10000; Iter 51/80; Loss: 0.3832
Epoch 8310/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8311/10000; Iter 1/80; Loss: 0.3256
Epoch 8311/10000; Iter 51/80; Loss: 0.3845
Epoch 8311/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.069
Epoch 8312/10000; Iter 1/80; Loss: 0.3582
Epoch 8312/10000; Iter 51/80; Loss: 0.3541
Epoch 8312/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8313/10000; Iter 1/80; Loss: 0.2951
Epoch 8313/10000; Iter 51/80; Loss: 0.3069
Epoch 8313/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 8314/10000; Iter 1/80; Loss: 0.3127
Epoch 8314/10000; Iter 51/80; Loss: 0.3743
Epoch 8314/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8315/10000; Iter 1/80; Loss: 0.2949
Epoch 8315/10000; Iter 51/80; Loss: 0.3200
Epoch 8315/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.077
Epoch 8316/10000; Iter 1/80; Loss: 0.3254
Epoch 8316/10000; Iter 51/80; Loss: 0.3725
Epoch 8316/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 8317/10000; Iter 1/80; Loss: 0.3120
Epoch 8317/10000; Iter 51/80; Loss: 0.2973
Epoch 8317/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 8318/10000; Iter 1/80; Loss: 0.3264
Epoch 8318/10000; Iter 51/80; Loss: 0.2652
Epoch 8318/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 8319/10000; Iter 1/80; Loss: 0.3491
Epoch 8319/10000; Iter 51/80; Loss: 0.3100
Epoch 8319/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.065
Epoch 8320/10000; Iter 1/80; Loss: 0.3566
Epoch 8320/10000; Iter 51/80; Loss: 0.3503
Epoch 8320/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.077
Epoch 8321/10000; Iter 1/80; Loss: 0.3991
Epoch 8321/10000; Iter 51/80; Loss: 0.3800
Epoch 8321/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.078
Epoch 8322/10000; Iter 1/80; Loss: 0.4114
Epoch 8322/10000; Iter 51/80; Loss: 0.3350
Epoch 8322/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 8323/10000; Iter 1/80; Loss: 0.3428
Epoch 8323/10000; Iter 51/80; Loss: 0.3711
Epoch 8323/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.081
Epoch 8324/10000; Iter 1/80; Loss: 0.3693
Epoch 8324/10000; Iter 51/80; Loss: 0.3128
Epoch 8324/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8325/10000; Iter 1/80; Loss: 0.3478
Epoch 8325/10000; Iter 51/80; Loss: 0.3631
Epoch 8325/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8326/10000; Iter 1/80; Loss: 0.3331
Epoch 8326/10000; Iter 51/80; Loss: 0.3893
Epoch 8326/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8327/10000; Iter 1/80; Loss: 0.3496
Epoch 8327/10000; Iter 51/80; Loss: 0.3226
Epoch 8327/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 8328/10000; Iter 1/80; Loss: 0.3150
Epoch 8328/10000; Iter 51/80; Loss: 0.3270
Epoch 8328/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 8329/10000; Iter 1/80; Loss: 0.3651
Epoch 8329/10000; Iter 51/80; Loss: 0.2910
Epoch 8329/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8330/10000; Iter 1/80; Loss: 0.3384
Epoch 8330/10000; Iter 51/80; Loss: 0.3721
Epoch 8330/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.071
Epoch 8331/10000; Iter 1/80; Loss: 0.3131
Epoch 8331/10000; Iter 51/80; Loss: 0.2926
Epoch 8331/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.067
Epoch 8332/10000; Iter 1/80; Loss: 0.3419
Epoch 8332/10000; Iter 51/80; Loss: 0.3375
Epoch 8332/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8333/10000; Iter 1/80; Loss: 0.3721
Epoch 8333/10000; Iter 51/80; Loss: 0.3068
Epoch 8333/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8334/10000; Iter 1/80; Loss: 0.3276
Epoch 8334/10000; Iter 51/80; Loss: 0.3242
Epoch 8334/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8335/10000; Iter 1/80; Loss: 0.3540
Epoch 8335/10000; Iter 51/80; Loss: 0.3043
Epoch 8335/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8336/10000; Iter 1/80; Loss: 0.3589
Epoch 8336/10000; Iter 51/80; Loss: 0.3112
Epoch 8336/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.066
Epoch 8337/10000; Iter 1/80; Loss: 0.3918
Epoch 8337/10000; Iter 51/80; Loss: 0.2942
Epoch 8337/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.077
Epoch 8338/10000; Iter 1/80; Loss: 0.3336
Epoch 8338/10000; Iter 51/80; Loss: 0.3386
Epoch 8338/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.068
Epoch 8339/10000; Iter 1/80; Loss: 0.3222
Epoch 8339/10000; Iter 51/80; Loss: 0.3547
Epoch 8339/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.069
Epoch 8340/10000; Iter 1/80; Loss: 0.3095
Epoch 8340/10000; Iter 51/80; Loss: 0.3923
Epoch 8340/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8341/10000; Iter 1/80; Loss: 0.3827
Epoch 8341/10000; Iter 51/80; Loss: 0.2826
Epoch 8341/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8342/10000; Iter 1/80; Loss: 0.3322
Epoch 8342/10000; Iter 51/80; Loss: 0.3938
Epoch 8342/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8343/10000; Iter 1/80; Loss: 0.3171
Epoch 8343/10000; Iter 51/80; Loss: 0.3604
Epoch 8343/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.067
Epoch 8344/10000; Iter 1/80; Loss: 0.4278
Epoch 8344/10000; Iter 51/80; Loss: 0.3286
Epoch 8344/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 8345/10000; Iter 1/80; Loss: 0.3196
Epoch 8345/10000; Iter 51/80; Loss: 0.3511
Epoch 8345/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8346/10000; Iter 1/80; Loss: 0.2925
Epoch 8346/10000; Iter 51/80; Loss: 0.2993
Epoch 8346/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.067
Epoch 8347/10000; Iter 1/80; Loss: 0.3814
Epoch 8347/10000; Iter 51/80; Loss: 0.2920
Epoch 8347/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.067
Epoch 8348/10000; Iter 1/80; Loss: 0.3427
Epoch 8348/10000; Iter 51/80; Loss: 0.3863
Epoch 8348/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.076
Epoch 8349/10000; Iter 1/80; Loss: 0.3341
Epoch 8349/10000; Iter 51/80; Loss: 0.2823
Epoch 8349/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.087
Epoch 8350/10000; Iter 1/80; Loss: 0.3353
Epoch 8350/10000; Iter 51/80; Loss: 0.4088
Epoch 8350/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8351/10000; Iter 1/80; Loss: 0.3321
Epoch 8351/10000; Iter 51/80; Loss: 0.2952
Epoch 8351/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.084
Epoch 8352/10000; Iter 1/80; Loss: 0.3560
Epoch 8352/10000; Iter 51/80; Loss: 0.3158
Epoch 8352/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 8353/10000; Iter 1/80; Loss: 0.3026
Epoch 8353/10000; Iter 51/80; Loss: 0.3516
Epoch 8353/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 8354/10000; Iter 1/80; Loss: 0.2644
Epoch 8354/10000; Iter 51/80; Loss: 0.2970
Epoch 8354/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8355/10000; Iter 1/80; Loss: 0.3132
Epoch 8355/10000; Iter 51/80; Loss: 0.3370
Epoch 8355/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.063
Epoch 8356/10000; Iter 1/80; Loss: 0.3282
Epoch 8356/10000; Iter 51/80; Loss: 0.3371
Epoch 8356/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 8357/10000; Iter 1/80; Loss: 0.3386
Epoch 8357/10000; Iter 51/80; Loss: 0.3322
Epoch 8357/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8358/10000; Iter 1/80; Loss: 0.3382
Epoch 8358/10000; Iter 51/80; Loss: 0.3606
Epoch 8358/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8359/10000; Iter 1/80; Loss: 0.3662
Epoch 8359/10000; Iter 51/80; Loss: 0.3211
Epoch 8359/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8360/10000; Iter 1/80; Loss: 0.2877
Epoch 8360/10000; Iter 51/80; Loss: 0.3020
Epoch 8360/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.08
Epoch 8361/10000; Iter 1/80; Loss: 0.3159
Epoch 8361/10000; Iter 51/80; Loss: 0.3207
Epoch 8361/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.076
Epoch 8362/10000; Iter 1/80; Loss: 0.3117
Epoch 8362/10000; Iter 51/80; Loss: 0.3022
Epoch 8362/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.07
Epoch 8363/10000; Iter 1/80; Loss: 0.3499
Epoch 8363/10000; Iter 51/80; Loss: 0.3837
Epoch 8363/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.081
Epoch 8364/10000; Iter 1/80; Loss: 0.3155
Epoch 8364/10000; Iter 51/80; Loss: 0.3591
Epoch 8364/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.066
Epoch 8365/10000; Iter 1/80; Loss: 0.3094
Epoch 8365/10000; Iter 51/80; Loss: 0.3184
Epoch 8365/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8366/10000; Iter 1/80; Loss: 0.3219
Epoch 8366/10000; Iter 51/80; Loss: 0.3200
Epoch 8366/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8367/10000; Iter 1/80; Loss: 0.3306
Epoch 8367/10000; Iter 51/80; Loss: 0.2851
Epoch 8367/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8368/10000; Iter 1/80; Loss: 0.3077
Epoch 8368/10000; Iter 51/80; Loss: 0.3333
Epoch 8368/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8369/10000; Iter 1/80; Loss: 0.3779
Epoch 8369/10000; Iter 51/80; Loss: 0.4185
Epoch 8369/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.078
Epoch 8370/10000; Iter 1/80; Loss: 0.3073
Epoch 8370/10000; Iter 51/80; Loss: 0.3519
Epoch 8370/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.071
Epoch 8371/10000; Iter 1/80; Loss: 0.3325
Epoch 8371/10000; Iter 51/80; Loss: 0.3083
Epoch 8371/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8372/10000; Iter 1/80; Loss: 0.3451
Epoch 8372/10000; Iter 51/80; Loss: 0.3385
Epoch 8372/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.079
Epoch 8373/10000; Iter 1/80; Loss: 0.3842
Epoch 8373/10000; Iter 51/80; Loss: 0.3440
Epoch 8373/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.064
Epoch 8374/10000; Iter 1/80; Loss: 0.2988
Epoch 8374/10000; Iter 51/80; Loss: 0.3591
Epoch 8374/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.074
Epoch 8375/10000; Iter 1/80; Loss: 0.3242
Epoch 8375/10000; Iter 51/80; Loss: 0.4092
Epoch 8375/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 8376/10000; Iter 1/80; Loss: 0.3508
Epoch 8376/10000; Iter 51/80; Loss: 0.3623
Epoch 8376/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.071
Epoch 8377/10000; Iter 1/80; Loss: 0.3253
Epoch 8377/10000; Iter 51/80; Loss: 0.2682
Epoch 8377/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 8378/10000; Iter 1/80; Loss: 0.3510
Epoch 8378/10000; Iter 51/80; Loss: 0.3100
Epoch 8378/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 8379/10000; Iter 1/80; Loss: 0.3200
Epoch 8379/10000; Iter 51/80; Loss: 0.3124
Epoch 8379/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.081
Epoch 8380/10000; Iter 1/80; Loss: 0.3577
Epoch 8380/10000; Iter 51/80; Loss: 0.3768
Epoch 8380/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 8381/10000; Iter 1/80; Loss: 0.3269
Epoch 8381/10000; Iter 51/80; Loss: 0.4008
Epoch 8381/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 8382/10000; Iter 1/80; Loss: 0.2939
Epoch 8382/10000; Iter 51/80; Loss: 0.3208
Epoch 8382/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8383/10000; Iter 1/80; Loss: 0.2860
Epoch 8383/10000; Iter 51/80; Loss: 0.3334
Epoch 8383/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 8384/10000; Iter 1/80; Loss: 0.2926
Epoch 8384/10000; Iter 51/80; Loss: 0.3133
Epoch 8384/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8385/10000; Iter 1/80; Loss: 0.2722
Epoch 8385/10000; Iter 51/80; Loss: 0.3040
Epoch 8385/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8386/10000; Iter 1/80; Loss: 0.2806
Epoch 8386/10000; Iter 51/80; Loss: 0.3187
Epoch 8386/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.071
Epoch 8387/10000; Iter 1/80; Loss: 0.3029
Epoch 8387/10000; Iter 51/80; Loss: 0.3660
Epoch 8387/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.069
Epoch 8388/10000; Iter 1/80; Loss: 0.3143
Epoch 8388/10000; Iter 51/80; Loss: 0.3637
Epoch 8388/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.063
Epoch 8389/10000; Iter 1/80; Loss: 0.3623
Epoch 8389/10000; Iter 51/80; Loss: 0.3212
Epoch 8389/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8390/10000; Iter 1/80; Loss: 0.3544
Epoch 8390/10000; Iter 51/80; Loss: 0.3751
Epoch 8390/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 8391/10000; Iter 1/80; Loss: 0.3345
Epoch 8391/10000; Iter 51/80; Loss: 0.3517
Epoch 8391/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8392/10000; Iter 1/80; Loss: 0.3112
Epoch 8392/10000; Iter 51/80; Loss: 0.3019
Epoch 8392/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8393/10000; Iter 1/80; Loss: 0.3517
Epoch 8393/10000; Iter 51/80; Loss: 0.2969
Epoch 8393/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8394/10000; Iter 1/80; Loss: 0.3218
Epoch 8394/10000; Iter 51/80; Loss: 0.2988
Epoch 8394/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8395/10000; Iter 1/80; Loss: 0.3384
Epoch 8395/10000; Iter 51/80; Loss: 0.3396
Epoch 8395/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.071
Epoch 8396/10000; Iter 1/80; Loss: 0.3147
Epoch 8396/10000; Iter 51/80; Loss: 0.3264
Epoch 8396/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8397/10000; Iter 1/80; Loss: 0.3159
Epoch 8397/10000; Iter 51/80; Loss: 0.3063
Epoch 8397/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8398/10000; Iter 1/80; Loss: 0.3603
Epoch 8398/10000; Iter 51/80; Loss: 0.2736
Epoch 8398/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8399/10000; Iter 1/80; Loss: 0.3838
Epoch 8399/10000; Iter 51/80; Loss: 0.3305
Epoch 8399/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.077
Epoch 8400/10000; Iter 1/80; Loss: 0.3794
Epoch 8400/10000; Iter 51/80; Loss: 0.3509
Epoch 8400/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8401/10000; Iter 1/80; Loss: 0.3639
Epoch 8401/10000; Iter 51/80; Loss: 0.3162
Epoch 8401/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Model saved
Epoch 8402/10000; Iter 1/80; Loss: 0.3372
Epoch 8402/10000; Iter 51/80; Loss: 0.3261
Epoch 8402/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8403/10000; Iter 1/80; Loss: 0.2604
Epoch 8403/10000; Iter 51/80; Loss: 0.3423
Epoch 8403/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.066
Epoch 8404/10000; Iter 1/80; Loss: 0.3109
Epoch 8404/10000; Iter 51/80; Loss: 0.3318
Epoch 8404/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 8405/10000; Iter 1/80; Loss: 0.3640
Epoch 8405/10000; Iter 51/80; Loss: 0.3260
Epoch 8405/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.078
Epoch 8406/10000; Iter 1/80; Loss: 0.3699
Epoch 8406/10000; Iter 51/80; Loss: 0.3259
Epoch 8406/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8407/10000; Iter 1/80; Loss: 0.3024
Epoch 8407/10000; Iter 51/80; Loss: 0.3559
Epoch 8407/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 8408/10000; Iter 1/80; Loss: 0.3147
Epoch 8408/10000; Iter 51/80; Loss: 0.2880
Epoch 8408/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8409/10000; Iter 1/80; Loss: 0.3165
Epoch 8409/10000; Iter 51/80; Loss: 0.3221
Epoch 8409/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8410/10000; Iter 1/80; Loss: 0.3501
Epoch 8410/10000; Iter 51/80; Loss: 0.3243
Epoch 8410/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.064
Epoch 8411/10000; Iter 1/80; Loss: 0.3654
Epoch 8411/10000; Iter 51/80; Loss: 0.2952
Epoch 8411/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8412/10000; Iter 1/80; Loss: 0.2858
Epoch 8412/10000; Iter 51/80; Loss: 0.3297
Epoch 8412/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8413/10000; Iter 1/80; Loss: 0.3191
Epoch 8413/10000; Iter 51/80; Loss: 0.3228
Epoch 8413/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8414/10000; Iter 1/80; Loss: 0.2903
Epoch 8414/10000; Iter 51/80; Loss: 0.3126
Epoch 8414/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8415/10000; Iter 1/80; Loss: 0.3936
Epoch 8415/10000; Iter 51/80; Loss: 0.3112
Epoch 8415/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8416/10000; Iter 1/80; Loss: 0.3449
Epoch 8416/10000; Iter 51/80; Loss: 0.3702
Epoch 8416/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8417/10000; Iter 1/80; Loss: 0.2822
Epoch 8417/10000; Iter 51/80; Loss: 0.3470
Epoch 8417/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.067
Epoch 8418/10000; Iter 1/80; Loss: 0.3162
Epoch 8418/10000; Iter 51/80; Loss: 0.3027
Epoch 8418/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.074
Epoch 8419/10000; Iter 1/80; Loss: 0.3079
Epoch 8419/10000; Iter 51/80; Loss: 0.3577
Epoch 8419/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.067
Epoch 8420/10000; Iter 1/80; Loss: 0.3626
Epoch 8420/10000; Iter 51/80; Loss: 0.3714
Epoch 8420/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.077
Epoch 8421/10000; Iter 1/80; Loss: 0.3159
Epoch 8421/10000; Iter 51/80; Loss: 0.3357
Epoch 8421/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.066
Epoch 8422/10000; Iter 1/80; Loss: 0.3628
Epoch 8422/10000; Iter 51/80; Loss: 0.2926
Epoch 8422/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.075
Epoch 8423/10000; Iter 1/80; Loss: 0.3616
Epoch 8423/10000; Iter 51/80; Loss: 0.3127
Epoch 8423/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.069
Epoch 8424/10000; Iter 1/80; Loss: 0.3602
Epoch 8424/10000; Iter 51/80; Loss: 0.3230
Epoch 8424/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8425/10000; Iter 1/80; Loss: 0.3036
Epoch 8425/10000; Iter 51/80; Loss: 0.3418
Epoch 8425/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.067
Epoch 8426/10000; Iter 1/80; Loss: 0.3204
Epoch 8426/10000; Iter 51/80; Loss: 0.2921
Epoch 8426/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8427/10000; Iter 1/80; Loss: 0.3360
Epoch 8427/10000; Iter 51/80; Loss: 0.4177
Epoch 8427/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 8428/10000; Iter 1/80; Loss: 0.3752
Epoch 8428/10000; Iter 51/80; Loss: 0.3407
Epoch 8428/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 8429/10000; Iter 1/80; Loss: 0.3822
Epoch 8429/10000; Iter 51/80; Loss: 0.3057
Epoch 8429/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 8430/10000; Iter 1/80; Loss: 0.3169
Epoch 8430/10000; Iter 51/80; Loss: 0.3151
Epoch 8430/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8431/10000; Iter 1/80; Loss: 0.2998
Epoch 8431/10000; Iter 51/80; Loss: 0.2868
Epoch 8431/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8432/10000; Iter 1/80; Loss: 0.3084
Epoch 8432/10000; Iter 51/80; Loss: 0.3358
Epoch 8432/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 8433/10000; Iter 1/80; Loss: 0.2681
Epoch 8433/10000; Iter 51/80; Loss: 0.3218
Epoch 8433/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8434/10000; Iter 1/80; Loss: 0.3549
Epoch 8434/10000; Iter 51/80; Loss: 0.2961
Epoch 8434/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.067
Epoch 8435/10000; Iter 1/80; Loss: 0.3622
Epoch 8435/10000; Iter 51/80; Loss: 0.3219
Epoch 8435/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 8436/10000; Iter 1/80; Loss: 0.2860
Epoch 8436/10000; Iter 51/80; Loss: 0.2802
Epoch 8436/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8437/10000; Iter 1/80; Loss: 0.3340
Epoch 8437/10000; Iter 51/80; Loss: 0.2976
Epoch 8437/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.066
Epoch 8438/10000; Iter 1/80; Loss: 0.2831
Epoch 8438/10000; Iter 51/80; Loss: 0.2839
Epoch 8438/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8439/10000; Iter 1/80; Loss: 0.3402
Epoch 8439/10000; Iter 51/80; Loss: 0.3328
Epoch 8439/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8440/10000; Iter 1/80; Loss: 0.3146
Epoch 8440/10000; Iter 51/80; Loss: 0.3462
Epoch 8440/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.069
Epoch 8441/10000; Iter 1/80; Loss: 0.3738
Epoch 8441/10000; Iter 51/80; Loss: 0.2951
Epoch 8441/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8442/10000; Iter 1/80; Loss: 0.3002
Epoch 8442/10000; Iter 51/80; Loss: 0.3195
Epoch 8442/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 8443/10000; Iter 1/80; Loss: 0.3670
Epoch 8443/10000; Iter 51/80; Loss: 0.2940
Epoch 8443/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 8444/10000; Iter 1/80; Loss: 0.3529
Epoch 8444/10000; Iter 51/80; Loss: 0.3204
Epoch 8444/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.078
Epoch 8445/10000; Iter 1/80; Loss: 0.3738
Epoch 8445/10000; Iter 51/80; Loss: 0.3370
Epoch 8445/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8446/10000; Iter 1/80; Loss: 0.3447
Epoch 8446/10000; Iter 51/80; Loss: 0.3011
Epoch 8446/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.069
Epoch 8447/10000; Iter 1/80; Loss: 0.3337
Epoch 8447/10000; Iter 51/80; Loss: 0.3442
Epoch 8447/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.081
Epoch 8448/10000; Iter 1/80; Loss: 0.3209
Epoch 8448/10000; Iter 51/80; Loss: 0.3472
Epoch 8448/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8449/10000; Iter 1/80; Loss: 0.3213
Epoch 8449/10000; Iter 51/80; Loss: 0.3464
Epoch 8449/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.072
Epoch 8450/10000; Iter 1/80; Loss: 0.3055
Epoch 8450/10000; Iter 51/80; Loss: 0.3362
Epoch 8450/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.079
Epoch 8451/10000; Iter 1/80; Loss: 0.3054
Epoch 8451/10000; Iter 51/80; Loss: 0.3108
Epoch 8451/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8452/10000; Iter 1/80; Loss: 0.3630
Epoch 8452/10000; Iter 51/80; Loss: 0.3332
Epoch 8452/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.068
Epoch 8453/10000; Iter 1/80; Loss: 0.3083
Epoch 8453/10000; Iter 51/80; Loss: 0.3485
Epoch 8453/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 8454/10000; Iter 1/80; Loss: 0.3265
Epoch 8454/10000; Iter 51/80; Loss: 0.2860
Epoch 8454/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8455/10000; Iter 1/80; Loss: 0.3731
Epoch 8455/10000; Iter 51/80; Loss: 0.3119
Epoch 8455/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8456/10000; Iter 1/80; Loss: 0.3247
Epoch 8456/10000; Iter 51/80; Loss: 0.3191
Epoch 8456/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8457/10000; Iter 1/80; Loss: 0.3893
Epoch 8457/10000; Iter 51/80; Loss: 0.3398
Epoch 8457/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8458/10000; Iter 1/80; Loss: 0.3693
Epoch 8458/10000; Iter 51/80; Loss: 0.2875
Epoch 8458/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8459/10000; Iter 1/80; Loss: 0.2982
Epoch 8459/10000; Iter 51/80; Loss: 0.3592
Epoch 8459/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 8460/10000; Iter 1/80; Loss: 0.2916
Epoch 8460/10000; Iter 51/80; Loss: 0.2606
Epoch 8460/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8461/10000; Iter 1/80; Loss: 0.3391
Epoch 8461/10000; Iter 51/80; Loss: 0.3711
Epoch 8461/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 8462/10000; Iter 1/80; Loss: 0.3327
Epoch 8462/10000; Iter 51/80; Loss: 0.2893
Epoch 8462/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8463/10000; Iter 1/80; Loss: 0.3106
Epoch 8463/10000; Iter 51/80; Loss: 0.3426
Epoch 8463/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 8464/10000; Iter 1/80; Loss: 0.2957
Epoch 8464/10000; Iter 51/80; Loss: 0.2809
Epoch 8464/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 8465/10000; Iter 1/80; Loss: 0.4062
Epoch 8465/10000; Iter 51/80; Loss: 0.2825
Epoch 8465/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8466/10000; Iter 1/80; Loss: 0.3858
Epoch 8466/10000; Iter 51/80; Loss: 0.3011
Epoch 8466/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 8467/10000; Iter 1/80; Loss: 0.2993
Epoch 8467/10000; Iter 51/80; Loss: 0.3444
Epoch 8467/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.075
Epoch 8468/10000; Iter 1/80; Loss: 0.3233
Epoch 8468/10000; Iter 51/80; Loss: 0.2957
Epoch 8468/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.067
Epoch 8469/10000; Iter 1/80; Loss: 0.3174
Epoch 8469/10000; Iter 51/80; Loss: 0.3259
Epoch 8469/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 8470/10000; Iter 1/80; Loss: 0.3474
Epoch 8470/10000; Iter 51/80; Loss: 0.3479
Epoch 8470/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8471/10000; Iter 1/80; Loss: 0.3089
Epoch 8471/10000; Iter 51/80; Loss: 0.3636
Epoch 8471/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8472/10000; Iter 1/80; Loss: 0.3062
Epoch 8472/10000; Iter 51/80; Loss: 0.3119
Epoch 8472/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 8473/10000; Iter 1/80; Loss: 0.3288
Epoch 8473/10000; Iter 51/80; Loss: 0.3144
Epoch 8473/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8474/10000; Iter 1/80; Loss: 0.3185
Epoch 8474/10000; Iter 51/80; Loss: 0.3492
Epoch 8474/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8475/10000; Iter 1/80; Loss: 0.3349
Epoch 8475/10000; Iter 51/80; Loss: 0.3003
Epoch 8475/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8476/10000; Iter 1/80; Loss: 0.2971
Epoch 8476/10000; Iter 51/80; Loss: 0.3121
Epoch 8476/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8477/10000; Iter 1/80; Loss: 0.3408
Epoch 8477/10000; Iter 51/80; Loss: 0.3202
Epoch 8477/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8478/10000; Iter 1/80; Loss: 0.3269
Epoch 8478/10000; Iter 51/80; Loss: 0.2906
Epoch 8478/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8479/10000; Iter 1/80; Loss: 0.3447
Epoch 8479/10000; Iter 51/80; Loss: 0.3044
Epoch 8479/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 8480/10000; Iter 1/80; Loss: 0.3213
Epoch 8480/10000; Iter 51/80; Loss: 0.3562
Epoch 8480/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 8481/10000; Iter 1/80; Loss: 0.3773
Epoch 8481/10000; Iter 51/80; Loss: 0.3200
Epoch 8481/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 8482/10000; Iter 1/80; Loss: 0.4309
Epoch 8482/10000; Iter 51/80; Loss: 0.3142
Epoch 8482/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8483/10000; Iter 1/80; Loss: 0.2490
Epoch 8483/10000; Iter 51/80; Loss: 0.2845
Epoch 8483/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.077
Epoch 8484/10000; Iter 1/80; Loss: 0.3238
Epoch 8484/10000; Iter 51/80; Loss: 0.3012
Epoch 8484/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8485/10000; Iter 1/80; Loss: 0.3507
Epoch 8485/10000; Iter 51/80; Loss: 0.3367
Epoch 8485/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 8486/10000; Iter 1/80; Loss: 0.2905
Epoch 8486/10000; Iter 51/80; Loss: 0.3367
Epoch 8486/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 8487/10000; Iter 1/80; Loss: 0.3089
Epoch 8487/10000; Iter 51/80; Loss: 0.2955
Epoch 8487/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.081
Epoch 8488/10000; Iter 1/80; Loss: 0.3091
Epoch 8488/10000; Iter 51/80; Loss: 0.3218
Epoch 8488/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8489/10000; Iter 1/80; Loss: 0.3176
Epoch 8489/10000; Iter 51/80; Loss: 0.3102
Epoch 8489/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8490/10000; Iter 1/80; Loss: 0.3887
Epoch 8490/10000; Iter 51/80; Loss: 0.3651
Epoch 8490/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 8491/10000; Iter 1/80; Loss: 0.3546
Epoch 8491/10000; Iter 51/80; Loss: 0.3278
Epoch 8491/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 8492/10000; Iter 1/80; Loss: 0.3342
Epoch 8492/10000; Iter 51/80; Loss: 0.3422
Epoch 8492/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.069
Epoch 8493/10000; Iter 1/80; Loss: 0.3372
Epoch 8493/10000; Iter 51/80; Loss: 0.3358
Epoch 8493/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8494/10000; Iter 1/80; Loss: 0.3768
Epoch 8494/10000; Iter 51/80; Loss: 0.3775
Epoch 8494/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.068
Epoch 8495/10000; Iter 1/80; Loss: 0.4042
Epoch 8495/10000; Iter 51/80; Loss: 0.3864
Epoch 8495/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.069
Epoch 8496/10000; Iter 1/80; Loss: 0.3160
Epoch 8496/10000; Iter 51/80; Loss: 0.3402
Epoch 8496/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.068
Epoch 8497/10000; Iter 1/80; Loss: 0.3015
Epoch 8497/10000; Iter 51/80; Loss: 0.2817
Epoch 8497/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.081
Epoch 8498/10000; Iter 1/80; Loss: 0.3417
Epoch 8498/10000; Iter 51/80; Loss: 0.3176
Epoch 8498/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 8499/10000; Iter 1/80; Loss: 0.2984
Epoch 8499/10000; Iter 51/80; Loss: 0.3157
Epoch 8499/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 8500/10000; Iter 1/80; Loss: 0.3429
Epoch 8500/10000; Iter 51/80; Loss: 0.3572
Epoch 8500/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.08
Epoch 8501/10000; Iter 1/80; Loss: 0.3037
Epoch 8501/10000; Iter 51/80; Loss: 0.3253
Epoch 8501/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.078
Model saved
Epoch 8502/10000; Iter 1/80; Loss: 0.2918
Epoch 8502/10000; Iter 51/80; Loss: 0.3881
Epoch 8502/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 8503/10000; Iter 1/80; Loss: 0.3700
Epoch 8503/10000; Iter 51/80; Loss: 0.3416
Epoch 8503/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8504/10000; Iter 1/80; Loss: 0.3457
Epoch 8504/10000; Iter 51/80; Loss: 0.3466
Epoch 8504/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8505/10000; Iter 1/80; Loss: 0.3580
Epoch 8505/10000; Iter 51/80; Loss: 0.3557
Epoch 8505/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8506/10000; Iter 1/80; Loss: 0.3343
Epoch 8506/10000; Iter 51/80; Loss: 0.3162
Epoch 8506/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.078
Epoch 8507/10000; Iter 1/80; Loss: 0.3239
Epoch 8507/10000; Iter 51/80; Loss: 0.2660
Epoch 8507/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8508/10000; Iter 1/80; Loss: 0.2713
Epoch 8508/10000; Iter 51/80; Loss: 0.2845
Epoch 8508/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 8509/10000; Iter 1/80; Loss: 0.3248
Epoch 8509/10000; Iter 51/80; Loss: 0.3461
Epoch 8509/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8510/10000; Iter 1/80; Loss: 0.2906
Epoch 8510/10000; Iter 51/80; Loss: 0.3129
Epoch 8510/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.09
Epoch 8511/10000; Iter 1/80; Loss: 0.3788
Epoch 8511/10000; Iter 51/80; Loss: 0.3232
Epoch 8511/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.083
Epoch 8512/10000; Iter 1/80; Loss: 0.2939
Epoch 8512/10000; Iter 51/80; Loss: 0.3644
Epoch 8512/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8513/10000; Iter 1/80; Loss: 0.2850
Epoch 8513/10000; Iter 51/80; Loss: 0.3551
Epoch 8513/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8514/10000; Iter 1/80; Loss: 0.3268
Epoch 8514/10000; Iter 51/80; Loss: 0.2950
Epoch 8514/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8515/10000; Iter 1/80; Loss: 0.3693
Epoch 8515/10000; Iter 51/80; Loss: 0.3589
Epoch 8515/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.064
Epoch 8516/10000; Iter 1/80; Loss: 0.3842
Epoch 8516/10000; Iter 51/80; Loss: 0.3511
Epoch 8516/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8517/10000; Iter 1/80; Loss: 0.3063
Epoch 8517/10000; Iter 51/80; Loss: 0.3616
Epoch 8517/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8518/10000; Iter 1/80; Loss: 0.2885
Epoch 8518/10000; Iter 51/80; Loss: 0.2811
Epoch 8518/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.087
Epoch 8519/10000; Iter 1/80; Loss: 0.3415
Epoch 8519/10000; Iter 51/80; Loss: 0.3762
Epoch 8519/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.065
Epoch 8520/10000; Iter 1/80; Loss: 0.3006
Epoch 8520/10000; Iter 51/80; Loss: 0.3322
Epoch 8520/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 8521/10000; Iter 1/80; Loss: 0.2937
Epoch 8521/10000; Iter 51/80; Loss: 0.3614
Epoch 8521/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 8522/10000; Iter 1/80; Loss: 0.3074
Epoch 8522/10000; Iter 51/80; Loss: 0.3658
Epoch 8522/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8523/10000; Iter 1/80; Loss: 0.3101
Epoch 8523/10000; Iter 51/80; Loss: 0.3561
Epoch 8523/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 8524/10000; Iter 1/80; Loss: 0.3929
Epoch 8524/10000; Iter 51/80; Loss: 0.3262
Epoch 8524/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.082
Epoch 8525/10000; Iter 1/80; Loss: 0.3211
Epoch 8525/10000; Iter 51/80; Loss: 0.3478
Epoch 8525/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 8526/10000; Iter 1/80; Loss: 0.2875
Epoch 8526/10000; Iter 51/80; Loss: 0.3253
Epoch 8526/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8527/10000; Iter 1/80; Loss: 0.3445
Epoch 8527/10000; Iter 51/80; Loss: 0.3389
Epoch 8527/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8528/10000; Iter 1/80; Loss: 0.3480
Epoch 8528/10000; Iter 51/80; Loss: 0.3313
Epoch 8528/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 8529/10000; Iter 1/80; Loss: 0.3062
Epoch 8529/10000; Iter 51/80; Loss: 0.3527
Epoch 8529/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8530/10000; Iter 1/80; Loss: 0.2897
Epoch 8530/10000; Iter 51/80; Loss: 0.2951
Epoch 8530/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8531/10000; Iter 1/80; Loss: 0.3028
Epoch 8531/10000; Iter 51/80; Loss: 0.3415
Epoch 8531/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 8532/10000; Iter 1/80; Loss: 0.3313
Epoch 8532/10000; Iter 51/80; Loss: 0.3323
Epoch 8532/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.069
Epoch 8533/10000; Iter 1/80; Loss: 0.3260
Epoch 8533/10000; Iter 51/80; Loss: 0.3672
Epoch 8533/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.065
Epoch 8534/10000; Iter 1/80; Loss: 0.3218
Epoch 8534/10000; Iter 51/80; Loss: 0.3310
Epoch 8534/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.066
Epoch 8535/10000; Iter 1/80; Loss: 0.3176
Epoch 8535/10000; Iter 51/80; Loss: 0.3721
Epoch 8535/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.072
Epoch 8536/10000; Iter 1/80; Loss: 0.3476
Epoch 8536/10000; Iter 51/80; Loss: 0.3215
Epoch 8536/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 8537/10000; Iter 1/80; Loss: 0.3747
Epoch 8537/10000; Iter 51/80; Loss: 0.3232
Epoch 8537/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8538/10000; Iter 1/80; Loss: 0.3845
Epoch 8538/10000; Iter 51/80; Loss: 0.3213
Epoch 8538/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8539/10000; Iter 1/80; Loss: 0.2931
Epoch 8539/10000; Iter 51/80; Loss: 0.2893
Epoch 8539/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.072
Epoch 8540/10000; Iter 1/80; Loss: 0.3517
Epoch 8540/10000; Iter 51/80; Loss: 0.3060
Epoch 8540/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.074
Epoch 8541/10000; Iter 1/80; Loss: 0.3100
Epoch 8541/10000; Iter 51/80; Loss: 0.3146
Epoch 8541/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8542/10000; Iter 1/80; Loss: 0.3547
Epoch 8542/10000; Iter 51/80; Loss: 0.3080
Epoch 8542/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8543/10000; Iter 1/80; Loss: 0.3207
Epoch 8543/10000; Iter 51/80; Loss: 0.3264
Epoch 8543/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 8544/10000; Iter 1/80; Loss: 0.3318
Epoch 8544/10000; Iter 51/80; Loss: 0.3263
Epoch 8544/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.08
Epoch 8545/10000; Iter 1/80; Loss: 0.3064
Epoch 8545/10000; Iter 51/80; Loss: 0.3281
Epoch 8545/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8546/10000; Iter 1/80; Loss: 0.3081
Epoch 8546/10000; Iter 51/80; Loss: 0.2967
Epoch 8546/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8547/10000; Iter 1/80; Loss: 0.3635
Epoch 8547/10000; Iter 51/80; Loss: 0.4390
Epoch 8547/10000; Iter 80/80; Training Loss: 0.3370, Test Loss: 0.075
Epoch 8548/10000; Iter 1/80; Loss: 0.3312
Epoch 8548/10000; Iter 51/80; Loss: 0.2930
Epoch 8548/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8549/10000; Iter 1/80; Loss: 0.3035
Epoch 8549/10000; Iter 51/80; Loss: 0.3004
Epoch 8549/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8550/10000; Iter 1/80; Loss: 0.3229
Epoch 8550/10000; Iter 51/80; Loss: 0.3248
Epoch 8550/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.079
Epoch 8551/10000; Iter 1/80; Loss: 0.3126
Epoch 8551/10000; Iter 51/80; Loss: 0.3074
Epoch 8551/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.08
Epoch 8552/10000; Iter 1/80; Loss: 0.3140
Epoch 8552/10000; Iter 51/80; Loss: 0.3749
Epoch 8552/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8553/10000; Iter 1/80; Loss: 0.3512
Epoch 8553/10000; Iter 51/80; Loss: 0.3819
Epoch 8553/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.075
Epoch 8554/10000; Iter 1/80; Loss: 0.3366
Epoch 8554/10000; Iter 51/80; Loss: 0.3313
Epoch 8554/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.066
Epoch 8555/10000; Iter 1/80; Loss: 0.3677
Epoch 8555/10000; Iter 51/80; Loss: 0.3176
Epoch 8555/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8556/10000; Iter 1/80; Loss: 0.3328
Epoch 8556/10000; Iter 51/80; Loss: 0.3229
Epoch 8556/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8557/10000; Iter 1/80; Loss: 0.3478
Epoch 8557/10000; Iter 51/80; Loss: 0.3328
Epoch 8557/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8558/10000; Iter 1/80; Loss: 0.3616
Epoch 8558/10000; Iter 51/80; Loss: 0.3314
Epoch 8558/10000; Iter 80/80; Training Loss: 0.3380, Test Loss: 0.068
Epoch 8559/10000; Iter 1/80; Loss: 0.3375
Epoch 8559/10000; Iter 51/80; Loss: 0.3435
Epoch 8559/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8560/10000; Iter 1/80; Loss: 0.2685
Epoch 8560/10000; Iter 51/80; Loss: 0.3317
Epoch 8560/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8561/10000; Iter 1/80; Loss: 0.2835
Epoch 8561/10000; Iter 51/80; Loss: 0.3538
Epoch 8561/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8562/10000; Iter 1/80; Loss: 0.3629
Epoch 8562/10000; Iter 51/80; Loss: 0.2933
Epoch 8562/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.082
Epoch 8563/10000; Iter 1/80; Loss: 0.2953
Epoch 8563/10000; Iter 51/80; Loss: 0.2992
Epoch 8563/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8564/10000; Iter 1/80; Loss: 0.3799
Epoch 8564/10000; Iter 51/80; Loss: 0.3175
Epoch 8564/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.066
Epoch 8565/10000; Iter 1/80; Loss: 0.3584
Epoch 8565/10000; Iter 51/80; Loss: 0.3584
Epoch 8565/10000; Iter 80/80; Training Loss: 0.3360, Test Loss: 0.069
Epoch 8566/10000; Iter 1/80; Loss: 0.3156
Epoch 8566/10000; Iter 51/80; Loss: 0.3428
Epoch 8566/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.062
Epoch 8567/10000; Iter 1/80; Loss: 0.3038
Epoch 8567/10000; Iter 51/80; Loss: 0.2838
Epoch 8567/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8568/10000; Iter 1/80; Loss: 0.3634
Epoch 8568/10000; Iter 51/80; Loss: 0.3344
Epoch 8568/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.068
Epoch 8569/10000; Iter 1/80; Loss: 0.3553
Epoch 8569/10000; Iter 51/80; Loss: 0.3022
Epoch 8569/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.077
Epoch 8570/10000; Iter 1/80; Loss: 0.3133
Epoch 8570/10000; Iter 51/80; Loss: 0.4298
Epoch 8570/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8571/10000; Iter 1/80; Loss: 0.3013
Epoch 8571/10000; Iter 51/80; Loss: 0.3139
Epoch 8571/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8572/10000; Iter 1/80; Loss: 0.3139
Epoch 8572/10000; Iter 51/80; Loss: 0.3059
Epoch 8572/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.083
Epoch 8573/10000; Iter 1/80; Loss: 0.3354
Epoch 8573/10000; Iter 51/80; Loss: 0.3263
Epoch 8573/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8574/10000; Iter 1/80; Loss: 0.3043
Epoch 8574/10000; Iter 51/80; Loss: 0.2973
Epoch 8574/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8575/10000; Iter 1/80; Loss: 0.3474
Epoch 8575/10000; Iter 51/80; Loss: 0.3105
Epoch 8575/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8576/10000; Iter 1/80; Loss: 0.3488
Epoch 8576/10000; Iter 51/80; Loss: 0.3656
Epoch 8576/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8577/10000; Iter 1/80; Loss: 0.3418
Epoch 8577/10000; Iter 51/80; Loss: 0.3364
Epoch 8577/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8578/10000; Iter 1/80; Loss: 0.2797
Epoch 8578/10000; Iter 51/80; Loss: 0.3584
Epoch 8578/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8579/10000; Iter 1/80; Loss: 0.3435
Epoch 8579/10000; Iter 51/80; Loss: 0.3465
Epoch 8579/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8580/10000; Iter 1/80; Loss: 0.3341
Epoch 8580/10000; Iter 51/80; Loss: 0.3298
Epoch 8580/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.068
Epoch 8581/10000; Iter 1/80; Loss: 0.3468
Epoch 8581/10000; Iter 51/80; Loss: 0.2982
Epoch 8581/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.071
Epoch 8582/10000; Iter 1/80; Loss: 0.3303
Epoch 8582/10000; Iter 51/80; Loss: 0.3174
Epoch 8582/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8583/10000; Iter 1/80; Loss: 0.3035
Epoch 8583/10000; Iter 51/80; Loss: 0.3059
Epoch 8583/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8584/10000; Iter 1/80; Loss: 0.3844
Epoch 8584/10000; Iter 51/80; Loss: 0.3592
Epoch 8584/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.072
Epoch 8585/10000; Iter 1/80; Loss: 0.3349
Epoch 8585/10000; Iter 51/80; Loss: 0.2842
Epoch 8585/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 8586/10000; Iter 1/80; Loss: 0.3038
Epoch 8586/10000; Iter 51/80; Loss: 0.2710
Epoch 8586/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8587/10000; Iter 1/80; Loss: 0.3542
Epoch 8587/10000; Iter 51/80; Loss: 0.3129
Epoch 8587/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.071
Epoch 8588/10000; Iter 1/80; Loss: 0.3080
Epoch 8588/10000; Iter 51/80; Loss: 0.2708
Epoch 8588/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 8589/10000; Iter 1/80; Loss: 0.3069
Epoch 8589/10000; Iter 51/80; Loss: 0.3815
Epoch 8589/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8590/10000; Iter 1/80; Loss: 0.3024
Epoch 8590/10000; Iter 51/80; Loss: 0.3435
Epoch 8590/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.066
Epoch 8591/10000; Iter 1/80; Loss: 0.3327
Epoch 8591/10000; Iter 51/80; Loss: 0.3402
Epoch 8591/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.078
Epoch 8592/10000; Iter 1/80; Loss: 0.3875
Epoch 8592/10000; Iter 51/80; Loss: 0.2875
Epoch 8592/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.068
Epoch 8593/10000; Iter 1/80; Loss: 0.3887
Epoch 8593/10000; Iter 51/80; Loss: 0.3217
Epoch 8593/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.071
Epoch 8594/10000; Iter 1/80; Loss: 0.4128
Epoch 8594/10000; Iter 51/80; Loss: 0.3961
Epoch 8594/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.068
Epoch 8595/10000; Iter 1/80; Loss: 0.3295
Epoch 8595/10000; Iter 51/80; Loss: 0.2799
Epoch 8595/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 8596/10000; Iter 1/80; Loss: 0.3395
Epoch 8596/10000; Iter 51/80; Loss: 0.2754
Epoch 8596/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 8597/10000; Iter 1/80; Loss: 0.3315
Epoch 8597/10000; Iter 51/80; Loss: 0.3073
Epoch 8597/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 8598/10000; Iter 1/80; Loss: 0.3252
Epoch 8598/10000; Iter 51/80; Loss: 0.3579
Epoch 8598/10000; Iter 80/80; Training Loss: 0.3350, Test Loss: 0.075
Epoch 8599/10000; Iter 1/80; Loss: 0.3886
Epoch 8599/10000; Iter 51/80; Loss: 0.3390
Epoch 8599/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8600/10000; Iter 1/80; Loss: 0.3158
Epoch 8600/10000; Iter 51/80; Loss: 0.3135
Epoch 8600/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8601/10000; Iter 1/80; Loss: 0.3720
Epoch 8601/10000; Iter 51/80; Loss: 0.2566
Epoch 8601/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Model saved
Epoch 8602/10000; Iter 1/80; Loss: 0.3805
Epoch 8602/10000; Iter 51/80; Loss: 0.3250
Epoch 8602/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.079
Epoch 8603/10000; Iter 1/80; Loss: 0.3510
Epoch 8603/10000; Iter 51/80; Loss: 0.3541
Epoch 8603/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.082
Epoch 8604/10000; Iter 1/80; Loss: 0.3147
Epoch 8604/10000; Iter 51/80; Loss: 0.3188
Epoch 8604/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8605/10000; Iter 1/80; Loss: 0.3348
Epoch 8605/10000; Iter 51/80; Loss: 0.3015
Epoch 8605/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 8606/10000; Iter 1/80; Loss: 0.3427
Epoch 8606/10000; Iter 51/80; Loss: 0.3197
Epoch 8606/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 8607/10000; Iter 1/80; Loss: 0.3088
Epoch 8607/10000; Iter 51/80; Loss: 0.2817
Epoch 8607/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8608/10000; Iter 1/80; Loss: 0.3341
Epoch 8608/10000; Iter 51/80; Loss: 0.3945
Epoch 8608/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.067
Epoch 8609/10000; Iter 1/80; Loss: 0.3300
Epoch 8609/10000; Iter 51/80; Loss: 0.3335
Epoch 8609/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.064
Epoch 8610/10000; Iter 1/80; Loss: 0.3302
Epoch 8610/10000; Iter 51/80; Loss: 0.3651
Epoch 8610/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8611/10000; Iter 1/80; Loss: 0.2989
Epoch 8611/10000; Iter 51/80; Loss: 0.3213
Epoch 8611/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 8612/10000; Iter 1/80; Loss: 0.3193
Epoch 8612/10000; Iter 51/80; Loss: 0.3066
Epoch 8612/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 8613/10000; Iter 1/80; Loss: 0.3027
Epoch 8613/10000; Iter 51/80; Loss: 0.4009
Epoch 8613/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 8614/10000; Iter 1/80; Loss: 0.3034
Epoch 8614/10000; Iter 51/80; Loss: 0.3853
Epoch 8614/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.061
Epoch 8615/10000; Iter 1/80; Loss: 0.3288
Epoch 8615/10000; Iter 51/80; Loss: 0.3514
Epoch 8615/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.068
Epoch 8616/10000; Iter 1/80; Loss: 0.2811
Epoch 8616/10000; Iter 51/80; Loss: 0.3122
Epoch 8616/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 8617/10000; Iter 1/80; Loss: 0.2619
Epoch 8617/10000; Iter 51/80; Loss: 0.3610
Epoch 8617/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 8618/10000; Iter 1/80; Loss: 0.3926
Epoch 8618/10000; Iter 51/80; Loss: 0.3238
Epoch 8618/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.077
Epoch 8619/10000; Iter 1/80; Loss: 0.3064
Epoch 8619/10000; Iter 51/80; Loss: 0.3154
Epoch 8619/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8620/10000; Iter 1/80; Loss: 0.3138
Epoch 8620/10000; Iter 51/80; Loss: 0.3635
Epoch 8620/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8621/10000; Iter 1/80; Loss: 0.3420
Epoch 8621/10000; Iter 51/80; Loss: 0.3204
Epoch 8621/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8622/10000; Iter 1/80; Loss: 0.3165
Epoch 8622/10000; Iter 51/80; Loss: 0.2929
Epoch 8622/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.068
Epoch 8623/10000; Iter 1/80; Loss: 0.2927
Epoch 8623/10000; Iter 51/80; Loss: 0.3595
Epoch 8623/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8624/10000; Iter 1/80; Loss: 0.3086
Epoch 8624/10000; Iter 51/80; Loss: 0.3568
Epoch 8624/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8625/10000; Iter 1/80; Loss: 0.3103
Epoch 8625/10000; Iter 51/80; Loss: 0.3425
Epoch 8625/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8626/10000; Iter 1/80; Loss: 0.3310
Epoch 8626/10000; Iter 51/80; Loss: 0.3026
Epoch 8626/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 8627/10000; Iter 1/80; Loss: 0.3495
Epoch 8627/10000; Iter 51/80; Loss: 0.3837
Epoch 8627/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8628/10000; Iter 1/80; Loss: 0.3251
Epoch 8628/10000; Iter 51/80; Loss: 0.2848
Epoch 8628/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8629/10000; Iter 1/80; Loss: 0.3205
Epoch 8629/10000; Iter 51/80; Loss: 0.3306
Epoch 8629/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.081
Epoch 8630/10000; Iter 1/80; Loss: 0.2957
Epoch 8630/10000; Iter 51/80; Loss: 0.4060
Epoch 8630/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 8631/10000; Iter 1/80; Loss: 0.3108
Epoch 8631/10000; Iter 51/80; Loss: 0.2935
Epoch 8631/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.074
Epoch 8632/10000; Iter 1/80; Loss: 0.3036
Epoch 8632/10000; Iter 51/80; Loss: 0.3246
Epoch 8632/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8633/10000; Iter 1/80; Loss: 0.3159
Epoch 8633/10000; Iter 51/80; Loss: 0.3951
Epoch 8633/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.072
Epoch 8634/10000; Iter 1/80; Loss: 0.3049
Epoch 8634/10000; Iter 51/80; Loss: 0.3063
Epoch 8634/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8635/10000; Iter 1/80; Loss: 0.3181
Epoch 8635/10000; Iter 51/80; Loss: 0.3155
Epoch 8635/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8636/10000; Iter 1/80; Loss: 0.2709
Epoch 8636/10000; Iter 51/80; Loss: 0.4026
Epoch 8636/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.063
Epoch 8637/10000; Iter 1/80; Loss: 0.3113
Epoch 8637/10000; Iter 51/80; Loss: 0.3515
Epoch 8637/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8638/10000; Iter 1/80; Loss: 0.3212
Epoch 8638/10000; Iter 51/80; Loss: 0.3533
Epoch 8638/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8639/10000; Iter 1/80; Loss: 0.3144
Epoch 8639/10000; Iter 51/80; Loss: 0.2741
Epoch 8639/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8640/10000; Iter 1/80; Loss: 0.3162
Epoch 8640/10000; Iter 51/80; Loss: 0.3200
Epoch 8640/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 8641/10000; Iter 1/80; Loss: 0.3350
Epoch 8641/10000; Iter 51/80; Loss: 0.3184
Epoch 8641/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 8642/10000; Iter 1/80; Loss: 0.2955
Epoch 8642/10000; Iter 51/80; Loss: 0.3253
Epoch 8642/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8643/10000; Iter 1/80; Loss: 0.3610
Epoch 8643/10000; Iter 51/80; Loss: 0.3489
Epoch 8643/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.08
Epoch 8644/10000; Iter 1/80; Loss: 0.3282
Epoch 8644/10000; Iter 51/80; Loss: 0.3770
Epoch 8644/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.082
Epoch 8645/10000; Iter 1/80; Loss: 0.3269
Epoch 8645/10000; Iter 51/80; Loss: 0.3605
Epoch 8645/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8646/10000; Iter 1/80; Loss: 0.3148
Epoch 8646/10000; Iter 51/80; Loss: 0.3356
Epoch 8646/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8647/10000; Iter 1/80; Loss: 0.3268
Epoch 8647/10000; Iter 51/80; Loss: 0.2868
Epoch 8647/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 8648/10000; Iter 1/80; Loss: 0.3336
Epoch 8648/10000; Iter 51/80; Loss: 0.3363
Epoch 8648/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 8649/10000; Iter 1/80; Loss: 0.3105
Epoch 8649/10000; Iter 51/80; Loss: 0.3575
Epoch 8649/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 8650/10000; Iter 1/80; Loss: 0.3806
Epoch 8650/10000; Iter 51/80; Loss: 0.3228
Epoch 8650/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8651/10000; Iter 1/80; Loss: 0.3115
Epoch 8651/10000; Iter 51/80; Loss: 0.3111
Epoch 8651/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.067
Epoch 8652/10000; Iter 1/80; Loss: 0.3151
Epoch 8652/10000; Iter 51/80; Loss: 0.2986
Epoch 8652/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8653/10000; Iter 1/80; Loss: 0.2727
Epoch 8653/10000; Iter 51/80; Loss: 0.3064
Epoch 8653/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.083
Epoch 8654/10000; Iter 1/80; Loss: 0.3214
Epoch 8654/10000; Iter 51/80; Loss: 0.3405
Epoch 8654/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.081
Epoch 8655/10000; Iter 1/80; Loss: 0.3090
Epoch 8655/10000; Iter 51/80; Loss: 0.3482
Epoch 8655/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8656/10000; Iter 1/80; Loss: 0.3487
Epoch 8656/10000; Iter 51/80; Loss: 0.3818
Epoch 8656/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8657/10000; Iter 1/80; Loss: 0.2662
Epoch 8657/10000; Iter 51/80; Loss: 0.3333
Epoch 8657/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8658/10000; Iter 1/80; Loss: 0.3079
Epoch 8658/10000; Iter 51/80; Loss: 0.3627
Epoch 8658/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8659/10000; Iter 1/80; Loss: 0.3756
Epoch 8659/10000; Iter 51/80; Loss: 0.2511
Epoch 8659/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8660/10000; Iter 1/80; Loss: 0.3836
Epoch 8660/10000; Iter 51/80; Loss: 0.3275
Epoch 8660/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8661/10000; Iter 1/80; Loss: 0.2944
Epoch 8661/10000; Iter 51/80; Loss: 0.3317
Epoch 8661/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.077
Epoch 8662/10000; Iter 1/80; Loss: 0.3764
Epoch 8662/10000; Iter 51/80; Loss: 0.3377
Epoch 8662/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8663/10000; Iter 1/80; Loss: 0.3296
Epoch 8663/10000; Iter 51/80; Loss: 0.3385
Epoch 8663/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 8664/10000; Iter 1/80; Loss: 0.3035
Epoch 8664/10000; Iter 51/80; Loss: 0.3220
Epoch 8664/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 8665/10000; Iter 1/80; Loss: 0.2946
Epoch 8665/10000; Iter 51/80; Loss: 0.3344
Epoch 8665/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 8666/10000; Iter 1/80; Loss: 0.3583
Epoch 8666/10000; Iter 51/80; Loss: 0.2941
Epoch 8666/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.07
Epoch 8667/10000; Iter 1/80; Loss: 0.3232
Epoch 8667/10000; Iter 51/80; Loss: 0.3682
Epoch 8667/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.066
Epoch 8668/10000; Iter 1/80; Loss: 0.3156
Epoch 8668/10000; Iter 51/80; Loss: 0.3320
Epoch 8668/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.067
Epoch 8669/10000; Iter 1/80; Loss: 0.2912
Epoch 8669/10000; Iter 51/80; Loss: 0.3025
Epoch 8669/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8670/10000; Iter 1/80; Loss: 0.3058
Epoch 8670/10000; Iter 51/80; Loss: 0.2878
Epoch 8670/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.07
Epoch 8671/10000; Iter 1/80; Loss: 0.3439
Epoch 8671/10000; Iter 51/80; Loss: 0.2851
Epoch 8671/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 8672/10000; Iter 1/80; Loss: 0.3721
Epoch 8672/10000; Iter 51/80; Loss: 0.3382
Epoch 8672/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8673/10000; Iter 1/80; Loss: 0.2910
Epoch 8673/10000; Iter 51/80; Loss: 0.3025
Epoch 8673/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.07
Epoch 8674/10000; Iter 1/80; Loss: 0.3693
Epoch 8674/10000; Iter 51/80; Loss: 0.2984
Epoch 8674/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 8675/10000; Iter 1/80; Loss: 0.3272
Epoch 8675/10000; Iter 51/80; Loss: 0.3824
Epoch 8675/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8676/10000; Iter 1/80; Loss: 0.3092
Epoch 8676/10000; Iter 51/80; Loss: 0.3395
Epoch 8676/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8677/10000; Iter 1/80; Loss: 0.3982
Epoch 8677/10000; Iter 51/80; Loss: 0.3784
Epoch 8677/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8678/10000; Iter 1/80; Loss: 0.2800
Epoch 8678/10000; Iter 51/80; Loss: 0.3207
Epoch 8678/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.088
Epoch 8679/10000; Iter 1/80; Loss: 0.3090
Epoch 8679/10000; Iter 51/80; Loss: 0.3038
Epoch 8679/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.07
Epoch 8680/10000; Iter 1/80; Loss: 0.2797
Epoch 8680/10000; Iter 51/80; Loss: 0.2971
Epoch 8680/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8681/10000; Iter 1/80; Loss: 0.3737
Epoch 8681/10000; Iter 51/80; Loss: 0.3689
Epoch 8681/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8682/10000; Iter 1/80; Loss: 0.3172
Epoch 8682/10000; Iter 51/80; Loss: 0.3245
Epoch 8682/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 8683/10000; Iter 1/80; Loss: 0.2968
Epoch 8683/10000; Iter 51/80; Loss: 0.3358
Epoch 8683/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8684/10000; Iter 1/80; Loss: 0.3550
Epoch 8684/10000; Iter 51/80; Loss: 0.3108
Epoch 8684/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.069
Epoch 8685/10000; Iter 1/80; Loss: 0.3274
Epoch 8685/10000; Iter 51/80; Loss: 0.3264
Epoch 8685/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.07
Epoch 8686/10000; Iter 1/80; Loss: 0.2999
Epoch 8686/10000; Iter 51/80; Loss: 0.3574
Epoch 8686/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.083
Epoch 8687/10000; Iter 1/80; Loss: 0.2908
Epoch 8687/10000; Iter 51/80; Loss: 0.3656
Epoch 8687/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 8688/10000; Iter 1/80; Loss: 0.3268
Epoch 8688/10000; Iter 51/80; Loss: 0.3525
Epoch 8688/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 8689/10000; Iter 1/80; Loss: 0.3386
Epoch 8689/10000; Iter 51/80; Loss: 0.2950
Epoch 8689/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 8690/10000; Iter 1/80; Loss: 0.3699
Epoch 8690/10000; Iter 51/80; Loss: 0.3435
Epoch 8690/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.078
Epoch 8691/10000; Iter 1/80; Loss: 0.3113
Epoch 8691/10000; Iter 51/80; Loss: 0.2998
Epoch 8691/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8692/10000; Iter 1/80; Loss: 0.3300
Epoch 8692/10000; Iter 51/80; Loss: 0.3913
Epoch 8692/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8693/10000; Iter 1/80; Loss: 0.3153
Epoch 8693/10000; Iter 51/80; Loss: 0.3174
Epoch 8693/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.081
Epoch 8694/10000; Iter 1/80; Loss: 0.3430
Epoch 8694/10000; Iter 51/80; Loss: 0.2934
Epoch 8694/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8695/10000; Iter 1/80; Loss: 0.3249
Epoch 8695/10000; Iter 51/80; Loss: 0.3278
Epoch 8695/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.068
Epoch 8696/10000; Iter 1/80; Loss: 0.3509
Epoch 8696/10000; Iter 51/80; Loss: 0.3497
Epoch 8696/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8697/10000; Iter 1/80; Loss: 0.3318
Epoch 8697/10000; Iter 51/80; Loss: 0.3413
Epoch 8697/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.088
Epoch 8698/10000; Iter 1/80; Loss: 0.2971
Epoch 8698/10000; Iter 51/80; Loss: 0.3250
Epoch 8698/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.071
Epoch 8699/10000; Iter 1/80; Loss: 0.2695
Epoch 8699/10000; Iter 51/80; Loss: 0.3003
Epoch 8699/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.089
Epoch 8700/10000; Iter 1/80; Loss: 0.3568
Epoch 8700/10000; Iter 51/80; Loss: 0.3572
Epoch 8700/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.076
Epoch 8701/10000; Iter 1/80; Loss: 0.3353
Epoch 8701/10000; Iter 51/80; Loss: 0.3546
Epoch 8701/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Model saved
Epoch 8702/10000; Iter 1/80; Loss: 0.2808
Epoch 8702/10000; Iter 51/80; Loss: 0.3300
Epoch 8702/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.081
Epoch 8703/10000; Iter 1/80; Loss: 0.3026
Epoch 8703/10000; Iter 51/80; Loss: 0.3359
Epoch 8703/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.069
Epoch 8704/10000; Iter 1/80; Loss: 0.2891
Epoch 8704/10000; Iter 51/80; Loss: 0.3534
Epoch 8704/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.081
Epoch 8705/10000; Iter 1/80; Loss: 0.3292
Epoch 8705/10000; Iter 51/80; Loss: 0.3180
Epoch 8705/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 8706/10000; Iter 1/80; Loss: 0.2941
Epoch 8706/10000; Iter 51/80; Loss: 0.3751
Epoch 8706/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8707/10000; Iter 1/80; Loss: 0.3423
Epoch 8707/10000; Iter 51/80; Loss: 0.3379
Epoch 8707/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.076
Epoch 8708/10000; Iter 1/80; Loss: 0.3178
Epoch 8708/10000; Iter 51/80; Loss: 0.3668
Epoch 8708/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8709/10000; Iter 1/80; Loss: 0.3489
Epoch 8709/10000; Iter 51/80; Loss: 0.3300
Epoch 8709/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.066
Epoch 8710/10000; Iter 1/80; Loss: 0.3438
Epoch 8710/10000; Iter 51/80; Loss: 0.3879
Epoch 8710/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8711/10000; Iter 1/80; Loss: 0.3067
Epoch 8711/10000; Iter 51/80; Loss: 0.2732
Epoch 8711/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.079
Epoch 8712/10000; Iter 1/80; Loss: 0.2907
Epoch 8712/10000; Iter 51/80; Loss: 0.3591
Epoch 8712/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.073
Epoch 8713/10000; Iter 1/80; Loss: 0.3154
Epoch 8713/10000; Iter 51/80; Loss: 0.3496
Epoch 8713/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.08
Epoch 8714/10000; Iter 1/80; Loss: 0.3182
Epoch 8714/10000; Iter 51/80; Loss: 0.3432
Epoch 8714/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 8715/10000; Iter 1/80; Loss: 0.3283
Epoch 8715/10000; Iter 51/80; Loss: 0.3636
Epoch 8715/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8716/10000; Iter 1/80; Loss: 0.3387
Epoch 8716/10000; Iter 51/80; Loss: 0.3340
Epoch 8716/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.071
Epoch 8717/10000; Iter 1/80; Loss: 0.3394
Epoch 8717/10000; Iter 51/80; Loss: 0.3232
Epoch 8717/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8718/10000; Iter 1/80; Loss: 0.2871
Epoch 8718/10000; Iter 51/80; Loss: 0.3563
Epoch 8718/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8719/10000; Iter 1/80; Loss: 0.3098
Epoch 8719/10000; Iter 51/80; Loss: 0.3339
Epoch 8719/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 8720/10000; Iter 1/80; Loss: 0.3275
Epoch 8720/10000; Iter 51/80; Loss: 0.3542
Epoch 8720/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 8721/10000; Iter 1/80; Loss: 0.3210
Epoch 8721/10000; Iter 51/80; Loss: 0.3068
Epoch 8721/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.08
Epoch 8722/10000; Iter 1/80; Loss: 0.3129
Epoch 8722/10000; Iter 51/80; Loss: 0.3087
Epoch 8722/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8723/10000; Iter 1/80; Loss: 0.3016
Epoch 8723/10000; Iter 51/80; Loss: 0.3291
Epoch 8723/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 8724/10000; Iter 1/80; Loss: 0.2829
Epoch 8724/10000; Iter 51/80; Loss: 0.3939
Epoch 8724/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8725/10000; Iter 1/80; Loss: 0.3436
Epoch 8725/10000; Iter 51/80; Loss: 0.3362
Epoch 8725/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8726/10000; Iter 1/80; Loss: 0.3320
Epoch 8726/10000; Iter 51/80; Loss: 0.2932
Epoch 8726/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.082
Epoch 8727/10000; Iter 1/80; Loss: 0.3269
Epoch 8727/10000; Iter 51/80; Loss: 0.3077
Epoch 8727/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.081
Epoch 8728/10000; Iter 1/80; Loss: 0.2917
Epoch 8728/10000; Iter 51/80; Loss: 0.3862
Epoch 8728/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8729/10000; Iter 1/80; Loss: 0.3531
Epoch 8729/10000; Iter 51/80; Loss: 0.3596
Epoch 8729/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8730/10000; Iter 1/80; Loss: 0.3516
Epoch 8730/10000; Iter 51/80; Loss: 0.3518
Epoch 8730/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.083
Epoch 8731/10000; Iter 1/80; Loss: 0.3237
Epoch 8731/10000; Iter 51/80; Loss: 0.2871
Epoch 8731/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 8732/10000; Iter 1/80; Loss: 0.3300
Epoch 8732/10000; Iter 51/80; Loss: 0.3283
Epoch 8732/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.069
Epoch 8733/10000; Iter 1/80; Loss: 0.3485
Epoch 8733/10000; Iter 51/80; Loss: 0.3328
Epoch 8733/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8734/10000; Iter 1/80; Loss: 0.4104
Epoch 8734/10000; Iter 51/80; Loss: 0.3143
Epoch 8734/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.082
Epoch 8735/10000; Iter 1/80; Loss: 0.2725
Epoch 8735/10000; Iter 51/80; Loss: 0.2967
Epoch 8735/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 8736/10000; Iter 1/80; Loss: 0.3115
Epoch 8736/10000; Iter 51/80; Loss: 0.3467
Epoch 8736/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.07
Epoch 8737/10000; Iter 1/80; Loss: 0.3716
Epoch 8737/10000; Iter 51/80; Loss: 0.3231
Epoch 8737/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8738/10000; Iter 1/80; Loss: 0.3477
Epoch 8738/10000; Iter 51/80; Loss: 0.3641
Epoch 8738/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.068
Epoch 8739/10000; Iter 1/80; Loss: 0.3127
Epoch 8739/10000; Iter 51/80; Loss: 0.3089
Epoch 8739/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8740/10000; Iter 1/80; Loss: 0.2974
Epoch 8740/10000; Iter 51/80; Loss: 0.3336
Epoch 8740/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 8741/10000; Iter 1/80; Loss: 0.2785
Epoch 8741/10000; Iter 51/80; Loss: 0.3126
Epoch 8741/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 8742/10000; Iter 1/80; Loss: 0.3214
Epoch 8742/10000; Iter 51/80; Loss: 0.3586
Epoch 8742/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.073
Epoch 8743/10000; Iter 1/80; Loss: 0.2896
Epoch 8743/10000; Iter 51/80; Loss: 0.3248
Epoch 8743/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 8744/10000; Iter 1/80; Loss: 0.3014
Epoch 8744/10000; Iter 51/80; Loss: 0.3166
Epoch 8744/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.081
Epoch 8745/10000; Iter 1/80; Loss: 0.3691
Epoch 8745/10000; Iter 51/80; Loss: 0.2951
Epoch 8745/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.067
Epoch 8746/10000; Iter 1/80; Loss: 0.3009
Epoch 8746/10000; Iter 51/80; Loss: 0.3050
Epoch 8746/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.069
Epoch 8747/10000; Iter 1/80; Loss: 0.3154
Epoch 8747/10000; Iter 51/80; Loss: 0.2796
Epoch 8747/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 8748/10000; Iter 1/80; Loss: 0.3156
Epoch 8748/10000; Iter 51/80; Loss: 0.3411
Epoch 8748/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.082
Epoch 8749/10000; Iter 1/80; Loss: 0.3050
Epoch 8749/10000; Iter 51/80; Loss: 0.3043
Epoch 8749/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8750/10000; Iter 1/80; Loss: 0.4092
Epoch 8750/10000; Iter 51/80; Loss: 0.3447
Epoch 8750/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.07
Epoch 8751/10000; Iter 1/80; Loss: 0.3307
Epoch 8751/10000; Iter 51/80; Loss: 0.3072
Epoch 8751/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.069
Epoch 8752/10000; Iter 1/80; Loss: 0.3491
Epoch 8752/10000; Iter 51/80; Loss: 0.3257
Epoch 8752/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.079
Epoch 8753/10000; Iter 1/80; Loss: 0.3084
Epoch 8753/10000; Iter 51/80; Loss: 0.3056
Epoch 8753/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 8754/10000; Iter 1/80; Loss: 0.3274
Epoch 8754/10000; Iter 51/80; Loss: 0.3041
Epoch 8754/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8755/10000; Iter 1/80; Loss: 0.3448
Epoch 8755/10000; Iter 51/80; Loss: 0.3212
Epoch 8755/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 8756/10000; Iter 1/80; Loss: 0.3307
Epoch 8756/10000; Iter 51/80; Loss: 0.3174
Epoch 8756/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8757/10000; Iter 1/80; Loss: 0.3248
Epoch 8757/10000; Iter 51/80; Loss: 0.3733
Epoch 8757/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.064
Epoch 8758/10000; Iter 1/80; Loss: 0.3309
Epoch 8758/10000; Iter 51/80; Loss: 0.2951
Epoch 8758/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8759/10000; Iter 1/80; Loss: 0.3608
Epoch 8759/10000; Iter 51/80; Loss: 0.3200
Epoch 8759/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.065
Epoch 8760/10000; Iter 1/80; Loss: 0.3328
Epoch 8760/10000; Iter 51/80; Loss: 0.3330
Epoch 8760/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.066
Epoch 8761/10000; Iter 1/80; Loss: 0.3336
Epoch 8761/10000; Iter 51/80; Loss: 0.2981
Epoch 8761/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 8762/10000; Iter 1/80; Loss: 0.3804
Epoch 8762/10000; Iter 51/80; Loss: 0.3332
Epoch 8762/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.077
Epoch 8763/10000; Iter 1/80; Loss: 0.3200
Epoch 8763/10000; Iter 51/80; Loss: 0.3114
Epoch 8763/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8764/10000; Iter 1/80; Loss: 0.2731
Epoch 8764/10000; Iter 51/80; Loss: 0.3471
Epoch 8764/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8765/10000; Iter 1/80; Loss: 0.3347
Epoch 8765/10000; Iter 51/80; Loss: 0.3732
Epoch 8765/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8766/10000; Iter 1/80; Loss: 0.2829
Epoch 8766/10000; Iter 51/80; Loss: 0.3396
Epoch 8766/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8767/10000; Iter 1/80; Loss: 0.3226
Epoch 8767/10000; Iter 51/80; Loss: 0.3132
Epoch 8767/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 8768/10000; Iter 1/80; Loss: 0.3132
Epoch 8768/10000; Iter 51/80; Loss: 0.3677
Epoch 8768/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8769/10000; Iter 1/80; Loss: 0.2923
Epoch 8769/10000; Iter 51/80; Loss: 0.3223
Epoch 8769/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.073
Epoch 8770/10000; Iter 1/80; Loss: 0.3936
Epoch 8770/10000; Iter 51/80; Loss: 0.3909
Epoch 8770/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.07
Epoch 8771/10000; Iter 1/80; Loss: 0.3310
Epoch 8771/10000; Iter 51/80; Loss: 0.3273
Epoch 8771/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.067
Epoch 8772/10000; Iter 1/80; Loss: 0.3137
Epoch 8772/10000; Iter 51/80; Loss: 0.3583
Epoch 8772/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.075
Epoch 8773/10000; Iter 1/80; Loss: 0.3454
Epoch 8773/10000; Iter 51/80; Loss: 0.3741
Epoch 8773/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 8774/10000; Iter 1/80; Loss: 0.3118
Epoch 8774/10000; Iter 51/80; Loss: 0.2689
Epoch 8774/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.069
Epoch 8775/10000; Iter 1/80; Loss: 0.2937
Epoch 8775/10000; Iter 51/80; Loss: 0.2918
Epoch 8775/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 8776/10000; Iter 1/80; Loss: 0.2838
Epoch 8776/10000; Iter 51/80; Loss: 0.3364
Epoch 8776/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.069
Epoch 8777/10000; Iter 1/80; Loss: 0.3723
Epoch 8777/10000; Iter 51/80; Loss: 0.3072
Epoch 8777/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 8778/10000; Iter 1/80; Loss: 0.3592
Epoch 8778/10000; Iter 51/80; Loss: 0.3550
Epoch 8778/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 8779/10000; Iter 1/80; Loss: 0.3657
Epoch 8779/10000; Iter 51/80; Loss: 0.3343
Epoch 8779/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 8780/10000; Iter 1/80; Loss: 0.3127
Epoch 8780/10000; Iter 51/80; Loss: 0.3352
Epoch 8780/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.079
Epoch 8781/10000; Iter 1/80; Loss: 0.3113
Epoch 8781/10000; Iter 51/80; Loss: 0.3511
Epoch 8781/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 8782/10000; Iter 1/80; Loss: 0.3275
Epoch 8782/10000; Iter 51/80; Loss: 0.3166
Epoch 8782/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.078
Epoch 8783/10000; Iter 1/80; Loss: 0.2908
Epoch 8783/10000; Iter 51/80; Loss: 0.3005
Epoch 8783/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8784/10000; Iter 1/80; Loss: 0.3355
Epoch 8784/10000; Iter 51/80; Loss: 0.2661
Epoch 8784/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 8785/10000; Iter 1/80; Loss: 0.2917
Epoch 8785/10000; Iter 51/80; Loss: 0.3505
Epoch 8785/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8786/10000; Iter 1/80; Loss: 0.3280
Epoch 8786/10000; Iter 51/80; Loss: 0.2791
Epoch 8786/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8787/10000; Iter 1/80; Loss: 0.3611
Epoch 8787/10000; Iter 51/80; Loss: 0.2937
Epoch 8787/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 8788/10000; Iter 1/80; Loss: 0.3197
Epoch 8788/10000; Iter 51/80; Loss: 0.3842
Epoch 8788/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.082
Epoch 8789/10000; Iter 1/80; Loss: 0.3450
Epoch 8789/10000; Iter 51/80; Loss: 0.3148
Epoch 8789/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 8790/10000; Iter 1/80; Loss: 0.3641
Epoch 8790/10000; Iter 51/80; Loss: 0.3518
Epoch 8790/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8791/10000; Iter 1/80; Loss: 0.3477
Epoch 8791/10000; Iter 51/80; Loss: 0.3541
Epoch 8791/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.077
Epoch 8792/10000; Iter 1/80; Loss: 0.3192
Epoch 8792/10000; Iter 51/80; Loss: 0.3349
Epoch 8792/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 8793/10000; Iter 1/80; Loss: 0.3274
Epoch 8793/10000; Iter 51/80; Loss: 0.3531
Epoch 8793/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8794/10000; Iter 1/80; Loss: 0.3912
Epoch 8794/10000; Iter 51/80; Loss: 0.3024
Epoch 8794/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.071
Epoch 8795/10000; Iter 1/80; Loss: 0.3245
Epoch 8795/10000; Iter 51/80; Loss: 0.2944
Epoch 8795/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 8796/10000; Iter 1/80; Loss: 0.3612
Epoch 8796/10000; Iter 51/80; Loss: 0.3465
Epoch 8796/10000; Iter 80/80; Training Loss: 0.3340, Test Loss: 0.073
Epoch 8797/10000; Iter 1/80; Loss: 0.2862
Epoch 8797/10000; Iter 51/80; Loss: 0.3132
Epoch 8797/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 8798/10000; Iter 1/80; Loss: 0.3120
Epoch 8798/10000; Iter 51/80; Loss: 0.3351
Epoch 8798/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.068
Epoch 8799/10000; Iter 1/80; Loss: 0.3307
Epoch 8799/10000; Iter 51/80; Loss: 0.2963
Epoch 8799/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 8800/10000; Iter 1/80; Loss: 0.4267
Epoch 8800/10000; Iter 51/80; Loss: 0.3419
Epoch 8800/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.079
Epoch 8801/10000; Iter 1/80; Loss: 0.3383
Epoch 8801/10000; Iter 51/80; Loss: 0.3197
Epoch 8801/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.075
Model saved
Epoch 8802/10000; Iter 1/80; Loss: 0.3919
Epoch 8802/10000; Iter 51/80; Loss: 0.3378
Epoch 8802/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.071
Epoch 8803/10000; Iter 1/80; Loss: 0.3165
Epoch 8803/10000; Iter 51/80; Loss: 0.3518
Epoch 8803/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8804/10000; Iter 1/80; Loss: 0.3473
Epoch 8804/10000; Iter 51/80; Loss: 0.2728
Epoch 8804/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.07
Epoch 8805/10000; Iter 1/80; Loss: 0.3799
Epoch 8805/10000; Iter 51/80; Loss: 0.3228
Epoch 8805/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.078
Epoch 8806/10000; Iter 1/80; Loss: 0.3241
Epoch 8806/10000; Iter 51/80; Loss: 0.3159
Epoch 8806/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.074
Epoch 8807/10000; Iter 1/80; Loss: 0.2844
Epoch 8807/10000; Iter 51/80; Loss: 0.2866
Epoch 8807/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 8808/10000; Iter 1/80; Loss: 0.3358
Epoch 8808/10000; Iter 51/80; Loss: 0.3539
Epoch 8808/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 8809/10000; Iter 1/80; Loss: 0.3323
Epoch 8809/10000; Iter 51/80; Loss: 0.2891
Epoch 8809/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 8810/10000; Iter 1/80; Loss: 0.2644
Epoch 8810/10000; Iter 51/80; Loss: 0.3262
Epoch 8810/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8811/10000; Iter 1/80; Loss: 0.3074
Epoch 8811/10000; Iter 51/80; Loss: 0.3098
Epoch 8811/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8812/10000; Iter 1/80; Loss: 0.3223
Epoch 8812/10000; Iter 51/80; Loss: 0.3099
Epoch 8812/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 8813/10000; Iter 1/80; Loss: 0.3528
Epoch 8813/10000; Iter 51/80; Loss: 0.3541
Epoch 8813/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.068
Epoch 8814/10000; Iter 1/80; Loss: 0.3209
Epoch 8814/10000; Iter 51/80; Loss: 0.2968
Epoch 8814/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8815/10000; Iter 1/80; Loss: 0.3597
Epoch 8815/10000; Iter 51/80; Loss: 0.2881
Epoch 8815/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8816/10000; Iter 1/80; Loss: 0.3632
Epoch 8816/10000; Iter 51/80; Loss: 0.3461
Epoch 8816/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8817/10000; Iter 1/80; Loss: 0.2862
Epoch 8817/10000; Iter 51/80; Loss: 0.3585
Epoch 8817/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8818/10000; Iter 1/80; Loss: 0.3499
Epoch 8818/10000; Iter 51/80; Loss: 0.2811
Epoch 8818/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 8819/10000; Iter 1/80; Loss: 0.3278
Epoch 8819/10000; Iter 51/80; Loss: 0.3023
Epoch 8819/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.073
Epoch 8820/10000; Iter 1/80; Loss: 0.3337
Epoch 8820/10000; Iter 51/80; Loss: 0.3361
Epoch 8820/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.08
Epoch 8821/10000; Iter 1/80; Loss: 0.3319
Epoch 8821/10000; Iter 51/80; Loss: 0.3394
Epoch 8821/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 8822/10000; Iter 1/80; Loss: 0.3244
Epoch 8822/10000; Iter 51/80; Loss: 0.2925
Epoch 8822/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 8823/10000; Iter 1/80; Loss: 0.3054
Epoch 8823/10000; Iter 51/80; Loss: 0.2975
Epoch 8823/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.078
Epoch 8824/10000; Iter 1/80; Loss: 0.2699
Epoch 8824/10000; Iter 51/80; Loss: 0.3629
Epoch 8824/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.073
Epoch 8825/10000; Iter 1/80; Loss: 0.2800
Epoch 8825/10000; Iter 51/80; Loss: 0.3189
Epoch 8825/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.064
Epoch 8826/10000; Iter 1/80; Loss: 0.3179
Epoch 8826/10000; Iter 51/80; Loss: 0.2916
Epoch 8826/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 8827/10000; Iter 1/80; Loss: 0.2887
Epoch 8827/10000; Iter 51/80; Loss: 0.3407
Epoch 8827/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 8828/10000; Iter 1/80; Loss: 0.3035
Epoch 8828/10000; Iter 51/80; Loss: 0.3413
Epoch 8828/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 8829/10000; Iter 1/80; Loss: 0.3375
Epoch 8829/10000; Iter 51/80; Loss: 0.3223
Epoch 8829/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8830/10000; Iter 1/80; Loss: 0.2958
Epoch 8830/10000; Iter 51/80; Loss: 0.3234
Epoch 8830/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 8831/10000; Iter 1/80; Loss: 0.3223
Epoch 8831/10000; Iter 51/80; Loss: 0.3207
Epoch 8831/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 8832/10000; Iter 1/80; Loss: 0.2937
Epoch 8832/10000; Iter 51/80; Loss: 0.2858
Epoch 8832/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.069
Epoch 8833/10000; Iter 1/80; Loss: 0.2654
Epoch 8833/10000; Iter 51/80; Loss: 0.3364
Epoch 8833/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 8834/10000; Iter 1/80; Loss: 0.3886
Epoch 8834/10000; Iter 51/80; Loss: 0.3456
Epoch 8834/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.076
Epoch 8835/10000; Iter 1/80; Loss: 0.3765
Epoch 8835/10000; Iter 51/80; Loss: 0.3033
Epoch 8835/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.069
Epoch 8836/10000; Iter 1/80; Loss: 0.3219
Epoch 8836/10000; Iter 51/80; Loss: 0.3117
Epoch 8836/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.07
Epoch 8837/10000; Iter 1/80; Loss: 0.3194
Epoch 8837/10000; Iter 51/80; Loss: 0.3015
Epoch 8837/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 8838/10000; Iter 1/80; Loss: 0.3259
Epoch 8838/10000; Iter 51/80; Loss: 0.3294
Epoch 8838/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 8839/10000; Iter 1/80; Loss: 0.3409
Epoch 8839/10000; Iter 51/80; Loss: 0.3364
Epoch 8839/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 8840/10000; Iter 1/80; Loss: 0.3434
Epoch 8840/10000; Iter 51/80; Loss: 0.3395
Epoch 8840/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.069
Epoch 8841/10000; Iter 1/80; Loss: 0.3006
Epoch 8841/10000; Iter 51/80; Loss: 0.3154
Epoch 8841/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8842/10000; Iter 1/80; Loss: 0.4319
Epoch 8842/10000; Iter 51/80; Loss: 0.3190
Epoch 8842/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 8843/10000; Iter 1/80; Loss: 0.3496
Epoch 8843/10000; Iter 51/80; Loss: 0.3068
Epoch 8843/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8844/10000; Iter 1/80; Loss: 0.3960
Epoch 8844/10000; Iter 51/80; Loss: 0.2940
Epoch 8844/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 8845/10000; Iter 1/80; Loss: 0.3186
Epoch 8845/10000; Iter 51/80; Loss: 0.3384
Epoch 8845/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 8846/10000; Iter 1/80; Loss: 0.3615
Epoch 8846/10000; Iter 51/80; Loss: 0.3023
Epoch 8846/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 8847/10000; Iter 1/80; Loss: 0.2981
Epoch 8847/10000; Iter 51/80; Loss: 0.3052
Epoch 8847/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.067
Epoch 8848/10000; Iter 1/80; Loss: 0.3341
Epoch 8848/10000; Iter 51/80; Loss: 0.3067
Epoch 8848/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 8849/10000; Iter 1/80; Loss: 0.3861
Epoch 8849/10000; Iter 51/80; Loss: 0.3810
Epoch 8849/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.075
Epoch 8850/10000; Iter 1/80; Loss: 0.3159
Epoch 8850/10000; Iter 51/80; Loss: 0.4065
Epoch 8850/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 8851/10000; Iter 1/80; Loss: 0.3253
Epoch 8851/10000; Iter 51/80; Loss: 0.2889
Epoch 8851/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8852/10000; Iter 1/80; Loss: 0.2773
Epoch 8852/10000; Iter 51/80; Loss: 0.3380
Epoch 8852/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.07
Epoch 8853/10000; Iter 1/80; Loss: 0.2911
Epoch 8853/10000; Iter 51/80; Loss: 0.2807
Epoch 8853/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.075
Epoch 8854/10000; Iter 1/80; Loss: 0.3100
Epoch 8854/10000; Iter 51/80; Loss: 0.3803
Epoch 8854/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 8855/10000; Iter 1/80; Loss: 0.3516
Epoch 8855/10000; Iter 51/80; Loss: 0.3357
Epoch 8855/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8856/10000; Iter 1/80; Loss: 0.3275
Epoch 8856/10000; Iter 51/80; Loss: 0.2977
Epoch 8856/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8857/10000; Iter 1/80; Loss: 0.3083
Epoch 8857/10000; Iter 51/80; Loss: 0.3414
Epoch 8857/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 8858/10000; Iter 1/80; Loss: 0.3119
Epoch 8858/10000; Iter 51/80; Loss: 0.3279
Epoch 8858/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 8859/10000; Iter 1/80; Loss: 0.3163
Epoch 8859/10000; Iter 51/80; Loss: 0.3366
Epoch 8859/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8860/10000; Iter 1/80; Loss: 0.3503
Epoch 8860/10000; Iter 51/80; Loss: 0.2952
Epoch 8860/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 8861/10000; Iter 1/80; Loss: 0.3118
Epoch 8861/10000; Iter 51/80; Loss: 0.3322
Epoch 8861/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 8862/10000; Iter 1/80; Loss: 0.3080
Epoch 8862/10000; Iter 51/80; Loss: 0.3207
Epoch 8862/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.067
Epoch 8863/10000; Iter 1/80; Loss: 0.3726
Epoch 8863/10000; Iter 51/80; Loss: 0.3863
Epoch 8863/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.084
Epoch 8864/10000; Iter 1/80; Loss: 0.3640
Epoch 8864/10000; Iter 51/80; Loss: 0.3025
Epoch 8864/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 8865/10000; Iter 1/80; Loss: 0.3238
Epoch 8865/10000; Iter 51/80; Loss: 0.3292
Epoch 8865/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.072
Epoch 8866/10000; Iter 1/80; Loss: 0.3648
Epoch 8866/10000; Iter 51/80; Loss: 0.3551
Epoch 8866/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 8867/10000; Iter 1/80; Loss: 0.3522
Epoch 8867/10000; Iter 51/80; Loss: 0.3505
Epoch 8867/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8868/10000; Iter 1/80; Loss: 0.3235
Epoch 8868/10000; Iter 51/80; Loss: 0.3195
Epoch 8868/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 8869/10000; Iter 1/80; Loss: 0.3539
Epoch 8869/10000; Iter 51/80; Loss: 0.2812
Epoch 8869/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8870/10000; Iter 1/80; Loss: 0.2804
Epoch 8870/10000; Iter 51/80; Loss: 0.2930
Epoch 8870/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 8871/10000; Iter 1/80; Loss: 0.2990
Epoch 8871/10000; Iter 51/80; Loss: 0.3536
Epoch 8871/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 8872/10000; Iter 1/80; Loss: 0.3095
Epoch 8872/10000; Iter 51/80; Loss: 0.3587
Epoch 8872/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.068
Epoch 8873/10000; Iter 1/80; Loss: 0.2895
Epoch 8873/10000; Iter 51/80; Loss: 0.3226
Epoch 8873/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.076
Epoch 8874/10000; Iter 1/80; Loss: 0.3474
Epoch 8874/10000; Iter 51/80; Loss: 0.2929
Epoch 8874/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 8875/10000; Iter 1/80; Loss: 0.3449
Epoch 8875/10000; Iter 51/80; Loss: 0.3050
Epoch 8875/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 8876/10000; Iter 1/80; Loss: 0.3553
Epoch 8876/10000; Iter 51/80; Loss: 0.3040
Epoch 8876/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 8877/10000; Iter 1/80; Loss: 0.3946
Epoch 8877/10000; Iter 51/80; Loss: 0.3215
Epoch 8877/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 8878/10000; Iter 1/80; Loss: 0.2904
Epoch 8878/10000; Iter 51/80; Loss: 0.2819
Epoch 8878/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 8879/10000; Iter 1/80; Loss: 0.3000
Epoch 8879/10000; Iter 51/80; Loss: 0.3339
Epoch 8879/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.077
Epoch 8880/10000; Iter 1/80; Loss: 0.3242
Epoch 8880/10000; Iter 51/80; Loss: 0.3491
Epoch 8880/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 8881/10000; Iter 1/80; Loss: 0.3858
Epoch 8881/10000; Iter 51/80; Loss: 0.3765
Epoch 8881/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 8882/10000; Iter 1/80; Loss: 0.3314
Epoch 8882/10000; Iter 51/80; Loss: 0.3111
Epoch 8882/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 8883/10000; Iter 1/80; Loss: 0.3304
Epoch 8883/10000; Iter 51/80; Loss: 0.3786
Epoch 8883/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 8884/10000; Iter 1/80; Loss: 0.2764
Epoch 8884/10000; Iter 51/80; Loss: 0.3115
Epoch 8884/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 8885/10000; Iter 1/80; Loss: 0.2880
Epoch 8885/10000; Iter 51/80; Loss: 0.3080
Epoch 8885/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.072
Epoch 8886/10000; Iter 1/80; Loss: 0.2872
Epoch 8886/10000; Iter 51/80; Loss: 0.3585
Epoch 8886/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8887/10000; Iter 1/80; Loss: 0.3130
Epoch 8887/10000; Iter 51/80; Loss: 0.3471
Epoch 8887/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 8888/10000; Iter 1/80; Loss: 0.4310
Epoch 8888/10000; Iter 51/80; Loss: 0.3289
Epoch 8888/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.082
Epoch 8889/10000; Iter 1/80; Loss: 0.3698
Epoch 8889/10000; Iter 51/80; Loss: 0.3292
Epoch 8889/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8890/10000; Iter 1/80; Loss: 0.3091
Epoch 8890/10000; Iter 51/80; Loss: 0.2848
Epoch 8890/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.075
Epoch 8891/10000; Iter 1/80; Loss: 0.3195
Epoch 8891/10000; Iter 51/80; Loss: 0.3339
Epoch 8891/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 8892/10000; Iter 1/80; Loss: 0.3708
Epoch 8892/10000; Iter 51/80; Loss: 0.3304
Epoch 8892/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8893/10000; Iter 1/80; Loss: 0.3438
Epoch 8893/10000; Iter 51/80; Loss: 0.3219
Epoch 8893/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.085
Epoch 8894/10000; Iter 1/80; Loss: 0.3048
Epoch 8894/10000; Iter 51/80; Loss: 0.3144
Epoch 8894/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.07
Epoch 8895/10000; Iter 1/80; Loss: 0.2832
Epoch 8895/10000; Iter 51/80; Loss: 0.3109
Epoch 8895/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 8896/10000; Iter 1/80; Loss: 0.2934
Epoch 8896/10000; Iter 51/80; Loss: 0.2918
Epoch 8896/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8897/10000; Iter 1/80; Loss: 0.2744
Epoch 8897/10000; Iter 51/80; Loss: 0.3307
Epoch 8897/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8898/10000; Iter 1/80; Loss: 0.3759
Epoch 8898/10000; Iter 51/80; Loss: 0.3180
Epoch 8898/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.073
Epoch 8899/10000; Iter 1/80; Loss: 0.3588
Epoch 8899/10000; Iter 51/80; Loss: 0.2946
Epoch 8899/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 8900/10000; Iter 1/80; Loss: 0.3133
Epoch 8900/10000; Iter 51/80; Loss: 0.3434
Epoch 8900/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.076
Epoch 8901/10000; Iter 1/80; Loss: 0.3070
Epoch 8901/10000; Iter 51/80; Loss: 0.3127
Epoch 8901/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Model saved
Epoch 8902/10000; Iter 1/80; Loss: 0.3743
Epoch 8902/10000; Iter 51/80; Loss: 0.2876
Epoch 8902/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.069
Epoch 8903/10000; Iter 1/80; Loss: 0.3527
Epoch 8903/10000; Iter 51/80; Loss: 0.3212
Epoch 8903/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 8904/10000; Iter 1/80; Loss: 0.3044
Epoch 8904/10000; Iter 51/80; Loss: 0.3571
Epoch 8904/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8905/10000; Iter 1/80; Loss: 0.3435
Epoch 8905/10000; Iter 51/80; Loss: 0.2871
Epoch 8905/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.07
Epoch 8906/10000; Iter 1/80; Loss: 0.3384
Epoch 8906/10000; Iter 51/80; Loss: 0.2990
Epoch 8906/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.083
Epoch 8907/10000; Iter 1/80; Loss: 0.3772
Epoch 8907/10000; Iter 51/80; Loss: 0.3200
Epoch 8907/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 8908/10000; Iter 1/80; Loss: 0.3677
Epoch 8908/10000; Iter 51/80; Loss: 0.3096
Epoch 8908/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 8909/10000; Iter 1/80; Loss: 0.3325
Epoch 8909/10000; Iter 51/80; Loss: 0.3554
Epoch 8909/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.07
Epoch 8910/10000; Iter 1/80; Loss: 0.2664
Epoch 8910/10000; Iter 51/80; Loss: 0.3243
Epoch 8910/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 8911/10000; Iter 1/80; Loss: 0.3757
Epoch 8911/10000; Iter 51/80; Loss: 0.3261
Epoch 8911/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 8912/10000; Iter 1/80; Loss: 0.3115
Epoch 8912/10000; Iter 51/80; Loss: 0.2828
Epoch 8912/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 8913/10000; Iter 1/80; Loss: 0.3532
Epoch 8913/10000; Iter 51/80; Loss: 0.3331
Epoch 8913/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 8914/10000; Iter 1/80; Loss: 0.2927
Epoch 8914/10000; Iter 51/80; Loss: 0.3407
Epoch 8914/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 8915/10000; Iter 1/80; Loss: 0.3251
Epoch 8915/10000; Iter 51/80; Loss: 0.3485
Epoch 8915/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8916/10000; Iter 1/80; Loss: 0.3731
Epoch 8916/10000; Iter 51/80; Loss: 0.3646
Epoch 8916/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 8917/10000; Iter 1/80; Loss: 0.3044
Epoch 8917/10000; Iter 51/80; Loss: 0.3173
Epoch 8917/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8918/10000; Iter 1/80; Loss: 0.3033
Epoch 8918/10000; Iter 51/80; Loss: 0.3222
Epoch 8918/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.07
Epoch 8919/10000; Iter 1/80; Loss: 0.3170
Epoch 8919/10000; Iter 51/80; Loss: 0.3544
Epoch 8919/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 8920/10000; Iter 1/80; Loss: 0.3280
Epoch 8920/10000; Iter 51/80; Loss: 0.3498
Epoch 8920/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 8921/10000; Iter 1/80; Loss: 0.2722
Epoch 8921/10000; Iter 51/80; Loss: 0.3164
Epoch 8921/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.072
Epoch 8922/10000; Iter 1/80; Loss: 0.2822
Epoch 8922/10000; Iter 51/80; Loss: 0.3058
Epoch 8922/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 8923/10000; Iter 1/80; Loss: 0.3077
Epoch 8923/10000; Iter 51/80; Loss: 0.3345
Epoch 8923/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.067
Epoch 8924/10000; Iter 1/80; Loss: 0.2646
Epoch 8924/10000; Iter 51/80; Loss: 0.3434
Epoch 8924/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.083
Epoch 8925/10000; Iter 1/80; Loss: 0.2901
Epoch 8925/10000; Iter 51/80; Loss: 0.3493
Epoch 8925/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.078
Epoch 8926/10000; Iter 1/80; Loss: 0.2894
Epoch 8926/10000; Iter 51/80; Loss: 0.2782
Epoch 8926/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8927/10000; Iter 1/80; Loss: 0.3255
Epoch 8927/10000; Iter 51/80; Loss: 0.2585
Epoch 8927/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8928/10000; Iter 1/80; Loss: 0.2865
Epoch 8928/10000; Iter 51/80; Loss: 0.3361
Epoch 8928/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 8929/10000; Iter 1/80; Loss: 0.3374
Epoch 8929/10000; Iter 51/80; Loss: 0.2882
Epoch 8929/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8930/10000; Iter 1/80; Loss: 0.2883
Epoch 8930/10000; Iter 51/80; Loss: 0.3090
Epoch 8930/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 8931/10000; Iter 1/80; Loss: 0.2970
Epoch 8931/10000; Iter 51/80; Loss: 0.3227
Epoch 8931/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 8932/10000; Iter 1/80; Loss: 0.2762
Epoch 8932/10000; Iter 51/80; Loss: 0.3207
Epoch 8932/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 8933/10000; Iter 1/80; Loss: 0.2725
Epoch 8933/10000; Iter 51/80; Loss: 0.2853
Epoch 8933/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.07
Epoch 8934/10000; Iter 1/80; Loss: 0.3398
Epoch 8934/10000; Iter 51/80; Loss: 0.3241
Epoch 8934/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.081
Epoch 8935/10000; Iter 1/80; Loss: 0.3531
Epoch 8935/10000; Iter 51/80; Loss: 0.3402
Epoch 8935/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.07
Epoch 8936/10000; Iter 1/80; Loss: 0.3582
Epoch 8936/10000; Iter 51/80; Loss: 0.3024
Epoch 8936/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.082
Epoch 8937/10000; Iter 1/80; Loss: 0.2631
Epoch 8937/10000; Iter 51/80; Loss: 0.2898
Epoch 8937/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.079
Epoch 8938/10000; Iter 1/80; Loss: 0.3704
Epoch 8938/10000; Iter 51/80; Loss: 0.2980
Epoch 8938/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 8939/10000; Iter 1/80; Loss: 0.2917
Epoch 8939/10000; Iter 51/80; Loss: 0.2929
Epoch 8939/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8940/10000; Iter 1/80; Loss: 0.3127
Epoch 8940/10000; Iter 51/80; Loss: 0.3091
Epoch 8940/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 8941/10000; Iter 1/80; Loss: 0.3703
Epoch 8941/10000; Iter 51/80; Loss: 0.2774
Epoch 8941/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 8942/10000; Iter 1/80; Loss: 0.3135
Epoch 8942/10000; Iter 51/80; Loss: 0.3105
Epoch 8942/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8943/10000; Iter 1/80; Loss: 0.3644
Epoch 8943/10000; Iter 51/80; Loss: 0.2913
Epoch 8943/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.08
Epoch 8944/10000; Iter 1/80; Loss: 0.3140
Epoch 8944/10000; Iter 51/80; Loss: 0.3733
Epoch 8944/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 8945/10000; Iter 1/80; Loss: 0.2970
Epoch 8945/10000; Iter 51/80; Loss: 0.3807
Epoch 8945/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 8946/10000; Iter 1/80; Loss: 0.3337
Epoch 8946/10000; Iter 51/80; Loss: 0.2996
Epoch 8946/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.068
Epoch 8947/10000; Iter 1/80; Loss: 0.3183
Epoch 8947/10000; Iter 51/80; Loss: 0.3290
Epoch 8947/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 8948/10000; Iter 1/80; Loss: 0.2816
Epoch 8948/10000; Iter 51/80; Loss: 0.3135
Epoch 8948/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.07
Epoch 8949/10000; Iter 1/80; Loss: 0.3436
Epoch 8949/10000; Iter 51/80; Loss: 0.2944
Epoch 8949/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 8950/10000; Iter 1/80; Loss: 0.3037
Epoch 8950/10000; Iter 51/80; Loss: 0.3056
Epoch 8950/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 8951/10000; Iter 1/80; Loss: 0.3237
Epoch 8951/10000; Iter 51/80; Loss: 0.3129
Epoch 8951/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 8952/10000; Iter 1/80; Loss: 0.3714
Epoch 8952/10000; Iter 51/80; Loss: 0.3953
Epoch 8952/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 8953/10000; Iter 1/80; Loss: 0.3754
Epoch 8953/10000; Iter 51/80; Loss: 0.3322
Epoch 8953/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 8954/10000; Iter 1/80; Loss: 0.2906
Epoch 8954/10000; Iter 51/80; Loss: 0.3110
Epoch 8954/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 8955/10000; Iter 1/80; Loss: 0.2982
Epoch 8955/10000; Iter 51/80; Loss: 0.2978
Epoch 8955/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 8956/10000; Iter 1/80; Loss: 0.3337
Epoch 8956/10000; Iter 51/80; Loss: 0.2553
Epoch 8956/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.072
Epoch 8957/10000; Iter 1/80; Loss: 0.3532
Epoch 8957/10000; Iter 51/80; Loss: 0.3193
Epoch 8957/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 8958/10000; Iter 1/80; Loss: 0.3107
Epoch 8958/10000; Iter 51/80; Loss: 0.3755
Epoch 8958/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.069
Epoch 8959/10000; Iter 1/80; Loss: 0.2727
Epoch 8959/10000; Iter 51/80; Loss: 0.3717
Epoch 8959/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 8960/10000; Iter 1/80; Loss: 0.3300
Epoch 8960/10000; Iter 51/80; Loss: 0.3259
Epoch 8960/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 8961/10000; Iter 1/80; Loss: 0.2745
Epoch 8961/10000; Iter 51/80; Loss: 0.3441
Epoch 8961/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 8962/10000; Iter 1/80; Loss: 0.2989
Epoch 8962/10000; Iter 51/80; Loss: 0.3078
Epoch 8962/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 8963/10000; Iter 1/80; Loss: 0.3576
Epoch 8963/10000; Iter 51/80; Loss: 0.3369
Epoch 8963/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.074
Epoch 8964/10000; Iter 1/80; Loss: 0.2897
Epoch 8964/10000; Iter 51/80; Loss: 0.3211
Epoch 8964/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.073
Epoch 8965/10000; Iter 1/80; Loss: 0.3366
Epoch 8965/10000; Iter 51/80; Loss: 0.3405
Epoch 8965/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8966/10000; Iter 1/80; Loss: 0.3476
Epoch 8966/10000; Iter 51/80; Loss: 0.3638
Epoch 8966/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.082
Epoch 8967/10000; Iter 1/80; Loss: 0.3272
Epoch 8967/10000; Iter 51/80; Loss: 0.3215
Epoch 8967/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.081
Epoch 8968/10000; Iter 1/80; Loss: 0.3553
Epoch 8968/10000; Iter 51/80; Loss: 0.3992
Epoch 8968/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 8969/10000; Iter 1/80; Loss: 0.3371
Epoch 8969/10000; Iter 51/80; Loss: 0.3693
Epoch 8969/10000; Iter 80/80; Training Loss: 0.3310, Test Loss: 0.078
Epoch 8970/10000; Iter 1/80; Loss: 0.3204
Epoch 8970/10000; Iter 51/80; Loss: 0.2810
Epoch 8970/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 8971/10000; Iter 1/80; Loss: 0.3045
Epoch 8971/10000; Iter 51/80; Loss: 0.2961
Epoch 8971/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 8972/10000; Iter 1/80; Loss: 0.2851
Epoch 8972/10000; Iter 51/80; Loss: 0.3835
Epoch 8972/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 8973/10000; Iter 1/80; Loss: 0.2895
Epoch 8973/10000; Iter 51/80; Loss: 0.3207
Epoch 8973/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 8974/10000; Iter 1/80; Loss: 0.3445
Epoch 8974/10000; Iter 51/80; Loss: 0.2965
Epoch 8974/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 8975/10000; Iter 1/80; Loss: 0.3141
Epoch 8975/10000; Iter 51/80; Loss: 0.3499
Epoch 8975/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.071
Epoch 8976/10000; Iter 1/80; Loss: 0.2787
Epoch 8976/10000; Iter 51/80; Loss: 0.3470
Epoch 8976/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 8977/10000; Iter 1/80; Loss: 0.3461
Epoch 8977/10000; Iter 51/80; Loss: 0.3635
Epoch 8977/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 8978/10000; Iter 1/80; Loss: 0.2989
Epoch 8978/10000; Iter 51/80; Loss: 0.3136
Epoch 8978/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 8979/10000; Iter 1/80; Loss: 0.2883
Epoch 8979/10000; Iter 51/80; Loss: 0.3337
Epoch 8979/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8980/10000; Iter 1/80; Loss: 0.2864
Epoch 8980/10000; Iter 51/80; Loss: 0.3416
Epoch 8980/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 8981/10000; Iter 1/80; Loss: 0.3063
Epoch 8981/10000; Iter 51/80; Loss: 0.3546
Epoch 8981/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 8982/10000; Iter 1/80; Loss: 0.3221
Epoch 8982/10000; Iter 51/80; Loss: 0.3127
Epoch 8982/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 8983/10000; Iter 1/80; Loss: 0.2767
Epoch 8983/10000; Iter 51/80; Loss: 0.3225
Epoch 8983/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8984/10000; Iter 1/80; Loss: 0.3379
Epoch 8984/10000; Iter 51/80; Loss: 0.3392
Epoch 8984/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.079
Epoch 8985/10000; Iter 1/80; Loss: 0.3530
Epoch 8985/10000; Iter 51/80; Loss: 0.3043
Epoch 8985/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.081
Epoch 8986/10000; Iter 1/80; Loss: 0.3118
Epoch 8986/10000; Iter 51/80; Loss: 0.3836
Epoch 8986/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 8987/10000; Iter 1/80; Loss: 0.3392
Epoch 8987/10000; Iter 51/80; Loss: 0.2796
Epoch 8987/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 8988/10000; Iter 1/80; Loss: 0.3222
Epoch 8988/10000; Iter 51/80; Loss: 0.2989
Epoch 8988/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 8989/10000; Iter 1/80; Loss: 0.3175
Epoch 8989/10000; Iter 51/80; Loss: 0.2894
Epoch 8989/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8990/10000; Iter 1/80; Loss: 0.2923
Epoch 8990/10000; Iter 51/80; Loss: 0.3857
Epoch 8990/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 8991/10000; Iter 1/80; Loss: 0.3596
Epoch 8991/10000; Iter 51/80; Loss: 0.3757
Epoch 8991/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.078
Epoch 8992/10000; Iter 1/80; Loss: 0.3462
Epoch 8992/10000; Iter 51/80; Loss: 0.3510
Epoch 8992/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 8993/10000; Iter 1/80; Loss: 0.3185
Epoch 8993/10000; Iter 51/80; Loss: 0.2735
Epoch 8993/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 8994/10000; Iter 1/80; Loss: 0.2637
Epoch 8994/10000; Iter 51/80; Loss: 0.2685
Epoch 8994/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8995/10000; Iter 1/80; Loss: 0.3383
Epoch 8995/10000; Iter 51/80; Loss: 0.3720
Epoch 8995/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.067
Epoch 8996/10000; Iter 1/80; Loss: 0.3148
Epoch 8996/10000; Iter 51/80; Loss: 0.3522
Epoch 8996/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 8997/10000; Iter 1/80; Loss: 0.3325
Epoch 8997/10000; Iter 51/80; Loss: 0.3399
Epoch 8997/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 8998/10000; Iter 1/80; Loss: 0.3122
Epoch 8998/10000; Iter 51/80; Loss: 0.2661
Epoch 8998/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 8999/10000; Iter 1/80; Loss: 0.2943
Epoch 8999/10000; Iter 51/80; Loss: 0.2817
Epoch 8999/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.077
Epoch 9000/10000; Iter 1/80; Loss: 0.2841
Epoch 9000/10000; Iter 51/80; Loss: 0.3854
Epoch 9000/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9001/10000; Iter 1/80; Loss: 0.2976
Epoch 9001/10000; Iter 51/80; Loss: 0.3631
Epoch 9001/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Model saved
Epoch 9002/10000; Iter 1/80; Loss: 0.3747
Epoch 9002/10000; Iter 51/80; Loss: 0.3438
Epoch 9002/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9003/10000; Iter 1/80; Loss: 0.3065
Epoch 9003/10000; Iter 51/80; Loss: 0.3060
Epoch 9003/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9004/10000; Iter 1/80; Loss: 0.3854
Epoch 9004/10000; Iter 51/80; Loss: 0.3501
Epoch 9004/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 9005/10000; Iter 1/80; Loss: 0.3351
Epoch 9005/10000; Iter 51/80; Loss: 0.2901
Epoch 9005/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9006/10000; Iter 1/80; Loss: 0.3688
Epoch 9006/10000; Iter 51/80; Loss: 0.2472
Epoch 9006/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9007/10000; Iter 1/80; Loss: 0.3176
Epoch 9007/10000; Iter 51/80; Loss: 0.2976
Epoch 9007/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 9008/10000; Iter 1/80; Loss: 0.3320
Epoch 9008/10000; Iter 51/80; Loss: 0.3467
Epoch 9008/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.078
Epoch 9009/10000; Iter 1/80; Loss: 0.3607
Epoch 9009/10000; Iter 51/80; Loss: 0.3149
Epoch 9009/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.08
Epoch 9010/10000; Iter 1/80; Loss: 0.3010
Epoch 9010/10000; Iter 51/80; Loss: 0.3167
Epoch 9010/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9011/10000; Iter 1/80; Loss: 0.3156
Epoch 9011/10000; Iter 51/80; Loss: 0.2744
Epoch 9011/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.08
Epoch 9012/10000; Iter 1/80; Loss: 0.2999
Epoch 9012/10000; Iter 51/80; Loss: 0.3568
Epoch 9012/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9013/10000; Iter 1/80; Loss: 0.3218
Epoch 9013/10000; Iter 51/80; Loss: 0.3163
Epoch 9013/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 9014/10000; Iter 1/80; Loss: 0.2740
Epoch 9014/10000; Iter 51/80; Loss: 0.2826
Epoch 9014/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.071
Epoch 9015/10000; Iter 1/80; Loss: 0.3103
Epoch 9015/10000; Iter 51/80; Loss: 0.3602
Epoch 9015/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 9016/10000; Iter 1/80; Loss: 0.3287
Epoch 9016/10000; Iter 51/80; Loss: 0.2933
Epoch 9016/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 9017/10000; Iter 1/80; Loss: 0.3315
Epoch 9017/10000; Iter 51/80; Loss: 0.3260
Epoch 9017/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 9018/10000; Iter 1/80; Loss: 0.3095
Epoch 9018/10000; Iter 51/80; Loss: 0.3021
Epoch 9018/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 9019/10000; Iter 1/80; Loss: 0.2758
Epoch 9019/10000; Iter 51/80; Loss: 0.3012
Epoch 9019/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 9020/10000; Iter 1/80; Loss: 0.3293
Epoch 9020/10000; Iter 51/80; Loss: 0.3207
Epoch 9020/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 9021/10000; Iter 1/80; Loss: 0.2880
Epoch 9021/10000; Iter 51/80; Loss: 0.3328
Epoch 9021/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 9022/10000; Iter 1/80; Loss: 0.3025
Epoch 9022/10000; Iter 51/80; Loss: 0.3184
Epoch 9022/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9023/10000; Iter 1/80; Loss: 0.2983
Epoch 9023/10000; Iter 51/80; Loss: 0.3219
Epoch 9023/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 9024/10000; Iter 1/80; Loss: 0.3122
Epoch 9024/10000; Iter 51/80; Loss: 0.3304
Epoch 9024/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9025/10000; Iter 1/80; Loss: 0.3485
Epoch 9025/10000; Iter 51/80; Loss: 0.3142
Epoch 9025/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9026/10000; Iter 1/80; Loss: 0.3167
Epoch 9026/10000; Iter 51/80; Loss: 0.2792
Epoch 9026/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.069
Epoch 9027/10000; Iter 1/80; Loss: 0.3172
Epoch 9027/10000; Iter 51/80; Loss: 0.2748
Epoch 9027/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9028/10000; Iter 1/80; Loss: 0.3170
Epoch 9028/10000; Iter 51/80; Loss: 0.3314
Epoch 9028/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 9029/10000; Iter 1/80; Loss: 0.3355
Epoch 9029/10000; Iter 51/80; Loss: 0.2675
Epoch 9029/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 9030/10000; Iter 1/80; Loss: 0.4313
Epoch 9030/10000; Iter 51/80; Loss: 0.3421
Epoch 9030/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9031/10000; Iter 1/80; Loss: 0.3163
Epoch 9031/10000; Iter 51/80; Loss: 0.3360
Epoch 9031/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 9032/10000; Iter 1/80; Loss: 0.3172
Epoch 9032/10000; Iter 51/80; Loss: 0.3753
Epoch 9032/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 9033/10000; Iter 1/80; Loss: 0.2894
Epoch 9033/10000; Iter 51/80; Loss: 0.3525
Epoch 9033/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.071
Epoch 9034/10000; Iter 1/80; Loss: 0.2875
Epoch 9034/10000; Iter 51/80; Loss: 0.3359
Epoch 9034/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.075
Epoch 9035/10000; Iter 1/80; Loss: 0.3105
Epoch 9035/10000; Iter 51/80; Loss: 0.2956
Epoch 9035/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.087
Epoch 9036/10000; Iter 1/80; Loss: 0.3422
Epoch 9036/10000; Iter 51/80; Loss: 0.3256
Epoch 9036/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 9037/10000; Iter 1/80; Loss: 0.3145
Epoch 9037/10000; Iter 51/80; Loss: 0.3539
Epoch 9037/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 9038/10000; Iter 1/80; Loss: 0.3616
Epoch 9038/10000; Iter 51/80; Loss: 0.3567
Epoch 9038/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9039/10000; Iter 1/80; Loss: 0.3335
Epoch 9039/10000; Iter 51/80; Loss: 0.3120
Epoch 9039/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9040/10000; Iter 1/80; Loss: 0.3656
Epoch 9040/10000; Iter 51/80; Loss: 0.3107
Epoch 9040/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.078
Epoch 9041/10000; Iter 1/80; Loss: 0.3140
Epoch 9041/10000; Iter 51/80; Loss: 0.3129
Epoch 9041/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.081
Epoch 9042/10000; Iter 1/80; Loss: 0.3265
Epoch 9042/10000; Iter 51/80; Loss: 0.2626
Epoch 9042/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 9043/10000; Iter 1/80; Loss: 0.3744
Epoch 9043/10000; Iter 51/80; Loss: 0.3030
Epoch 9043/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9044/10000; Iter 1/80; Loss: 0.2999
Epoch 9044/10000; Iter 51/80; Loss: 0.4012
Epoch 9044/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 9045/10000; Iter 1/80; Loss: 0.3358
Epoch 9045/10000; Iter 51/80; Loss: 0.3214
Epoch 9045/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.082
Epoch 9046/10000; Iter 1/80; Loss: 0.3139
Epoch 9046/10000; Iter 51/80; Loss: 0.3096
Epoch 9046/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9047/10000; Iter 1/80; Loss: 0.2888
Epoch 9047/10000; Iter 51/80; Loss: 0.3204
Epoch 9047/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 9048/10000; Iter 1/80; Loss: 0.2999
Epoch 9048/10000; Iter 51/80; Loss: 0.3171
Epoch 9048/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9049/10000; Iter 1/80; Loss: 0.2809
Epoch 9049/10000; Iter 51/80; Loss: 0.3457
Epoch 9049/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.08
Epoch 9050/10000; Iter 1/80; Loss: 0.3000
Epoch 9050/10000; Iter 51/80; Loss: 0.3122
Epoch 9050/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.068
Epoch 9051/10000; Iter 1/80; Loss: 0.3200
Epoch 9051/10000; Iter 51/80; Loss: 0.2969
Epoch 9051/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.066
Epoch 9052/10000; Iter 1/80; Loss: 0.3434
Epoch 9052/10000; Iter 51/80; Loss: 0.2688
Epoch 9052/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 9053/10000; Iter 1/80; Loss: 0.3179
Epoch 9053/10000; Iter 51/80; Loss: 0.3326
Epoch 9053/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 9054/10000; Iter 1/80; Loss: 0.3641
Epoch 9054/10000; Iter 51/80; Loss: 0.3291
Epoch 9054/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 9055/10000; Iter 1/80; Loss: 0.3354
Epoch 9055/10000; Iter 51/80; Loss: 0.3035
Epoch 9055/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 9056/10000; Iter 1/80; Loss: 0.2939
Epoch 9056/10000; Iter 51/80; Loss: 0.3814
Epoch 9056/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 9057/10000; Iter 1/80; Loss: 0.2793
Epoch 9057/10000; Iter 51/80; Loss: 0.3029
Epoch 9057/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9058/10000; Iter 1/80; Loss: 0.3457
Epoch 9058/10000; Iter 51/80; Loss: 0.3777
Epoch 9058/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9059/10000; Iter 1/80; Loss: 0.3610
Epoch 9059/10000; Iter 51/80; Loss: 0.2706
Epoch 9059/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 9060/10000; Iter 1/80; Loss: 0.3467
Epoch 9060/10000; Iter 51/80; Loss: 0.3444
Epoch 9060/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.067
Epoch 9061/10000; Iter 1/80; Loss: 0.2845
Epoch 9061/10000; Iter 51/80; Loss: 0.3493
Epoch 9061/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9062/10000; Iter 1/80; Loss: 0.2911
Epoch 9062/10000; Iter 51/80; Loss: 0.3282
Epoch 9062/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9063/10000; Iter 1/80; Loss: 0.3420
Epoch 9063/10000; Iter 51/80; Loss: 0.3395
Epoch 9063/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 9064/10000; Iter 1/80; Loss: 0.3354
Epoch 9064/10000; Iter 51/80; Loss: 0.3022
Epoch 9064/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.068
Epoch 9065/10000; Iter 1/80; Loss: 0.2987
Epoch 9065/10000; Iter 51/80; Loss: 0.3554
Epoch 9065/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9066/10000; Iter 1/80; Loss: 0.3525
Epoch 9066/10000; Iter 51/80; Loss: 0.3780
Epoch 9066/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.071
Epoch 9067/10000; Iter 1/80; Loss: 0.2756
Epoch 9067/10000; Iter 51/80; Loss: 0.3174
Epoch 9067/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9068/10000; Iter 1/80; Loss: 0.3664
Epoch 9068/10000; Iter 51/80; Loss: 0.3778
Epoch 9068/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 9069/10000; Iter 1/80; Loss: 0.3239
Epoch 9069/10000; Iter 51/80; Loss: 0.3113
Epoch 9069/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9070/10000; Iter 1/80; Loss: 0.3065
Epoch 9070/10000; Iter 51/80; Loss: 0.3367
Epoch 9070/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.07
Epoch 9071/10000; Iter 1/80; Loss: 0.2865
Epoch 9071/10000; Iter 51/80; Loss: 0.3243
Epoch 9071/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9072/10000; Iter 1/80; Loss: 0.3056
Epoch 9072/10000; Iter 51/80; Loss: 0.3072
Epoch 9072/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.082
Epoch 9073/10000; Iter 1/80; Loss: 0.3158
Epoch 9073/10000; Iter 51/80; Loss: 0.2986
Epoch 9073/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 9074/10000; Iter 1/80; Loss: 0.3130
Epoch 9074/10000; Iter 51/80; Loss: 0.3249
Epoch 9074/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 9075/10000; Iter 1/80; Loss: 0.2822
Epoch 9075/10000; Iter 51/80; Loss: 0.3148
Epoch 9075/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.078
Epoch 9076/10000; Iter 1/80; Loss: 0.3493
Epoch 9076/10000; Iter 51/80; Loss: 0.3510
Epoch 9076/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9077/10000; Iter 1/80; Loss: 0.3420
Epoch 9077/10000; Iter 51/80; Loss: 0.3250
Epoch 9077/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9078/10000; Iter 1/80; Loss: 0.2775
Epoch 9078/10000; Iter 51/80; Loss: 0.3316
Epoch 9078/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 9079/10000; Iter 1/80; Loss: 0.3256
Epoch 9079/10000; Iter 51/80; Loss: 0.3000
Epoch 9079/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 9080/10000; Iter 1/80; Loss: 0.3405
Epoch 9080/10000; Iter 51/80; Loss: 0.2965
Epoch 9080/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 9081/10000; Iter 1/80; Loss: 0.3288
Epoch 9081/10000; Iter 51/80; Loss: 0.3326
Epoch 9081/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.081
Epoch 9082/10000; Iter 1/80; Loss: 0.2983
Epoch 9082/10000; Iter 51/80; Loss: 0.3464
Epoch 9082/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.074
Epoch 9083/10000; Iter 1/80; Loss: 0.3175
Epoch 9083/10000; Iter 51/80; Loss: 0.3113
Epoch 9083/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 9084/10000; Iter 1/80; Loss: 0.3344
Epoch 9084/10000; Iter 51/80; Loss: 0.3305
Epoch 9084/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.076
Epoch 9085/10000; Iter 1/80; Loss: 0.3175
Epoch 9085/10000; Iter 51/80; Loss: 0.3350
Epoch 9085/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.068
Epoch 9086/10000; Iter 1/80; Loss: 0.3912
Epoch 9086/10000; Iter 51/80; Loss: 0.3486
Epoch 9086/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.074
Epoch 9087/10000; Iter 1/80; Loss: 0.3485
Epoch 9087/10000; Iter 51/80; Loss: 0.3361
Epoch 9087/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.068
Epoch 9088/10000; Iter 1/80; Loss: 0.2906
Epoch 9088/10000; Iter 51/80; Loss: 0.3436
Epoch 9088/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9089/10000; Iter 1/80; Loss: 0.4063
Epoch 9089/10000; Iter 51/80; Loss: 0.3648
Epoch 9089/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9090/10000; Iter 1/80; Loss: 0.3049
Epoch 9090/10000; Iter 51/80; Loss: 0.3311
Epoch 9090/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9091/10000; Iter 1/80; Loss: 0.3660
Epoch 9091/10000; Iter 51/80; Loss: 0.3450
Epoch 9091/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.069
Epoch 9092/10000; Iter 1/80; Loss: 0.2940
Epoch 9092/10000; Iter 51/80; Loss: 0.2918
Epoch 9092/10000; Iter 80/80; Training Loss: 0.3320, Test Loss: 0.079
Epoch 9093/10000; Iter 1/80; Loss: 0.3310
Epoch 9093/10000; Iter 51/80; Loss: 0.3162
Epoch 9093/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.065
Epoch 9094/10000; Iter 1/80; Loss: 0.3601
Epoch 9094/10000; Iter 51/80; Loss: 0.3823
Epoch 9094/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.081
Epoch 9095/10000; Iter 1/80; Loss: 0.3308
Epoch 9095/10000; Iter 51/80; Loss: 0.3994
Epoch 9095/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9096/10000; Iter 1/80; Loss: 0.3409
Epoch 9096/10000; Iter 51/80; Loss: 0.2875
Epoch 9096/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.074
Epoch 9097/10000; Iter 1/80; Loss: 0.3370
Epoch 9097/10000; Iter 51/80; Loss: 0.3555
Epoch 9097/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 9098/10000; Iter 1/80; Loss: 0.3785
Epoch 9098/10000; Iter 51/80; Loss: 0.2866
Epoch 9098/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.082
Epoch 9099/10000; Iter 1/80; Loss: 0.3394
Epoch 9099/10000; Iter 51/80; Loss: 0.3352
Epoch 9099/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9100/10000; Iter 1/80; Loss: 0.3242
Epoch 9100/10000; Iter 51/80; Loss: 0.3196
Epoch 9100/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 9101/10000; Iter 1/80; Loss: 0.3125
Epoch 9101/10000; Iter 51/80; Loss: 0.2933
Epoch 9101/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Model saved
Epoch 9102/10000; Iter 1/80; Loss: 0.3223
Epoch 9102/10000; Iter 51/80; Loss: 0.3082
Epoch 9102/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.08
Epoch 9103/10000; Iter 1/80; Loss: 0.3474
Epoch 9103/10000; Iter 51/80; Loss: 0.3133
Epoch 9103/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 9104/10000; Iter 1/80; Loss: 0.2923
Epoch 9104/10000; Iter 51/80; Loss: 0.2934
Epoch 9104/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.069
Epoch 9105/10000; Iter 1/80; Loss: 0.3417
Epoch 9105/10000; Iter 51/80; Loss: 0.3066
Epoch 9105/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9106/10000; Iter 1/80; Loss: 0.3293
Epoch 9106/10000; Iter 51/80; Loss: 0.2548
Epoch 9106/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9107/10000; Iter 1/80; Loss: 0.3365
Epoch 9107/10000; Iter 51/80; Loss: 0.3360
Epoch 9107/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9108/10000; Iter 1/80; Loss: 0.4199
Epoch 9108/10000; Iter 51/80; Loss: 0.3257
Epoch 9108/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.071
Epoch 9109/10000; Iter 1/80; Loss: 0.3387
Epoch 9109/10000; Iter 51/80; Loss: 0.3376
Epoch 9109/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.078
Epoch 9110/10000; Iter 1/80; Loss: 0.3269
Epoch 9110/10000; Iter 51/80; Loss: 0.3462
Epoch 9110/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.069
Epoch 9111/10000; Iter 1/80; Loss: 0.3684
Epoch 9111/10000; Iter 51/80; Loss: 0.3687
Epoch 9111/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.066
Epoch 9112/10000; Iter 1/80; Loss: 0.3299
Epoch 9112/10000; Iter 51/80; Loss: 0.3478
Epoch 9112/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9113/10000; Iter 1/80; Loss: 0.3268
Epoch 9113/10000; Iter 51/80; Loss: 0.3249
Epoch 9113/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.071
Epoch 9114/10000; Iter 1/80; Loss: 0.3283
Epoch 9114/10000; Iter 51/80; Loss: 0.3090
Epoch 9114/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9115/10000; Iter 1/80; Loss: 0.3124
Epoch 9115/10000; Iter 51/80; Loss: 0.3363
Epoch 9115/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 9116/10000; Iter 1/80; Loss: 0.2847
Epoch 9116/10000; Iter 51/80; Loss: 0.3398
Epoch 9116/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9117/10000; Iter 1/80; Loss: 0.3499
Epoch 9117/10000; Iter 51/80; Loss: 0.3139
Epoch 9117/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 9118/10000; Iter 1/80; Loss: 0.3069
Epoch 9118/10000; Iter 51/80; Loss: 0.3023
Epoch 9118/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 9119/10000; Iter 1/80; Loss: 0.3301
Epoch 9119/10000; Iter 51/80; Loss: 0.3492
Epoch 9119/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 9120/10000; Iter 1/80; Loss: 0.3022
Epoch 9120/10000; Iter 51/80; Loss: 0.3071
Epoch 9120/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.078
Epoch 9121/10000; Iter 1/80; Loss: 0.3801
Epoch 9121/10000; Iter 51/80; Loss: 0.3072
Epoch 9121/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.079
Epoch 9122/10000; Iter 1/80; Loss: 0.3703
Epoch 9122/10000; Iter 51/80; Loss: 0.3092
Epoch 9122/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 9123/10000; Iter 1/80; Loss: 0.3083
Epoch 9123/10000; Iter 51/80; Loss: 0.3160
Epoch 9123/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 9124/10000; Iter 1/80; Loss: 0.3510
Epoch 9124/10000; Iter 51/80; Loss: 0.3678
Epoch 9124/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 9125/10000; Iter 1/80; Loss: 0.3812
Epoch 9125/10000; Iter 51/80; Loss: 0.3138
Epoch 9125/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 9126/10000; Iter 1/80; Loss: 0.3330
Epoch 9126/10000; Iter 51/80; Loss: 0.3235
Epoch 9126/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 9127/10000; Iter 1/80; Loss: 0.3098
Epoch 9127/10000; Iter 51/80; Loss: 0.3176
Epoch 9127/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 9128/10000; Iter 1/80; Loss: 0.2896
Epoch 9128/10000; Iter 51/80; Loss: 0.3237
Epoch 9128/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 9129/10000; Iter 1/80; Loss: 0.3373
Epoch 9129/10000; Iter 51/80; Loss: 0.3638
Epoch 9129/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9130/10000; Iter 1/80; Loss: 0.2775
Epoch 9130/10000; Iter 51/80; Loss: 0.3634
Epoch 9130/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 9131/10000; Iter 1/80; Loss: 0.2805
Epoch 9131/10000; Iter 51/80; Loss: 0.3601
Epoch 9131/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 9132/10000; Iter 1/80; Loss: 0.3280
Epoch 9132/10000; Iter 51/80; Loss: 0.3660
Epoch 9132/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9133/10000; Iter 1/80; Loss: 0.2702
Epoch 9133/10000; Iter 51/80; Loss: 0.2802
Epoch 9133/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 9134/10000; Iter 1/80; Loss: 0.3601
Epoch 9134/10000; Iter 51/80; Loss: 0.3500
Epoch 9134/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9135/10000; Iter 1/80; Loss: 0.3693
Epoch 9135/10000; Iter 51/80; Loss: 0.3113
Epoch 9135/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 9136/10000; Iter 1/80; Loss: 0.3199
Epoch 9136/10000; Iter 51/80; Loss: 0.4292
Epoch 9136/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9137/10000; Iter 1/80; Loss: 0.3267
Epoch 9137/10000; Iter 51/80; Loss: 0.2924
Epoch 9137/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.086
Epoch 9138/10000; Iter 1/80; Loss: 0.3234
Epoch 9138/10000; Iter 51/80; Loss: 0.3028
Epoch 9138/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9139/10000; Iter 1/80; Loss: 0.3056
Epoch 9139/10000; Iter 51/80; Loss: 0.3286
Epoch 9139/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.085
Epoch 9140/10000; Iter 1/80; Loss: 0.3304
Epoch 9140/10000; Iter 51/80; Loss: 0.3185
Epoch 9140/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9141/10000; Iter 1/80; Loss: 0.3028
Epoch 9141/10000; Iter 51/80; Loss: 0.2754
Epoch 9141/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.078
Epoch 9142/10000; Iter 1/80; Loss: 0.3100
Epoch 9142/10000; Iter 51/80; Loss: 0.3541
Epoch 9142/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 9143/10000; Iter 1/80; Loss: 0.3098
Epoch 9143/10000; Iter 51/80; Loss: 0.3147
Epoch 9143/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9144/10000; Iter 1/80; Loss: 0.3381
Epoch 9144/10000; Iter 51/80; Loss: 0.3360
Epoch 9144/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.08
Epoch 9145/10000; Iter 1/80; Loss: 0.3313
Epoch 9145/10000; Iter 51/80; Loss: 0.3450
Epoch 9145/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.078
Epoch 9146/10000; Iter 1/80; Loss: 0.3378
Epoch 9146/10000; Iter 51/80; Loss: 0.2953
Epoch 9146/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9147/10000; Iter 1/80; Loss: 0.3717
Epoch 9147/10000; Iter 51/80; Loss: 0.2984
Epoch 9147/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 9148/10000; Iter 1/80; Loss: 0.3025
Epoch 9148/10000; Iter 51/80; Loss: 0.3521
Epoch 9148/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9149/10000; Iter 1/80; Loss: 0.3098
Epoch 9149/10000; Iter 51/80; Loss: 0.2731
Epoch 9149/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.068
Epoch 9150/10000; Iter 1/80; Loss: 0.3747
Epoch 9150/10000; Iter 51/80; Loss: 0.3111
Epoch 9150/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9151/10000; Iter 1/80; Loss: 0.3001
Epoch 9151/10000; Iter 51/80; Loss: 0.3527
Epoch 9151/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.072
Epoch 9152/10000; Iter 1/80; Loss: 0.3310
Epoch 9152/10000; Iter 51/80; Loss: 0.3093
Epoch 9152/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.066
Epoch 9153/10000; Iter 1/80; Loss: 0.3438
Epoch 9153/10000; Iter 51/80; Loss: 0.2947
Epoch 9153/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.07
Epoch 9154/10000; Iter 1/80; Loss: 0.3158
Epoch 9154/10000; Iter 51/80; Loss: 0.3135
Epoch 9154/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9155/10000; Iter 1/80; Loss: 0.3183
Epoch 9155/10000; Iter 51/80; Loss: 0.3053
Epoch 9155/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 9156/10000; Iter 1/80; Loss: 0.3204
Epoch 9156/10000; Iter 51/80; Loss: 0.2948
Epoch 9156/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.072
Epoch 9157/10000; Iter 1/80; Loss: 0.4129
Epoch 9157/10000; Iter 51/80; Loss: 0.3170
Epoch 9157/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 9158/10000; Iter 1/80; Loss: 0.3463
Epoch 9158/10000; Iter 51/80; Loss: 0.2657
Epoch 9158/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9159/10000; Iter 1/80; Loss: 0.3243
Epoch 9159/10000; Iter 51/80; Loss: 0.3440
Epoch 9159/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 9160/10000; Iter 1/80; Loss: 0.3741
Epoch 9160/10000; Iter 51/80; Loss: 0.3225
Epoch 9160/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.066
Epoch 9161/10000; Iter 1/80; Loss: 0.3456
Epoch 9161/10000; Iter 51/80; Loss: 0.2921
Epoch 9161/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9162/10000; Iter 1/80; Loss: 0.2901
Epoch 9162/10000; Iter 51/80; Loss: 0.2786
Epoch 9162/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9163/10000; Iter 1/80; Loss: 0.3205
Epoch 9163/10000; Iter 51/80; Loss: 0.2814
Epoch 9163/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.074
Epoch 9164/10000; Iter 1/80; Loss: 0.3770
Epoch 9164/10000; Iter 51/80; Loss: 0.3575
Epoch 9164/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 9165/10000; Iter 1/80; Loss: 0.3287
Epoch 9165/10000; Iter 51/80; Loss: 0.3103
Epoch 9165/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9166/10000; Iter 1/80; Loss: 0.3157
Epoch 9166/10000; Iter 51/80; Loss: 0.3407
Epoch 9166/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 9167/10000; Iter 1/80; Loss: 0.3546
Epoch 9167/10000; Iter 51/80; Loss: 0.3662
Epoch 9167/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9168/10000; Iter 1/80; Loss: 0.3776
Epoch 9168/10000; Iter 51/80; Loss: 0.3272
Epoch 9168/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9169/10000; Iter 1/80; Loss: 0.2835
Epoch 9169/10000; Iter 51/80; Loss: 0.2748
Epoch 9169/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9170/10000; Iter 1/80; Loss: 0.2772
Epoch 9170/10000; Iter 51/80; Loss: 0.3495
Epoch 9170/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9171/10000; Iter 1/80; Loss: 0.2991
Epoch 9171/10000; Iter 51/80; Loss: 0.3249
Epoch 9171/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9172/10000; Iter 1/80; Loss: 0.2912
Epoch 9172/10000; Iter 51/80; Loss: 0.3173
Epoch 9172/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9173/10000; Iter 1/80; Loss: 0.2993
Epoch 9173/10000; Iter 51/80; Loss: 0.2896
Epoch 9173/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.086
Epoch 9174/10000; Iter 1/80; Loss: 0.3113
Epoch 9174/10000; Iter 51/80; Loss: 0.2860
Epoch 9174/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 9175/10000; Iter 1/80; Loss: 0.3026
Epoch 9175/10000; Iter 51/80; Loss: 0.3185
Epoch 9175/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 9176/10000; Iter 1/80; Loss: 0.2446
Epoch 9176/10000; Iter 51/80; Loss: 0.3144
Epoch 9176/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9177/10000; Iter 1/80; Loss: 0.2908
Epoch 9177/10000; Iter 51/80; Loss: 0.3130
Epoch 9177/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9178/10000; Iter 1/80; Loss: 0.3306
Epoch 9178/10000; Iter 51/80; Loss: 0.2714
Epoch 9178/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9179/10000; Iter 1/80; Loss: 0.2790
Epoch 9179/10000; Iter 51/80; Loss: 0.3016
Epoch 9179/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9180/10000; Iter 1/80; Loss: 0.2904
Epoch 9180/10000; Iter 51/80; Loss: 0.3496
Epoch 9180/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 9181/10000; Iter 1/80; Loss: 0.3492
Epoch 9181/10000; Iter 51/80; Loss: 0.2640
Epoch 9181/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9182/10000; Iter 1/80; Loss: 0.4095
Epoch 9182/10000; Iter 51/80; Loss: 0.2677
Epoch 9182/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9183/10000; Iter 1/80; Loss: 0.4330
Epoch 9183/10000; Iter 51/80; Loss: 0.3242
Epoch 9183/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 9184/10000; Iter 1/80; Loss: 0.3508
Epoch 9184/10000; Iter 51/80; Loss: 0.3064
Epoch 9184/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 9185/10000; Iter 1/80; Loss: 0.2641
Epoch 9185/10000; Iter 51/80; Loss: 0.3088
Epoch 9185/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9186/10000; Iter 1/80; Loss: 0.3404
Epoch 9186/10000; Iter 51/80; Loss: 0.3537
Epoch 9186/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 9187/10000; Iter 1/80; Loss: 0.3049
Epoch 9187/10000; Iter 51/80; Loss: 0.3121
Epoch 9187/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 9188/10000; Iter 1/80; Loss: 0.3013
Epoch 9188/10000; Iter 51/80; Loss: 0.3424
Epoch 9188/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.071
Epoch 9189/10000; Iter 1/80; Loss: 0.3123
Epoch 9189/10000; Iter 51/80; Loss: 0.3106
Epoch 9189/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9190/10000; Iter 1/80; Loss: 0.3303
Epoch 9190/10000; Iter 51/80; Loss: 0.2996
Epoch 9190/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9191/10000; Iter 1/80; Loss: 0.3342
Epoch 9191/10000; Iter 51/80; Loss: 0.2897
Epoch 9191/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9192/10000; Iter 1/80; Loss: 0.3413
Epoch 9192/10000; Iter 51/80; Loss: 0.3269
Epoch 9192/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 9193/10000; Iter 1/80; Loss: 0.3175
Epoch 9193/10000; Iter 51/80; Loss: 0.3461
Epoch 9193/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 9194/10000; Iter 1/80; Loss: 0.2700
Epoch 9194/10000; Iter 51/80; Loss: 0.3462
Epoch 9194/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9195/10000; Iter 1/80; Loss: 0.2995
Epoch 9195/10000; Iter 51/80; Loss: 0.3336
Epoch 9195/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9196/10000; Iter 1/80; Loss: 0.3804
Epoch 9196/10000; Iter 51/80; Loss: 0.3045
Epoch 9196/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9197/10000; Iter 1/80; Loss: 0.3050
Epoch 9197/10000; Iter 51/80; Loss: 0.3092
Epoch 9197/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9198/10000; Iter 1/80; Loss: 0.3513
Epoch 9198/10000; Iter 51/80; Loss: 0.3300
Epoch 9198/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.08
Epoch 9199/10000; Iter 1/80; Loss: 0.2985
Epoch 9199/10000; Iter 51/80; Loss: 0.3341
Epoch 9199/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.077
Epoch 9200/10000; Iter 1/80; Loss: 0.3584
Epoch 9200/10000; Iter 51/80; Loss: 0.3641
Epoch 9200/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 9201/10000; Iter 1/80; Loss: 0.3118
Epoch 9201/10000; Iter 51/80; Loss: 0.3785
Epoch 9201/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Model saved
Epoch 9202/10000; Iter 1/80; Loss: 0.3492
Epoch 9202/10000; Iter 51/80; Loss: 0.3962
Epoch 9202/10000; Iter 80/80; Training Loss: 0.3330, Test Loss: 0.076
Epoch 9203/10000; Iter 1/80; Loss: 0.3877
Epoch 9203/10000; Iter 51/80; Loss: 0.3545
Epoch 9203/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9204/10000; Iter 1/80; Loss: 0.3317
Epoch 9204/10000; Iter 51/80; Loss: 0.3412
Epoch 9204/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9205/10000; Iter 1/80; Loss: 0.3099
Epoch 9205/10000; Iter 51/80; Loss: 0.3227
Epoch 9205/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 9206/10000; Iter 1/80; Loss: 0.3500
Epoch 9206/10000; Iter 51/80; Loss: 0.3307
Epoch 9206/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9207/10000; Iter 1/80; Loss: 0.3461
Epoch 9207/10000; Iter 51/80; Loss: 0.2888
Epoch 9207/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 9208/10000; Iter 1/80; Loss: 0.3079
Epoch 9208/10000; Iter 51/80; Loss: 0.3284
Epoch 9208/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.075
Epoch 9209/10000; Iter 1/80; Loss: 0.2988
Epoch 9209/10000; Iter 51/80; Loss: 0.2946
Epoch 9209/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.081
Epoch 9210/10000; Iter 1/80; Loss: 0.3028
Epoch 9210/10000; Iter 51/80; Loss: 0.2907
Epoch 9210/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9211/10000; Iter 1/80; Loss: 0.2858
Epoch 9211/10000; Iter 51/80; Loss: 0.3088
Epoch 9211/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9212/10000; Iter 1/80; Loss: 0.3179
Epoch 9212/10000; Iter 51/80; Loss: 0.3282
Epoch 9212/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9213/10000; Iter 1/80; Loss: 0.2975
Epoch 9213/10000; Iter 51/80; Loss: 0.3169
Epoch 9213/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 9214/10000; Iter 1/80; Loss: 0.3108
Epoch 9214/10000; Iter 51/80; Loss: 0.3578
Epoch 9214/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 9215/10000; Iter 1/80; Loss: 0.3755
Epoch 9215/10000; Iter 51/80; Loss: 0.2804
Epoch 9215/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9216/10000; Iter 1/80; Loss: 0.3841
Epoch 9216/10000; Iter 51/80; Loss: 0.3688
Epoch 9216/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9217/10000; Iter 1/80; Loss: 0.3372
Epoch 9217/10000; Iter 51/80; Loss: 0.3084
Epoch 9217/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9218/10000; Iter 1/80; Loss: 0.3498
Epoch 9218/10000; Iter 51/80; Loss: 0.3596
Epoch 9218/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9219/10000; Iter 1/80; Loss: 0.3555
Epoch 9219/10000; Iter 51/80; Loss: 0.3397
Epoch 9219/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9220/10000; Iter 1/80; Loss: 0.2728
Epoch 9220/10000; Iter 51/80; Loss: 0.3175
Epoch 9220/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 9221/10000; Iter 1/80; Loss: 0.3717
Epoch 9221/10000; Iter 51/80; Loss: 0.3131
Epoch 9221/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9222/10000; Iter 1/80; Loss: 0.3344
Epoch 9222/10000; Iter 51/80; Loss: 0.2997
Epoch 9222/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.084
Epoch 9223/10000; Iter 1/80; Loss: 0.2924
Epoch 9223/10000; Iter 51/80; Loss: 0.3639
Epoch 9223/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9224/10000; Iter 1/80; Loss: 0.3153
Epoch 9224/10000; Iter 51/80; Loss: 0.2936
Epoch 9224/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9225/10000; Iter 1/80; Loss: 0.3260
Epoch 9225/10000; Iter 51/80; Loss: 0.4427
Epoch 9225/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9226/10000; Iter 1/80; Loss: 0.3736
Epoch 9226/10000; Iter 51/80; Loss: 0.3051
Epoch 9226/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.084
Epoch 9227/10000; Iter 1/80; Loss: 0.3694
Epoch 9227/10000; Iter 51/80; Loss: 0.3427
Epoch 9227/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.064
Epoch 9228/10000; Iter 1/80; Loss: 0.4013
Epoch 9228/10000; Iter 51/80; Loss: 0.3557
Epoch 9228/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9229/10000; Iter 1/80; Loss: 0.3312
Epoch 9229/10000; Iter 51/80; Loss: 0.3062
Epoch 9229/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.071
Epoch 9230/10000; Iter 1/80; Loss: 0.2745
Epoch 9230/10000; Iter 51/80; Loss: 0.3627
Epoch 9230/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 9231/10000; Iter 1/80; Loss: 0.2733
Epoch 9231/10000; Iter 51/80; Loss: 0.2969
Epoch 9231/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.079
Epoch 9232/10000; Iter 1/80; Loss: 0.3203
Epoch 9232/10000; Iter 51/80; Loss: 0.3283
Epoch 9232/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9233/10000; Iter 1/80; Loss: 0.3545
Epoch 9233/10000; Iter 51/80; Loss: 0.3858
Epoch 9233/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.082
Epoch 9234/10000; Iter 1/80; Loss: 0.3060
Epoch 9234/10000; Iter 51/80; Loss: 0.3042
Epoch 9234/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 9235/10000; Iter 1/80; Loss: 0.2807
Epoch 9235/10000; Iter 51/80; Loss: 0.2861
Epoch 9235/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 9236/10000; Iter 1/80; Loss: 0.3355
Epoch 9236/10000; Iter 51/80; Loss: 0.2922
Epoch 9236/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9237/10000; Iter 1/80; Loss: 0.2958
Epoch 9237/10000; Iter 51/80; Loss: 0.3812
Epoch 9237/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.078
Epoch 9238/10000; Iter 1/80; Loss: 0.3241
Epoch 9238/10000; Iter 51/80; Loss: 0.3104
Epoch 9238/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9239/10000; Iter 1/80; Loss: 0.3287
Epoch 9239/10000; Iter 51/80; Loss: 0.3316
Epoch 9239/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9240/10000; Iter 1/80; Loss: 0.3307
Epoch 9240/10000; Iter 51/80; Loss: 0.3280
Epoch 9240/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9241/10000; Iter 1/80; Loss: 0.3480
Epoch 9241/10000; Iter 51/80; Loss: 0.3261
Epoch 9241/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9242/10000; Iter 1/80; Loss: 0.3209
Epoch 9242/10000; Iter 51/80; Loss: 0.3477
Epoch 9242/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 9243/10000; Iter 1/80; Loss: 0.3083
Epoch 9243/10000; Iter 51/80; Loss: 0.3606
Epoch 9243/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9244/10000; Iter 1/80; Loss: 0.3725
Epoch 9244/10000; Iter 51/80; Loss: 0.3433
Epoch 9244/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9245/10000; Iter 1/80; Loss: 0.2759
Epoch 9245/10000; Iter 51/80; Loss: 0.3349
Epoch 9245/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.083
Epoch 9246/10000; Iter 1/80; Loss: 0.3230
Epoch 9246/10000; Iter 51/80; Loss: 0.3576
Epoch 9246/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.074
Epoch 9247/10000; Iter 1/80; Loss: 0.3902
Epoch 9247/10000; Iter 51/80; Loss: 0.3025
Epoch 9247/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 9248/10000; Iter 1/80; Loss: 0.3385
Epoch 9248/10000; Iter 51/80; Loss: 0.3079
Epoch 9248/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.082
Epoch 9249/10000; Iter 1/80; Loss: 0.3360
Epoch 9249/10000; Iter 51/80; Loss: 0.3067
Epoch 9249/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.075
Epoch 9250/10000; Iter 1/80; Loss: 0.3082
Epoch 9250/10000; Iter 51/80; Loss: 0.2796
Epoch 9250/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.083
Epoch 9251/10000; Iter 1/80; Loss: 0.2873
Epoch 9251/10000; Iter 51/80; Loss: 0.3282
Epoch 9251/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 9252/10000; Iter 1/80; Loss: 0.3506
Epoch 9252/10000; Iter 51/80; Loss: 0.3826
Epoch 9252/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 9253/10000; Iter 1/80; Loss: 0.3765
Epoch 9253/10000; Iter 51/80; Loss: 0.3003
Epoch 9253/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9254/10000; Iter 1/80; Loss: 0.3490
Epoch 9254/10000; Iter 51/80; Loss: 0.3353
Epoch 9254/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9255/10000; Iter 1/80; Loss: 0.3277
Epoch 9255/10000; Iter 51/80; Loss: 0.2905
Epoch 9255/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9256/10000; Iter 1/80; Loss: 0.3214
Epoch 9256/10000; Iter 51/80; Loss: 0.2978
Epoch 9256/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.083
Epoch 9257/10000; Iter 1/80; Loss: 0.3397
Epoch 9257/10000; Iter 51/80; Loss: 0.2943
Epoch 9257/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.078
Epoch 9258/10000; Iter 1/80; Loss: 0.2801
Epoch 9258/10000; Iter 51/80; Loss: 0.3411
Epoch 9258/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.082
Epoch 9259/10000; Iter 1/80; Loss: 0.3335
Epoch 9259/10000; Iter 51/80; Loss: 0.3384
Epoch 9259/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9260/10000; Iter 1/80; Loss: 0.3163
Epoch 9260/10000; Iter 51/80; Loss: 0.3399
Epoch 9260/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9261/10000; Iter 1/80; Loss: 0.3178
Epoch 9261/10000; Iter 51/80; Loss: 0.2834
Epoch 9261/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.082
Epoch 9262/10000; Iter 1/80; Loss: 0.3932
Epoch 9262/10000; Iter 51/80; Loss: 0.2917
Epoch 9262/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.073
Epoch 9263/10000; Iter 1/80; Loss: 0.3138
Epoch 9263/10000; Iter 51/80; Loss: 0.3291
Epoch 9263/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9264/10000; Iter 1/80; Loss: 0.2972
Epoch 9264/10000; Iter 51/80; Loss: 0.3226
Epoch 9264/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.082
Epoch 9265/10000; Iter 1/80; Loss: 0.3377
Epoch 9265/10000; Iter 51/80; Loss: 0.3056
Epoch 9265/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 9266/10000; Iter 1/80; Loss: 0.3216
Epoch 9266/10000; Iter 51/80; Loss: 0.3579
Epoch 9266/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9267/10000; Iter 1/80; Loss: 0.3086
Epoch 9267/10000; Iter 51/80; Loss: 0.3691
Epoch 9267/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 9268/10000; Iter 1/80; Loss: 0.3395
Epoch 9268/10000; Iter 51/80; Loss: 0.3836
Epoch 9268/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9269/10000; Iter 1/80; Loss: 0.2733
Epoch 9269/10000; Iter 51/80; Loss: 0.3308
Epoch 9269/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9270/10000; Iter 1/80; Loss: 0.3471
Epoch 9270/10000; Iter 51/80; Loss: 0.3550
Epoch 9270/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 9271/10000; Iter 1/80; Loss: 0.3337
Epoch 9271/10000; Iter 51/80; Loss: 0.3331
Epoch 9271/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9272/10000; Iter 1/80; Loss: 0.2802
Epoch 9272/10000; Iter 51/80; Loss: 0.3456
Epoch 9272/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9273/10000; Iter 1/80; Loss: 0.3577
Epoch 9273/10000; Iter 51/80; Loss: 0.3271
Epoch 9273/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.082
Epoch 9274/10000; Iter 1/80; Loss: 0.3300
Epoch 9274/10000; Iter 51/80; Loss: 0.3558
Epoch 9274/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.071
Epoch 9275/10000; Iter 1/80; Loss: 0.3175
Epoch 9275/10000; Iter 51/80; Loss: 0.3304
Epoch 9275/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9276/10000; Iter 1/80; Loss: 0.2665
Epoch 9276/10000; Iter 51/80; Loss: 0.3197
Epoch 9276/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.084
Epoch 9277/10000; Iter 1/80; Loss: 0.3530
Epoch 9277/10000; Iter 51/80; Loss: 0.3195
Epoch 9277/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.07
Epoch 9278/10000; Iter 1/80; Loss: 0.2705
Epoch 9278/10000; Iter 51/80; Loss: 0.3262
Epoch 9278/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9279/10000; Iter 1/80; Loss: 0.2858
Epoch 9279/10000; Iter 51/80; Loss: 0.3198
Epoch 9279/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9280/10000; Iter 1/80; Loss: 0.3577
Epoch 9280/10000; Iter 51/80; Loss: 0.2770
Epoch 9280/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.071
Epoch 9281/10000; Iter 1/80; Loss: 0.3186
Epoch 9281/10000; Iter 51/80; Loss: 0.3270
Epoch 9281/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9282/10000; Iter 1/80; Loss: 0.4120
Epoch 9282/10000; Iter 51/80; Loss: 0.3087
Epoch 9282/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.075
Epoch 9283/10000; Iter 1/80; Loss: 0.3022
Epoch 9283/10000; Iter 51/80; Loss: 0.3234
Epoch 9283/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9284/10000; Iter 1/80; Loss: 0.3055
Epoch 9284/10000; Iter 51/80; Loss: 0.2764
Epoch 9284/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 9285/10000; Iter 1/80; Loss: 0.3276
Epoch 9285/10000; Iter 51/80; Loss: 0.2855
Epoch 9285/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.083
Epoch 9286/10000; Iter 1/80; Loss: 0.2989
Epoch 9286/10000; Iter 51/80; Loss: 0.3145
Epoch 9286/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.083
Epoch 9287/10000; Iter 1/80; Loss: 0.3176
Epoch 9287/10000; Iter 51/80; Loss: 0.3037
Epoch 9287/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9288/10000; Iter 1/80; Loss: 0.3180
Epoch 9288/10000; Iter 51/80; Loss: 0.3217
Epoch 9288/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 9289/10000; Iter 1/80; Loss: 0.3112
Epoch 9289/10000; Iter 51/80; Loss: 0.3169
Epoch 9289/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 9290/10000; Iter 1/80; Loss: 0.2981
Epoch 9290/10000; Iter 51/80; Loss: 0.3466
Epoch 9290/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9291/10000; Iter 1/80; Loss: 0.2901
Epoch 9291/10000; Iter 51/80; Loss: 0.2829
Epoch 9291/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.082
Epoch 9292/10000; Iter 1/80; Loss: 0.3448
Epoch 9292/10000; Iter 51/80; Loss: 0.3147
Epoch 9292/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.075
Epoch 9293/10000; Iter 1/80; Loss: 0.3149
Epoch 9293/10000; Iter 51/80; Loss: 0.3588
Epoch 9293/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.072
Epoch 9294/10000; Iter 1/80; Loss: 0.2838
Epoch 9294/10000; Iter 51/80; Loss: 0.3041
Epoch 9294/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.082
Epoch 9295/10000; Iter 1/80; Loss: 0.3159
Epoch 9295/10000; Iter 51/80; Loss: 0.3411
Epoch 9295/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9296/10000; Iter 1/80; Loss: 0.3743
Epoch 9296/10000; Iter 51/80; Loss: 0.3342
Epoch 9296/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9297/10000; Iter 1/80; Loss: 0.3147
Epoch 9297/10000; Iter 51/80; Loss: 0.2656
Epoch 9297/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9298/10000; Iter 1/80; Loss: 0.2912
Epoch 9298/10000; Iter 51/80; Loss: 0.4134
Epoch 9298/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.082
Epoch 9299/10000; Iter 1/80; Loss: 0.3893
Epoch 9299/10000; Iter 51/80; Loss: 0.3310
Epoch 9299/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 9300/10000; Iter 1/80; Loss: 0.2885
Epoch 9300/10000; Iter 51/80; Loss: 0.3538
Epoch 9300/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 9301/10000; Iter 1/80; Loss: 0.2920
Epoch 9301/10000; Iter 51/80; Loss: 0.3817
Epoch 9301/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.063
Model saved
Epoch 9302/10000; Iter 1/80; Loss: 0.2685
Epoch 9302/10000; Iter 51/80; Loss: 0.3028
Epoch 9302/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9303/10000; Iter 1/80; Loss: 0.2915
Epoch 9303/10000; Iter 51/80; Loss: 0.3905
Epoch 9303/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.071
Epoch 9304/10000; Iter 1/80; Loss: 0.2771
Epoch 9304/10000; Iter 51/80; Loss: 0.3427
Epoch 9304/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.081
Epoch 9305/10000; Iter 1/80; Loss: 0.3525
Epoch 9305/10000; Iter 51/80; Loss: 0.2897
Epoch 9305/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 9306/10000; Iter 1/80; Loss: 0.3603
Epoch 9306/10000; Iter 51/80; Loss: 0.3206
Epoch 9306/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.084
Epoch 9307/10000; Iter 1/80; Loss: 0.3672
Epoch 9307/10000; Iter 51/80; Loss: 0.3257
Epoch 9307/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9308/10000; Iter 1/80; Loss: 0.3648
Epoch 9308/10000; Iter 51/80; Loss: 0.3274
Epoch 9308/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.08
Epoch 9309/10000; Iter 1/80; Loss: 0.3266
Epoch 9309/10000; Iter 51/80; Loss: 0.2914
Epoch 9309/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9310/10000; Iter 1/80; Loss: 0.3603
Epoch 9310/10000; Iter 51/80; Loss: 0.3440
Epoch 9310/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9311/10000; Iter 1/80; Loss: 0.4491
Epoch 9311/10000; Iter 51/80; Loss: 0.3103
Epoch 9311/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.073
Epoch 9312/10000; Iter 1/80; Loss: 0.3102
Epoch 9312/10000; Iter 51/80; Loss: 0.2688
Epoch 9312/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.08
Epoch 9313/10000; Iter 1/80; Loss: 0.3439
Epoch 9313/10000; Iter 51/80; Loss: 0.3097
Epoch 9313/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9314/10000; Iter 1/80; Loss: 0.3128
Epoch 9314/10000; Iter 51/80; Loss: 0.3668
Epoch 9314/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.083
Epoch 9315/10000; Iter 1/80; Loss: 0.3523
Epoch 9315/10000; Iter 51/80; Loss: 0.3747
Epoch 9315/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.071
Epoch 9316/10000; Iter 1/80; Loss: 0.2986
Epoch 9316/10000; Iter 51/80; Loss: 0.3274
Epoch 9316/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9317/10000; Iter 1/80; Loss: 0.3176
Epoch 9317/10000; Iter 51/80; Loss: 0.3425
Epoch 9317/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.082
Epoch 9318/10000; Iter 1/80; Loss: 0.3002
Epoch 9318/10000; Iter 51/80; Loss: 0.3222
Epoch 9318/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9319/10000; Iter 1/80; Loss: 0.3299
Epoch 9319/10000; Iter 51/80; Loss: 0.3128
Epoch 9319/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9320/10000; Iter 1/80; Loss: 0.3172
Epoch 9320/10000; Iter 51/80; Loss: 0.3015
Epoch 9320/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.082
Epoch 9321/10000; Iter 1/80; Loss: 0.2857
Epoch 9321/10000; Iter 51/80; Loss: 0.2997
Epoch 9321/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9322/10000; Iter 1/80; Loss: 0.2990
Epoch 9322/10000; Iter 51/80; Loss: 0.3214
Epoch 9322/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 9323/10000; Iter 1/80; Loss: 0.3296
Epoch 9323/10000; Iter 51/80; Loss: 0.3424
Epoch 9323/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9324/10000; Iter 1/80; Loss: 0.3281
Epoch 9324/10000; Iter 51/80; Loss: 0.3562
Epoch 9324/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 9325/10000; Iter 1/80; Loss: 0.2920
Epoch 9325/10000; Iter 51/80; Loss: 0.3284
Epoch 9325/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.089
Epoch 9326/10000; Iter 1/80; Loss: 0.3019
Epoch 9326/10000; Iter 51/80; Loss: 0.3133
Epoch 9326/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 9327/10000; Iter 1/80; Loss: 0.3147
Epoch 9327/10000; Iter 51/80; Loss: 0.3298
Epoch 9327/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9328/10000; Iter 1/80; Loss: 0.2995
Epoch 9328/10000; Iter 51/80; Loss: 0.3736
Epoch 9328/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.076
Epoch 9329/10000; Iter 1/80; Loss: 0.3294
Epoch 9329/10000; Iter 51/80; Loss: 0.3012
Epoch 9329/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.086
Epoch 9330/10000; Iter 1/80; Loss: 0.3525
Epoch 9330/10000; Iter 51/80; Loss: 0.3264
Epoch 9330/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.075
Epoch 9331/10000; Iter 1/80; Loss: 0.2823
Epoch 9331/10000; Iter 51/80; Loss: 0.3641
Epoch 9331/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 9332/10000; Iter 1/80; Loss: 0.3347
Epoch 9332/10000; Iter 51/80; Loss: 0.3259
Epoch 9332/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.073
Epoch 9333/10000; Iter 1/80; Loss: 0.3214
Epoch 9333/10000; Iter 51/80; Loss: 0.3302
Epoch 9333/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9334/10000; Iter 1/80; Loss: 0.2854
Epoch 9334/10000; Iter 51/80; Loss: 0.3129
Epoch 9334/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.068
Epoch 9335/10000; Iter 1/80; Loss: 0.2926
Epoch 9335/10000; Iter 51/80; Loss: 0.3138
Epoch 9335/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.079
Epoch 9336/10000; Iter 1/80; Loss: 0.2991
Epoch 9336/10000; Iter 51/80; Loss: 0.3388
Epoch 9336/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9337/10000; Iter 1/80; Loss: 0.3194
Epoch 9337/10000; Iter 51/80; Loss: 0.2954
Epoch 9337/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.067
Epoch 9338/10000; Iter 1/80; Loss: 0.2901
Epoch 9338/10000; Iter 51/80; Loss: 0.3124
Epoch 9338/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9339/10000; Iter 1/80; Loss: 0.2699
Epoch 9339/10000; Iter 51/80; Loss: 0.3289
Epoch 9339/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.075
Epoch 9340/10000; Iter 1/80; Loss: 0.2686
Epoch 9340/10000; Iter 51/80; Loss: 0.4060
Epoch 9340/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.078
Epoch 9341/10000; Iter 1/80; Loss: 0.3163
Epoch 9341/10000; Iter 51/80; Loss: 0.2667
Epoch 9341/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 9342/10000; Iter 1/80; Loss: 0.2881
Epoch 9342/10000; Iter 51/80; Loss: 0.2964
Epoch 9342/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.075
Epoch 9343/10000; Iter 1/80; Loss: 0.3166
Epoch 9343/10000; Iter 51/80; Loss: 0.3467
Epoch 9343/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 9344/10000; Iter 1/80; Loss: 0.3341
Epoch 9344/10000; Iter 51/80; Loss: 0.3312
Epoch 9344/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.082
Epoch 9345/10000; Iter 1/80; Loss: 0.3052
Epoch 9345/10000; Iter 51/80; Loss: 0.2644
Epoch 9345/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9346/10000; Iter 1/80; Loss: 0.3699
Epoch 9346/10000; Iter 51/80; Loss: 0.3289
Epoch 9346/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9347/10000; Iter 1/80; Loss: 0.2973
Epoch 9347/10000; Iter 51/80; Loss: 0.2826
Epoch 9347/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9348/10000; Iter 1/80; Loss: 0.3718
Epoch 9348/10000; Iter 51/80; Loss: 0.3421
Epoch 9348/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 9349/10000; Iter 1/80; Loss: 0.3171
Epoch 9349/10000; Iter 51/80; Loss: 0.3283
Epoch 9349/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.071
Epoch 9350/10000; Iter 1/80; Loss: 0.3160
Epoch 9350/10000; Iter 51/80; Loss: 0.3463
Epoch 9350/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.087
Epoch 9351/10000; Iter 1/80; Loss: 0.3495
Epoch 9351/10000; Iter 51/80; Loss: 0.3662
Epoch 9351/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.084
Epoch 9352/10000; Iter 1/80; Loss: 0.3286
Epoch 9352/10000; Iter 51/80; Loss: 0.3947
Epoch 9352/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.085
Epoch 9353/10000; Iter 1/80; Loss: 0.4094
Epoch 9353/10000; Iter 51/80; Loss: 0.3589
Epoch 9353/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.077
Epoch 9354/10000; Iter 1/80; Loss: 0.3711
Epoch 9354/10000; Iter 51/80; Loss: 0.3236
Epoch 9354/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.081
Epoch 9355/10000; Iter 1/80; Loss: 0.4099
Epoch 9355/10000; Iter 51/80; Loss: 0.3451
Epoch 9355/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 9356/10000; Iter 1/80; Loss: 0.3153
Epoch 9356/10000; Iter 51/80; Loss: 0.3368
Epoch 9356/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.064
Epoch 9357/10000; Iter 1/80; Loss: 0.3705
Epoch 9357/10000; Iter 51/80; Loss: 0.2834
Epoch 9357/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9358/10000; Iter 1/80; Loss: 0.2932
Epoch 9358/10000; Iter 51/80; Loss: 0.2764
Epoch 9358/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.07
Epoch 9359/10000; Iter 1/80; Loss: 0.2929
Epoch 9359/10000; Iter 51/80; Loss: 0.3238
Epoch 9359/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.071
Epoch 9360/10000; Iter 1/80; Loss: 0.2978
Epoch 9360/10000; Iter 51/80; Loss: 0.3079
Epoch 9360/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 9361/10000; Iter 1/80; Loss: 0.2610
Epoch 9361/10000; Iter 51/80; Loss: 0.2941
Epoch 9361/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.071
Epoch 9362/10000; Iter 1/80; Loss: 0.3329
Epoch 9362/10000; Iter 51/80; Loss: 0.3194
Epoch 9362/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9363/10000; Iter 1/80; Loss: 0.3265
Epoch 9363/10000; Iter 51/80; Loss: 0.3118
Epoch 9363/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.075
Epoch 9364/10000; Iter 1/80; Loss: 0.3035
Epoch 9364/10000; Iter 51/80; Loss: 0.3592
Epoch 9364/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9365/10000; Iter 1/80; Loss: 0.3511
Epoch 9365/10000; Iter 51/80; Loss: 0.3576
Epoch 9365/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 9366/10000; Iter 1/80; Loss: 0.3553
Epoch 9366/10000; Iter 51/80; Loss: 0.3046
Epoch 9366/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9367/10000; Iter 1/80; Loss: 0.3275
Epoch 9367/10000; Iter 51/80; Loss: 0.3350
Epoch 9367/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9368/10000; Iter 1/80; Loss: 0.3106
Epoch 9368/10000; Iter 51/80; Loss: 0.2931
Epoch 9368/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.076
Epoch 9369/10000; Iter 1/80; Loss: 0.3749
Epoch 9369/10000; Iter 51/80; Loss: 0.3097
Epoch 9369/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.084
Epoch 9370/10000; Iter 1/80; Loss: 0.3151
Epoch 9370/10000; Iter 51/80; Loss: 0.3245
Epoch 9370/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9371/10000; Iter 1/80; Loss: 0.3217
Epoch 9371/10000; Iter 51/80; Loss: 0.3022
Epoch 9371/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.076
Epoch 9372/10000; Iter 1/80; Loss: 0.3981
Epoch 9372/10000; Iter 51/80; Loss: 0.3872
Epoch 9372/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.076
Epoch 9373/10000; Iter 1/80; Loss: 0.3484
Epoch 9373/10000; Iter 51/80; Loss: 0.3229
Epoch 9373/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.076
Epoch 9374/10000; Iter 1/80; Loss: 0.3265
Epoch 9374/10000; Iter 51/80; Loss: 0.3754
Epoch 9374/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9375/10000; Iter 1/80; Loss: 0.3043
Epoch 9375/10000; Iter 51/80; Loss: 0.3197
Epoch 9375/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.091
Epoch 9376/10000; Iter 1/80; Loss: 0.3444
Epoch 9376/10000; Iter 51/80; Loss: 0.3910
Epoch 9376/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9377/10000; Iter 1/80; Loss: 0.3494
Epoch 9377/10000; Iter 51/80; Loss: 0.3724
Epoch 9377/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.07
Epoch 9378/10000; Iter 1/80; Loss: 0.2930
Epoch 9378/10000; Iter 51/80; Loss: 0.2828
Epoch 9378/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9379/10000; Iter 1/80; Loss: 0.2704
Epoch 9379/10000; Iter 51/80; Loss: 0.3319
Epoch 9379/10000; Iter 80/80; Training Loss: 0.3300, Test Loss: 0.079
Epoch 9380/10000; Iter 1/80; Loss: 0.3227
Epoch 9380/10000; Iter 51/80; Loss: 0.3291
Epoch 9380/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9381/10000; Iter 1/80; Loss: 0.3323
Epoch 9381/10000; Iter 51/80; Loss: 0.3312
Epoch 9381/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 9382/10000; Iter 1/80; Loss: 0.3619
Epoch 9382/10000; Iter 51/80; Loss: 0.3115
Epoch 9382/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9383/10000; Iter 1/80; Loss: 0.3387
Epoch 9383/10000; Iter 51/80; Loss: 0.4037
Epoch 9383/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.085
Epoch 9384/10000; Iter 1/80; Loss: 0.3134
Epoch 9384/10000; Iter 51/80; Loss: 0.3458
Epoch 9384/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.083
Epoch 9385/10000; Iter 1/80; Loss: 0.3451
Epoch 9385/10000; Iter 51/80; Loss: 0.3616
Epoch 9385/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9386/10000; Iter 1/80; Loss: 0.3126
Epoch 9386/10000; Iter 51/80; Loss: 0.3152
Epoch 9386/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.086
Epoch 9387/10000; Iter 1/80; Loss: 0.3629
Epoch 9387/10000; Iter 51/80; Loss: 0.3167
Epoch 9387/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9388/10000; Iter 1/80; Loss: 0.3082
Epoch 9388/10000; Iter 51/80; Loss: 0.2987
Epoch 9388/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9389/10000; Iter 1/80; Loss: 0.3137
Epoch 9389/10000; Iter 51/80; Loss: 0.3330
Epoch 9389/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.076
Epoch 9390/10000; Iter 1/80; Loss: 0.3148
Epoch 9390/10000; Iter 51/80; Loss: 0.3207
Epoch 9390/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9391/10000; Iter 1/80; Loss: 0.3058
Epoch 9391/10000; Iter 51/80; Loss: 0.3036
Epoch 9391/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9392/10000; Iter 1/80; Loss: 0.3179
Epoch 9392/10000; Iter 51/80; Loss: 0.3364
Epoch 9392/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 9393/10000; Iter 1/80; Loss: 0.2960
Epoch 9393/10000; Iter 51/80; Loss: 0.3250
Epoch 9393/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9394/10000; Iter 1/80; Loss: 0.3403
Epoch 9394/10000; Iter 51/80; Loss: 0.2991
Epoch 9394/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9395/10000; Iter 1/80; Loss: 0.3275
Epoch 9395/10000; Iter 51/80; Loss: 0.3471
Epoch 9395/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9396/10000; Iter 1/80; Loss: 0.3496
Epoch 9396/10000; Iter 51/80; Loss: 0.3145
Epoch 9396/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9397/10000; Iter 1/80; Loss: 0.2967
Epoch 9397/10000; Iter 51/80; Loss: 0.3300
Epoch 9397/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9398/10000; Iter 1/80; Loss: 0.3298
Epoch 9398/10000; Iter 51/80; Loss: 0.3355
Epoch 9398/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.076
Epoch 9399/10000; Iter 1/80; Loss: 0.3117
Epoch 9399/10000; Iter 51/80; Loss: 0.3156
Epoch 9399/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.081
Epoch 9400/10000; Iter 1/80; Loss: 0.4059
Epoch 9400/10000; Iter 51/80; Loss: 0.2854
Epoch 9400/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.069
Epoch 9401/10000; Iter 1/80; Loss: 0.3480
Epoch 9401/10000; Iter 51/80; Loss: 0.2579
Epoch 9401/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.077
Model saved
Epoch 9402/10000; Iter 1/80; Loss: 0.3000
Epoch 9402/10000; Iter 51/80; Loss: 0.3640
Epoch 9402/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 9403/10000; Iter 1/80; Loss: 0.3153
Epoch 9403/10000; Iter 51/80; Loss: 0.3467
Epoch 9403/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.078
Epoch 9404/10000; Iter 1/80; Loss: 0.3235
Epoch 9404/10000; Iter 51/80; Loss: 0.3558
Epoch 9404/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 9405/10000; Iter 1/80; Loss: 0.2306
Epoch 9405/10000; Iter 51/80; Loss: 0.3316
Epoch 9405/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9406/10000; Iter 1/80; Loss: 0.3619
Epoch 9406/10000; Iter 51/80; Loss: 0.3150
Epoch 9406/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.077
Epoch 9407/10000; Iter 1/80; Loss: 0.2902
Epoch 9407/10000; Iter 51/80; Loss: 0.3757
Epoch 9407/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9408/10000; Iter 1/80; Loss: 0.3139
Epoch 9408/10000; Iter 51/80; Loss: 0.3262
Epoch 9408/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9409/10000; Iter 1/80; Loss: 0.3270
Epoch 9409/10000; Iter 51/80; Loss: 0.3252
Epoch 9409/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.079
Epoch 9410/10000; Iter 1/80; Loss: 0.3176
Epoch 9410/10000; Iter 51/80; Loss: 0.3186
Epoch 9410/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.08
Epoch 9411/10000; Iter 1/80; Loss: 0.3169
Epoch 9411/10000; Iter 51/80; Loss: 0.3264
Epoch 9411/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 9412/10000; Iter 1/80; Loss: 0.2875
Epoch 9412/10000; Iter 51/80; Loss: 0.3240
Epoch 9412/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9413/10000; Iter 1/80; Loss: 0.3211
Epoch 9413/10000; Iter 51/80; Loss: 0.3102
Epoch 9413/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9414/10000; Iter 1/80; Loss: 0.2823
Epoch 9414/10000; Iter 51/80; Loss: 0.3184
Epoch 9414/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 9415/10000; Iter 1/80; Loss: 0.2752
Epoch 9415/10000; Iter 51/80; Loss: 0.3213
Epoch 9415/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 9416/10000; Iter 1/80; Loss: 0.2981
Epoch 9416/10000; Iter 51/80; Loss: 0.2847
Epoch 9416/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.079
Epoch 9417/10000; Iter 1/80; Loss: 0.3286
Epoch 9417/10000; Iter 51/80; Loss: 0.2980
Epoch 9417/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9418/10000; Iter 1/80; Loss: 0.3873
Epoch 9418/10000; Iter 51/80; Loss: 0.2644
Epoch 9418/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.083
Epoch 9419/10000; Iter 1/80; Loss: 0.3286
Epoch 9419/10000; Iter 51/80; Loss: 0.3685
Epoch 9419/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.077
Epoch 9420/10000; Iter 1/80; Loss: 0.2945
Epoch 9420/10000; Iter 51/80; Loss: 0.3020
Epoch 9420/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 9421/10000; Iter 1/80; Loss: 0.3166
Epoch 9421/10000; Iter 51/80; Loss: 0.3117
Epoch 9421/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.089
Epoch 9422/10000; Iter 1/80; Loss: 0.3285
Epoch 9422/10000; Iter 51/80; Loss: 0.3355
Epoch 9422/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.082
Epoch 9423/10000; Iter 1/80; Loss: 0.3014
Epoch 9423/10000; Iter 51/80; Loss: 0.3155
Epoch 9423/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.079
Epoch 9424/10000; Iter 1/80; Loss: 0.3216
Epoch 9424/10000; Iter 51/80; Loss: 0.2990
Epoch 9424/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.082
Epoch 9425/10000; Iter 1/80; Loss: 0.2858
Epoch 9425/10000; Iter 51/80; Loss: 0.3159
Epoch 9425/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.082
Epoch 9426/10000; Iter 1/80; Loss: 0.3163
Epoch 9426/10000; Iter 51/80; Loss: 0.3971
Epoch 9426/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.072
Epoch 9427/10000; Iter 1/80; Loss: 0.3564
Epoch 9427/10000; Iter 51/80; Loss: 0.3443
Epoch 9427/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.083
Epoch 9428/10000; Iter 1/80; Loss: 0.3162
Epoch 9428/10000; Iter 51/80; Loss: 0.3715
Epoch 9428/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.072
Epoch 9429/10000; Iter 1/80; Loss: 0.2843
Epoch 9429/10000; Iter 51/80; Loss: 0.3323
Epoch 9429/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.076
Epoch 9430/10000; Iter 1/80; Loss: 0.3512
Epoch 9430/10000; Iter 51/80; Loss: 0.3095
Epoch 9430/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.073
Epoch 9431/10000; Iter 1/80; Loss: 0.2939
Epoch 9431/10000; Iter 51/80; Loss: 0.2996
Epoch 9431/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.081
Epoch 9432/10000; Iter 1/80; Loss: 0.3890
Epoch 9432/10000; Iter 51/80; Loss: 0.2796
Epoch 9432/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9433/10000; Iter 1/80; Loss: 0.3095
Epoch 9433/10000; Iter 51/80; Loss: 0.2988
Epoch 9433/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.076
Epoch 9434/10000; Iter 1/80; Loss: 0.3987
Epoch 9434/10000; Iter 51/80; Loss: 0.3156
Epoch 9434/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.084
Epoch 9435/10000; Iter 1/80; Loss: 0.3400
Epoch 9435/10000; Iter 51/80; Loss: 0.3140
Epoch 9435/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9436/10000; Iter 1/80; Loss: 0.2758
Epoch 9436/10000; Iter 51/80; Loss: 0.2958
Epoch 9436/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.086
Epoch 9437/10000; Iter 1/80; Loss: 0.3489
Epoch 9437/10000; Iter 51/80; Loss: 0.3013
Epoch 9437/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 9438/10000; Iter 1/80; Loss: 0.3131
Epoch 9438/10000; Iter 51/80; Loss: 0.3033
Epoch 9438/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9439/10000; Iter 1/80; Loss: 0.3207
Epoch 9439/10000; Iter 51/80; Loss: 0.3149
Epoch 9439/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.085
Epoch 9440/10000; Iter 1/80; Loss: 0.3539
Epoch 9440/10000; Iter 51/80; Loss: 0.2772
Epoch 9440/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 9441/10000; Iter 1/80; Loss: 0.2742
Epoch 9441/10000; Iter 51/80; Loss: 0.3611
Epoch 9441/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9442/10000; Iter 1/80; Loss: 0.3407
Epoch 9442/10000; Iter 51/80; Loss: 0.3423
Epoch 9442/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 9443/10000; Iter 1/80; Loss: 0.3289
Epoch 9443/10000; Iter 51/80; Loss: 0.3325
Epoch 9443/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 9444/10000; Iter 1/80; Loss: 0.3294
Epoch 9444/10000; Iter 51/80; Loss: 0.3112
Epoch 9444/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.071
Epoch 9445/10000; Iter 1/80; Loss: 0.3112
Epoch 9445/10000; Iter 51/80; Loss: 0.2856
Epoch 9445/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9446/10000; Iter 1/80; Loss: 0.3292
Epoch 9446/10000; Iter 51/80; Loss: 0.3593
Epoch 9446/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 9447/10000; Iter 1/80; Loss: 0.3481
Epoch 9447/10000; Iter 51/80; Loss: 0.3062
Epoch 9447/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9448/10000; Iter 1/80; Loss: 0.3424
Epoch 9448/10000; Iter 51/80; Loss: 0.3502
Epoch 9448/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.072
Epoch 9449/10000; Iter 1/80; Loss: 0.3538
Epoch 9449/10000; Iter 51/80; Loss: 0.3480
Epoch 9449/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 9450/10000; Iter 1/80; Loss: 0.3156
Epoch 9450/10000; Iter 51/80; Loss: 0.2978
Epoch 9450/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.084
Epoch 9451/10000; Iter 1/80; Loss: 0.3206
Epoch 9451/10000; Iter 51/80; Loss: 0.3540
Epoch 9451/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.081
Epoch 9452/10000; Iter 1/80; Loss: 0.3607
Epoch 9452/10000; Iter 51/80; Loss: 0.3161
Epoch 9452/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.08
Epoch 9453/10000; Iter 1/80; Loss: 0.3142
Epoch 9453/10000; Iter 51/80; Loss: 0.3547
Epoch 9453/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.084
Epoch 9454/10000; Iter 1/80; Loss: 0.3081
Epoch 9454/10000; Iter 51/80; Loss: 0.3261
Epoch 9454/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9455/10000; Iter 1/80; Loss: 0.3105
Epoch 9455/10000; Iter 51/80; Loss: 0.3008
Epoch 9455/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.083
Epoch 9456/10000; Iter 1/80; Loss: 0.2959
Epoch 9456/10000; Iter 51/80; Loss: 0.3145
Epoch 9456/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.086
Epoch 9457/10000; Iter 1/80; Loss: 0.2912
Epoch 9457/10000; Iter 51/80; Loss: 0.2855
Epoch 9457/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.081
Epoch 9458/10000; Iter 1/80; Loss: 0.3582
Epoch 9458/10000; Iter 51/80; Loss: 0.3287
Epoch 9458/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.079
Epoch 9459/10000; Iter 1/80; Loss: 0.3221
Epoch 9459/10000; Iter 51/80; Loss: 0.2983
Epoch 9459/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9460/10000; Iter 1/80; Loss: 0.3204
Epoch 9460/10000; Iter 51/80; Loss: 0.2804
Epoch 9460/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.081
Epoch 9461/10000; Iter 1/80; Loss: 0.3764
Epoch 9461/10000; Iter 51/80; Loss: 0.4143
Epoch 9461/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.073
Epoch 9462/10000; Iter 1/80; Loss: 0.3989
Epoch 9462/10000; Iter 51/80; Loss: 0.3864
Epoch 9462/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.078
Epoch 9463/10000; Iter 1/80; Loss: 0.2788
Epoch 9463/10000; Iter 51/80; Loss: 0.3107
Epoch 9463/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.074
Epoch 9464/10000; Iter 1/80; Loss: 0.3071
Epoch 9464/10000; Iter 51/80; Loss: 0.3073
Epoch 9464/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.085
Epoch 9465/10000; Iter 1/80; Loss: 0.2899
Epoch 9465/10000; Iter 51/80; Loss: 0.3067
Epoch 9465/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.068
Epoch 9466/10000; Iter 1/80; Loss: 0.3150
Epoch 9466/10000; Iter 51/80; Loss: 0.3240
Epoch 9466/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 9467/10000; Iter 1/80; Loss: 0.3086
Epoch 9467/10000; Iter 51/80; Loss: 0.2750
Epoch 9467/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9468/10000; Iter 1/80; Loss: 0.3359
Epoch 9468/10000; Iter 51/80; Loss: 0.2818
Epoch 9468/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.075
Epoch 9469/10000; Iter 1/80; Loss: 0.2825
Epoch 9469/10000; Iter 51/80; Loss: 0.3566
Epoch 9469/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9470/10000; Iter 1/80; Loss: 0.3307
Epoch 9470/10000; Iter 51/80; Loss: 0.3086
Epoch 9470/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.075
Epoch 9471/10000; Iter 1/80; Loss: 0.2800
Epoch 9471/10000; Iter 51/80; Loss: 0.3247
Epoch 9471/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.073
Epoch 9472/10000; Iter 1/80; Loss: 0.3147
Epoch 9472/10000; Iter 51/80; Loss: 0.2948
Epoch 9472/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.071
Epoch 9473/10000; Iter 1/80; Loss: 0.3121
Epoch 9473/10000; Iter 51/80; Loss: 0.2889
Epoch 9473/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9474/10000; Iter 1/80; Loss: 0.2850
Epoch 9474/10000; Iter 51/80; Loss: 0.2850
Epoch 9474/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9475/10000; Iter 1/80; Loss: 0.3253
Epoch 9475/10000; Iter 51/80; Loss: 0.3058
Epoch 9475/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.072
Epoch 9476/10000; Iter 1/80; Loss: 0.3270
Epoch 9476/10000; Iter 51/80; Loss: 0.3270
Epoch 9476/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.075
Epoch 9477/10000; Iter 1/80; Loss: 0.3530
Epoch 9477/10000; Iter 51/80; Loss: 0.3761
Epoch 9477/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.083
Epoch 9478/10000; Iter 1/80; Loss: 0.3087
Epoch 9478/10000; Iter 51/80; Loss: 0.3299
Epoch 9478/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9479/10000; Iter 1/80; Loss: 0.2918
Epoch 9479/10000; Iter 51/80; Loss: 0.2592
Epoch 9479/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9480/10000; Iter 1/80; Loss: 0.2685
Epoch 9480/10000; Iter 51/80; Loss: 0.3626
Epoch 9480/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9481/10000; Iter 1/80; Loss: 0.3302
Epoch 9481/10000; Iter 51/80; Loss: 0.3205
Epoch 9481/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9482/10000; Iter 1/80; Loss: 0.3110
Epoch 9482/10000; Iter 51/80; Loss: 0.3145
Epoch 9482/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.082
Epoch 9483/10000; Iter 1/80; Loss: 0.3147
Epoch 9483/10000; Iter 51/80; Loss: 0.3402
Epoch 9483/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9484/10000; Iter 1/80; Loss: 0.2998
Epoch 9484/10000; Iter 51/80; Loss: 0.3288
Epoch 9484/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.07
Epoch 9485/10000; Iter 1/80; Loss: 0.3315
Epoch 9485/10000; Iter 51/80; Loss: 0.2752
Epoch 9485/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.074
Epoch 9486/10000; Iter 1/80; Loss: 0.3466
Epoch 9486/10000; Iter 51/80; Loss: 0.3137
Epoch 9486/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 9487/10000; Iter 1/80; Loss: 0.3059
Epoch 9487/10000; Iter 51/80; Loss: 0.3763
Epoch 9487/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.074
Epoch 9488/10000; Iter 1/80; Loss: 0.3354
Epoch 9488/10000; Iter 51/80; Loss: 0.3254
Epoch 9488/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 9489/10000; Iter 1/80; Loss: 0.4098
Epoch 9489/10000; Iter 51/80; Loss: 0.3343
Epoch 9489/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9490/10000; Iter 1/80; Loss: 0.3254
Epoch 9490/10000; Iter 51/80; Loss: 0.3139
Epoch 9490/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.075
Epoch 9491/10000; Iter 1/80; Loss: 0.3327
Epoch 9491/10000; Iter 51/80; Loss: 0.3587
Epoch 9491/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9492/10000; Iter 1/80; Loss: 0.3269
Epoch 9492/10000; Iter 51/80; Loss: 0.3263
Epoch 9492/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.084
Epoch 9493/10000; Iter 1/80; Loss: 0.2651
Epoch 9493/10000; Iter 51/80; Loss: 0.2928
Epoch 9493/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.069
Epoch 9494/10000; Iter 1/80; Loss: 0.2888
Epoch 9494/10000; Iter 51/80; Loss: 0.2826
Epoch 9494/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9495/10000; Iter 1/80; Loss: 0.3016
Epoch 9495/10000; Iter 51/80; Loss: 0.3351
Epoch 9495/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 9496/10000; Iter 1/80; Loss: 0.2981
Epoch 9496/10000; Iter 51/80; Loss: 0.2974
Epoch 9496/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 9497/10000; Iter 1/80; Loss: 0.3253
Epoch 9497/10000; Iter 51/80; Loss: 0.2611
Epoch 9497/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.071
Epoch 9498/10000; Iter 1/80; Loss: 0.3411
Epoch 9498/10000; Iter 51/80; Loss: 0.3146
Epoch 9498/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.08
Epoch 9499/10000; Iter 1/80; Loss: 0.3362
Epoch 9499/10000; Iter 51/80; Loss: 0.2661
Epoch 9499/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9500/10000; Iter 1/80; Loss: 0.3767
Epoch 9500/10000; Iter 51/80; Loss: 0.3369
Epoch 9500/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.084
Epoch 9501/10000; Iter 1/80; Loss: 0.2892
Epoch 9501/10000; Iter 51/80; Loss: 0.3101
Epoch 9501/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.084
Model saved
Epoch 9502/10000; Iter 1/80; Loss: 0.2675
Epoch 9502/10000; Iter 51/80; Loss: 0.3439
Epoch 9502/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.081
Epoch 9503/10000; Iter 1/80; Loss: 0.3193
Epoch 9503/10000; Iter 51/80; Loss: 0.3264
Epoch 9503/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9504/10000; Iter 1/80; Loss: 0.2885
Epoch 9504/10000; Iter 51/80; Loss: 0.3378
Epoch 9504/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.079
Epoch 9505/10000; Iter 1/80; Loss: 0.3159
Epoch 9505/10000; Iter 51/80; Loss: 0.3070
Epoch 9505/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9506/10000; Iter 1/80; Loss: 0.3315
Epoch 9506/10000; Iter 51/80; Loss: 0.3164
Epoch 9506/10000; Iter 80/80; Training Loss: 0.3290, Test Loss: 0.075
Epoch 9507/10000; Iter 1/80; Loss: 0.2891
Epoch 9507/10000; Iter 51/80; Loss: 0.3714
Epoch 9507/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.073
Epoch 9508/10000; Iter 1/80; Loss: 0.2847
Epoch 9508/10000; Iter 51/80; Loss: 0.3097
Epoch 9508/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.074
Epoch 9509/10000; Iter 1/80; Loss: 0.3932
Epoch 9509/10000; Iter 51/80; Loss: 0.3368
Epoch 9509/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9510/10000; Iter 1/80; Loss: 0.2935
Epoch 9510/10000; Iter 51/80; Loss: 0.3311
Epoch 9510/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 9511/10000; Iter 1/80; Loss: 0.3147
Epoch 9511/10000; Iter 51/80; Loss: 0.2870
Epoch 9511/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 9512/10000; Iter 1/80; Loss: 0.3738
Epoch 9512/10000; Iter 51/80; Loss: 0.3804
Epoch 9512/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.09
Epoch 9513/10000; Iter 1/80; Loss: 0.3394
Epoch 9513/10000; Iter 51/80; Loss: 0.3417
Epoch 9513/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.081
Epoch 9514/10000; Iter 1/80; Loss: 0.2889
Epoch 9514/10000; Iter 51/80; Loss: 0.3066
Epoch 9514/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 9515/10000; Iter 1/80; Loss: 0.3072
Epoch 9515/10000; Iter 51/80; Loss: 0.3574
Epoch 9515/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 9516/10000; Iter 1/80; Loss: 0.3369
Epoch 9516/10000; Iter 51/80; Loss: 0.3193
Epoch 9516/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.073
Epoch 9517/10000; Iter 1/80; Loss: 0.3658
Epoch 9517/10000; Iter 51/80; Loss: 0.3278
Epoch 9517/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.078
Epoch 9518/10000; Iter 1/80; Loss: 0.3358
Epoch 9518/10000; Iter 51/80; Loss: 0.3277
Epoch 9518/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9519/10000; Iter 1/80; Loss: 0.3164
Epoch 9519/10000; Iter 51/80; Loss: 0.3315
Epoch 9519/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.079
Epoch 9520/10000; Iter 1/80; Loss: 0.3240
Epoch 9520/10000; Iter 51/80; Loss: 0.3778
Epoch 9520/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.086
Epoch 9521/10000; Iter 1/80; Loss: 0.3400
Epoch 9521/10000; Iter 51/80; Loss: 0.3261
Epoch 9521/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.082
Epoch 9522/10000; Iter 1/80; Loss: 0.2780
Epoch 9522/10000; Iter 51/80; Loss: 0.3143
Epoch 9522/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.088
Epoch 9523/10000; Iter 1/80; Loss: 0.3268
Epoch 9523/10000; Iter 51/80; Loss: 0.2823
Epoch 9523/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.08
Epoch 9524/10000; Iter 1/80; Loss: 0.3457
Epoch 9524/10000; Iter 51/80; Loss: 0.2822
Epoch 9524/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.076
Epoch 9525/10000; Iter 1/80; Loss: 0.3444
Epoch 9525/10000; Iter 51/80; Loss: 0.3334
Epoch 9525/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.086
Epoch 9526/10000; Iter 1/80; Loss: 0.3149
Epoch 9526/10000; Iter 51/80; Loss: 0.3586
Epoch 9526/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.072
Epoch 9527/10000; Iter 1/80; Loss: 0.2971
Epoch 9527/10000; Iter 51/80; Loss: 0.2946
Epoch 9527/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9528/10000; Iter 1/80; Loss: 0.3921
Epoch 9528/10000; Iter 51/80; Loss: 0.3118
Epoch 9528/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.076
Epoch 9529/10000; Iter 1/80; Loss: 0.3337
Epoch 9529/10000; Iter 51/80; Loss: 0.3280
Epoch 9529/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9530/10000; Iter 1/80; Loss: 0.3344
Epoch 9530/10000; Iter 51/80; Loss: 0.2918
Epoch 9530/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.082
Epoch 9531/10000; Iter 1/80; Loss: 0.3787
Epoch 9531/10000; Iter 51/80; Loss: 0.3012
Epoch 9531/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 9532/10000; Iter 1/80; Loss: 0.3216
Epoch 9532/10000; Iter 51/80; Loss: 0.3370
Epoch 9532/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.08
Epoch 9533/10000; Iter 1/80; Loss: 0.3280
Epoch 9533/10000; Iter 51/80; Loss: 0.3109
Epoch 9533/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.073
Epoch 9534/10000; Iter 1/80; Loss: 0.3091
Epoch 9534/10000; Iter 51/80; Loss: 0.3065
Epoch 9534/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 9535/10000; Iter 1/80; Loss: 0.3562
Epoch 9535/10000; Iter 51/80; Loss: 0.3203
Epoch 9535/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.081
Epoch 9536/10000; Iter 1/80; Loss: 0.2821
Epoch 9536/10000; Iter 51/80; Loss: 0.3672
Epoch 9536/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.082
Epoch 9537/10000; Iter 1/80; Loss: 0.2972
Epoch 9537/10000; Iter 51/80; Loss: 0.3067
Epoch 9537/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.082
Epoch 9538/10000; Iter 1/80; Loss: 0.3468
Epoch 9538/10000; Iter 51/80; Loss: 0.3137
Epoch 9538/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9539/10000; Iter 1/80; Loss: 0.3106
Epoch 9539/10000; Iter 51/80; Loss: 0.2515
Epoch 9539/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.071
Epoch 9540/10000; Iter 1/80; Loss: 0.3179
Epoch 9540/10000; Iter 51/80; Loss: 0.3636
Epoch 9540/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.073
Epoch 9541/10000; Iter 1/80; Loss: 0.3963
Epoch 9541/10000; Iter 51/80; Loss: 0.3054
Epoch 9541/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.081
Epoch 9542/10000; Iter 1/80; Loss: 0.3610
Epoch 9542/10000; Iter 51/80; Loss: 0.3086
Epoch 9542/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.077
Epoch 9543/10000; Iter 1/80; Loss: 0.2667
Epoch 9543/10000; Iter 51/80; Loss: 0.3239
Epoch 9543/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.074
Epoch 9544/10000; Iter 1/80; Loss: 0.3056
Epoch 9544/10000; Iter 51/80; Loss: 0.3420
Epoch 9544/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.079
Epoch 9545/10000; Iter 1/80; Loss: 0.3687
Epoch 9545/10000; Iter 51/80; Loss: 0.3076
Epoch 9545/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.07
Epoch 9546/10000; Iter 1/80; Loss: 0.2739
Epoch 9546/10000; Iter 51/80; Loss: 0.3734
Epoch 9546/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9547/10000; Iter 1/80; Loss: 0.2943
Epoch 9547/10000; Iter 51/80; Loss: 0.3346
Epoch 9547/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.082
Epoch 9548/10000; Iter 1/80; Loss: 0.3642
Epoch 9548/10000; Iter 51/80; Loss: 0.3570
Epoch 9548/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.085
Epoch 9549/10000; Iter 1/80; Loss: 0.3440
Epoch 9549/10000; Iter 51/80; Loss: 0.3136
Epoch 9549/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.081
Epoch 9550/10000; Iter 1/80; Loss: 0.4194
Epoch 9550/10000; Iter 51/80; Loss: 0.3109
Epoch 9550/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.085
Epoch 9551/10000; Iter 1/80; Loss: 0.3769
Epoch 9551/10000; Iter 51/80; Loss: 0.2759
Epoch 9551/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.069
Epoch 9552/10000; Iter 1/80; Loss: 0.3181
Epoch 9552/10000; Iter 51/80; Loss: 0.3491
Epoch 9552/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.074
Epoch 9553/10000; Iter 1/80; Loss: 0.3017
Epoch 9553/10000; Iter 51/80; Loss: 0.3029
Epoch 9553/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.074
Epoch 9554/10000; Iter 1/80; Loss: 0.3521
Epoch 9554/10000; Iter 51/80; Loss: 0.3431
Epoch 9554/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9555/10000; Iter 1/80; Loss: 0.2911
Epoch 9555/10000; Iter 51/80; Loss: 0.3319
Epoch 9555/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.074
Epoch 9556/10000; Iter 1/80; Loss: 0.3063
Epoch 9556/10000; Iter 51/80; Loss: 0.3311
Epoch 9556/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.083
Epoch 9557/10000; Iter 1/80; Loss: 0.3447
Epoch 9557/10000; Iter 51/80; Loss: 0.2858
Epoch 9557/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9558/10000; Iter 1/80; Loss: 0.3176
Epoch 9558/10000; Iter 51/80; Loss: 0.3398
Epoch 9558/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.083
Epoch 9559/10000; Iter 1/80; Loss: 0.2914
Epoch 9559/10000; Iter 51/80; Loss: 0.2912
Epoch 9559/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.084
Epoch 9560/10000; Iter 1/80; Loss: 0.2685
Epoch 9560/10000; Iter 51/80; Loss: 0.3169
Epoch 9560/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9561/10000; Iter 1/80; Loss: 0.2972
Epoch 9561/10000; Iter 51/80; Loss: 0.3079
Epoch 9561/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.086
Epoch 9562/10000; Iter 1/80; Loss: 0.3538
Epoch 9562/10000; Iter 51/80; Loss: 0.3444
Epoch 9562/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.081
Epoch 9563/10000; Iter 1/80; Loss: 0.2913
Epoch 9563/10000; Iter 51/80; Loss: 0.3311
Epoch 9563/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9564/10000; Iter 1/80; Loss: 0.3477
Epoch 9564/10000; Iter 51/80; Loss: 0.3421
Epoch 9564/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.075
Epoch 9565/10000; Iter 1/80; Loss: 0.3138
Epoch 9565/10000; Iter 51/80; Loss: 0.3648
Epoch 9565/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.085
Epoch 9566/10000; Iter 1/80; Loss: 0.3371
Epoch 9566/10000; Iter 51/80; Loss: 0.3129
Epoch 9566/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.081
Epoch 9567/10000; Iter 1/80; Loss: 0.3724
Epoch 9567/10000; Iter 51/80; Loss: 0.3332
Epoch 9567/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.084
Epoch 9568/10000; Iter 1/80; Loss: 0.3020
Epoch 9568/10000; Iter 51/80; Loss: 0.2946
Epoch 9568/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.073
Epoch 9569/10000; Iter 1/80; Loss: 0.3242
Epoch 9569/10000; Iter 51/80; Loss: 0.2890
Epoch 9569/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.082
Epoch 9570/10000; Iter 1/80; Loss: 0.3502
Epoch 9570/10000; Iter 51/80; Loss: 0.3486
Epoch 9570/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9571/10000; Iter 1/80; Loss: 0.3289
Epoch 9571/10000; Iter 51/80; Loss: 0.3372
Epoch 9571/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.07
Epoch 9572/10000; Iter 1/80; Loss: 0.3119
Epoch 9572/10000; Iter 51/80; Loss: 0.3184
Epoch 9572/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9573/10000; Iter 1/80; Loss: 0.2760
Epoch 9573/10000; Iter 51/80; Loss: 0.3750
Epoch 9573/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9574/10000; Iter 1/80; Loss: 0.3626
Epoch 9574/10000; Iter 51/80; Loss: 0.3492
Epoch 9574/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.083
Epoch 9575/10000; Iter 1/80; Loss: 0.2632
Epoch 9575/10000; Iter 51/80; Loss: 0.2902
Epoch 9575/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9576/10000; Iter 1/80; Loss: 0.2596
Epoch 9576/10000; Iter 51/80; Loss: 0.3521
Epoch 9576/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.072
Epoch 9577/10000; Iter 1/80; Loss: 0.3095
Epoch 9577/10000; Iter 51/80; Loss: 0.3633
Epoch 9577/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9578/10000; Iter 1/80; Loss: 0.2932
Epoch 9578/10000; Iter 51/80; Loss: 0.3081
Epoch 9578/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9579/10000; Iter 1/80; Loss: 0.3275
Epoch 9579/10000; Iter 51/80; Loss: 0.2976
Epoch 9579/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9580/10000; Iter 1/80; Loss: 0.3319
Epoch 9580/10000; Iter 51/80; Loss: 0.3087
Epoch 9580/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9581/10000; Iter 1/80; Loss: 0.2679
Epoch 9581/10000; Iter 51/80; Loss: 0.3099
Epoch 9581/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9582/10000; Iter 1/80; Loss: 0.3280
Epoch 9582/10000; Iter 51/80; Loss: 0.3072
Epoch 9582/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9583/10000; Iter 1/80; Loss: 0.2597
Epoch 9583/10000; Iter 51/80; Loss: 0.3453
Epoch 9583/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.083
Epoch 9584/10000; Iter 1/80; Loss: 0.2999
Epoch 9584/10000; Iter 51/80; Loss: 0.3044
Epoch 9584/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9585/10000; Iter 1/80; Loss: 0.2922
Epoch 9585/10000; Iter 51/80; Loss: 0.3269
Epoch 9585/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.08
Epoch 9586/10000; Iter 1/80; Loss: 0.4039
Epoch 9586/10000; Iter 51/80; Loss: 0.3419
Epoch 9586/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9587/10000; Iter 1/80; Loss: 0.3104
Epoch 9587/10000; Iter 51/80; Loss: 0.3254
Epoch 9587/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.08
Epoch 9588/10000; Iter 1/80; Loss: 0.3408
Epoch 9588/10000; Iter 51/80; Loss: 0.3029
Epoch 9588/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 9589/10000; Iter 1/80; Loss: 0.3092
Epoch 9589/10000; Iter 51/80; Loss: 0.2952
Epoch 9589/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9590/10000; Iter 1/80; Loss: 0.3259
Epoch 9590/10000; Iter 51/80; Loss: 0.3329
Epoch 9590/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 9591/10000; Iter 1/80; Loss: 0.3732
Epoch 9591/10000; Iter 51/80; Loss: 0.3461
Epoch 9591/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 9592/10000; Iter 1/80; Loss: 0.2994
Epoch 9592/10000; Iter 51/80; Loss: 0.3008
Epoch 9592/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9593/10000; Iter 1/80; Loss: 0.3011
Epoch 9593/10000; Iter 51/80; Loss: 0.3929
Epoch 9593/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.08
Epoch 9594/10000; Iter 1/80; Loss: 0.3343
Epoch 9594/10000; Iter 51/80; Loss: 0.3513
Epoch 9594/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.076
Epoch 9595/10000; Iter 1/80; Loss: 0.3413
Epoch 9595/10000; Iter 51/80; Loss: 0.3191
Epoch 9595/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.085
Epoch 9596/10000; Iter 1/80; Loss: 0.2891
Epoch 9596/10000; Iter 51/80; Loss: 0.3813
Epoch 9596/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.078
Epoch 9597/10000; Iter 1/80; Loss: 0.3645
Epoch 9597/10000; Iter 51/80; Loss: 0.3841
Epoch 9597/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.07
Epoch 9598/10000; Iter 1/80; Loss: 0.3404
Epoch 9598/10000; Iter 51/80; Loss: 0.2841
Epoch 9598/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.084
Epoch 9599/10000; Iter 1/80; Loss: 0.2792
Epoch 9599/10000; Iter 51/80; Loss: 0.2984
Epoch 9599/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9600/10000; Iter 1/80; Loss: 0.2622
Epoch 9600/10000; Iter 51/80; Loss: 0.3604
Epoch 9600/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9601/10000; Iter 1/80; Loss: 0.3569
Epoch 9601/10000; Iter 51/80; Loss: 0.3872
Epoch 9601/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.07
Model saved
Epoch 9602/10000; Iter 1/80; Loss: 0.3146
Epoch 9602/10000; Iter 51/80; Loss: 0.3116
Epoch 9602/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9603/10000; Iter 1/80; Loss: 0.3246
Epoch 9603/10000; Iter 51/80; Loss: 0.3217
Epoch 9603/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.073
Epoch 9604/10000; Iter 1/80; Loss: 0.2834
Epoch 9604/10000; Iter 51/80; Loss: 0.3182
Epoch 9604/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.078
Epoch 9605/10000; Iter 1/80; Loss: 0.3398
Epoch 9605/10000; Iter 51/80; Loss: 0.3051
Epoch 9605/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9606/10000; Iter 1/80; Loss: 0.2935
Epoch 9606/10000; Iter 51/80; Loss: 0.2831
Epoch 9606/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9607/10000; Iter 1/80; Loss: 0.2927
Epoch 9607/10000; Iter 51/80; Loss: 0.3033
Epoch 9607/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.082
Epoch 9608/10000; Iter 1/80; Loss: 0.3351
Epoch 9608/10000; Iter 51/80; Loss: 0.3327
Epoch 9608/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.085
Epoch 9609/10000; Iter 1/80; Loss: 0.3132
Epoch 9609/10000; Iter 51/80; Loss: 0.2823
Epoch 9609/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9610/10000; Iter 1/80; Loss: 0.3375
Epoch 9610/10000; Iter 51/80; Loss: 0.3798
Epoch 9610/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9611/10000; Iter 1/80; Loss: 0.3252
Epoch 9611/10000; Iter 51/80; Loss: 0.2945
Epoch 9611/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.077
Epoch 9612/10000; Iter 1/80; Loss: 0.3200
Epoch 9612/10000; Iter 51/80; Loss: 0.3385
Epoch 9612/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.067
Epoch 9613/10000; Iter 1/80; Loss: 0.3510
Epoch 9613/10000; Iter 51/80; Loss: 0.3818
Epoch 9613/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9614/10000; Iter 1/80; Loss: 0.3714
Epoch 9614/10000; Iter 51/80; Loss: 0.3025
Epoch 9614/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.083
Epoch 9615/10000; Iter 1/80; Loss: 0.3226
Epoch 9615/10000; Iter 51/80; Loss: 0.2713
Epoch 9615/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.078
Epoch 9616/10000; Iter 1/80; Loss: 0.3586
Epoch 9616/10000; Iter 51/80; Loss: 0.3877
Epoch 9616/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9617/10000; Iter 1/80; Loss: 0.3456
Epoch 9617/10000; Iter 51/80; Loss: 0.3206
Epoch 9617/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9618/10000; Iter 1/80; Loss: 0.3441
Epoch 9618/10000; Iter 51/80; Loss: 0.3742
Epoch 9618/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.076
Epoch 9619/10000; Iter 1/80; Loss: 0.3089
Epoch 9619/10000; Iter 51/80; Loss: 0.3757
Epoch 9619/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.082
Epoch 9620/10000; Iter 1/80; Loss: 0.3280
Epoch 9620/10000; Iter 51/80; Loss: 0.3528
Epoch 9620/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.083
Epoch 9621/10000; Iter 1/80; Loss: 0.3849
Epoch 9621/10000; Iter 51/80; Loss: 0.3231
Epoch 9621/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9622/10000; Iter 1/80; Loss: 0.2852
Epoch 9622/10000; Iter 51/80; Loss: 0.3502
Epoch 9622/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.088
Epoch 9623/10000; Iter 1/80; Loss: 0.3130
Epoch 9623/10000; Iter 51/80; Loss: 0.3237
Epoch 9623/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.08
Epoch 9624/10000; Iter 1/80; Loss: 0.3015
Epoch 9624/10000; Iter 51/80; Loss: 0.3363
Epoch 9624/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 9625/10000; Iter 1/80; Loss: 0.3420
Epoch 9625/10000; Iter 51/80; Loss: 0.2929
Epoch 9625/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.08
Epoch 9626/10000; Iter 1/80; Loss: 0.2787
Epoch 9626/10000; Iter 51/80; Loss: 0.3072
Epoch 9626/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.076
Epoch 9627/10000; Iter 1/80; Loss: 0.2943
Epoch 9627/10000; Iter 51/80; Loss: 0.2885
Epoch 9627/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9628/10000; Iter 1/80; Loss: 0.3150
Epoch 9628/10000; Iter 51/80; Loss: 0.3390
Epoch 9628/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.069
Epoch 9629/10000; Iter 1/80; Loss: 0.3142
Epoch 9629/10000; Iter 51/80; Loss: 0.3532
Epoch 9629/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.08
Epoch 9630/10000; Iter 1/80; Loss: 0.2812
Epoch 9630/10000; Iter 51/80; Loss: 0.2895
Epoch 9630/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9631/10000; Iter 1/80; Loss: 0.3508
Epoch 9631/10000; Iter 51/80; Loss: 0.2962
Epoch 9631/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9632/10000; Iter 1/80; Loss: 0.2680
Epoch 9632/10000; Iter 51/80; Loss: 0.3631
Epoch 9632/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.08
Epoch 9633/10000; Iter 1/80; Loss: 0.2909
Epoch 9633/10000; Iter 51/80; Loss: 0.3547
Epoch 9633/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.082
Epoch 9634/10000; Iter 1/80; Loss: 0.3262
Epoch 9634/10000; Iter 51/80; Loss: 0.3044
Epoch 9634/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9635/10000; Iter 1/80; Loss: 0.3719
Epoch 9635/10000; Iter 51/80; Loss: 0.3298
Epoch 9635/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9636/10000; Iter 1/80; Loss: 0.2704
Epoch 9636/10000; Iter 51/80; Loss: 0.3138
Epoch 9636/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.077
Epoch 9637/10000; Iter 1/80; Loss: 0.2866
Epoch 9637/10000; Iter 51/80; Loss: 0.3004
Epoch 9637/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.072
Epoch 9638/10000; Iter 1/80; Loss: 0.3209
Epoch 9638/10000; Iter 51/80; Loss: 0.2830
Epoch 9638/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.084
Epoch 9639/10000; Iter 1/80; Loss: 0.3577
Epoch 9639/10000; Iter 51/80; Loss: 0.3106
Epoch 9639/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9640/10000; Iter 1/80; Loss: 0.3698
Epoch 9640/10000; Iter 51/80; Loss: 0.3501
Epoch 9640/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 9641/10000; Iter 1/80; Loss: 0.3864
Epoch 9641/10000; Iter 51/80; Loss: 0.3513
Epoch 9641/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9642/10000; Iter 1/80; Loss: 0.3458
Epoch 9642/10000; Iter 51/80; Loss: 0.3001
Epoch 9642/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9643/10000; Iter 1/80; Loss: 0.3321
Epoch 9643/10000; Iter 51/80; Loss: 0.3285
Epoch 9643/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.077
Epoch 9644/10000; Iter 1/80; Loss: 0.3122
Epoch 9644/10000; Iter 51/80; Loss: 0.3334
Epoch 9644/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9645/10000; Iter 1/80; Loss: 0.2876
Epoch 9645/10000; Iter 51/80; Loss: 0.3402
Epoch 9645/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.075
Epoch 9646/10000; Iter 1/80; Loss: 0.3488
Epoch 9646/10000; Iter 51/80; Loss: 0.3458
Epoch 9646/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.073
Epoch 9647/10000; Iter 1/80; Loss: 0.3407
Epoch 9647/10000; Iter 51/80; Loss: 0.2683
Epoch 9647/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.08
Epoch 9648/10000; Iter 1/80; Loss: 0.3090
Epoch 9648/10000; Iter 51/80; Loss: 0.3481
Epoch 9648/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9649/10000; Iter 1/80; Loss: 0.2862
Epoch 9649/10000; Iter 51/80; Loss: 0.2835
Epoch 9649/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.075
Epoch 9650/10000; Iter 1/80; Loss: 0.3966
Epoch 9650/10000; Iter 51/80; Loss: 0.2954
Epoch 9650/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9651/10000; Iter 1/80; Loss: 0.2850
Epoch 9651/10000; Iter 51/80; Loss: 0.3111
Epoch 9651/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.07
Epoch 9652/10000; Iter 1/80; Loss: 0.3577
Epoch 9652/10000; Iter 51/80; Loss: 0.3266
Epoch 9652/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.083
Epoch 9653/10000; Iter 1/80; Loss: 0.3820
Epoch 9653/10000; Iter 51/80; Loss: 0.3182
Epoch 9653/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.084
Epoch 9654/10000; Iter 1/80; Loss: 0.3055
Epoch 9654/10000; Iter 51/80; Loss: 0.2622
Epoch 9654/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.073
Epoch 9655/10000; Iter 1/80; Loss: 0.2839
Epoch 9655/10000; Iter 51/80; Loss: 0.3145
Epoch 9655/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9656/10000; Iter 1/80; Loss: 0.3183
Epoch 9656/10000; Iter 51/80; Loss: 0.3325
Epoch 9656/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9657/10000; Iter 1/80; Loss: 0.2906
Epoch 9657/10000; Iter 51/80; Loss: 0.3158
Epoch 9657/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.089
Epoch 9658/10000; Iter 1/80; Loss: 0.2752
Epoch 9658/10000; Iter 51/80; Loss: 0.3478
Epoch 9658/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.081
Epoch 9659/10000; Iter 1/80; Loss: 0.3175
Epoch 9659/10000; Iter 51/80; Loss: 0.3426
Epoch 9659/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.073
Epoch 9660/10000; Iter 1/80; Loss: 0.3340
Epoch 9660/10000; Iter 51/80; Loss: 0.2885
Epoch 9660/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.078
Epoch 9661/10000; Iter 1/80; Loss: 0.3240
Epoch 9661/10000; Iter 51/80; Loss: 0.3027
Epoch 9661/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.074
Epoch 9662/10000; Iter 1/80; Loss: 0.2884
Epoch 9662/10000; Iter 51/80; Loss: 0.3196
Epoch 9662/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9663/10000; Iter 1/80; Loss: 0.3189
Epoch 9663/10000; Iter 51/80; Loss: 0.3091
Epoch 9663/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9664/10000; Iter 1/80; Loss: 0.3088
Epoch 9664/10000; Iter 51/80; Loss: 0.3239
Epoch 9664/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9665/10000; Iter 1/80; Loss: 0.3179
Epoch 9665/10000; Iter 51/80; Loss: 0.3671
Epoch 9665/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.069
Epoch 9666/10000; Iter 1/80; Loss: 0.3263
Epoch 9666/10000; Iter 51/80; Loss: 0.3432
Epoch 9666/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9667/10000; Iter 1/80; Loss: 0.3330
Epoch 9667/10000; Iter 51/80; Loss: 0.3351
Epoch 9667/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.078
Epoch 9668/10000; Iter 1/80; Loss: 0.2894
Epoch 9668/10000; Iter 51/80; Loss: 0.3373
Epoch 9668/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9669/10000; Iter 1/80; Loss: 0.3072
Epoch 9669/10000; Iter 51/80; Loss: 0.3300
Epoch 9669/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9670/10000; Iter 1/80; Loss: 0.3823
Epoch 9670/10000; Iter 51/80; Loss: 0.3171
Epoch 9670/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9671/10000; Iter 1/80; Loss: 0.3668
Epoch 9671/10000; Iter 51/80; Loss: 0.3262
Epoch 9671/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.074
Epoch 9672/10000; Iter 1/80; Loss: 0.3147
Epoch 9672/10000; Iter 51/80; Loss: 0.3075
Epoch 9672/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9673/10000; Iter 1/80; Loss: 0.2882
Epoch 9673/10000; Iter 51/80; Loss: 0.2954
Epoch 9673/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.087
Epoch 9674/10000; Iter 1/80; Loss: 0.3671
Epoch 9674/10000; Iter 51/80; Loss: 0.2815
Epoch 9674/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.089
Epoch 9675/10000; Iter 1/80; Loss: 0.2776
Epoch 9675/10000; Iter 51/80; Loss: 0.2918
Epoch 9675/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9676/10000; Iter 1/80; Loss: 0.3118
Epoch 9676/10000; Iter 51/80; Loss: 0.3220
Epoch 9676/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.074
Epoch 9677/10000; Iter 1/80; Loss: 0.3391
Epoch 9677/10000; Iter 51/80; Loss: 0.2772
Epoch 9677/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9678/10000; Iter 1/80; Loss: 0.3053
Epoch 9678/10000; Iter 51/80; Loss: 0.3311
Epoch 9678/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.085
Epoch 9679/10000; Iter 1/80; Loss: 0.2705
Epoch 9679/10000; Iter 51/80; Loss: 0.3572
Epoch 9679/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.066
Epoch 9680/10000; Iter 1/80; Loss: 0.2745
Epoch 9680/10000; Iter 51/80; Loss: 0.2827
Epoch 9680/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.071
Epoch 9681/10000; Iter 1/80; Loss: 0.2932
Epoch 9681/10000; Iter 51/80; Loss: 0.3166
Epoch 9681/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9682/10000; Iter 1/80; Loss: 0.3295
Epoch 9682/10000; Iter 51/80; Loss: 0.2694
Epoch 9682/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.075
Epoch 9683/10000; Iter 1/80; Loss: 0.3447
Epoch 9683/10000; Iter 51/80; Loss: 0.3084
Epoch 9683/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.071
Epoch 9684/10000; Iter 1/80; Loss: 0.3176
Epoch 9684/10000; Iter 51/80; Loss: 0.3594
Epoch 9684/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9685/10000; Iter 1/80; Loss: 0.2701
Epoch 9685/10000; Iter 51/80; Loss: 0.3458
Epoch 9685/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 9686/10000; Iter 1/80; Loss: 0.3125
Epoch 9686/10000; Iter 51/80; Loss: 0.2990
Epoch 9686/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9687/10000; Iter 1/80; Loss: 0.3069
Epoch 9687/10000; Iter 51/80; Loss: 0.3058
Epoch 9687/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9688/10000; Iter 1/80; Loss: 0.3289
Epoch 9688/10000; Iter 51/80; Loss: 0.3260
Epoch 9688/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.074
Epoch 9689/10000; Iter 1/80; Loss: 0.3675
Epoch 9689/10000; Iter 51/80; Loss: 0.3089
Epoch 9689/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.073
Epoch 9690/10000; Iter 1/80; Loss: 0.3181
Epoch 9690/10000; Iter 51/80; Loss: 0.3315
Epoch 9690/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.073
Epoch 9691/10000; Iter 1/80; Loss: 0.3046
Epoch 9691/10000; Iter 51/80; Loss: 0.3696
Epoch 9691/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.083
Epoch 9692/10000; Iter 1/80; Loss: 0.3017
Epoch 9692/10000; Iter 51/80; Loss: 0.3207
Epoch 9692/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9693/10000; Iter 1/80; Loss: 0.2686
Epoch 9693/10000; Iter 51/80; Loss: 0.2880
Epoch 9693/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.085
Epoch 9694/10000; Iter 1/80; Loss: 0.2904
Epoch 9694/10000; Iter 51/80; Loss: 0.3294
Epoch 9694/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9695/10000; Iter 1/80; Loss: 0.2670
Epoch 9695/10000; Iter 51/80; Loss: 0.2950
Epoch 9695/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9696/10000; Iter 1/80; Loss: 0.2605
Epoch 9696/10000; Iter 51/80; Loss: 0.3158
Epoch 9696/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.078
Epoch 9697/10000; Iter 1/80; Loss: 0.3280
Epoch 9697/10000; Iter 51/80; Loss: 0.3134
Epoch 9697/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.089
Epoch 9698/10000; Iter 1/80; Loss: 0.3474
Epoch 9698/10000; Iter 51/80; Loss: 0.2902
Epoch 9698/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.08
Epoch 9699/10000; Iter 1/80; Loss: 0.2767
Epoch 9699/10000; Iter 51/80; Loss: 0.3357
Epoch 9699/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9700/10000; Iter 1/80; Loss: 0.2831
Epoch 9700/10000; Iter 51/80; Loss: 0.3253
Epoch 9700/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9701/10000; Iter 1/80; Loss: 0.3156
Epoch 9701/10000; Iter 51/80; Loss: 0.3285
Epoch 9701/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.07
Model saved
Epoch 9702/10000; Iter 1/80; Loss: 0.3118
Epoch 9702/10000; Iter 51/80; Loss: 0.3479
Epoch 9702/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.071
Epoch 9703/10000; Iter 1/80; Loss: 0.3211
Epoch 9703/10000; Iter 51/80; Loss: 0.3173
Epoch 9703/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.076
Epoch 9704/10000; Iter 1/80; Loss: 0.2963
Epoch 9704/10000; Iter 51/80; Loss: 0.3278
Epoch 9704/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.08
Epoch 9705/10000; Iter 1/80; Loss: 0.3094
Epoch 9705/10000; Iter 51/80; Loss: 0.2889
Epoch 9705/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9706/10000; Iter 1/80; Loss: 0.2652
Epoch 9706/10000; Iter 51/80; Loss: 0.3778
Epoch 9706/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9707/10000; Iter 1/80; Loss: 0.3475
Epoch 9707/10000; Iter 51/80; Loss: 0.3308
Epoch 9707/10000; Iter 80/80; Training Loss: 0.3280, Test Loss: 0.07
Epoch 9708/10000; Iter 1/80; Loss: 0.3418
Epoch 9708/10000; Iter 51/80; Loss: 0.3051
Epoch 9708/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9709/10000; Iter 1/80; Loss: 0.3569
Epoch 9709/10000; Iter 51/80; Loss: 0.2987
Epoch 9709/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9710/10000; Iter 1/80; Loss: 0.3510
Epoch 9710/10000; Iter 51/80; Loss: 0.3046
Epoch 9710/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.077
Epoch 9711/10000; Iter 1/80; Loss: 0.2875
Epoch 9711/10000; Iter 51/80; Loss: 0.3408
Epoch 9711/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9712/10000; Iter 1/80; Loss: 0.3213
Epoch 9712/10000; Iter 51/80; Loss: 0.2946
Epoch 9712/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.076
Epoch 9713/10000; Iter 1/80; Loss: 0.3247
Epoch 9713/10000; Iter 51/80; Loss: 0.3680
Epoch 9713/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.079
Epoch 9714/10000; Iter 1/80; Loss: 0.3390
Epoch 9714/10000; Iter 51/80; Loss: 0.3812
Epoch 9714/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.078
Epoch 9715/10000; Iter 1/80; Loss: 0.3104
Epoch 9715/10000; Iter 51/80; Loss: 0.2834
Epoch 9715/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.08
Epoch 9716/10000; Iter 1/80; Loss: 0.3804
Epoch 9716/10000; Iter 51/80; Loss: 0.3441
Epoch 9716/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 9717/10000; Iter 1/80; Loss: 0.3652
Epoch 9717/10000; Iter 51/80; Loss: 0.3272
Epoch 9717/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.085
Epoch 9718/10000; Iter 1/80; Loss: 0.3332
Epoch 9718/10000; Iter 51/80; Loss: 0.3598
Epoch 9718/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.074
Epoch 9719/10000; Iter 1/80; Loss: 0.3109
Epoch 9719/10000; Iter 51/80; Loss: 0.2840
Epoch 9719/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9720/10000; Iter 1/80; Loss: 0.3764
Epoch 9720/10000; Iter 51/80; Loss: 0.2656
Epoch 9720/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9721/10000; Iter 1/80; Loss: 0.3628
Epoch 9721/10000; Iter 51/80; Loss: 0.3462
Epoch 9721/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.084
Epoch 9722/10000; Iter 1/80; Loss: 0.3236
Epoch 9722/10000; Iter 51/80; Loss: 0.3351
Epoch 9722/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.073
Epoch 9723/10000; Iter 1/80; Loss: 0.3031
Epoch 9723/10000; Iter 51/80; Loss: 0.3104
Epoch 9723/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.083
Epoch 9724/10000; Iter 1/80; Loss: 0.3184
Epoch 9724/10000; Iter 51/80; Loss: 0.2519
Epoch 9724/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.082
Epoch 9725/10000; Iter 1/80; Loss: 0.3802
Epoch 9725/10000; Iter 51/80; Loss: 0.2770
Epoch 9725/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.079
Epoch 9726/10000; Iter 1/80; Loss: 0.2694
Epoch 9726/10000; Iter 51/80; Loss: 0.3137
Epoch 9726/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9727/10000; Iter 1/80; Loss: 0.3565
Epoch 9727/10000; Iter 51/80; Loss: 0.2435
Epoch 9727/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 9728/10000; Iter 1/80; Loss: 0.3721
Epoch 9728/10000; Iter 51/80; Loss: 0.2828
Epoch 9728/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.088
Epoch 9729/10000; Iter 1/80; Loss: 0.3404
Epoch 9729/10000; Iter 51/80; Loss: 0.3137
Epoch 9729/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.077
Epoch 9730/10000; Iter 1/80; Loss: 0.2679
Epoch 9730/10000; Iter 51/80; Loss: 0.2659
Epoch 9730/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.081
Epoch 9731/10000; Iter 1/80; Loss: 0.2652
Epoch 9731/10000; Iter 51/80; Loss: 0.2670
Epoch 9731/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.068
Epoch 9732/10000; Iter 1/80; Loss: 0.3495
Epoch 9732/10000; Iter 51/80; Loss: 0.3191
Epoch 9732/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.079
Epoch 9733/10000; Iter 1/80; Loss: 0.2811
Epoch 9733/10000; Iter 51/80; Loss: 0.2787
Epoch 9733/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.08
Epoch 9734/10000; Iter 1/80; Loss: 0.3208
Epoch 9734/10000; Iter 51/80; Loss: 0.3549
Epoch 9734/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.071
Epoch 9735/10000; Iter 1/80; Loss: 0.3092
Epoch 9735/10000; Iter 51/80; Loss: 0.3033
Epoch 9735/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.081
Epoch 9736/10000; Iter 1/80; Loss: 0.3588
Epoch 9736/10000; Iter 51/80; Loss: 0.2617
Epoch 9736/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.076
Epoch 9737/10000; Iter 1/80; Loss: 0.3080
Epoch 9737/10000; Iter 51/80; Loss: 0.3309
Epoch 9737/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9738/10000; Iter 1/80; Loss: 0.3096
Epoch 9738/10000; Iter 51/80; Loss: 0.3076
Epoch 9738/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 9739/10000; Iter 1/80; Loss: 0.3070
Epoch 9739/10000; Iter 51/80; Loss: 0.3389
Epoch 9739/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.076
Epoch 9740/10000; Iter 1/80; Loss: 0.3204
Epoch 9740/10000; Iter 51/80; Loss: 0.3865
Epoch 9740/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9741/10000; Iter 1/80; Loss: 0.2832
Epoch 9741/10000; Iter 51/80; Loss: 0.2719
Epoch 9741/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.075
Epoch 9742/10000; Iter 1/80; Loss: 0.3454
Epoch 9742/10000; Iter 51/80; Loss: 0.3297
Epoch 9742/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.075
Epoch 9743/10000; Iter 1/80; Loss: 0.3300
Epoch 9743/10000; Iter 51/80; Loss: 0.3505
Epoch 9743/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9744/10000; Iter 1/80; Loss: 0.3394
Epoch 9744/10000; Iter 51/80; Loss: 0.3265
Epoch 9744/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.083
Epoch 9745/10000; Iter 1/80; Loss: 0.3453
Epoch 9745/10000; Iter 51/80; Loss: 0.3438
Epoch 9745/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.075
Epoch 9746/10000; Iter 1/80; Loss: 0.2974
Epoch 9746/10000; Iter 51/80; Loss: 0.3596
Epoch 9746/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9747/10000; Iter 1/80; Loss: 0.3131
Epoch 9747/10000; Iter 51/80; Loss: 0.2272
Epoch 9747/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.078
Epoch 9748/10000; Iter 1/80; Loss: 0.3561
Epoch 9748/10000; Iter 51/80; Loss: 0.3001
Epoch 9748/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9749/10000; Iter 1/80; Loss: 0.3107
Epoch 9749/10000; Iter 51/80; Loss: 0.3601
Epoch 9749/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9750/10000; Iter 1/80; Loss: 0.3321
Epoch 9750/10000; Iter 51/80; Loss: 0.3161
Epoch 9750/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.085
Epoch 9751/10000; Iter 1/80; Loss: 0.3186
Epoch 9751/10000; Iter 51/80; Loss: 0.3248
Epoch 9751/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.073
Epoch 9752/10000; Iter 1/80; Loss: 0.3176
Epoch 9752/10000; Iter 51/80; Loss: 0.3121
Epoch 9752/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.078
Epoch 9753/10000; Iter 1/80; Loss: 0.2934
Epoch 9753/10000; Iter 51/80; Loss: 0.2549
Epoch 9753/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9754/10000; Iter 1/80; Loss: 0.2988
Epoch 9754/10000; Iter 51/80; Loss: 0.2790
Epoch 9754/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9755/10000; Iter 1/80; Loss: 0.3261
Epoch 9755/10000; Iter 51/80; Loss: 0.3516
Epoch 9755/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.076
Epoch 9756/10000; Iter 1/80; Loss: 0.2610
Epoch 9756/10000; Iter 51/80; Loss: 0.3288
Epoch 9756/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.075
Epoch 9757/10000; Iter 1/80; Loss: 0.2956
Epoch 9757/10000; Iter 51/80; Loss: 0.3765
Epoch 9757/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.069
Epoch 9758/10000; Iter 1/80; Loss: 0.3806
Epoch 9758/10000; Iter 51/80; Loss: 0.3099
Epoch 9758/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.074
Epoch 9759/10000; Iter 1/80; Loss: 0.3034
Epoch 9759/10000; Iter 51/80; Loss: 0.2932
Epoch 9759/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9760/10000; Iter 1/80; Loss: 0.2886
Epoch 9760/10000; Iter 51/80; Loss: 0.3177
Epoch 9760/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9761/10000; Iter 1/80; Loss: 0.3179
Epoch 9761/10000; Iter 51/80; Loss: 0.3042
Epoch 9761/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9762/10000; Iter 1/80; Loss: 0.3285
Epoch 9762/10000; Iter 51/80; Loss: 0.3674
Epoch 9762/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9763/10000; Iter 1/80; Loss: 0.2649
Epoch 9763/10000; Iter 51/80; Loss: 0.3556
Epoch 9763/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.078
Epoch 9764/10000; Iter 1/80; Loss: 0.2854
Epoch 9764/10000; Iter 51/80; Loss: 0.2984
Epoch 9764/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.078
Epoch 9765/10000; Iter 1/80; Loss: 0.2967
Epoch 9765/10000; Iter 51/80; Loss: 0.3601
Epoch 9765/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.074
Epoch 9766/10000; Iter 1/80; Loss: 0.2971
Epoch 9766/10000; Iter 51/80; Loss: 0.2588
Epoch 9766/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9767/10000; Iter 1/80; Loss: 0.3071
Epoch 9767/10000; Iter 51/80; Loss: 0.2908
Epoch 9767/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.082
Epoch 9768/10000; Iter 1/80; Loss: 0.3356
Epoch 9768/10000; Iter 51/80; Loss: 0.2981
Epoch 9768/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.076
Epoch 9769/10000; Iter 1/80; Loss: 0.2982
Epoch 9769/10000; Iter 51/80; Loss: 0.3061
Epoch 9769/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.071
Epoch 9770/10000; Iter 1/80; Loss: 0.3448
Epoch 9770/10000; Iter 51/80; Loss: 0.3316
Epoch 9770/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.076
Epoch 9771/10000; Iter 1/80; Loss: 0.3186
Epoch 9771/10000; Iter 51/80; Loss: 0.3328
Epoch 9771/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.079
Epoch 9772/10000; Iter 1/80; Loss: 0.3232
Epoch 9772/10000; Iter 51/80; Loss: 0.3608
Epoch 9772/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.089
Epoch 9773/10000; Iter 1/80; Loss: 0.3625
Epoch 9773/10000; Iter 51/80; Loss: 0.3032
Epoch 9773/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.079
Epoch 9774/10000; Iter 1/80; Loss: 0.3092
Epoch 9774/10000; Iter 51/80; Loss: 0.3239
Epoch 9774/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.079
Epoch 9775/10000; Iter 1/80; Loss: 0.3200
Epoch 9775/10000; Iter 51/80; Loss: 0.3062
Epoch 9775/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9776/10000; Iter 1/80; Loss: 0.3164
Epoch 9776/10000; Iter 51/80; Loss: 0.3741
Epoch 9776/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.084
Epoch 9777/10000; Iter 1/80; Loss: 0.2878
Epoch 9777/10000; Iter 51/80; Loss: 0.3762
Epoch 9777/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.078
Epoch 9778/10000; Iter 1/80; Loss: 0.3035
Epoch 9778/10000; Iter 51/80; Loss: 0.2973
Epoch 9778/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9779/10000; Iter 1/80; Loss: 0.3195
Epoch 9779/10000; Iter 51/80; Loss: 0.3172
Epoch 9779/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.076
Epoch 9780/10000; Iter 1/80; Loss: 0.2728
Epoch 9780/10000; Iter 51/80; Loss: 0.3719
Epoch 9780/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9781/10000; Iter 1/80; Loss: 0.2756
Epoch 9781/10000; Iter 51/80; Loss: 0.3108
Epoch 9781/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9782/10000; Iter 1/80; Loss: 0.3474
Epoch 9782/10000; Iter 51/80; Loss: 0.3306
Epoch 9782/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9783/10000; Iter 1/80; Loss: 0.3273
Epoch 9783/10000; Iter 51/80; Loss: 0.3166
Epoch 9783/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9784/10000; Iter 1/80; Loss: 0.2923
Epoch 9784/10000; Iter 51/80; Loss: 0.3725
Epoch 9784/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.082
Epoch 9785/10000; Iter 1/80; Loss: 0.3542
Epoch 9785/10000; Iter 51/80; Loss: 0.3337
Epoch 9785/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.074
Epoch 9786/10000; Iter 1/80; Loss: 0.3707
Epoch 9786/10000; Iter 51/80; Loss: 0.2983
Epoch 9786/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9787/10000; Iter 1/80; Loss: 0.3520
Epoch 9787/10000; Iter 51/80; Loss: 0.3196
Epoch 9787/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.081
Epoch 9788/10000; Iter 1/80; Loss: 0.3404
Epoch 9788/10000; Iter 51/80; Loss: 0.3142
Epoch 9788/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9789/10000; Iter 1/80; Loss: 0.3081
Epoch 9789/10000; Iter 51/80; Loss: 0.3589
Epoch 9789/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9790/10000; Iter 1/80; Loss: 0.2744
Epoch 9790/10000; Iter 51/80; Loss: 0.3243
Epoch 9790/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.077
Epoch 9791/10000; Iter 1/80; Loss: 0.3295
Epoch 9791/10000; Iter 51/80; Loss: 0.3333
Epoch 9791/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.067
Epoch 9792/10000; Iter 1/80; Loss: 0.3104
Epoch 9792/10000; Iter 51/80; Loss: 0.2763
Epoch 9792/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.075
Epoch 9793/10000; Iter 1/80; Loss: 0.3890
Epoch 9793/10000; Iter 51/80; Loss: 0.2970
Epoch 9793/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9794/10000; Iter 1/80; Loss: 0.3047
Epoch 9794/10000; Iter 51/80; Loss: 0.3301
Epoch 9794/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.087
Epoch 9795/10000; Iter 1/80; Loss: 0.3200
Epoch 9795/10000; Iter 51/80; Loss: 0.3006
Epoch 9795/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9796/10000; Iter 1/80; Loss: 0.2530
Epoch 9796/10000; Iter 51/80; Loss: 0.3455
Epoch 9796/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9797/10000; Iter 1/80; Loss: 0.3252
Epoch 9797/10000; Iter 51/80; Loss: 0.3627
Epoch 9797/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.076
Epoch 9798/10000; Iter 1/80; Loss: 0.3250
Epoch 9798/10000; Iter 51/80; Loss: 0.3270
Epoch 9798/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9799/10000; Iter 1/80; Loss: 0.2989
Epoch 9799/10000; Iter 51/80; Loss: 0.3188
Epoch 9799/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.083
Epoch 9800/10000; Iter 1/80; Loss: 0.3081
Epoch 9800/10000; Iter 51/80; Loss: 0.3093
Epoch 9800/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.08
Epoch 9801/10000; Iter 1/80; Loss: 0.2811
Epoch 9801/10000; Iter 51/80; Loss: 0.3068
Epoch 9801/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Model saved
Epoch 9802/10000; Iter 1/80; Loss: 0.3018
Epoch 9802/10000; Iter 51/80; Loss: 0.3124
Epoch 9802/10000; Iter 80/80; Training Loss: 0.3270, Test Loss: 0.071
Epoch 9803/10000; Iter 1/80; Loss: 0.3359
Epoch 9803/10000; Iter 51/80; Loss: 0.2824
Epoch 9803/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.075
Epoch 9804/10000; Iter 1/80; Loss: 0.3714
Epoch 9804/10000; Iter 51/80; Loss: 0.3076
Epoch 9804/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9805/10000; Iter 1/80; Loss: 0.2979
Epoch 9805/10000; Iter 51/80; Loss: 0.3238
Epoch 9805/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.084
Epoch 9806/10000; Iter 1/80; Loss: 0.3256
Epoch 9806/10000; Iter 51/80; Loss: 0.2764
Epoch 9806/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.076
Epoch 9807/10000; Iter 1/80; Loss: 0.3203
Epoch 9807/10000; Iter 51/80; Loss: 0.2772
Epoch 9807/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.072
Epoch 9808/10000; Iter 1/80; Loss: 0.3448
Epoch 9808/10000; Iter 51/80; Loss: 0.3568
Epoch 9808/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 9809/10000; Iter 1/80; Loss: 0.3405
Epoch 9809/10000; Iter 51/80; Loss: 0.2942
Epoch 9809/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.085
Epoch 9810/10000; Iter 1/80; Loss: 0.2863
Epoch 9810/10000; Iter 51/80; Loss: 0.2894
Epoch 9810/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9811/10000; Iter 1/80; Loss: 0.3151
Epoch 9811/10000; Iter 51/80; Loss: 0.3112
Epoch 9811/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.08
Epoch 9812/10000; Iter 1/80; Loss: 0.2913
Epoch 9812/10000; Iter 51/80; Loss: 0.2603
Epoch 9812/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 9813/10000; Iter 1/80; Loss: 0.3162
Epoch 9813/10000; Iter 51/80; Loss: 0.2940
Epoch 9813/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.085
Epoch 9814/10000; Iter 1/80; Loss: 0.3607
Epoch 9814/10000; Iter 51/80; Loss: 0.3410
Epoch 9814/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.079
Epoch 9815/10000; Iter 1/80; Loss: 0.3258
Epoch 9815/10000; Iter 51/80; Loss: 0.3519
Epoch 9815/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9816/10000; Iter 1/80; Loss: 0.3065
Epoch 9816/10000; Iter 51/80; Loss: 0.3093
Epoch 9816/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.073
Epoch 9817/10000; Iter 1/80; Loss: 0.3076
Epoch 9817/10000; Iter 51/80; Loss: 0.3105
Epoch 9817/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.081
Epoch 9818/10000; Iter 1/80; Loss: 0.3349
Epoch 9818/10000; Iter 51/80; Loss: 0.2752
Epoch 9818/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9819/10000; Iter 1/80; Loss: 0.3360
Epoch 9819/10000; Iter 51/80; Loss: 0.3346
Epoch 9819/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.072
Epoch 9820/10000; Iter 1/80; Loss: 0.3380
Epoch 9820/10000; Iter 51/80; Loss: 0.3150
Epoch 9820/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9821/10000; Iter 1/80; Loss: 0.3324
Epoch 9821/10000; Iter 51/80; Loss: 0.3239
Epoch 9821/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.078
Epoch 9822/10000; Iter 1/80; Loss: 0.2790
Epoch 9822/10000; Iter 51/80; Loss: 0.3108
Epoch 9822/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.079
Epoch 9823/10000; Iter 1/80; Loss: 0.3311
Epoch 9823/10000; Iter 51/80; Loss: 0.2910
Epoch 9823/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.076
Epoch 9824/10000; Iter 1/80; Loss: 0.3171
Epoch 9824/10000; Iter 51/80; Loss: 0.2735
Epoch 9824/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.086
Epoch 9825/10000; Iter 1/80; Loss: 0.2670
Epoch 9825/10000; Iter 51/80; Loss: 0.2872
Epoch 9825/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9826/10000; Iter 1/80; Loss: 0.2908
Epoch 9826/10000; Iter 51/80; Loss: 0.2578
Epoch 9826/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.082
Epoch 9827/10000; Iter 1/80; Loss: 0.3891
Epoch 9827/10000; Iter 51/80; Loss: 0.2829
Epoch 9827/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.084
Epoch 9828/10000; Iter 1/80; Loss: 0.3801
Epoch 9828/10000; Iter 51/80; Loss: 0.2852
Epoch 9828/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.08
Epoch 9829/10000; Iter 1/80; Loss: 0.2843
Epoch 9829/10000; Iter 51/80; Loss: 0.2897
Epoch 9829/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.075
Epoch 9830/10000; Iter 1/80; Loss: 0.3343
Epoch 9830/10000; Iter 51/80; Loss: 0.3398
Epoch 9830/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.08
Epoch 9831/10000; Iter 1/80; Loss: 0.3469
Epoch 9831/10000; Iter 51/80; Loss: 0.3290
Epoch 9831/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.071
Epoch 9832/10000; Iter 1/80; Loss: 0.3125
Epoch 9832/10000; Iter 51/80; Loss: 0.2966
Epoch 9832/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9833/10000; Iter 1/80; Loss: 0.2765
Epoch 9833/10000; Iter 51/80; Loss: 0.3387
Epoch 9833/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.081
Epoch 9834/10000; Iter 1/80; Loss: 0.3471
Epoch 9834/10000; Iter 51/80; Loss: 0.2817
Epoch 9834/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.088
Epoch 9835/10000; Iter 1/80; Loss: 0.3037
Epoch 9835/10000; Iter 51/80; Loss: 0.3218
Epoch 9835/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.083
Epoch 9836/10000; Iter 1/80; Loss: 0.3281
Epoch 9836/10000; Iter 51/80; Loss: 0.3122
Epoch 9836/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9837/10000; Iter 1/80; Loss: 0.3716
Epoch 9837/10000; Iter 51/80; Loss: 0.2826
Epoch 9837/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.066
Epoch 9838/10000; Iter 1/80; Loss: 0.2906
Epoch 9838/10000; Iter 51/80; Loss: 0.3231
Epoch 9838/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.086
Epoch 9839/10000; Iter 1/80; Loss: 0.2869
Epoch 9839/10000; Iter 51/80; Loss: 0.3203
Epoch 9839/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.082
Epoch 9840/10000; Iter 1/80; Loss: 0.3691
Epoch 9840/10000; Iter 51/80; Loss: 0.3167
Epoch 9840/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.078
Epoch 9841/10000; Iter 1/80; Loss: 0.3083
Epoch 9841/10000; Iter 51/80; Loss: 0.3415
Epoch 9841/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.077
Epoch 9842/10000; Iter 1/80; Loss: 0.2802
Epoch 9842/10000; Iter 51/80; Loss: 0.3172
Epoch 9842/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9843/10000; Iter 1/80; Loss: 0.3200
Epoch 9843/10000; Iter 51/80; Loss: 0.3264
Epoch 9843/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.072
Epoch 9844/10000; Iter 1/80; Loss: 0.3404
Epoch 9844/10000; Iter 51/80; Loss: 0.3148
Epoch 9844/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.077
Epoch 9845/10000; Iter 1/80; Loss: 0.3394
Epoch 9845/10000; Iter 51/80; Loss: 0.2998
Epoch 9845/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.08
Epoch 9846/10000; Iter 1/80; Loss: 0.2607
Epoch 9846/10000; Iter 51/80; Loss: 0.3228
Epoch 9846/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.082
Epoch 9847/10000; Iter 1/80; Loss: 0.3494
Epoch 9847/10000; Iter 51/80; Loss: 0.3511
Epoch 9847/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.077
Epoch 9848/10000; Iter 1/80; Loss: 0.3068
Epoch 9848/10000; Iter 51/80; Loss: 0.2948
Epoch 9848/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9849/10000; Iter 1/80; Loss: 0.3532
Epoch 9849/10000; Iter 51/80; Loss: 0.3155
Epoch 9849/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.082
Epoch 9850/10000; Iter 1/80; Loss: 0.3813
Epoch 9850/10000; Iter 51/80; Loss: 0.2902
Epoch 9850/10000; Iter 80/80; Training Loss: 0.3260, Test Loss: 0.08
Epoch 9851/10000; Iter 1/80; Loss: 0.3194
Epoch 9851/10000; Iter 51/80; Loss: 0.3279
Epoch 9851/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.079
Epoch 9852/10000; Iter 1/80; Loss: 0.2940
Epoch 9852/10000; Iter 51/80; Loss: 0.2852
Epoch 9852/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9853/10000; Iter 1/80; Loss: 0.2923
Epoch 9853/10000; Iter 51/80; Loss: 0.3174
Epoch 9853/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9854/10000; Iter 1/80; Loss: 0.3092
Epoch 9854/10000; Iter 51/80; Loss: 0.3451
Epoch 9854/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9855/10000; Iter 1/80; Loss: 0.3660
Epoch 9855/10000; Iter 51/80; Loss: 0.2781
Epoch 9855/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9856/10000; Iter 1/80; Loss: 0.3610
Epoch 9856/10000; Iter 51/80; Loss: 0.3264
Epoch 9856/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.076
Epoch 9857/10000; Iter 1/80; Loss: 0.2810
Epoch 9857/10000; Iter 51/80; Loss: 0.3122
Epoch 9857/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.079
Epoch 9858/10000; Iter 1/80; Loss: 0.3446
Epoch 9858/10000; Iter 51/80; Loss: 0.3493
Epoch 9858/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.08
Epoch 9859/10000; Iter 1/80; Loss: 0.2789
Epoch 9859/10000; Iter 51/80; Loss: 0.3359
Epoch 9859/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.083
Epoch 9860/10000; Iter 1/80; Loss: 0.3300
Epoch 9860/10000; Iter 51/80; Loss: 0.2943
Epoch 9860/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.091
Epoch 9861/10000; Iter 1/80; Loss: 0.3182
Epoch 9861/10000; Iter 51/80; Loss: 0.3065
Epoch 9861/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9862/10000; Iter 1/80; Loss: 0.3385
Epoch 9862/10000; Iter 51/80; Loss: 0.3045
Epoch 9862/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.077
Epoch 9863/10000; Iter 1/80; Loss: 0.2903
Epoch 9863/10000; Iter 51/80; Loss: 0.3045
Epoch 9863/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.073
Epoch 9864/10000; Iter 1/80; Loss: 0.3453
Epoch 9864/10000; Iter 51/80; Loss: 0.3207
Epoch 9864/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9865/10000; Iter 1/80; Loss: 0.2930
Epoch 9865/10000; Iter 51/80; Loss: 0.3228
Epoch 9865/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.081
Epoch 9866/10000; Iter 1/80; Loss: 0.3102
Epoch 9866/10000; Iter 51/80; Loss: 0.3554
Epoch 9866/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.083
Epoch 9867/10000; Iter 1/80; Loss: 0.2950
Epoch 9867/10000; Iter 51/80; Loss: 0.3506
Epoch 9867/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9868/10000; Iter 1/80; Loss: 0.3008
Epoch 9868/10000; Iter 51/80; Loss: 0.3152
Epoch 9868/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.079
Epoch 9869/10000; Iter 1/80; Loss: 0.3275
Epoch 9869/10000; Iter 51/80; Loss: 0.3902
Epoch 9869/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.081
Epoch 9870/10000; Iter 1/80; Loss: 0.3180
Epoch 9870/10000; Iter 51/80; Loss: 0.3502
Epoch 9870/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9871/10000; Iter 1/80; Loss: 0.2991
Epoch 9871/10000; Iter 51/80; Loss: 0.3023
Epoch 9871/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.084
Epoch 9872/10000; Iter 1/80; Loss: 0.2877
Epoch 9872/10000; Iter 51/80; Loss: 0.3003
Epoch 9872/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9873/10000; Iter 1/80; Loss: 0.2900
Epoch 9873/10000; Iter 51/80; Loss: 0.3656
Epoch 9873/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.078
Epoch 9874/10000; Iter 1/80; Loss: 0.2877
Epoch 9874/10000; Iter 51/80; Loss: 0.3591
Epoch 9874/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9875/10000; Iter 1/80; Loss: 0.2993
Epoch 9875/10000; Iter 51/80; Loss: 0.3294
Epoch 9875/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9876/10000; Iter 1/80; Loss: 0.3164
Epoch 9876/10000; Iter 51/80; Loss: 0.3408
Epoch 9876/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.082
Epoch 9877/10000; Iter 1/80; Loss: 0.2815
Epoch 9877/10000; Iter 51/80; Loss: 0.3578
Epoch 9877/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.085
Epoch 9878/10000; Iter 1/80; Loss: 0.3135
Epoch 9878/10000; Iter 51/80; Loss: 0.3218
Epoch 9878/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.08
Epoch 9879/10000; Iter 1/80; Loss: 0.2956
Epoch 9879/10000; Iter 51/80; Loss: 0.2930
Epoch 9879/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9880/10000; Iter 1/80; Loss: 0.3279
Epoch 9880/10000; Iter 51/80; Loss: 0.2853
Epoch 9880/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.081
Epoch 9881/10000; Iter 1/80; Loss: 0.3756
Epoch 9881/10000; Iter 51/80; Loss: 0.2669
Epoch 9881/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.077
Epoch 9882/10000; Iter 1/80; Loss: 0.3695
Epoch 9882/10000; Iter 51/80; Loss: 0.3646
Epoch 9882/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.08
Epoch 9883/10000; Iter 1/80; Loss: 0.3224
Epoch 9883/10000; Iter 51/80; Loss: 0.3118
Epoch 9883/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.078
Epoch 9884/10000; Iter 1/80; Loss: 0.3755
Epoch 9884/10000; Iter 51/80; Loss: 0.2603
Epoch 9884/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.086
Epoch 9885/10000; Iter 1/80; Loss: 0.2959
Epoch 9885/10000; Iter 51/80; Loss: 0.3420
Epoch 9885/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.079
Epoch 9886/10000; Iter 1/80; Loss: 0.3530
Epoch 9886/10000; Iter 51/80; Loss: 0.3584
Epoch 9886/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.083
Epoch 9887/10000; Iter 1/80; Loss: 0.3491
Epoch 9887/10000; Iter 51/80; Loss: 0.3024
Epoch 9887/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.074
Epoch 9888/10000; Iter 1/80; Loss: 0.3289
Epoch 9888/10000; Iter 51/80; Loss: 0.3236
Epoch 9888/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.076
Epoch 9889/10000; Iter 1/80; Loss: 0.2911
Epoch 9889/10000; Iter 51/80; Loss: 0.2975
Epoch 9889/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.076
Epoch 9890/10000; Iter 1/80; Loss: 0.3551
Epoch 9890/10000; Iter 51/80; Loss: 0.2946
Epoch 9890/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.083
Epoch 9891/10000; Iter 1/80; Loss: 0.3252
Epoch 9891/10000; Iter 51/80; Loss: 0.3111
Epoch 9891/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.081
Epoch 9892/10000; Iter 1/80; Loss: 0.2835
Epoch 9892/10000; Iter 51/80; Loss: 0.3013
Epoch 9892/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.073
Epoch 9893/10000; Iter 1/80; Loss: 0.3400
Epoch 9893/10000; Iter 51/80; Loss: 0.2966
Epoch 9893/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.078
Epoch 9894/10000; Iter 1/80; Loss: 0.3025
Epoch 9894/10000; Iter 51/80; Loss: 0.3032
Epoch 9894/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.079
Epoch 9895/10000; Iter 1/80; Loss: 0.2986
Epoch 9895/10000; Iter 51/80; Loss: 0.3132
Epoch 9895/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9896/10000; Iter 1/80; Loss: 0.3336
Epoch 9896/10000; Iter 51/80; Loss: 0.4017
Epoch 9896/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.078
Epoch 9897/10000; Iter 1/80; Loss: 0.3417
Epoch 9897/10000; Iter 51/80; Loss: 0.3391
Epoch 9897/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.084
Epoch 9898/10000; Iter 1/80; Loss: 0.3593
Epoch 9898/10000; Iter 51/80; Loss: 0.2985
Epoch 9898/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.087
Epoch 9899/10000; Iter 1/80; Loss: 0.3368
Epoch 9899/10000; Iter 51/80; Loss: 0.3152
Epoch 9899/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.083
Epoch 9900/10000; Iter 1/80; Loss: 0.3040
Epoch 9900/10000; Iter 51/80; Loss: 0.2647
Epoch 9900/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.083
Epoch 9901/10000; Iter 1/80; Loss: 0.3277
Epoch 9901/10000; Iter 51/80; Loss: 0.2801
Epoch 9901/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.073
Model saved
Epoch 9902/10000; Iter 1/80; Loss: 0.2644
Epoch 9902/10000; Iter 51/80; Loss: 0.3361
Epoch 9902/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.075
Epoch 9903/10000; Iter 1/80; Loss: 0.2908
Epoch 9903/10000; Iter 51/80; Loss: 0.2937
Epoch 9903/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9904/10000; Iter 1/80; Loss: 0.2806
Epoch 9904/10000; Iter 51/80; Loss: 0.3297
Epoch 9904/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.083
Epoch 9905/10000; Iter 1/80; Loss: 0.3452
Epoch 9905/10000; Iter 51/80; Loss: 0.3297
Epoch 9905/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.082
Epoch 9906/10000; Iter 1/80; Loss: 0.2785
Epoch 9906/10000; Iter 51/80; Loss: 0.2702
Epoch 9906/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.083
Epoch 9907/10000; Iter 1/80; Loss: 0.4059
Epoch 9907/10000; Iter 51/80; Loss: 0.3055
Epoch 9907/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.09
Epoch 9908/10000; Iter 1/80; Loss: 0.2919
Epoch 9908/10000; Iter 51/80; Loss: 0.2921
Epoch 9908/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.072
Epoch 9909/10000; Iter 1/80; Loss: 0.2615
Epoch 9909/10000; Iter 51/80; Loss: 0.3042
Epoch 9909/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9910/10000; Iter 1/80; Loss: 0.3064
Epoch 9910/10000; Iter 51/80; Loss: 0.3250
Epoch 9910/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.075
Epoch 9911/10000; Iter 1/80; Loss: 0.3140
Epoch 9911/10000; Iter 51/80; Loss: 0.3437
Epoch 9911/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9912/10000; Iter 1/80; Loss: 0.2754
Epoch 9912/10000; Iter 51/80; Loss: 0.3207
Epoch 9912/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.075
Epoch 9913/10000; Iter 1/80; Loss: 0.3295
Epoch 9913/10000; Iter 51/80; Loss: 0.3382
Epoch 9913/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.074
Epoch 9914/10000; Iter 1/80; Loss: 0.2897
Epoch 9914/10000; Iter 51/80; Loss: 0.3336
Epoch 9914/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.081
Epoch 9915/10000; Iter 1/80; Loss: 0.3007
Epoch 9915/10000; Iter 51/80; Loss: 0.2974
Epoch 9915/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.076
Epoch 9916/10000; Iter 1/80; Loss: 0.3136
Epoch 9916/10000; Iter 51/80; Loss: 0.3276
Epoch 9916/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.077
Epoch 9917/10000; Iter 1/80; Loss: 0.2949
Epoch 9917/10000; Iter 51/80; Loss: 0.3418
Epoch 9917/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.079
Epoch 9918/10000; Iter 1/80; Loss: 0.3019
Epoch 9918/10000; Iter 51/80; Loss: 0.3075
Epoch 9918/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.076
Epoch 9919/10000; Iter 1/80; Loss: 0.3761
Epoch 9919/10000; Iter 51/80; Loss: 0.3105
Epoch 9919/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.088
Epoch 9920/10000; Iter 1/80; Loss: 0.3306
Epoch 9920/10000; Iter 51/80; Loss: 0.3333
Epoch 9920/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9921/10000; Iter 1/80; Loss: 0.3449
Epoch 9921/10000; Iter 51/80; Loss: 0.2820
Epoch 9921/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.085
Epoch 9922/10000; Iter 1/80; Loss: 0.3147
Epoch 9922/10000; Iter 51/80; Loss: 0.3190
Epoch 9922/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.073
Epoch 9923/10000; Iter 1/80; Loss: 0.3247
Epoch 9923/10000; Iter 51/80; Loss: 0.3270
Epoch 9923/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9924/10000; Iter 1/80; Loss: 0.2743
Epoch 9924/10000; Iter 51/80; Loss: 0.3468
Epoch 9924/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.087
Epoch 9925/10000; Iter 1/80; Loss: 0.3454
Epoch 9925/10000; Iter 51/80; Loss: 0.3133
Epoch 9925/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.08
Epoch 9926/10000; Iter 1/80; Loss: 0.3031
Epoch 9926/10000; Iter 51/80; Loss: 0.2965
Epoch 9926/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.087
Epoch 9927/10000; Iter 1/80; Loss: 0.3026
Epoch 9927/10000; Iter 51/80; Loss: 0.2680
Epoch 9927/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.077
Epoch 9928/10000; Iter 1/80; Loss: 0.2873
Epoch 9928/10000; Iter 51/80; Loss: 0.2963
Epoch 9928/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.083
Epoch 9929/10000; Iter 1/80; Loss: 0.3158
Epoch 9929/10000; Iter 51/80; Loss: 0.3309
Epoch 9929/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.083
Epoch 9930/10000; Iter 1/80; Loss: 0.3542
Epoch 9930/10000; Iter 51/80; Loss: 0.3524
Epoch 9930/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.078
Epoch 9931/10000; Iter 1/80; Loss: 0.3109
Epoch 9931/10000; Iter 51/80; Loss: 0.3907
Epoch 9931/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.083
Epoch 9932/10000; Iter 1/80; Loss: 0.2921
Epoch 9932/10000; Iter 51/80; Loss: 0.3776
Epoch 9932/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9933/10000; Iter 1/80; Loss: 0.3343
Epoch 9933/10000; Iter 51/80; Loss: 0.2952
Epoch 9933/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.079
Epoch 9934/10000; Iter 1/80; Loss: 0.3106
Epoch 9934/10000; Iter 51/80; Loss: 0.3171
Epoch 9934/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.083
Epoch 9935/10000; Iter 1/80; Loss: 0.3105
Epoch 9935/10000; Iter 51/80; Loss: 0.3127
Epoch 9935/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.077
Epoch 9936/10000; Iter 1/80; Loss: 0.2625
Epoch 9936/10000; Iter 51/80; Loss: 0.3329
Epoch 9936/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.093
Epoch 9937/10000; Iter 1/80; Loss: 0.3365
Epoch 9937/10000; Iter 51/80; Loss: 0.3492
Epoch 9937/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.08
Epoch 9938/10000; Iter 1/80; Loss: 0.3241
Epoch 9938/10000; Iter 51/80; Loss: 0.2854
Epoch 9938/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.08
Epoch 9939/10000; Iter 1/80; Loss: 0.3194
Epoch 9939/10000; Iter 51/80; Loss: 0.3246
Epoch 9939/10000; Iter 80/80; Training Loss: 0.3240, Test Loss: 0.082
Epoch 9940/10000; Iter 1/80; Loss: 0.3093
Epoch 9940/10000; Iter 51/80; Loss: 0.3159
Epoch 9940/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9941/10000; Iter 1/80; Loss: 0.3231
Epoch 9941/10000; Iter 51/80; Loss: 0.3562
Epoch 9941/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9942/10000; Iter 1/80; Loss: 0.2933
Epoch 9942/10000; Iter 51/80; Loss: 0.3171
Epoch 9942/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.08
Epoch 9943/10000; Iter 1/80; Loss: 0.3414
Epoch 9943/10000; Iter 51/80; Loss: 0.3411
Epoch 9943/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9944/10000; Iter 1/80; Loss: 0.2825
Epoch 9944/10000; Iter 51/80; Loss: 0.3106
Epoch 9944/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.08
Epoch 9945/10000; Iter 1/80; Loss: 0.3142
Epoch 9945/10000; Iter 51/80; Loss: 0.3452
Epoch 9945/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.08
Epoch 9946/10000; Iter 1/80; Loss: 0.3084
Epoch 9946/10000; Iter 51/80; Loss: 0.2987
Epoch 9946/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.089
Epoch 9947/10000; Iter 1/80; Loss: 0.3570
Epoch 9947/10000; Iter 51/80; Loss: 0.3165
Epoch 9947/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.074
Epoch 9948/10000; Iter 1/80; Loss: 0.3369
Epoch 9948/10000; Iter 51/80; Loss: 0.3357
Epoch 9948/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.078
Epoch 9949/10000; Iter 1/80; Loss: 0.3617
Epoch 9949/10000; Iter 51/80; Loss: 0.2874
Epoch 9949/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.076
Epoch 9950/10000; Iter 1/80; Loss: 0.3140
Epoch 9950/10000; Iter 51/80; Loss: 0.3347
Epoch 9950/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.075
Epoch 9951/10000; Iter 1/80; Loss: 0.3328
Epoch 9951/10000; Iter 51/80; Loss: 0.2989
Epoch 9951/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.082
Epoch 9952/10000; Iter 1/80; Loss: 0.2804
Epoch 9952/10000; Iter 51/80; Loss: 0.3017
Epoch 9952/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.073
Epoch 9953/10000; Iter 1/80; Loss: 0.3248
Epoch 9953/10000; Iter 51/80; Loss: 0.3136
Epoch 9953/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.072
Epoch 9954/10000; Iter 1/80; Loss: 0.3944
Epoch 9954/10000; Iter 51/80; Loss: 0.3328
Epoch 9954/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.089
Epoch 9955/10000; Iter 1/80; Loss: 0.3714
Epoch 9955/10000; Iter 51/80; Loss: 0.3758
Epoch 9955/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.073
Epoch 9956/10000; Iter 1/80; Loss: 0.2777
Epoch 9956/10000; Iter 51/80; Loss: 0.3195
Epoch 9956/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.075
Epoch 9957/10000; Iter 1/80; Loss: 0.3388
Epoch 9957/10000; Iter 51/80; Loss: 0.3598
Epoch 9957/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.084
Epoch 9958/10000; Iter 1/80; Loss: 0.2993
Epoch 9958/10000; Iter 51/80; Loss: 0.2545
Epoch 9958/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.077
Epoch 9959/10000; Iter 1/80; Loss: 0.3380
Epoch 9959/10000; Iter 51/80; Loss: 0.3084
Epoch 9959/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.088
Epoch 9960/10000; Iter 1/80; Loss: 0.2588
Epoch 9960/10000; Iter 51/80; Loss: 0.3292
Epoch 9960/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.078
Epoch 9961/10000; Iter 1/80; Loss: 0.2874
Epoch 9961/10000; Iter 51/80; Loss: 0.3246
Epoch 9961/10000; Iter 80/80; Training Loss: 0.3250, Test Loss: 0.081
Epoch 9962/10000; Iter 1/80; Loss: 0.3251
Epoch 9962/10000; Iter 51/80; Loss: 0.3451
Epoch 9962/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.08
Epoch 9963/10000; Iter 1/80; Loss: 0.3219
Epoch 9963/10000; Iter 51/80; Loss: 0.2983
Epoch 9963/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.082
Epoch 9964/10000; Iter 1/80; Loss: 0.2512
Epoch 9964/10000; Iter 51/80; Loss: 0.3358
Epoch 9964/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.071
Epoch 9965/10000; Iter 1/80; Loss: 0.3353
Epoch 9965/10000; Iter 51/80; Loss: 0.3572
Epoch 9965/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.074
Epoch 9966/10000; Iter 1/80; Loss: 0.3004
Epoch 9966/10000; Iter 51/80; Loss: 0.3183
Epoch 9966/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.078
Epoch 9967/10000; Iter 1/80; Loss: 0.3783
Epoch 9967/10000; Iter 51/80; Loss: 0.3231
Epoch 9967/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.08
Epoch 9968/10000; Iter 1/80; Loss: 0.3156
Epoch 9968/10000; Iter 51/80; Loss: 0.2870
Epoch 9968/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.077
Epoch 9969/10000; Iter 1/80; Loss: 0.2952
Epoch 9969/10000; Iter 51/80; Loss: 0.3125
Epoch 9969/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.08
Epoch 9970/10000; Iter 1/80; Loss: 0.3698
Epoch 9970/10000; Iter 51/80; Loss: 0.3452
Epoch 9970/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.078
Epoch 9971/10000; Iter 1/80; Loss: 0.2943
Epoch 9971/10000; Iter 51/80; Loss: 0.2824
Epoch 9971/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.083
Epoch 9972/10000; Iter 1/80; Loss: 0.3541
Epoch 9972/10000; Iter 51/80; Loss: 0.3477
Epoch 9972/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.081
Epoch 9973/10000; Iter 1/80; Loss: 0.3290
Epoch 9973/10000; Iter 51/80; Loss: 0.3302
Epoch 9973/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.081
Epoch 9974/10000; Iter 1/80; Loss: 0.3101
Epoch 9974/10000; Iter 51/80; Loss: 0.3140
Epoch 9974/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.079
Epoch 9975/10000; Iter 1/80; Loss: 0.3075
Epoch 9975/10000; Iter 51/80; Loss: 0.2978
Epoch 9975/10000; Iter 80/80; Training Loss: 0.3110, Test Loss: 0.074
Epoch 9976/10000; Iter 1/80; Loss: 0.3327
Epoch 9976/10000; Iter 51/80; Loss: 0.3300
Epoch 9976/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.077
Epoch 9977/10000; Iter 1/80; Loss: 0.3736
Epoch 9977/10000; Iter 51/80; Loss: 0.3361
Epoch 9977/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.079
Epoch 9978/10000; Iter 1/80; Loss: 0.2992
Epoch 9978/10000; Iter 51/80; Loss: 0.2843
Epoch 9978/10000; Iter 80/80; Training Loss: 0.3140, Test Loss: 0.078
Epoch 9979/10000; Iter 1/80; Loss: 0.2744
Epoch 9979/10000; Iter 51/80; Loss: 0.2961
Epoch 9979/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.086
Epoch 9980/10000; Iter 1/80; Loss: 0.2613
Epoch 9980/10000; Iter 51/80; Loss: 0.3202
Epoch 9980/10000; Iter 80/80; Training Loss: 0.3220, Test Loss: 0.074
Epoch 9981/10000; Iter 1/80; Loss: 0.3129
Epoch 9981/10000; Iter 51/80; Loss: 0.2965
Epoch 9981/10000; Iter 80/80; Training Loss: 0.3230, Test Loss: 0.078
Epoch 9982/10000; Iter 1/80; Loss: 0.3505
Epoch 9982/10000; Iter 51/80; Loss: 0.2844
Epoch 9982/10000; Iter 80/80; Training Loss: 0.3090, Test Loss: 0.085
Epoch 9983/10000; Iter 1/80; Loss: 0.2989
Epoch 9983/10000; Iter 51/80; Loss: 0.2894
Epoch 9983/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.077
Epoch 9984/10000; Iter 1/80; Loss: 0.3106
Epoch 9984/10000; Iter 51/80; Loss: 0.2876
Epoch 9984/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.076
Epoch 9985/10000; Iter 1/80; Loss: 0.2997
Epoch 9985/10000; Iter 51/80; Loss: 0.3083
Epoch 9985/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.079
Epoch 9986/10000; Iter 1/80; Loss: 0.3495
Epoch 9986/10000; Iter 51/80; Loss: 0.3686
Epoch 9986/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.088
Epoch 9987/10000; Iter 1/80; Loss: 0.2756
Epoch 9987/10000; Iter 51/80; Loss: 0.3303
Epoch 9987/10000; Iter 80/80; Training Loss: 0.3160, Test Loss: 0.076
Epoch 9988/10000; Iter 1/80; Loss: 0.2789
Epoch 9988/10000; Iter 51/80; Loss: 0.3052
Epoch 9988/10000; Iter 80/80; Training Loss: 0.3200, Test Loss: 0.082
Epoch 9989/10000; Iter 1/80; Loss: 0.3383
Epoch 9989/10000; Iter 51/80; Loss: 0.3317
Epoch 9989/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.086
Epoch 9990/10000; Iter 1/80; Loss: 0.2984
Epoch 9990/10000; Iter 51/80; Loss: 0.3399
Epoch 9990/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.082
Epoch 9991/10000; Iter 1/80; Loss: 0.3102
Epoch 9991/10000; Iter 51/80; Loss: 0.2913
Epoch 9991/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.076
Epoch 9992/10000; Iter 1/80; Loss: 0.3438
Epoch 9992/10000; Iter 51/80; Loss: 0.3244
Epoch 9992/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.07
Epoch 9993/10000; Iter 1/80; Loss: 0.2570
Epoch 9993/10000; Iter 51/80; Loss: 0.2681
Epoch 9993/10000; Iter 80/80; Training Loss: 0.3180, Test Loss: 0.081
Epoch 9994/10000; Iter 1/80; Loss: 0.3182
Epoch 9994/10000; Iter 51/80; Loss: 0.3266
Epoch 9994/10000; Iter 80/80; Training Loss: 0.3170, Test Loss: 0.084
Epoch 9995/10000; Iter 1/80; Loss: 0.3636
Epoch 9995/10000; Iter 51/80; Loss: 0.3168
Epoch 9995/10000; Iter 80/80; Training Loss: 0.3150, Test Loss: 0.082
Epoch 9996/10000; Iter 1/80; Loss: 0.3179
Epoch 9996/10000; Iter 51/80; Loss: 0.3318
Epoch 9996/10000; Iter 80/80; Training Loss: 0.3130, Test Loss: 0.077
Epoch 9997/10000; Iter 1/80; Loss: 0.3047
Epoch 9997/10000; Iter 51/80; Loss: 0.2644
Epoch 9997/10000; Iter 80/80; Training Loss: 0.3120, Test Loss: 0.091
Epoch 9998/10000; Iter 1/80; Loss: 0.3484
Epoch 9998/10000; Iter 51/80; Loss: 0.2922
Epoch 9998/10000; Iter 80/80; Training Loss: 0.3210, Test Loss: 0.079
Epoch 9999/10000; Iter 1/80; Loss: 0.2714
Epoch 9999/10000; Iter 51/80; Loss: 0.3075
Epoch 9999/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.076
Epoch 10000/10000; Iter 1/80; Loss: 0.3271
Epoch 10000/10000; Iter 51/80; Loss: 0.2914
Epoch 10000/10000; Iter 80/80; Training Loss: 0.3190, Test Loss: 0.086
Training End !
Time taken for training = 4694.643874645233
Model loaded
Testing the model
